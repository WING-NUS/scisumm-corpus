%
% File acl2012.tex
%
% Contact: Maggie Li (cswjli@comp.polyu.edu.hk), Michael White (mwhite@ling.osu.edu)
%%
%% Based on the style files for ACL2008 by Joakim Nivre and Noah Smith
%% and that of ACL2010 by Jing-Shin Chang and Philipp Koehn


\documentclass[11pt]{article}
%\usepackage{}
\usepackage{times}
\usepackage{latexsym}
\usepackage{balance}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{array}
\usepackage{lingmacros}
\usepackage{graphicx}
\usepackage{url}
\usepackage{float}
\usepackage{verbatim}
\usepackage[lofdepth,lotdepth]{subfig}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{array}

\usepackage{makecell}

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

%\usepackage{natbib}
\DeclareMathOperator*{\argmax}{arg\,max}
%\setlength\titlebox{5cm}    % Expanding the titlebox

\captionsetup{font=scriptsize}

\newcommand{\ignore}[1]{}

\newcommand{\B}{\mathcal{B}} 

\title{Literature Review of Contradiction Detection}

\author{Rahul Jha \\
%   EECS Department \\
%   University of Michigan \\
%   Ann Arbor, MI, USA \\
  {\tt rahuljha@umich.edu} 
}

\date{}

\begin{document}

% TODO: Rewrite some of these so it doesn't sound so plagiarized
\paragraph{Lexical Features} We use two lexical features. The first feature is based on TF*IDF cosine similarity. The IDF's were computed over all sentences for each source paper, thus the IDF values differed across each of the 10 source papers. For any citing sentence, we computed the TF*IDF cosine similarity with all the sentences in the source paper and use them as a feature. The second lexical feature is based on the LCS (Longest Common Subsequence) between the citing sentence ($C$) and source sentence $S$ and is computed as:

\begin{eqnarray*}
  \frac{|LCS|}{min(|C|,|S|)}
\end{eqnarray*}
\paragraph{Knowledge Based Features} We also compute a set of features based on Wordnet similarity. We use six wordnet based word similarity measures and combine these word similarities to obtain six knowledge based sentence similarity features using the method proposed in \cite{Banea2012}. The wordnet based word similarity measures we use are path similarity, WUP similarity \cite{Wu:1994:VSL:981732.981751} , LCH similarity \cite{leacock1998combining}, Resnik similarity \cite{Resnik:1995:UIC:1625855.1625914},  Jiang-Conrath similarity \cite{Jiang97taxonomySimilarity}, and Lin similarity \cite{Lin:1998:IDS:645527.657297}. 

Given each of these similarity measures, the similarities between two sentences is computed by first creating a set of senses for each of the words in each of the sentences. Given these two sets of senses, the similarity score between citing sentence $C$ and source sentence $S$ is calculated as follows:

\begin{eqnarray*}
  sim_{wn}(C,S) = \frac{(\omega + \sum_{i=1}^{|\phi|}\phi_i) * (2|C||S|)}{|C|+|S|}
\end{eqnarray*}

Here $\omega$ is the number of shared senses between $C$ and $S$. The list $\phi$ contains the similarities of non-shared words in the shorter text, $\phi_i$ is the highest similarity score of the $i$th word among all the words of the lower text \cite{S13-1017}. 
\paragraph{Syntactic Features} We compute an additional feature based on similarity of dependency structures using the method described in \cite{S13-1017} . We use the Stanford parser to obtain dependency parse all the citing sentences and source sentences. Given a candidate sentence pair, two syntactic dependencies are considered equal if they have the same dependency type, govering lemma, and dependent lemma. If $R_c$ and $R_s$ are the set of all dependency relations in $C$ and $S$, the dependency overlap score is computed using the formula:

\begin{eqnarray*}
  sim_{dep}(C,S) = \frac{2*|R_c \cap R_s| * |R_c||R_s|}{|R_c|+|R_s|}
\end{eqnarray*}


\bibliographystyle{plain}
\bibliography{ref}

\end{document}
