**********************************************************************************
**** Biomedical Summarization Track - Text Analytics Conference 2014 *************
**** SciSum Computational Linguistics Summarization - Shared Task ****************
**** TALN, Universtiat Pompeu Fabra, Barcelona ***********************************

	SYSTEM DESCRIPTION

This document describes the system built in the context of the SciSum Computational Linguistics Summarization - Shared Task to carry out the tasks 1a and 1b (TAC 2014). In all tasks we based our approaches on sentence-level computations, thus considering sentences as the main text analysis unit.

We first briefly introduce the document pre processing steps we perform in order to support the tasks’ computations (Section 1). Then we describe our approach to each task (Sections 2, 3).


---------------
1) Pre-processing / documents’ preparation:
In order to support the computations related to Tasks 1(a/b), we carried out a set of preprocessing steps on the papers of each topic. We parsed each paper (both citing and reference papers) by the following sets of text analysis tools:
	A) Custom sentence splitter, to identify candidate sentences that will be validated or rejected by the following pre-processing steps;
	B) Tokenizer and POS tagger (GATE);
	C) Sentence sanitizer, to remove incorrectly annotated sentences, relying on a set of rules and heuristics;
	D) Document structural analyzer. to classify each sentence as belonging to one of the following document structural categories: ABSTRACT, INTRO, RESULT_DISCUSSION, EXPERIMENTAL_PROCEDURE, SUPPLEMENTAL_DATA, MATHERIAL_METHOD, CONCLUSION, ACKNOWLEDGMENT_FOUNDING, REFERENCE;
	E) Sentence TFIDF vector computation; we associate to each sentence a TFIDF vector where the IDF values are computed over all the papers of the related topic (up to 10 citing paper and one reference paper).


---------------
2) Task 1a: reference paper text spans identification for each citance
For each citance we consider its global citatance context span as the union of the citance context spans marked by human annotators.
Then we select the sentences of the citing paper that overlap totally or partially the global citatance context span; these sentences are referred to as the citance context sentences (CtxSent1,..., CtxSentN),
We characterize the citance by the document structural category associated with most of its citance context sentences (CtxSent1,..., CtxSentN). In case of tie in the number of occurrences of document structural categories among all the citance context sentences, we choose the document structural category that is most frequent in the citing paper. In case of persisting tie, we select the document structural category that is most frequent in the whole set of citing and reference papers.
We associate to each reference paper sentence (RefSent) a score equal to the sum of its TFIDF vector cosine similarity with each citance context sentence (CtxSent1,..., CtxSentN).
Then, considering the document structural category previously associated to the citation together with the document structural category of the RefSent, we weight the score of RefSent by the relative relevance in the whole training corpus of this kind of link between document structural categories. For instance, if there is a citance associated to the INTRO that references a RefSent belonging to the ABSTRACT and we know that in the whole training corpus this situation occurs in 6,5% of citance-referenced sentence pairs, we multiply the RefSent score for 0.065, obtaining the final RefSent score.

We choose the 3 reference paper sentences (RefSents) with the highest final RefSent score as the reference paper text spans.


---------------
3) Task 1b: for each citance, identify the facet of the cited text spans as one of: Aim, Method, Result, Implication

We train a linear-kernel SVM classifier to associate each citance with one of the five text facets considered in Task 1b. We characterize each citance by lexical and semantic features extracted from the sentences belonging to the citance context together with the sentences of the reference paper selected as outcome of Task 1a.
Some of the features we exploit are:
	- relative number of sentences belonging to each document structural category;
	- relative number of sentences belonging to the citance context or reference paper;
	- relative number of POS;
	- presence of key lexical patterns.

