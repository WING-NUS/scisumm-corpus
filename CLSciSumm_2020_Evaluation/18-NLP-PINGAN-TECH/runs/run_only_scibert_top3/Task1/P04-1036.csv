Citance Number,Citation Marker,Citation Marker Offset,Citation Offset,Citation Text,Citation Text Clean,Citing Article,Discourse Facet,Reference Article,Reference Offset,Reference Text
1.0,"McCarthy et al, 2004",0,0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)",W04-0837,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'8','107','2'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""107"" ssid=""5"">To disambiguate senses a system should take context into account.</S><S sid=""2"" ssid=""2"">The problem with using the predominant, or first sense heuristic, aside from the fact that it does not take surrounding context into account, is that it assumes some quantity of handtagged data.</S>"
2.0,"McCarthy et al, 2004",0,0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available",W04-0837,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'15','154','41'","<S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid=""154"" ssid=""2"">In contrast, our work is aimed at discovering the predominant senses from raw text because the first sense heuristic is such a useful one, and because handtagged data is not always available.</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S>"
3.0,"McCarthy et al, 2004",0,0,"The method is described in (McCarthy et al, 2004), which we summarise here","The method is described in (McCarthy et al, 2004), which we summarise here",W04-0837,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P04-1036,"'41','178','4'","<S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""178"" ssid=""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S><S sid=""4"" ssid=""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S>"
5.0,"McCarthy et al, 2004",0,0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges",McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD,I08-2105,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P04-1036,"'4','179','41'","<S sid=""4"" ssid=""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S><S sid=""179"" ssid=""2"">We use an automatically acquired thesaurus and a WordNet Similarity measure.</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S>"
6.0,"McCarthy et al, 2004",0,0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction",I08-2105,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P04-1036,"'41','4','15'","<S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""4"" ssid=""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S><S sid=""15"" ssid=""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a strong case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S>"
7.0,2004,0,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus",I08-2105,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P04-1036,"'4','41','169'","<S sid=""4"" ssid=""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""169"" ssid=""17"">This method obtains precision of 61% and recall 51%.</S>"
8.0,"McCarthy et al, 2004",0,0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn",P06-1012,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P04-1036,"'41','4','126'","<S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""4"" ssid=""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S><S sid=""126"" ssid=""3"">We demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.</S>"
9.0,"McCarthy et al, 2004",0,0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense",P06-1012,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P04-1036,"'41','48','45'","<S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""48"" ssid=""4"">To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid=""45"" ssid=""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S>"
11.0,2004,0,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)",P10-1155,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'80','61','4'","<S sid=""80"" ssid=""9"">All the results shown here are those with the size of thesaurus entries ( ) set to 50.</S><S sid=""61"" ssid=""17"">We use the WordNet Similarity Package 0.05 and WordNet version 1.6.</S><S sid=""4"" ssid=""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S>"
12.0,2004,0,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)",W12-3401,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'45','41','27'","<S sid=""45"" ssid=""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""27"" ssid=""20"">We use WordNet as our sense inventory for this work.</S>"
13.0,2004,0,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)",W12-3401,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'48','45','171'","<S sid=""48"" ssid=""4"">To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid=""45"" ssid=""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S><S sid=""171"" ssid=""19"">In contrast, we use the neighbours lists and WordNet similarity measures to impose a prevalence ranking on the WordNet senses.</S>"
14.0,2004,0,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)",W12-3401,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'133','41','168'","<S sid=""133"" ssid=""10"">We acquired thesauruses for these corpora using the procedure described in section 2.1.</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""168"" ssid=""16"">They evaluate using the lin measure described above in section 2.2 to determine the precision and recall of these discovered classes with respect to WordNet synsets.</S>"
16.0,"McCarthy et al, 2004",0,0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)",S12-1097,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'8','41','4'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""4"" ssid=""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S>"
17.0,"McCarthy et al, 2004",0,0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)",W10-2803,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P04-1036,"'41','45','178'","<S sid=""41"" ssid=""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid=""45"" ssid=""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S><S sid=""178"" ssid=""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S>"
18.0,2004,0,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))",W08-2107,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'27','48','8'","<S sid=""27"" ssid=""20"">We use WordNet as our sense inventory for this work.</S><S sid=""48"" ssid=""4"">To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S>"
19.0,"McCarthy et al, 2004",0,0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)",D07-1026,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'8','6','143'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""6"" ssid=""6"">This is a very promising result given that our method does not require any hand-tagged text, such as SemCor.</S><S sid=""143"" ssid=""20"">The results are promising.</S>"
20.0,"McCarthy et al, 2004",0,0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems",W12-2429,"Method_Citation,Hypothesis_Citation,Implication_Citation",P04-1036,"'8','115','27'","<S sid=""8"" ssid=""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid=""115"" ssid=""13"">Our automatically acquired predominant sense performs nearly as well as the first sense provided by SemCor, which is very encouraging given that our method only uses raw text, with no manual labelling.</S><S sid=""27"" ssid=""20"">We use WordNet as our sense inventory for this work.</S>"
