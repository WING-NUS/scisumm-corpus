In this paper the author aims at proposing an integration of the two models which outperforms each of them separately. Together with a PCFG reduction of DOP we obtain improved accuracy and efficiency on the Wall Street Journal Treebank.  It also presents the first published results with Goodman's PCFG-reductions of both Bonnema et al.'s (1999) and Bod's (2001) estimators on the WSJ. They show that these PCFG-reductions result in a 60 times speedup in processing time w.r.t. Bod (2001, 2003). But while Bod's estimator obtains state-of-the-art results on the WSJ, comparable to Charniak (2000) and Collins (2000), Bonnema et al.'s estimator performs worse and is comparable to Collins (1996). In the second part, the author extends his experiments with a new notion of the best parse tree. The DOP approach is based on two distinctive features as the first being the use of corpus fragments rather than grammar rules, and the other as the use of arbitrarily large fragments rather than restricted ones. Our results show an 11% relative reduction in error rate over previous models, and an average processing time of 3.6 seconds per WSJ sentence.