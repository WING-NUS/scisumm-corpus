Citance Number,Citation Marker,Citation Marker Offset,Citation Offset,Citation Text,Citation Text Clean,Citing Article,Discourse Facet,Reference Article,Reference Offset,Reference Text
2.0,"McDonald et al, 2006",,0.0,"Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)","Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)",W06-2920,"Method_Citation,Hypothesis_Citation,Implication_Citation",W06-2932,"'3','13','1'","<S sid=""3"" ssid=""3"">The second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.</S><S sid=""13"" ssid=""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al., 2006; Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit Torruella and MartiAntonin, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).</S><S sid=""1"" ssid=""1"">present a two-stage multilingual pendency parser and evaluate it on 13 diverse languages.</S>"
3.0,2006,0.0,0.0,Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),W06-2920,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",W06-2932,"'1','13','0'","<S sid=""1"" ssid=""1"">present a two-stage multilingual pendency parser and evaluate it on 13 diverse languages.</S><S sid=""13"" ssid=""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al., 2006; Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit Torruella and MartiAntonin, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).</S><S sid=""0"" ssid=""0"">Multilingual Dependency Analysis with a Two-Stage Discriminative Parser</S>"
4.0,2006,0.0,0.0,"Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences","Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences",W06-2920,"Method_Citation,Hypothesis_Citation,Implication_Citation",W06-2932,"'13','93','103'","<S sid=""13"" ssid=""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al., 2006; Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit Torruella and MartiAntonin, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).</S><S sid=""93"" ssid=""15"">A quick look at unlabeled attachment accuracies indicate that errors in Arabic parsing are the most common across all languages: prepositions (62%), conjunctions (69%) and to a lesser extent verbs (73%).</S><S sid=""103"" ssid=""25"">However, when compared to the performance of Slovene (1500 training instances) and Spanish (3300 instances), it appears that Arabic parsing is lagging.</S>"
5.0,2006,0.0,0.0,"The high est score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)","The highest score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (and a different policy regarding the inclusion of punctuation). The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)",W08-1007,"Method_Citation,Hypothesis_Citation,Results_Citation,Implication_Citation",W06-2932,"'66','13','4'","<S sid=""66"" ssid=""4"">These results report the average labeled and unlabeled precision for the 10 languages with the smallest training sets.</S><S sid=""13"" ssid=""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al., 2006; Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit Torruella and MartiAntonin, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).</S><S sid=""4"" ssid=""4"">We report results on the CoNLL-X shared task (Buchholz et al., 2006) data sets and present an error analysis.</S>"
6.0,2006,0.0,,McDonald et al (2006) use an additional algorithm,McDonald et al (2006) use an additional algorithm,W09-1210,"Method_Citation,Hypothesis_Citation,Implication_Citation",W06-2932,"'2','21','44'","<S sid=""2"" ssid=""2"">The first stage based on the unlabeled dependency parsing models described by McDonald and Pereira (2006) augmented with morphological features for a subset of the languages.</S><S sid=""21"" ssid=""3"">That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.</S><S sid=""44"" ssid=""13"">We use the MIRA online learner to set the weights (Crammer and Singer, 2003; McDonald et al., 2005a) since we found it trained quickly and provide good performance.</S>"
7.0,"McDonald et al, 2006",0.0,0.0,"Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)","Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)",W12-3407,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",W06-2932,"'1','104','12'","<S sid=""1"" ssid=""1"">present a two-stage multilingual pendency parser and evaluate it on 13 diverse languages.</S><S sid=""104"" ssid=""1"">We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al., 2005b; McDonald and Pereira, 2006) generalizes well to languages other than English.</S><S sid=""12"" ssid=""8"">In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.</S>"
8.0,"McDonald et al, 2006",0.0,0.0,"In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)? s parser, (McDonald et al., 2006)? s parser, and so on","In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)'s parser, (McDonald et al., 2006)'s parser, and so on",I08-1012,"Method_Citation,Aim_Citation,Results_Citation,Implication_Citation",W06-2932,"'12','1','104'","<S sid=""12"" ssid=""8"">In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.</S><S sid=""1"" ssid=""1"">present a two-stage multilingual pendency parser and evaluate it on 13 diverse languages.</S><S sid=""104"" ssid=""1"">We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al., 2005b; McDonald and Pereira, 2006) generalizes well to languages other than English.</S>"
11.0,"McDonald et al, 2006",0.0,0.0,"We have shown that, for languages with a7McDonald et al (2006) use post-processing for non projective dependencies and for labeling",McDonald et al (2006) use post-processing for non-projective dependencies and for labeling,N07-1050,"Method_Citation,Aim_Citation,Results_Citation,Implication_Citation",W06-2932,"'12','18','107'","<S sid=""12"" ssid=""8"">In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.</S><S sid=""18"" ssid=""14"">We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X), pages 216–220, New York City, June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective, both of which are true in the data sets we use.</S><S sid=""107"" ssid=""4"">It is our hypothesis that for languages with fine-grained label sets, joint parsing and labeling will improve performance.</S>"
12.0,"McDonald et al, 2006",0.0,0.0,"As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem","As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem",D07-1122,"Method_Citation,Hypothesis_Citation,Implication_Citation",W06-2932,"'41','76','12'","<S sid=""41"" ssid=""10"">To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.</S><S sid=""76"" ssid=""14"">For instance, sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S><S sid=""12"" ssid=""8"">In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.</S>"
14.0,2006,0.0,0.0,5It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,D07-1015,"Method_Citation,Hypothesis_Citation,Implication_Citation",W06-2932,"'21','64','2'","<S sid=""21"" ssid=""3"">That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.</S><S sid=""64"" ssid=""2"">N/P: Allow non-projective/Force projective, S/A: Sequential labeling/Atomic labeling, M/B: Include morphology features/No morphology features. assignment of edge labels instead of individual assignment, and a rich feature set that incorporates morphological properties when available.</S><S sid=""2"" ssid=""2"">The first stage based on the unlabeled dependency parsing models described by McDonald and Pereira (2006) augmented with morphological features for a subset of the languages.</S>"
18.0,2006,0.0,0.0,"Entries marked with? are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)","Entries marked with are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)",D10-1004,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",W06-2932,"'1','13','56'","<S sid=""1"" ssid=""1"">present a two-stage multilingual pendency parser and evaluate it on 13 diverse languages.</S><S sid=""13"" ssid=""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al., 2006; Hajiˇc et al., 2004; Simov et al., 2005; Simov and Osenova, 2003; Chen et al., 2003; B¨ohmov´a et al., 2003; Kromann, 2003; van der Beek et al., 2002; Brants et al., 2002; Kawata and Bartels, 2000; Afonso et al., 2002; Dˇzeroski et al., 2006; Civit Torruella and MartiAntonin, 2002; Nilsson et al., 2005; Oflazer et al., 2003; Atalay et al., 2003).</S><S sid=""56"" ssid=""4"">Results on the test set are given in Table 1.</S>"
19.0,"McDonald et al, 2006",0.0,0.0,"The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.2 2.3 Transition-Based Models","The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.",P08-1108,"Method_Citation,Hypothesis_Citation,Implication_Citation",W06-2932,"'20','21','12'","<S sid=""20"" ssid=""2"">This system is primarily based on the parsing models described by McDonald and Pereira (2006).</S><S sid=""21"" ssid=""3"">That work extends the maximum spanning tree dependency parsing framework (McDonald et al., 2005a; McDonald et al., 2005b) to incorporate features over multiple edges in the dependency graph.</S><S sid=""12"" ssid=""8"">In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.</S>"
20.0,"McDonald et al, 2006",0.0,0.0,"More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? Rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)","More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l) Rk, where f is typically a binary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)",P08-1108,"Method_Citation,Hypothesis_Citation,Implication_Citation",W06-2932,"'25','36','3'","<S sid=""25"" ssid=""7"">For instance, the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.</S><S sid=""36"" ssid=""5"">However, in a two stage system we can incorporate features over the entire output of the unlabeled parser since that structure is fixed as input.</S><S sid=""3"" ssid=""3"">The second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.</S>"
