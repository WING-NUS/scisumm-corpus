In this paper, Mitchell and Lapata proposed a framework for vector-based semantic composition. Central to their approach was vector composition which they operationalize in terms of additive and multiplicative functions. Under this framework, they introduced a wide range of composition models which they evaluated empirically on a sentence similarity task. Experimental results demonstrated that the multiplicative models were superior- at least, for the sentence similarity task attempted- to the additive alternatives when compared against human judgments. They conjectured that the additive models are not sensitive to the fine-grained meaning distinctions involved in their materials. Multiplicative models considered a subset, namely non-zero components whereas additive models captured composition by considering all vector components representing the meaning of the verb and its subject. The resulting vector is sparser but expresses more succinctly the meaning of the predicate-argument structure, and thus allows semantic similarity to be modelled more accurately. Further research would be needed to gain a deeper understanding of vector composition, both in terms of modeling a wider range of structures.