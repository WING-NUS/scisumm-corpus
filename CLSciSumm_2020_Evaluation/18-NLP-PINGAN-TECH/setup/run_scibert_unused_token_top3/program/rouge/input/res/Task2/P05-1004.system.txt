Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns. Such a corpus is needed to acquire reliable contextual information for the often very rare nouns we are attempting to supersense tag. They use the common nouns that have been added to WORDNET 1.7.1 since WORDNET 1.6 and compare this evaluation with a standard cross-validation approach that uses a small percentage of the words from their WORDNET 1.6 training set for evaluation. Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET. Another alternative is to only consider unambiguous synonyms with a single supersense in WORDNET. This same technique as is used in our approach to supersense tagging. Our evaluation will use exactly the same test sets as Ciaramita and Johnson (2003). The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words. This is determined by looking at the frequency and number of attributes for the unknown word. Another approach is to use the scores returned by the similarity system. Supersense tagging is also interesting for many applications that use shallow semantics, e.g. information extraction and question answering. Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns. This same technique as is used in our approach to
