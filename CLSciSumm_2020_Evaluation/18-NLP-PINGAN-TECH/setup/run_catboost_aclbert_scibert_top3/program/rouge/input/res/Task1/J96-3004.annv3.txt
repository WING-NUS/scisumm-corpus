Citance Number: 1 | Reference Article: J96-3004.xml | Citing Article: A00-2032.xml | Citation Marker Offset: ['142'] | Citation Marker: 1996 | Citation Offset: ['141','142'] | Citation Text: <S sid ="141" ssid = "10">Chinese According to Sproat et al.</S><S sid ="142" ssid = "11">(1996), most prior work in Chinese segmentation has exploited lexical knowledge bases; indeed, the authors assert that they were aware of only one previously pubÃÂÃÂ­ lished instance (the mutual-information method of Sproat and Shih (1990)) of a purely statistical apÃÂÃÂ­ proach.</S> | Reference Offset: ['91','89','76'] | Reference Text: <S sid="76" ssid="14">The most accurate characterization of Chinese writing is that it is morphosyllabic (DeFrancis 1984): each hanzi represents one morpheme lexically and semantically, and one syllable phonologiÃÂ­ cally.</S> <S sid="89" ssid="27">Roughly speaking, previous work can be divided into three categories, namely purely statistical approaches, purely lexiÃÂ­ cal rule-based approaches, and approaches that combine lexical information with staÃÂ­ tistical information.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 2 | Reference Article: J96-3004.xml | Citing Article: A00-2032.xml | Citation Marker Offset: ['5'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['5'] | Citation Text: <S sid ="5" ssid = "5">Proposed applications of segmentation technology include extracting new technical terms, indexing documents for information retrieval, and correcting optical character recognition (OCR) erÃÂÃÂ­ rors (Wu and Tseng, 1993; Nagao and Mori, 1994; Nagata, 1996a; Nagata, 1996b; Sproat et al., 1996; Fung, 1998).</S> | Reference Offset: ['52','1','36'] | Reference Text: <S sid="1" ssid="1">Any NLP application that presumes as input unrestricted text requires an initial phase of text analysis; such applications involve problems as diverse as machine translation, information retrieval, and text-to-speech synthesis (TIS).</S> <S sid="36" ssid="36">Now, for this application one might be tempted to simply bypass the segmentation problem and pronounce the text character-by-character.</S> <S sid="52" ssid="13">The points enumerated above are particularly related to ITS, but analogous arguments can easily be given for other applications; see for example Wu and Tseng&apos;s (1993) discussion of the role of segmentation in information retrieval.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 3 | Reference Article: J96-3004.xml | Citing Article: C00-2095.xml | Citation Marker Offset: ['80'] | Citation Marker: Sproat ct a.l., 1996 | Citation Offset: ['80'] | Citation Text: <S sid ="80" ssid = "25">As (Sproat ct a.l., 1996) testify, several native Chinese speakers do not always agree on one unique tokeniza.tion for a. given sentence.</S> | Reference Offset: ['228','33','221'] | Reference Text: <S sid="33" ssid="33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="228" ssid="92">Full Chinese personal names are in one respect simple: they are always of the form family+given.</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 4 | Reference Article: J96-3004.xml | Citing Article: C02-1049.xml | Citation Marker Offset: ['58'] | Citation Marker: Sproat et al, 1996 | Citation Offset: ['58'] | Citation Text: <S sid ="58" ssid = "39">Conventionally a word segmentation process identifies the words in input text by matching lexical entries and resolving the ambiguous matching (Chen &amp; Liu, 1992, Sproat et al, 1996).</S> | Reference Offset: ['108','112','305'] | Reference Text: <S sid="108" ssid="46">The most popular approach to dealing with segÃÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="305" ssid="14">A greedy algorithm (or maximum-matching algorithm), GR: proceed through the sentence, taking the longest match with a dictionary entry at each point.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 5 | Reference Article: J96-3004.xml | Citing Article: C02-1049.xml | Citation Marker Offset: ['127'] | Citation Marker: Sproat et al, 1996 | Citation Offset: ['125','126','127'] | Citation Text: <S sid ="124" ssid = "105">Mutu al infor matio n-like statist ics are very often adopt ed in meas uring assoc iation stren gth msi (?)</S><S sid ="127" ssid = "108">dsi +1 () combine (i, i + 1) 1993, Sproat et al, 1996)</S> | Reference Offset: ['365','245','358'] | Reference Text: <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> <S sid="358" ssid="67">However, we have reason to doubt Chang et al.&apos;s performance claims.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 6 | Reference Article: J96-3004.xml | Citing Article: C02-1080.xml | Citation Marker Offset: ['20'] | Citation Marker: Sproat et al. 96 | Citation Offset: ['20'] | Citation Text: <S sid ="20" ssid = "20">Chinese NE recognition is much more difficult than that in English due to two major problems.</S><S sid ="21" ssid = "21">The first is the word segmentation problem (Sproat et al. 96, Palmer 97).</S> | Reference Offset: ['415','137','3'] | Reference Text: <S sid="3" ssid="3">For a language like English, this problem is generally regarded as trivial since words are delimited in English text by whitespace or marks of punctuation.</S> <S sid="137" ssid="1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S> <S sid="415" ssid="18">The major problem for our segÃÂ­ menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 7 | Reference Article: J96-3004.xml | Citing Article: C02-1143.xml | Citation Marker Offset: ['107'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['107'] | Citation Text: <S sid ="107" ssid = "48">We used a maximum- matching algorithm and a dictionary compiled from the CTB (Sproat et al., 1996; Xue, 2001) to do segmentation | Reference Offset: ['320','112','168'] | Reference Text: <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="168" ssid="32">Word frequencies are estimated by a re-estimation procedure that involves applyÃÂ­ ing the segmentation algorithm presented here to a corpus of 20 million words,8 using 8 Our training corpus was drawn from a larger corpus of mixed-genre text consisting mostly of.</S> <S sid="320" ssid="29">from the subset of the United Informatics corpus not used in the training of the models.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 8 | Reference Article: J96-3004.xml | Citing Article: E09-1063.xml | Citation Marker Offset: ['107'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['107'] | Citation Text: <S sid ="107" ssid = "4">First of all, it is really difficult to build a reliable and objective gold-standard given the fact that there is only 70% agreement between native speakers on this task (Sproat et al., 1996).</S> | Reference Offset: ['221','246','93'] | Reference Text: <S sid="93" ssid="31">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S> <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="246" ssid="110">First, the model assumes independence between the first and second hanzi of a double given name.</S> | Discourse Facet: ['Implication_Citation','Results_Citation'] | Annotator: Ankita Patel


Citance Number: 9 | Reference Article: J96-3004.xml | Citing Article: I05-3031.xml | Citation Marker Offset: ['7'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['6','7'] | Citation Text: <S sid ="6" ssid = "6">The Chinese word segmentation is a nontrivial task because no explicit delimiters (like spaces in English) are used for word separation.</S><S sid ="7" ssid = "7">As the task is an important precursor to many natural language processing systems, it receives a lot of attentions in the literature for the past decade (Wu and Tseng, 1993; Sproat et al., 1996).</S> | Reference Offset: ['53','93','2'] | Reference Text: <S sid="2" ssid="2">An initial step of any textÃÂ­ analysis task is the tokenization of the input into words.</S> <S sid="53" ssid="14">There are thus some very good reasons why segmentation into words is an important task.</S> <S sid="93" ssid="31">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 10 | Reference Article: J96-3004.xml | Citing Article: J00-3004.xml | Citation Marker Offset: ['42'] | Citation Marker: 1996 | Citation Offset: ['42'] | Citation Text: <S sid ="42" ssid = "42">According to Sproat et al. {1996) and Wu and Fung {1994), experiments show that only about 75% agreement between native speakers is to be expected on the &quot;correct&quot; segmentation, and the figure reduces as more people become involved.</S> | Reference Offset: ['70','181','212'] | Reference Text: <S sid="70" ssid="8">This latter evaluation compares the performance of the system with that of several human judges since, as we shall show, even people do not agree on a single correct way to segment a text.</S> <S sid="181" ssid="45">4.2 A Sample Segmentation Using Only Dictionary Words Figure 4 shows two possible paths from the lattice of possible analyses of the input sentence B X:ÃÄ .:.S:P:l &apos;How do you say octopus in Japanese?&apos; previously shown in Figure 1.</S> <S sid="212" ssid="76">Figure 5 shows how this model is implemented as part of the dictionary WFST.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 11 | Reference Article: J96-3004.xml | Citing Article: J00-3004.xml | Citation Marker Offset: ['96'] | Citation Marker: 1996 | Citation Offset: ['96'] | Citation Text: <S sid ="96" ssid = "41">Sproat et al.</S><S sid ="97" ssid = "42">(1996) implement special recognizers not only for Chinese names and transliterated foreign names, but for components of morphologically obtained words as well.</S> | Reference Offset: ['399','286','281'] | Reference Text: <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="286" ssid="150">Finally, we model the probability of a new transliterated name as the product of PTN and PTN(hanzi;) for each hanzi; in the putative name.13 The foreign name model is implemented as an WFST, which is then summed with the WFST implementing the dictionary, morpho 13 The current model is too simplistic in several respects.</S> <S sid="399" ssid="2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 12 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['53'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['53'] | Citation Text: <S sid ="53" ssid = "53">In Chinese text segmentation there are three basic approaches (Sproat et al. 1996): pure heuristic, pure statistical, and a hybrid of the two.</S> | Reference Offset: ['89','91','455'] | Reference Text: <S sid="89" ssid="27">Roughly speaking, previous work can be divided into three categories, namely purely statistical approaches, purely lexiÃÂ­ cal rule-based approaches, and approaches that combine lexical information with staÃÂ­ tistical information.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="455" ssid="1">Despite these limitations, a purely finite-state approach to Chinese word segmentation enjoys a number of strong advantages.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 13 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['113'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['113'] | Citation Text: <S sid ="113" ssid = "9">There are several commonly used segmentation methods such as forward maximum matching and backward maximum matching(Teahan et al. 2000; Dai, Loh, and Khoo 1999; Sproat et al. 1996).</S> | Reference Offset: ['108','112','307'] | Reference Text: <S sid="108" ssid="46">The most popular approach to dealing with segÃÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> <S sid="307" ssid="16">An anti-greedy algorithm, AG: instead of the longest match, take the.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 14 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['211'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['211'] | Citation Text: <S sid ="211" ssid = "32">In addition, there is no commonly accepted standard for evaluating the performance of word extraction methods, and it is very hard to decide whether a word is meaningful or not (Sproat et al. 1996).</S> | Reference Offset: ['92','129','191'] | Reference Text: <S sid="92" ssid="30">In that work, mutual information was used to decide whether to group adjacent hanzi into two-hanzi words.</S> <S sid="129" ssid="67">However, it is almost universally the case that no clear definition of what constitutes a &quot;correct&quot; segmentation is given, so these performance measures are hard to evaluate.</S> <S sid="191" ssid="55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 15 | Reference Article: J96-3004.xml | Citing Article: J04-1004.xml | Citation Marker Offset: ['321'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['321'] | Citation Text: <S sid ="321" ssid = "7">As even human judges differ when facing the task of segmenting a text into words and test corpora differ from system to system (Sproat et al. 1996), it is very difficult to compare two methods.</S> | Reference Offset: ['133','370','130'] | Reference Text: <S sid="130" ssid="68">Indeed, as we shall show in Section 5, even human judges differ when presented with the task of segmenting a text into words, so a definition of the criteria used to determine that a given segmentation is correct is crucial before one can interpret such measures.</S> <S sid="133" ssid="71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> <S sid="370" ssid="79">In these examples, the names identified by the two systems (if any) are underlined; the sentence with the correct segmentation is boxed.19 The differences in performance between the two systems relate directly to three issues, which can be seen as differences in the tuning of the models, rather than repreÃÂ­ senting differences in the capabilities of the model per se.</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 16 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['88'] | Citation Marker: 1996 | Citation Offset: ['88'] | Citation Text: <S sid ="88" ssid = "24">A previous work along this line is Sproat et al.</S><S sid ="89" ssid = "25">(1996), which is based on weighted finite-state transducers (FSTs).</S> | Reference Offset: ['398','458','380'] | Reference Text: <S sid="380" ssid="89">set was based on an earlier version of the Chang et a!.</S> <S sid="398" ssid="1">In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 17 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['126'] | Citation Marker: 1996 | Citation Offset: ['125','126'] | Citation Text: <S sid ="125" ssid = "61">As shown in Sproat et al.</S><S sid ="126" ssid = "62">(1996), the rate of agreement between two human judges is less than 80%.</S> | Reference Offset: ['325','245','313'] | Reference Text: <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> <S sid="313" ssid="22">For each pair of judges consider one judge as the standard,.</S> <S sid="325" ssid="34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that disÃÂ­ tance matrix, and plotting the first two most significant dimensions.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 18 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['132'] | Citation Marker: 1996 | Citation Offset: ['131','132'] | Citation Text: <S sid ="131" ssid = "67">Similarly, Sproat et al.</S><S sid ="132" ssid = "68">(1996) also uses multiple human judges.</S> | Reference Offset: ['313','317','350'] | Reference Text: <S sid="313" ssid="22">For each pair of judges consider one judge as the standard,.</S> <S sid="317" ssid="26">For each pair of judges, consider one judge as the standard,.</S> <S sid="350" ssid="59">Under this scheme, n human judges are asked independently to segment a text.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 19 | Reference Article: J96-3004.xml | Citing Article: J05-4005.xml | Citation Marker Offset: ['490'] | Citation Marker: 1996 | Citation Offset: ['489','490'] | Citation Text: <S sid ="489" ssid = "153">The Chinese person-name model is a modified version of that described in Sproat et al.</S><S sid ="490" ssid = "154">(1996).</S> | Reference Offset: ['380','458','245'] | Reference Text: <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> <S sid="380" ssid="89">set was based on an earlier version of the Chang et a!.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 20 | Reference Article: J96-3004.xml | Citing Article: J11-1005.xml | Citation Marker Offset: ['123'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['123'] | Citation Text: <S sid ="123" ssid = "14">Experiments have shown that there is only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al. 1996).</S> | Reference Offset: ['325','18','56'] | Reference Text: <S sid="18" ssid="18">orthographic words are thus only a starting point for further analysis and can only be regarded as a useful hint at the desired division of the sentence into words.</S> <S sid="56" ssid="17">Among these are words derived by various productive processes, including: 1.</S> <S sid="325" ssid="34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that disÃÂ­ tance matrix, and plotting the first two most significant dimensions.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 21 | Reference Article: J96-3004.xml | Citing Article: J11-3001.xml | Citation Marker Offset: ['326'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['326'] | Citation Text: <S sid ="326" ssid = "279">Gold standards, however, 435 cannot be uniÃŸáṠĠÂed into a single standard (Fung and Wu 1994; Sproat et al. 1996).</S> | Reference Offset: ['408','318','314'] | Reference Text: <S sid="314" ssid="23">computing the precision of the other&apos;s judgments relative to this standard.</S> <S sid="318" ssid="27">computing the recall of the other&apos;s judgments relative to this standard.</S> <S sid="408" ssid="11">This is not to say that a set of standards by which a particular segmentation would count as correct and another incorrect could not be devised; indeed, such standards have been proposed and include the published PRCNSC (1994) and ROCLING (1993), as well as the unpublished Linguistic Data Consortium standards (ca.</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 22 | Reference Article: J96-3004.xml | Citing Article: J96-4004.xml | Citation Marker Offset: ['24'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['24'] | Citation Text: <S sid ="24" ssid = "24">Our ap . proach differs from existing work on Chinese word segmentation (Liang 1983; Wang, Wang, and Bai 1991; Fan and Tsai 1988; Chang, Chen, and Chen 1991; Chiang et al. 1992; Sproat and Shih 1990; Wu and Su 1993; Lua and Gan 1994; Lai et al. 1992; Sproat et al. 1994; Sproat et al. 1996) primarily in that our system performs sentence interÃÂÃÂ­ pretation, in addition to word boundary identification.</S> | Reference Offset: ['360','385','370'] | Reference Text: <S sid="360" ssid="69">The performance of our system on those sentences apÃÂ­ peared rather better than theirs.</S> <S sid="370" ssid="79">In these examples, the names identified by the two systems (if any) are underlined; the sentence with the correct segmentation is boxed.19 The differences in performance between the two systems relate directly to three issues, which can be seen as differences in the tuning of the models, rather than repreÃÂ­ senting differences in the capabilities of the model per se.</S> <S sid="385" ssid="94">Table 4 Differences in performance between our system and Wang, Li, and Chang (1992).</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 23 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['9'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['9'] | Citation Text: <S sid ="9" ssid = "9">Since in written Chinese there is no explicit word delimiter (equivalent to the blank space in written English), the problem of Chinese sentence tokenization has been the focus of considerable research efforts, and significant advancements have been made (e.g., Bai 1995; Zhang et al. 1994; Chen and Liu 1992; Chiang et al. 1992; Fan and Tsai 1988; Gan 1995; Gan, Palmer, and Lua 1996; Guo 1993; He, Xu, and Sun 1991; Huang 1989; Huang and Xia 1996; Jie 1989; Jie, Liu, and Liang 1991a, 1991b; Jin and Chen 1995; Lai et al. 1992; Li et al. 1995; Liang 1986, 1987, 1990; Liu 1986a, 1986b; Liu, Tan, and Shen 1994; Lua 1990, 1994, and 1995; Ma 1996; Nie, Jin, and Hannan 1994; Sproat and Shih 1990; Sproat et al. 1996;</S> | Reference Offset: ['110','365','245'] | Reference Text: <S sid="110" ssid="48">Papers that use this method or minor variants thereof include Liang (1986), Li et al.</S> <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 24 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['515'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['515'] | Citation Text: <S sid ="515" ssid = "92">The three tokenization definitions in this section are essentially descriptive restatements of the corresponding constructive tokenization procedures, which in turn are realizaÃÂÃÂ­ tions of the widely followed principle of maximum tokenization (e.g., Liu 1986; Liang 1986a, 1986b; Wang 1989; Jie 1989; Wang, Su, and Mo 1990; Jie, Liu, and Liang 1991a, b; Yeh and Lee 1991; Webster and Kit 1992; Chen and Liu 1992; Guo 1993; Wu and Su 1993; Nie, Jin, and Hannan 1994; Sproat et al. 1996;</S> | Reference Offset: ['88','111','2'] | Reference Text: <S sid="2" ssid="2">An initial step of any textÃÂ­ analysis task is the tokenization of the input into words.</S> <S sid="88" ssid="26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S> <S sid="111" ssid="49">(1991}, Gu and Mao (1994), and Nie, Jin, and Hannan (1994).</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 25 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['613'] | Citation Marker: 1996 | Citation Offset: ['612','613'] | Citation Text: <S sid ="612" ssid = "54">The weighted finite-state transducer model developed by Sproat et al.</S><S sid ="613" ssid = "55">(1996) is another excellent representative example.</S> | Reference Offset: ['398','458','245'] | Reference Text: <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> <S sid="398" ssid="1">In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 26 | Reference Article: J96-3004.xml | Citing Article: J97-4004.xml | Citation Marker Offset: ['621'] | Citation Marker: 1996 | Citation Offset: ['621'] | Citation Text: <S sid ="621" ssid = "63">While it may not be totally impossible to fully incorporate such knowledge and heuristics into the general framework of path evaluation and searching, they are apÃÂÃÂ­ parently employed neither in Sproat et al.</S><S sid ="622" ssid = "64">(1996) nor in Ma (1996).</S> | Reference Offset: ['67','224','365'] | Reference Text: <S sid="67" ssid="5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S> <S sid="224" ssid="88">f, nan2gual+men0 &apos;pumpkins&apos; is by no means impossible.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 27 | Reference Article: J96-3004.xml | Citing Article: N10-1068.xml | Citation Marker Offset: ['6'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['6'] | Citation Text: <S sid ="6" ssid = "6">Many natural language models can be captured by weighted finite-state transducers (Pereira et al., 1994; Sproat et al., 1996; Knight and AlOnaizan, 1998; Clark, 2002; Kolak et al., 2003; Mathias and Byrne, 2006), which offer several benefits:ÃáẁÃḃÂáṠĠÃáẁ WFSTs provide a uniform knowledge represen tation.</S> | Reference Offset: ['67','398','457'] | Reference Text: <S sid="67" ssid="5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S> <S sid="398" ssid="1">In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.</S> <S sid="457" ssid="3">The use of weighted transducers in particular has the attractive property that the model, as it stands, can be straightforwardly interfaced to other modules of a larger speech or natural language system: presumably one does not want to segment Chinese text for its own sake but instead with a larger purpose in mind.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 28 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['41'] | Citation Marker: 1996 | Citation Offset: ['41'] | Citation Text: <S sid ="41" ssid = "18">One example of such approaches is Sproat et al.</S><S sid ="42" ssid = "19">(1996), which is based on weighted finite-state transducers (FSTs).</S> | Reference Offset: ['398','458','380'] | Reference Text: <S sid="380" ssid="89">set was based on an earlier version of the Chang et a!.</S> <S sid="398" ssid="1">In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.</S> <S sid="458" ssid="4">As described in Sproat (1995), the Chinese segmenter presented here fits directly into the context of a broader finite-state model of text analysis for speech synthesis.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 29 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['122'] | Citation Marker: 1996 | Citation Offset: ['122'] | Citation Text: <S sid ="122" ssid = "27">Because any character strings can be in principle named entities of one or more types, to limit the number of candidates for a more effective search, we generate named entity candidates, given an input string, in two steps: First, for each type, we use a set of constraints (which are compiled by 3 Sproat et al.</S> | Reference Offset: ['2','230','243'] | Reference Text: <S sid="2" ssid="2">An initial step of any textÃÂ­ analysis task is the tokenization of the input into words.</S> <S sid="230" ssid="94">Given names are most commonly two hanzi long, occasionally one hanzi long: there are thus four possible name types, which can be described by a simple set of context-free rewrite rules such as the following: 1.</S> <S sid="243" ssid="107">This model is easily incorporated into the segmenter by building a WFST restrictÃÂ­ ing the names to the four licit types, with costs on the arcs for any particular name summing to an estimate of the cost of that name.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 30 | Reference Article: J96-3004.xml | Citing Article: P03-1035.xml | Citation Marker Offset: ['155'] | Citation Marker: 1996 | Citation Offset: ['155'] | Citation Text: <S sid ="154" ssid = "59">5.2.4 Transliterations of foreign names As described in Sproat et al.</S><S sid ="155" ssid = "60">(1996): FNs are usually transliterated using Chinese character strings whose sequential pronunciation mimics the source language pronunciation of the name.</S> | Reference Offset: ['281','284','285'] | Reference Text: <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabilÃÂ­ ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="285" ssid="149">As with personal names, we also derive an estimate from text of the probability of finding a transliterated name of any kind (PTN).</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 31 | Reference Article: J96-3004.xml | Citing Article: P06-1010.xml | Citation Marker Offset: ['43'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['42','43'] | Citation Text: <S sid ="42" ssid = "10">Candidate Chinese transliterations are generated by consulting a list of characters that are frequently used for transliterating foreign names.</S><S sid ="43" ssid = "11">As discussed elsewhere (Sproat et al., 1996), a subset of a few hundred characters (out of several thousand) tends to be used overwhelmingly for transliterating foreign names into Chinese.</S> | Reference Offset: ['284','281','399'] | Reference Text: <S sid="281" ssid="145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> <S sid="284" ssid="148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabilÃÂ­ ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> <S sid="399" ssid="2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 32 | Reference Article: J96-3004.xml | Citing Article: P06-1126.xml | Citation Marker Offset: ['7'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['7'] | Citation Text: <S sid ="7" ssid = "7">Chinese word segmentation is the initial stage of many Chinese language processing tasks, and has received a lot of attention in the literature (Sproat et al., 1996; Sun and Tsou, 2001; Zhang et al., 2003; Peng et al., 2004).</S> | Reference Offset: ['24','2','88'] | Reference Text: <S sid="2" ssid="2">An initial step of any textÃÂ­ analysis task is the tokenization of the input into words.</S> <S sid="24" ssid="24">2 Chinese ?l* han4zi4 &apos;Chinese character&apos;; this is the same word as Japanese kanji..</S> <S sid="88" ssid="26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S> | Discourse Facet: Aim_Citation | Annotator: Ankita Patel


Citance Number: 33 | Reference Article: J96-3004.xml | Citing Article: P07-1015.xml | Citation Marker Offset: ['113'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['113'] | Citation Text: <S sid ="113" ssid = "21">Using the 495 characters that are frequently used for transliterating foreign names (Sproat et al., 1996), a sequence of three of more characters from the list was taken as a possible candidate for Chinese.</S> | Reference Offset: ['162','24','103'] | Reference Text: <S sid="24" ssid="24">2 Chinese ?l* han4zi4 &apos;Chinese character&apos;; this is the same word as Japanese kanji..</S> <S sid="103" ssid="41">Church and Hanks [1989]), and we have used lists of character pairs ranked by mutual information to expand our own dictionary.</S> <S sid="162" ssid="26">It is. based on the traditional character set rather than the simplified character set used in Singapore and Mainland China.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 34 | Reference Article: J96-3004.xml | Citing Article: P07-1016.xml | Citation Marker Offset: ['70'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['70'] | Citation Text: <S sid ="70" ssid = "42">As discussed elsewhere (Sproat et al., 1996), out of several thousand common Chinese characters, a subset of a few hundred characters tends to be used overwhelmingly for transliterating English names to Chinese, e.g. only 731 Chinese characters are adopted in the E-C corpus.</S> | Reference Offset: ['24','162','161'] | Reference Text: <S sid="24" ssid="24">2 Chinese ?l* han4zi4 &apos;Chinese character&apos;; this is the same word as Japanese kanji..</S> <S sid="161" ssid="25">7 Big 5 is the most popular Chinese character coding standard in use in Taiwan and Hong Kong.</S> <S sid="162" ssid="26">It is. based on the traditional character set rather than the simplified character set used in Singapore and Mainland China.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 35 | Reference Article: J96-3004.xml | Citing Article: P12-1110.xml | Citation Marker Offset: ['105'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['105'] | Citation Text: <S sid ="105" ssid = "53">3.3.1 Dictionary features Because segmentation using a dictionary alone can serve as a strong baseline in Chinese word segmentation (Sproat et al., 1996), the use of dictionaries is expected to make our joint model more robust and enables us to investigate the contribution of the syntactic dependency in a more realistic setting.</S> | Reference Offset: ['170','187','54'] | Reference Text: <S sid="54" ssid="15">A minimal requirement for building a Chinese word segmenter is obviously a dictionary; furthermore, as has been argued persuasively by Fung and Wu (1994), one will perform much better at segmenting text by using a dictionary constructed with text of the same genre as the text to be segmented.</S> <S sid="170" ssid="34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S> <S sid="187" ssid="51">The method just described segments dictionary words, but as noted in Section 1, there are several classes of words that should be handled that are not found in a standard dictionary.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 36 | Reference Article: J96-3004.xml | Citing Article: P12-1111.xml | Citation Marker Offset: ['91'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['91'] | Citation Text: <S sid ="91" ssid = "31">In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996).</S> | Reference Offset: ['108','112','33'] | Reference Text: <S sid="33" ssid="33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S> <S sid="108" ssid="46">The most popular approach to dealing with segÃÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> <S sid="112" ssid="50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 37 | Reference Article: J96-3004.xml | Citing Article: P97-1041.xml | Citation Marker Offset: ['12'] | Citation Marker: 1996 | Citation Offset: ['12'] | Citation Text: <S sid ="12" ssid = "12">For a discussion of recent Chinese segmentation work, see Sproat et al. {1996).</S> | Reference Offset: ['367','244','365'] | Reference Text: <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> <S sid="367" ssid="76">In a more recent study than Chang et al., Wang, Li, and Chang (1992) propose a surname-driven, non-stochastic, rule-based system for identifying personal names.17 Wang, Li, and Chang also compare their performance with Chang et al.&apos;s system.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 38 | Reference Article: J96-3004.xml | Citing Article: P97-1041.xml | Citation Marker Offset: ['39'] | Citation Marker: 1996 | Citation Offset: ['39'] | Citation Text: <S sid ="39" ssid = "5">It is rule-based, but relies on 2 See, for example, Sproat et al.</S><S sid ="40" ssid = "6">(1996)</S> | Reference Offset: ['244','367','365'] | Reference Text: <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> <S sid="367" ssid="76">In a more recent study than Chang et al., Wang, Li, and Chang (1992) propose a surname-driven, non-stochastic, rule-based system for identifying personal names.17 Wang, Li, and Chang also compare their performance with Chang et al.&apos;s system.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 39 | Reference Article: J96-3004.xml | Citing Article: P98-1076.xml | Citation Marker Offset: ['145'] | Citation Marker: 1996 | Citation Offset: ['144','145'] | Citation Text: <S sid ="144" ssid = "11">The actual implementation of the weighted finiteÃÂÃÂ­ state transducer by Sproat et al.</S><S sid ="145" ssid = "12">(1996) can be taken as an evidence that the hypothesis of one tokenization per source has already in practical use.</S> | Reference Offset: ['244','398','461'] | Reference Text: <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S> <S sid="398" ssid="1">In this paper we have argued that Chinese word segmentation can be modeled efÃÂ­ fectively using weighted finite-state transducers.</S> <S sid="461" ssid="7">While size of the resulting transducers may seem daunting-the segmenter described here, as it is used in the Bell Labs Mandarin TTS system has about 32,000 states and 209,000 arcs-recent work on minimization of weighted machines and transducers (cf.</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 40 | Reference Article: J96-3004.xml | Citing Article: P98-1076.xml | Citation Marker Offset: ['150'] | Citation Marker: 1996 | Citation Offset: ['149','150'] | Citation Text: <S sid ="149" ssid = "2">utilizing local and sentential constraints, what Sproat et al.</S><S sid ="150" ssid = "3">( 1996) implemented was simply a token unigram scoring function.</S> | Reference Offset: ['244','421','365'] | Reference Text: <S sid="244" ssid="108">This WFST is then summed with the WFST implementing the dictionary and morphological rules, and the transitive closure of the resulting transducer is computed; see Pereira, Riley, and Sproat (1994) for an explanation of the notion of summing WFSTs.12 Conceptual Improvements over Chang et al.&apos;s Model.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> <S sid="421" ssid="24">For example, as Gan (1994) has noted, one can construct examples where the segmenÃÂ­ tation is locally ambiguous but can be determined on the basis of sentential or even discourse context.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 41 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['6'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['5','6'] | Citation Text: <S sid ="5" ssid = "5">In Japanese, around 95% word segmentation acÃÂÃÂ­ curacy is reported by using a word-based lanÃÂÃÂ­ guage model and the Viterbi-like dynamic programÃÂÃÂ­ ming procedures (Nagata, 1994; Yamamoto, 1996; Takeuchi and Matsumoto, 1997; Haruno and MatÃÂÃÂ­ sumoto, 1997).</S><S sid ="6" ssid = "6">About the same accuracy is reported in Chinese by statistical methods (Sproat et al., 1996).</S> | Reference Offset: ['419','24','337'] | Reference Text: <S sid="24" ssid="24">2 Chinese ?l* han4zi4 &apos;Chinese character&apos;; this is the same word as Japanese kanji..</S> <S sid="337" ssid="46">In this way, the method reported on here will necessarily be similar to a greedy method, though of course not identical.</S> <S sid="419" ssid="22">The method reported in this paper makes use solely of unigram probabilities, and is therefore a zeroeth-order model: the cost of a particular segmentation is estimated as the sum of the costs of the individual words in the segmentation.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 42 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['8'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['8'] | Citation Text: <S sid ="8" ssid = "8">There are two approaches to solve this problem: to increase the coverage of the dictionary (Fung and Wu, 1994; Chang et al., 1995; Mori and Nagao, 1996) and to design a better model for unknown words (Nagata, 1996; Sproat et al., 1996).</S> | Reference Offset: ['134','415','159'] | Reference Text: <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="159" ssid="23">Note that hanzi that are not grouped into dictionary words (and are not identified as singleÃÂ­ hanzi words), or into one of the other categories of words discussed in this paper, are left unattached and tagged as unknown words.</S> <S sid="415" ssid="18">The major problem for our segÃÂ­ menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 43 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['10'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['10'] | Citation Text: <S sid ="10" ssid = "10">To improve word segmentaÃÂÃÂ­ tion accuracy, (Nagata, 1996) used a single general purpose unknown word model, while (Sproat et al., 1996) used a set of specific word models such as for plurals, personal names, and transliterated foreign words.</S> | Reference Offset: ['170','159','399'] | Reference Text: <S sid="159" ssid="23">Note that hanzi that are not grouped into dictionary words (and are not identified as singleÃÂ­ hanzi words), or into one of the other categories of words discussed in this paper, are left unattached and tagged as unknown words.</S> <S sid="170" ssid="34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S> <S sid="399" ssid="2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 44 | Reference Article: J96-3004.xml | Citing Article: P99-1036.xml | Citation Marker Offset: ['178'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['178'] | Citation Text: <S sid ="178" ssid = "108">Word segmentation accuracy is expressed in terms of recall and precision as is done in the previous research (Sproat et al., 1996).</S> | Reference Offset: ['405','128','296'] | Reference Text: <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="296" ssid="5">Previous reports on Chinese segmentation have invariably cited performance either in terms of a single percent-correct score, or else a single precision-recall pair.</S> <S sid="405" ssid="8">First of all, most previous articles report perforÃÂ­ mance in terms of a single percent-correct score, or else in terms of the paired measures of precision and recall.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 45 | Reference Article: J96-3004.xml | Citing Article: W00-0803.xml | Citation Marker Offset: ['29'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['29'] | Citation Text: <S sid ="29" ssid = "29">Segmentation rutd morphological analysis related issues of both Chinese and Japanese are intensively addressed elsewhere (Sproat et al., 1996; MatsUIIt(ltO et al., 1997 and many others).</S> | Reference Offset: ['340','24','371'] | Reference Text: <S sid="24" ssid="24">2 Chinese ?l* han4zi4 &apos;Chinese character&apos;; this is the same word as Japanese kanji..</S> <S sid="340" ssid="49">This is an issue that we have not addressed at the current stage of our research.</S> <S sid="371" ssid="80">The first issue relates to the completeness of the base lexicon.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 46 | Reference Article: J96-3004.xml | Citing Article: W00-1207.xml | Citation Marker Offset: ['10'] | Citation Marker: Sproat et al 1996 | Citation Offset: ['10'] | Citation Text: <S sid ="10" ssid = "10">Purely statistical methods of word segmentation (e.g. de Marcken 1996, Sproat et al 1996, Tung and Lee 1994, Lin et al (1993), Chiang et al (1992), Lua, Huang et al, etc.) often fail to identify those words because of the sparse data problem, as the likelihood for those words to appear in the training texts is extremely low.</S> | Reference Offset: ['364','365','245'] | Reference Text: <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> <S sid="364" ssid="73">Note that it is in precision that our overÃÂ­ all performance would appear to be poorer than the reported performance of Chang et al., yet based on their published examples, our system appears to be doing better precisionwise.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 47 | Reference Article: J96-3004.xml | Citing Article: W01-0513.xml | Citation Marker Offset: ['41'] | Citation Marker: Sproat, et al, 1996 | Citation Offset: ['40','41'] | Citation Text: <S sid ="40" ssid = "11">The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et.</S><S sid ="41" ssid = "12">al, 1996; Brent, 1996; de Marcken, 1996) or on tokenizing Asian and Indian languages that do not normally include word delimiters in their orthography (Sproat, et al, 1996; Ponte and Croft 1996; Shimohata, 1997; Teahan, et al., 2000; and many others).</S> | Reference Offset: ['42','66','2'] | Reference Text: <S sid="2" ssid="2">An initial step of any textÃÂ­ analysis task is the tokenization of the input into words.</S> <S sid="42" ssid="3">In various dialects of Mandarin certain phonetic rules apply at the word.</S> <S sid="66" ssid="4">The segmenter handles the grouping of hanzi into words and outputs word pronunciations, with default pronunciations for hanzi it cannot group; we focus here primarily on the system&apos;s ability to segment text appropriately (rather than on its pronunciation abilities).</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 48 | Reference Article: J96-3004.xml | Citing Article: W02-1117.xml | Citation Marker Offset: ['13'] | Citation Marker: Sproat et al. 1996 | Citation Offset: ['13'] | Citation Text: <S sid ="13" ssid = "13">For examples: these words should be obtained: The ambiguous string is .There are some methods to resolve this problem: the one is the method forward maximum matching, backward maximum matching and minimum matching are used to find out the possible word strings from the character string [Guo 1997; Sproat et al. 1996; Gu and Mao 1994; Li et al. 1991; Wang et al. 1991b; Wang et al. 1990].</S> | Reference Offset: ['367','110','108'] | Reference Text: <S sid="108" ssid="46">The most popular approach to dealing with segÃÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> <S sid="110" ssid="48">Papers that use this method or minor variants thereof include Liang (1986), Li et al.</S> <S sid="367" ssid="76">In a more recent study than Chang et al., Wang, Li, and Chang (1992) propose a surname-driven, non-stochastic, rule-based system for identifying personal names.17 Wang, Li, and Chang also compare their performance with Chang et al.&apos;s system.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 49 | Reference Article: J96-3004.xml | Citing Article: W02-1808.xml | Citation Marker Offset: ['5'] | Citation Marker: 1996 | Citation Offset: ['5'] | Citation Text: <S sid ="5" ssid = "5">Statistical approaches involve language mod els mostly finite-state ones trained on some large-scale corpora as showed in Fan and Tsai (1988) Chang et al (1991) Chiang et al (1992) Sproat et al (1996)</S> | Reference Offset: ['365','245','358'] | Reference Text: <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> <S sid="358" ssid="67">However, we have reason to doubt Chang et al.&apos;s performance claims.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 50 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['17'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['17'] | Citation Text: <S sid ="17" ssid = "17">There are multiple studies (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) showing that the agreement between two (untrained) native speakers is about upper to lower</S> | Reference Offset: ['331','332','325'] | Reference Text: <S sid="325" ssid="34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that disÃÂ­ tance matrix, and plotting the first two most significant dimensions.</S> <S sid="331" ssid="40">It can also be seen clearly in this plot that two of the Taiwan speakers cluster very closely together, and the third TaiÃÂ­ wan speaker is also close in the most significant dimension (the x axis).</S> <S sid="332" ssid="41">Two of the Mainlanders also cluster close together but, interestingly, not particularly close to the Taiwan speakers; the third Mainlander is much more similar to the Taiwan speakers.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 51 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['180'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['180'] | Citation Text: <S sid ="180" ssid = "4">Chinese word segmentation is a well-known problem that has been studied extensively (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) and it is known that human agreement is relatively low.</S> | Reference Offset: ['347','190','137'] | Reference Text: <S sid="137" ssid="1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S> <S sid="190" ssid="54">The morphological analÃÂ­ysis itself can be handled using well-known techniques from finite-state morphol 9 The initial estimates are derived from the frequencies in the corpus of the strings of hanzi making up.</S> <S sid="347" ssid="56">It may seem surprising to some readers that the interhuman agreement scores reported here are so low.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 52 | Reference Article: J96-3004.xml | Citing Article: W03-1025.xml | Citation Marker Offset: ['187'] | Citation Marker: 1996 | Citation Offset: ['186','187'] | Citation Text: <S sid ="186" ssid = "10">Sproat et al.</S><S sid ="187" ssid = "11">(1996) employs stochastic finite state machines to find word boundaries.</S> | Reference Offset: ['138','367','365'] | Reference Text: <S sid="138" ssid="2">More formally, we start by representing the dictionary D as a Weighted Finite State TransÃÂ­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> <S sid="367" ssid="76">In a more recent study than Chang et al., Wang, Li, and Chang (1992) propose a surname-driven, non-stochastic, rule-based system for identifying personal names.17 Wang, Li, and Chang also compare their performance with Chang et al.&apos;s system.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 53 | Reference Article: J96-3004.xml | Citing Article: W03-1728.xml | Citation Marker Offset: ['3'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['3'] | Citation Text: <S sid ="3" ssid = "3">This may sound simple enough but in reality identifying words in Chinese is a nontrivial problem that has drawn a large body of research in the Chinese language processing community (Fan and Tsai, 1988; Gan et al., 1996; Sproat et al., 1996; Wu, 2003; Xue, 2003).</S> | Reference Offset: ['23','19','137'] | Reference Text: <S sid="19" ssid="19">Whether a language even has orthographic words is largely dependent on the writing system used to represent the language (rather than the language itself); the notion &quot;orthographic word&quot; is not universal.</S> <S sid="23" ssid="23">All notions of word, with the exception of the orthographic word, are as relevant in Chinese as they are in English, and just as is the case in other languages, a word in Chinese may correspond to one or more symbols in the orthog 1 For a related approach to the problem of word-segrnention in Japanese, see Nagata (1994), inter alia..</S> <S sid="137" ssid="1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 54 | Reference Article: J96-3004.xml | Citing Article: W04-3236.xml | Citation Marker Offset: ['157'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['157'] | Citation Text: <S sid ="157" ssid = "35">Much previous research on Chinese language processing focused on word segmentation (Sproat et al., 1996; Teahan et al., 2000; Sproat and Emerson, 2003).</S> | Reference Offset: ['65','66','56'] | Reference Text: <S sid="56" ssid="17">Among these are words derived by various productive processes, including: 1.</S> <S sid="65" ssid="3">In this paper we present a stochastic finite-state model for segmenting Chinese text into words, both words found in a (static) lexicon as well as words derived via the above-mentioned productive processes.</S> <S sid="66" ssid="4">The segmenter handles the grouping of hanzi into words and outputs word pronunciations, with default pronunciations for hanzi it cannot group; we focus here primarily on the system&apos;s ability to segment text appropriately (rather than on its pronunciation abilities).</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 55 | Reference Article: J96-3004.xml | Citing Article: W05-0709.xml | Citation Marker Offset: ['83'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['83'] | Citation Text: <S sid ="83" ssid = "9">In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al., 1996).</S> | Reference Offset: ['245','170','107'] | Reference Text: <S sid="107" ssid="45">The second concerns the methods used (if any) to exÃÂ­ tend the lexicon beyond the static list of entries provided by the machine-readable dictionary upon which it is based.</S> <S sid="170" ssid="34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S> <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 56 | Reference Article: J96-3004.xml | Citing Article: W06-1630.xml | Citation Marker Offset: ['118'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['118'] | Citation Text: <S sid ="118" ssid = "13">The words were stemmed all possible ways using simple hand-developed affix lists: for example, given a Hindi word c1 c2 c3 , if both c3 and c2 c3 are in our suffix and ending list, then this single word generates three possible candidates: c1 , c1 c2 , and c1c2 c3 . In contrast, Chinese candidates were extracted using a list of 495 characters that are frequently used for foreign names (Sproat et al., 1996).</S> | Reference Offset: ['55','435','103'] | Reference Text: <S sid="55" ssid="16">For novel texts, no lexicon that consists simply of a list of word entries will ever be entirely satisfactory, since the list will inevitably omit many constructions that should be considered words.</S> <S sid="103" ssid="41">Church and Hanks [1989]), and we have used lists of character pairs ranked by mutual information to expand our own dictionary.</S> <S sid="435" ssid="38">For the examples given in (1) and (2) this certainly seems possible.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 57 | Reference Article: J96-3004.xml | Citing Article: W10-3212.xml | Citation Marker Offset: ['16'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['16'] | Citation Text: <S sid ="16" ssid = "2">In such languages, words are segmented using more advanced techniques, which can be categorized into three methods: (i) Dictionary/lexicon based approaches (ii) Linguistic knowledge based approaches (iii) Machine learning based approaches/statistical approaches (Haruechaiyasak et al., 2008) Longest matching (Poowarawan, 1986; Richard Sproat, 1996) and maximum matching (Sproat et al., 1996; Haizhou &amp; Baosheng, 1998) are examples of lexicon based approaches.</S> | Reference Offset: ['371','108','89'] | Reference Text: <S sid="89" ssid="27">Roughly speaking, previous work can be divided into three categories, namely purely statistical approaches, purely lexiÃÂ­ cal rule-based approaches, and approaches that combine lexical information with staÃÂ­ tistical information.</S> <S sid="108" ssid="46">The most popular approach to dealing with segÃÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> <S sid="371" ssid="80">The first issue relates to the completeness of the base lexicon.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 58 | Reference Article: J96-3004.xml | Citing Article: W10-3708.xml | Citation Marker Offset: ['16'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['16'] | Citation Text: <S sid ="16" ssid = "16">Experiments have shown only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al., 1996).</S> | Reference Offset: ['325','18','56'] | Reference Text: <S sid="18" ssid="18">orthographic words are thus only a starting point for further analysis and can only be regarded as a useful hint at the desired division of the sentence into words.</S> <S sid="56" ssid="17">Among these are words derived by various productive processes, including: 1.</S> <S sid="325" ssid="34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that disÃÂ­ tance matrix, and plotting the first two most significant dimensions.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 59 | Reference Article: J96-3004.xml | Citing Article: W11-0823.xml | Citation Marker Offset: ['174'] | Citation Marker: 1996 | Citation Offset: ['174'] | Citation Text: <S sid ="174" ssid = "7">There are a number of popular dictionary-based solutions such as Cha Sen10 and Juman.11 Sproat et al (1996) proposed an alternative solution based on distributional statistics such as mutual information.</S> | Reference Offset: ['329','248','91'] | Reference Text: <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="248" ssid="112">As a partial solution, for pairs of hanzi that co-occur sufficiently often in our namelists, we use the estimated bigram cost, rather than the independence-based cost.</S> <S sid="329" ssid="38">This is to allow for fair comparison between the statistical method and GR, which is also purely dictionary-based.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 60 | Reference Article: J96-3004.xml | Citing Article: W12-1011.xml | Citation Marker Offset: ['41'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['41'] | Citation Text: <S sid ="41" ssid = "5">Indeed, even native speakers can agree on word boundaries in modern Chinese only about 76% of the time (Sproat et al., 1996).</S> | Reference Offset: ['297','352','221'] | Reference Text: <S sid="221" ssid="85">10 Chinese speakers may object to this form, since the suffix f, menD (PL) is usually restricted to.</S> <S sid="297" ssid="6">The problem with these styles of evaluation is that, as we shall demonstrate, even human judges do not agree perfectly on how to segment a given text.</S> <S sid="352" ssid="61">For a given &quot;word&quot; in the automatic segmentation, if at least k of the huÃÂ­ man judges agree that this is a word, then that word is considered to be correct.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 61 | Reference Article: J96-3004.xml | Citing Article: W12-1011.xml | Citation Marker Offset: ['204'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['204'] | Citation Text: <S sid ="204" ssid = "9">No comparable figure has been reported for classical Chinese word segmentation, but this rate compares favorably with past attempts for modern Chinese, e.g., an average of 76% inter- human agreement rate in (Sproat et al., 1996).</S> | Reference Offset: ['304','325','132'] | Reference Text: <S sid="132" ssid="70">For example Chen and Liu (1992) report precision and recall rates of over 99%, but this counts only the words that occur in the test corpus that also occur in their dictionary.</S> <S sid="304" ssid="13">Various segmentation approaches were then compared with human performance: 1.</S> <S sid="325" ssid="34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 One can better visualize the precision-recall similarity matrix by producing from that matrix a distance matrix, computing a classical metric multidimensional scaling (Torgerson 1958; Becker, Chambers, Wilks 1988) on that disÃÂ­ tance matrix, and plotting the first two most significant dimensions.</S> | Discourse Facet: Results_Citation | Annotator: Ankita Patel


Citance Number: 62 | Reference Article: J96-3004.xml | Citing Article: W12-2303.xml | Citation Marker Offset: ['12'] | Citation Marker: 1996 | Citation Offset: ['11','12'] | Citation Text: <S sid ="11" ssid = "11">An extension of this approach is the dynamic programming search of the most probable word combination on the word lattice, such as Ma (1996) and Sproat et al.</S><S sid ="12" ssid = "12">(1996), which utilize information such as word frequency statistics in a corpus to build the model and are less efficient but more accurate.</S> | Reference Offset: ['89','91','245'] | Reference Text: <S sid="89" ssid="27">Roughly speaking, previous work can be divided into three categories, namely purely statistical approaches, purely lexiÃÂ­ cal rule-based approaches, and approaches that combine lexical information with staÃÂ­ tistical information.</S> <S sid="91" ssid="29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> <S sid="245" ssid="109">There are two weaknesses in Chang et al.&apos;s model, which we improve upon.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 63 | Reference Article: J96-3004.xml | Citing Article: W12-2303.xml | Citation Marker Offset: ['157'] | Citation Marker: 1996 | Citation Offset: ['156','157'] | Citation Text: <S sid ="155" ssid = "30">There are many other OOV recognition methods proposed in literature before the rise of machine learning in the field.</S><S sid ="156" ssid = "31">For example, the Sproat et al.</S><S sid ="157" ssid = "32">(1996) system can successfully recognize OOVs of strong patterns, such as Chinese personal names, transliterations, using finite-state techniques.</S> | Reference Offset: ['377','455','367'] | Reference Text: <S sid="367" ssid="76">In a more recent study than Chang et al., Wang, Li, and Chang (1992) propose a surname-driven, non-stochastic, rule-based system for identifying personal names.17 Wang, Li, and Chang also compare their performance with Chang et al.&apos;s system.</S> <S sid="377" ssid="86">Our system does not currently make use of titles, but it would be straightforward to do so within the finite-state framework that we propose.</S> <S sid="455" ssid="1">Despite these limitations, a purely finite-state approach to Chinese word segmentation enjoys a number of strong advantages.</S> | Discourse Facet: Implication_Citation | Annotator: Ankita Patel


Citance Number: 64 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['26'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['26'] | Citation Text: <S sid ="26" ssid = "26">One of the major problems in unsupervised word segmentation is the treatment of unseen word [Sproat et al., 1996] wrote lexical rules for each productive morphological process, such as plur noun formation, Chinese personal names, and transliterations of foreign words.</S> | Reference Offset: ['188','134','65'] | Reference Text: <S sid="65" ssid="3">In this paper we present a stochastic finite-state model for segmenting Chinese text into words, both words found in a (static) lexicon as well as words derived via the above-mentioned productive processes.</S> <S sid="134" ssid="72">The major problem for all segmentation systems remains the coverage afforded by the dictionary and the lexical rules used to augment the dictionary to deal with unseen words.</S> <S sid="188" ssid="52">One class comprises words derived by productive morphologiÃÂ­ cal processes, such as plural noun formation using the suffix ir, menD.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 65 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['69'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['69'] | Citation Text: <S sid ="69" ssid = "5">We used a simple greedy algorithm described in [Sproat et al., 1996].</S> | Reference Offset: ['307','305','365'] | Reference Text: <S sid="305" ssid="14">A greedy algorithm (or maximum-matching algorithm), GR: proceed through the sentence, taking the longest match with a dictionary entry at each point.</S> <S sid="307" ssid="16">An anti-greedy algorithm, AG: instead of the longest match, take the.</S> <S sid="365" ssid="74">Thus we have some confidence that our own performance is at least as good as that of Chang et al.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 66 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['73'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['73'] | Citation Text: <S sid ="73" ssid = "9">[Sproat et al., 1996] also proposed another method to estimate a set of initial word frequencies without segmenting the corpus.</S> | Reference Offset: ['173','168','170'] | Reference Text: <S sid="168" ssid="32">Word frequencies are estimated by a re-estimation procedure that involves applyÃÂ­ ing the segmentation algorithm presented here to a corpus of 20 million words,8 using 8 Our training corpus was drawn from a larger corpus of mixed-genre text consisting mostly of.</S> <S sid="170" ssid="34">This larger corpus was kindly provided to us by United Informatics Inc., R.O.C. a set of initial estimates of the word frequencies.9 In this re-estimation procedure only the entries in the base dictionary were used: in other words, derived words not in the base dictionary and personal and foreign names were not used.</S> <S sid="173" ssid="37">In any event, to date, we have not compared different methods for deriving the set of initial frequency estimates.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 67 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['86'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['86'] | Citation Text: <S sid ="86" ssid = "22">The problem of the longest match string frequency method is that if a word W1 is a substring of other word w2 and if wl always appears as a substring of w2 in the training text, just like m 1Although (Sproat et al., 1996] calls it &quot;maximum matching&quot;, we call this method &quot;longest match&quot; according to a review on Chinese word segmentation [Wu and Tseng, 1993) and the literal translation of the Japanese name of the method Hi!:.</S> | Reference Offset: ['32','123','307'] | Reference Text: <S sid="32" ssid="32">On the other hand, in a translation system one probably wants to treat this string as a single dictionary word since it has a conventional and somewhat unpredictable translation into English.</S> <S sid="123" ssid="61">Statistical methods seem particularly applicable to the problem of unknown-word identification, especially for constructions like names, where the linguistic constraints are minimal, and where one therefore wants to know not only that a particular seÃÂ­ quence of hanzi might be a name, but that it is likely to be a name with some probabilÃÂ­ ity.</S> <S sid="307" ssid="16">An anti-greedy algorithm, AG: instead of the longest match, take the.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


Citance Number: 68 | Reference Article: J96-3004.xml | Citing Article: W97-0120.xml | Citation Marker Offset: ['121'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['121'] | Citation Text: <S sid ="121" ssid = "15">Word Segmentation accuracy is expressed in terms of recall and precision as is done for bracketing of partial parses [Nagata, 1994, Sproat et al., 1996).</S> | Reference Offset: ['128','405','361'] | Reference Text: <S sid="128" ssid="66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recalP It is fairly standard to report precision and recall scores in the mid to high 90% range.</S> <S sid="361" ssid="70">On a set of 11 sentence fragments-the A set-where they reported 100% recall and precision for name identification, we had 73% recall and 80% precision.</S> <S sid="405" ssid="8">First of all, most previous articles report perforÃÂ­ mance in terms of a single percent-correct score, or else in terms of the paired measures of precision and recall.</S> | Discourse Facet: ['Method_Citation','Results_Citation'] | Annotator: Ankita Patel


Citance Number: 69 | Reference Article: J96-3004.xml | Citing Article: W97-0316.xml | Citation Marker Offset: ['11'] | Citation Marker: Sproat et al., 1996 | Citation Offset: ['10','11'] | Citation Text: <S sid ="10" ssid = "10">Automatic methods for correctly isolating words in a sentence -- a process called word segmentation -- is therefore an important and necessary first step to be taken before other analysis can begin.</S><S sid ="11" ssid = "11">Many researchers have proposed practical methods to resolve this problem such as (Nie et al., 1995, Wu and Tsang, 1995, Jin &amp; Chen, 1996, Ponte &amp; Croft, 1996, Sproat et al., 1996, Sun et al., 1997).</S> | Reference Offset: ['352','109','2'] | Reference Text: <S sid="2" ssid="2">An initial step of any textÃÂ­ analysis task is the tokenization of the input into words.</S> <S sid="109" ssid="47">This method, one instance of which we term the &quot;greedy algorithm&quot; in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (beginÃÂ­ ning) of the sentence is reached.</S> <S sid="352" ssid="61">For a given &quot;word&quot; in the automatic segmentation, if at least k of the huÃÂ­ man judges agree that this is a word, then that word is considered to be correct.</S> | Discourse Facet: Method_Citation | Annotator: Ankita Patel


