Citance Number,Citation Marker,Citation Marker Offset,Citation Offset,Citation Text,Citation Text Clean,Citing Article,Discourse Facet,Reference Article,Reference Offset,Reference Text
1.0,"Skut et al, 1997",0,0,"This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)","This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)",E99-1016,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'74','70','12'","<S sid=""74"" ssid=""19"">During the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc.</S><S sid=""70"" ssid=""15"">Their further classification must reflect different kinds of linguistic information: morphology (e.g., case, inflection), category, dependency type (complementation vs. modification), thematic role, etc.'</S><S sid=""12"" ssid=""2"">Realworld texts annotated with different strata of linguistic information can be used for grammar induction.</S>"
2.0,"Skut et al, 1997",0,0,"For our experiments, we use the NEGRA corpus (Skut et al, 1997)","For our experiments, we use the NEGRA corpus (Skut et al, 1997)",E99-1016,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'144','72','83'","<S sid=""144"" ssid=""25"">We distinguish five degrees of automation: So far, about 1100 sentences of our corpus have been annotated.</S><S sid=""72"" ssid=""17"">In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.</S><S sid=""83"" ssid=""28"">A phrase or a lexical item can perform multiple functions in a sentence.</S>"
3.0,"Skut et al, 1997",0,0,"As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training ,devel 1 10 100 1000 10000 100000 3 4 5 6 7 8 9 Frequenc y Parsing complexity head-driven optimal head-driven Figure 6: The distribution of parsing complexity among productions in Markovized, head-driven grammars read off from NEGRA-25","As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training",E12-1047,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'24','145','167'","<S sid=""24"" ssid=""14"">The typical treebank architecture is as follows: Structures: A context-free backbone is augmented with trace-filler representations of non-local dependencies.</S><S sid=""145"" ssid=""26"">This amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above).</S><S sid=""167"" ssid=""9"">In the second phase of the project Verbmobil a. treebank for :30,000 German spoken sentences as well as for the same amount of English and Japanese sentences will be created.</S>"
5.0,1997,0,0,According to Skut et al (1997) tree banks have to meet the following requirements: 1,According to Skut et al (1997) tree banks have to meet the following requirements: 1,I05-6010,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'15','53','34'","<S sid=""15"" ssid=""5"">Existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: Descriptivity: Grammatical phenomena are to be described rather than explained.</S><S sid=""53"" ssid=""43"">A tree meeting these requirements is given below: Adv V NP NP V CPL NP V damn wird ihn Anna erkennen, dais er 'vein!</S><S sid=""34"" ssid=""24"">Treebanks of the format, described in the above section have been designed for English.</S>"
7.0,"Skut et al, 1997",0,0,"In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997) .Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node","In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997). Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node",C10-1061,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'24','55','74'","<S sid=""24"" ssid=""14"">The typical treebank architecture is as follows: Structures: A context-free backbone is augmented with trace-filler representations of non-local dependencies.</S><S sid=""55"" ssid=""45"">A uniform representation of local and non-local dependencies makes the structure more transparent'.</S><S sid=""74"" ssid=""19"">During the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc.</S>"
8.0,"Skut et al, 1997",0,0,"Our data source is the German NeGra tree bank (Skut et al, 1997)","Our data source is the German NeGra tree bank (Skut et al, 1997)",C10-1061,"Method_Citation,Hypothesis_Citation,Aim_Citation,Implication_Citation",A97-1014,"'167','159','11'","<S sid=""167"" ssid=""9"">In the second phase of the project Verbmobil a. treebank for :30,000 German spoken sentences as well as for the same amount of English and Japanese sentences will be created.</S><S sid=""159"" ssid=""1"">As the annotation scheme described in this paper focusses on annotating argument structure rather than constituent trees, it differs from existing treebanks in several aspects.</S><S sid=""11"" ssid=""1"">Combining raw language data with linguistic information offers a promising basis for the development of new efficient and robust NLP methods.</S>"
9.0,"Skut et al, 1997",0,0,"The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences","The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences",P05-1039,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'144','151','74'","<S sid=""144"" ssid=""25"">We distinguish five degrees of automation: So far, about 1100 sentences of our corpus have been annotated.</S><S sid=""151"" ssid=""32"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S sid=""74"" ssid=""19"">During the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc.</S>"
10.0,"Skut et al, 1997",0,0,"The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German","The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German",P03-1013,"Method_Citation,Hypothesis_Citation,Aim_Citation,Implication_Citation",A97-1014,"'4','144','72'","<S sid=""4"" ssid=""1"">The work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.</S><S sid=""144"" ssid=""25"">We distinguish five degrees of automation: So far, about 1100 sentences of our corpus have been annotated.</S><S sid=""72"" ssid=""17"">In order to avoid inconsistencies, the corpus is annotated in two stages: basic annotation and nfirtellte714.</S>"
11.0,"Skut et al, 1997",0,0,"The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences","The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences",P03-1013,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'160','159','34'","<S sid=""160"" ssid=""2"">These differences can be illustrated by a comparison with the Penn Treebank annotation scheme.</S><S sid=""159"" ssid=""1"">As the annotation scheme described in this paper focusses on annotating argument structure rather than constituent trees, it differs from existing treebanks in several aspects.</S><S sid=""34"" ssid=""24"">Treebanks of the format, described in the above section have been designed for English.</S>"
13.0,"Skut et al, 1997",0,0,"German is con sider ably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA an notation has been conceived to be quite at (Skut et al, 1997)","German is considerably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA annotation has been conceived to be quite at (Skut et al, 1997)",W04-1505,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'81','12','74'","<S sid=""81"" ssid=""26"">During the second annotation stage, the annotation is enriched with information about thematic roles, quantifier scope and anaphoric reference.</S><S sid=""12"" ssid=""2"">Realworld texts annotated with different strata of linguistic information can be used for grammar induction.</S><S sid=""74"" ssid=""19"">During the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc.</S>"
14.0,"Skut et al, 1997",0,0,"The factors used in the algorithms and the algorithms themselves are evaluated on a Germancorpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)","The factors used in the algorithms and the algorithms themselves are evaluated on a German corpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)",C04-1074,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'74','144','12'","<S sid=""74"" ssid=""19"">During the first phase, the focus is on annotating correct structures and a coarse-grained classification of grammatical functions, which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC), accusative objects (OA), datives (DA), etc.</S><S sid=""144"" ssid=""25"">We distinguish five degrees of automation: So far, about 1100 sentences of our corpus have been annotated.</S><S sid=""12"" ssid=""2"">Realworld texts annotated with different strata of linguistic information can be used for grammar induction.</S>"
16.0,"Skut et al, 1997",0,0,"CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)","CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)",P11-2067,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,'144',"<S sid=""144"" ssid=""25"">We distinguish five degrees of automation: So far, about 1100 sentences of our corpus have been annotated.</S>"
17.0,"Skut et al, 1997",0,0,"Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negratreebank (Skut et al, 1997) reports that lexicaliza tion of PCFGs decrease the parsing accuracy when parsing Negra? s flat constituent structures","Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al, 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra's flat constituent structures",W08-1007,"Method_Citation,Hypothesis_Citation,Implication_Citation",A97-1014,"'65','157','113'","<S sid=""65"" ssid=""10"">The tree resembles traditional constituent structures.</S><S sid=""157"" ssid=""38"">Overall accuracy of the tagger is 95%.</S><S sid=""113"" ssid=""26"">Since a precise structural description of non-constituent coordination would require a. rich inventory of incomplete phrase types, we have agreed on a sort of unde.rspe.cified representations: the coordinated units are assigned structures in which missing lexical material is not represented at the level of primary links.</S>"
19.0,"Skut et al, 1997",0,0,"A comparison of unlexicalised PCFG parsing (Ku ?bler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)","A comparison of unlexicalised PCFG parsing (Kubler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)",D07-1066,"Method_Citation,Hypothesis_Citation,Results_Citation,Implication_Citation",A97-1014,"'151','156','24'","<S sid=""151"" ssid=""32"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S sid=""156"" ssid=""37"">Accuracy of the unreliable 10% of assignments is 75%, i.e., the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.</S><S sid=""24"" ssid=""14"">The typical treebank architecture is as follows: Structures: A context-free backbone is augmented with trace-filler representations of non-local dependencies.</S>"
