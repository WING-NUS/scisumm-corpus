<S sid="8" ssid="1">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S>
<S sid="82" ssid="11">We also calculate the WSD accuracy that would be obtained on SemCor, when using our first sense in all contexts ( ).</S>
<S sid="64" ssid="20">We briefly summarise the two measures here; for a more detailed summary see (Patwardhan et al., 2003).</S>
<S sid="172" ssid="20">We believe automatic ranking techniques such as ours will be useful for systems that rely on WordNet, for example those that use it for lexical acquisition or WSD.</S>
<S sid="153" ssid="1">Most research in WSD concentrates on using contextual features, typically neighbouring words, to help determine the correct sense of a target word.</S>
<S sid="1" ssid="1">word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.</S>
<S sid="165" ssid="13">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus, whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S>
<S sid="171" ssid="19">In contrast, we use the neighbours lists and WordNet similarity measures to impose a prevalence ranking on the WordNet senses.</S>
<S sid="89" ssid="18">Since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense, and is much more efficient than lesk, given the precompilation of the IC files.</S>
<S sid="189" ssid="12">Additionally, we need to determine whether senses which do not occur in a wide variety of grammatical contexts fare badly using distributional measures of similarity, and what can be done to combat this problem using relation specific thesauruses.</S>
<S sid="87" ssid="16">Again, the automatic ranking outperforms this by a large margin.</S>
 <S sid="137" ssid="14">Additionally, we evaluated our method quantitatively using the Subject Field Codes (SFC) resource (Magnini and Cavagli`a, 2000) which annotates WordNet synsets with domain labels.</S>
<S sid="63" ssid="19">We experimented using six of these to provide the in equation 1 above and obtained results well over our baseline, but because of space limitations give results for the two which perform the best.</S>
<S sid="159" ssid="7">Magnini and Cavagli`a (2000) have identified WordNet word senses with particular domains, and this has proven useful for high precision WSD (Magnini et al., 2001); indeed in section 5 we used these domain labels for evaluation.</S>