S sid="6" ssid="4">In this paper, we report adapting a lexicalized, probabilistic context-free parser with head rules (LPCFG-HR) to information extraction.</S>
"<S sid=""33"" ssid=""1"">Our integrated model represents syntax and semantics jointly using augmented parse trees.</S>
    <S sid=""34"" ssid=""2"">In these trees, the standard TREEBANK structures are augmented to convey semantic information, that is, entities and relations.</S>"
"<S sid=""49"" ssid=""9"">By necessity, we adopted the strategy of hand marking only the semantics.</S>
    <S sid=""50"" ssid=""10"">Figure 4 shows an example of the semantic annotation, which was the only type of manual annotation we performed.</S>"
<S sid="10" ssid="8">Instead, our parsing algorithm, trained on the UPenn TREEBANK, was run on the New York Times source to create unsupervised syntactic training which was constrained to be consistent with semantic annotation.</S
<S sid="16" ssid="6">For the following example, the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE.</S>
"<S sid=""23"" ssid=""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S>
    <S sid=""24"" ssid=""7"">For this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other.</S>"
"<S sid=""23"" ssid=""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S>
    <S sid=""24"" ssid=""7"">For this reason, we focused on designing an integrated model in which tagging, namefinding, parsing, and semantic interpretation decisions all have the opportunity to mutually influence each other.</S><S sid=""33"" ssid=""1"">Our integrated model represents syntax and semantics jointly using augmented parse trees.</S>
    <S sid=""34"" ssid=""2"">In these trees, the standard TREEBANK structures are augmented to convey semantic information, that is, entities and relations.</S>"
"S sid=""60"" ssid=""1"">In our statistical model, trees are generated according to a process similar to that described in (Collins 1996, 1997).</S>
    <S sid=""61"" ssid=""2"">The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.</S>"
<S sid="33" ssid="1">Our integrated model represents syntax and semantics jointly using augmented parse trees.</S>
"<S sid=""11"" ssid=""1"">We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh, 1998).</S>
    <S sid=""12"" ssid=""2"">The Template Element (TE) task identifies organizations, persons, locations, and some artifacts (rocket and airplane-related artifacts).</S><S sid=""16"" ssid=""6"">For the following example, the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE.</S>"
<S sid="105" ssid="2">A single model proved capable of performing all necessary sentential processing, both syntactic and semantic.</S>
"<S sid=""60"" ssid=""1"">In our statistical model, trees are generated according to a process similar to that described in (Collins 1996, 1997).</S>
    <S sid=""61"" ssid=""2"">The detailed probability structure differs, however, in that it was designed to jointly perform part-of-speech tagging, name finding, syntactic parsing, and relation finding in a single process.</S>"