In this paper, Ren Bods proposes an integration of two existing DOP models (one which computes the parse tree involving the most frequent subtrees from a treebank and one which computes the parse tree involving the fewest subtrees from a treebank)which outperforms each of them separately. They showed that a PCFG-reduction of DOP in combination with a new notion of the best parse tree resulted in fast processing times and very competitive accuracy on the Wall Street Journal treebank. They also re-affirmed that the coarsegrained approach of using all subtrees from a treebank outperforms the fine-grained approach of specifically modeling lexical-syntactic dependencies. The results showed an 11% relative reduction in error rate over previous models, and an average processing time of 3.6 seconds per WSJ sentence.