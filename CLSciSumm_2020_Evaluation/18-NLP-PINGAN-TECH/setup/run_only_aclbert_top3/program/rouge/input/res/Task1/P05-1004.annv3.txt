Citance Number: 1 | Reference Article: P05-1004.xml | Citing Article: C10-2101.xml | Citation Marker Offset: ['74'] | Citation Marker: Curran, 2005 | Citation Offset: ['74'] | Citation Text: <S sid ="74" ssid = "44">Another related task is supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006).</S> | Reference Offset: ['168','162','64'] | Reference Text: <S sid="64" ssid="17">This same technique as is used in our approach to supersense tagging.</S> <S sid="162" ssid="16">Another approach is to use the scores returned by the similarity system.</S> <S sid="168" ssid="22">Another alternative is to only consider unambiguous synonyms with a single supersense in WORDNET.</S> | Discourse Facet: Method_Citation | Annotator: Mark Able, Re


Citance Number: 2 | Reference Article: P05-1004.xml | Citing Article: E09-1045.xml | Citation Marker Offset: ['23'] | Citation Marker: Curran, 2005 | Citation Offset: ['23'] | Citation Text: <S sid ="23" ssid = "23">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset: ['65','7','226'] | Reference Text: <S sid="7" ssid="7">In particular, WORDNET (Fellbaum, 1998) has significantly influenced research in NLP.</S> <S sid="65" ssid="18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> <S sid="226" ssid="2">To classify a previously unseen common noun our approach extracts synonyms which vote using their supersenses in WORDNET 1.6.</S> | Discourse Facet: Method_Citation | Annotator: Mark Able, Re


Citance Number: 3 | Reference Article: P05-1004.xml | Citing Article: J07-4005.xml | Citation Marker Offset: ['229'] | Citation Marker: 2005 | Citation Offset: ['229'] | Citation Text: <S sid ="229" ssid = "72">Although we could adapt our method for use with an automatically induced inventory, our method which uses WordNet might also be combined with one that can automatically find new senses from text and then relate these to WordNet synsets, as Ciaramita and Johnson (2003) and Curran (2005) do with unknown nouns.</S> | Reference Offset: ['147','18','36'] | Reference Text: <S sid="18" ssid="18">These problems demonstrate the need for automatic or semiautomatic methods for the creation and maintenance of lexical-semantic resources.</S> <S sid="36" ssid="10">There are 11 unique beginners in the WORDNET noun hierarchy which could also be used as supersenses.</S> <S sid="147" ssid="1">Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 4 | Reference Article: P05-1004.xml | Citing Article: J09-3004.xml | Citation Marker Offset: ['446'] | Citation Marker: Curran 2005 | Citation Offset: ['446'] | Citation Text: <S sid ="446" ssid = "30">An additional potential is to integrate automatically acquired relationships with the information found in WordNet, which seems to suffer from several serious limitations (Curran 2005), and typically overlaps to a rather limited extent with the output of automatic acquisition methods.</S> | Reference Offset: ['1','18','231'] | Reference Text: <S sid="1" ssid="1">The limited coverage of lexical-semantic resources is a significant problem for NLP systems which can be alleviated by automatically classifying the unknown words.</S> <S sid="18" ssid="18">These problems demonstrate the need for automatic or semiautomatic methods for the creation and maintenance of lexical-semantic resources.</S> <S sid="231" ssid="7">Such a corpus is needed to acquire reliable contextual information for the often very rare nouns we are attempting to supersense tag.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 5 | Reference Article: P05-1004.xml | Citing Article: N06-1017.xml | Citation Marker Offset: ['26'] | Citation Marker: Curran, 2005 | Citation Offset: ['26'] | Citation Text: <S sid ="26" ssid = "26">There are, however, approaches to the complementary problem of determining the closest known sense for unknown words (Widdows, 2003; Curran, 2005; Burchardt et al., 2005), which can be viewed as the logical next step after unknown sense detection.</S> | Reference Offset: ['147','186','154'] | Reference Text: <S sid="147" ssid="1">Our approach uses voting across the known supersenses of automatically extracted synonyms, to select a super- sense for the unknown nouns.</S> <S sid="154" ssid="8">The problem now becomes how to convert the ranked list of extracted synonyms for each unknown noun into a single supersense selection.</S> <S sid="186" ssid="16">This is determined by looking at the frequency and number of attributes for the unknown word.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 6 | Reference Article: P05-1004.xml | Citing Article: N06-1017.xml | Citation Marker Offset: ['189'] | Citation Marker: Curran, 2005 | Citation Offset: ['189'] | Citation Text: <S sid ="189" ssid = "11">Possibilities include associating items with similar existing senses (Widdows, 2003; Curran, 2005; Burchardt et al., 2005) or clustering them into approximate senses.</S> | Reference Offset: ['106','57','9'] | Reference Text: <S sid="9" ssid="9">Lexicographers cannot possibly keep pace with language evolution: sense distinctions are continually made and merged, words are coined or become obsolete, and technical terms migrate into the vernacular.</S> <S sid="57" ssid="10">This suggests it will only be possible to add words to an existing abstract structure rather than create categories right up to the unique beginners.</S> <S sid="106" ssid="20">JACCARD and TTEST produced better quality synonyms than existing measures in the literature, so we use Curran and MoenÃḃÂÂs configuration for our super- sense tagging experiments.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 7 | Reference Article: P05-1004.xml | Citing Article: N07-1024.xml | Citation Marker Offset: ['83'] | Citation Marker: Curran 2005 | Citation Offset: ['83'] | Citation Text: <S sid ="83" ssid = "3">While contextual information is the primary source of information used in WSD research and has been used for acquiring semantic lexicons and classifying unknown words in other languages (e.g., Roark and Charniak 1998; Ci aramita 2003; Curran 2005)</S> | Reference Offset: ['231','94','47'] | Reference Text: <S sid="47" ssid="21">Supersense tagging is also interesting for many applications that use shallow semantics, e.g. information extraction and question answering.</S> <S sid="94" ssid="8">The efficiency of the SEXTANT approach makes the extraction of contextual information from over 2 billion words of raw text feasible.</S> <S sid="231" ssid="7">Such a corpus is needed to acquire reliable contextual information for the often very rare nouns we are attempting to supersense tag.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 8 | Reference Article: P05-1004.xml | Citing Article: P12-2050.xml | Citation Marker Offset: ['15'] | Citation Marker: Curran, 2005 | Citation Offset: ['15'] | Citation Text: <S sid ="15" ssid = "15">More re cently, the task of automatic supersense tagging has emerged for English (Ciaramita and Johnson, 2003; Curran, 2005; Ciaramita and Altun, 2006; PaaÃÂÃáẃ and Reichartz, 2009), as well as for Italian (Picca et al., 2008; Picca et al., 2009; Attardi et al., 2010) and Chinese (Qiu et al., 2011), languages with WordNetsmapped to English WordNet.3 In principle, we be lieve supersenses ought to apply to nouns and verbsin any language, and need not depend on the avail ability of a semantic lexicon.4 In this work we focuson the noun SSTs, summarized in figure 2 and ap plied to an Arabic sentence in figure 1.</S> | Reference Offset: ['6','15','225'] | Reference Text: <S sid="6" ssid="6">Lexical-semantic resources have been applied successful to a wide range of Natural Language Processing (NLP) problems ranging from collocation extraction (Pearce, 2001) and class-based smoothing (Clark and Weir, 2002), to text classification (Baker and McCallum, 1998) and question answering (Pasca and Harabagiu, 2001).</S> <S sid="15" ssid="15">By WORDNET 2.0, coverage has improved but the problem of keeping up with language evolution remains difficult.</S> <S sid="225" ssid="1">Our application of semantic similarity to supersense tagging follows earlier work by Hearst and SchuÃáẃ tze (1993) and Widdows (2003).</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 9 | Reference Article: P05-1004.xml | Citing Article: S07-1032.xml | Citation Marker Offset: ['16'] | Citation Marker: Curran, 2005 | Citation Offset: ['16'] | Citation Text: <S sid ="16" ssid = "16">Thus, some research has been focused on deriving different sense groupings to overcome the fineÃáẁÃḃÂáṠĠÃḃÂÂ grained distinctions of WN (Hearst and SchuÃÂÃáẃ tze, 1993) (Peters et al., 1998) (Mihalcea and Moldo- van, 2001) (Agirre et al., 2003) and on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997) (Ciaramita and Johnson, 2003) (Villarejo et al., 2005) (Curran, 2005) (Ciaramita and Altun, 2006).</S> | Reference Offset: ['30','65','31'] | Reference Text: <S sid="30" ssid="4">Lex-files form a set of coarse-grained sense distinctions within WORDNET.</S> <S sid="31" ssid="5">For example, company appears in the following lex-files in WORDNET 2.0: group, which covers company in the social, commercial and troupe fine-grained senses; and state, which covers companionship.</S> <S sid="65" ssid="18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 10 | Reference Article: P05-1004.xml | Citing Article: S10-1090.xml | Citation Marker Offset: ['16'] | Citation Marker: Curran, 2005 | Citation Offset: ['16'] | Citation Text: <S sid ="16" ssid = "16">In contrast, some research have been focused on using predefined sets of sense-groupings for learning class-based classifiers for WSD (Segond et al., 1997), (Ciaramita and Johnson, 2003), (Villarejo et al., 2005), (Curran, 2005), (Kohomban and Lee, 2005) and (Ciaramita and Altun, 2006).</S> | Reference Offset: ['65','7','226'] | Reference Text: <S sid="7" ssid="7">In particular, WORDNET (Fellbaum, 1998) has significantly influenced research in NLP.</S> <S sid="65" ssid="18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> <S sid="226" ssid="2">To classify a previously unseen common noun our approach extracts synonyms which vote using their supersenses in WORDNET 1.6.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 11 | Reference Article: P05-1004.xml | Citing Article: S12-1011.xml | Citation Marker Offset: ['6'] | Citation Marker: Curran, 2005 | Citation Offset: ['6'] | Citation Text: <S sid ="6" ssid = "6">Distributed representations are useful in capturing such meaning for individual words (Sato et al., 2008; Maas and Ng, 2010; Curran, 2005).</S> | Reference Offset: ['53','87','217'] | Reference Text: <S sid="53" ssid="6">The other measure they found to be successful was the entropy of the conditional distribution of surrounding words given the noun.</S> <S sid="87" ssid="1">Similarity Vector-space models of similarity are based on the distributional hypothesis that similar words appear in similar contexts.</S> <S sid="217" ssid="15">Firstly, we do not include proper names in our similarity system which means that location entities can be very difficult to identify correctly (as the results demonstrate).</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 12 | Reference Article: P05-1004.xml | Citing Article: S12-1011.xml | Citation Marker Offset: ['50'] | Citation Marker: Curran, 2005 | Citation Offset: ['50'] | Citation Text: <S sid ="50" ssid = "2">Supersense tagging (Ciaramita and Johnson, 2003; Curran, 2005) evaluates a modelÃáẁÃḃÂáṠĠÃḃÂáẁs ability to cluster words by their semantics.</S> | Reference Offset: ['69','68','64'] | Reference Text: <S sid="64" ssid="17">This same technique as is used in our approach to supersense tagging.</S> <S sid="68" ssid="1">Ciaramita and Johnson (2003) propose a very natural evaluation for supersense tagging: inserting the extra common nouns that have been added to a new version of WORDNET.</S> <S sid="69" ssid="2">They use the common nouns that have been added to WORDNET 1.7.1 since WORDNET 1.6 and compare this evaluation with a standard cross-validation approach that uses a small percentage of the words from their WORDNET 1.6 training set for evaluation.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 13 | Reference Article: P05-1004.xml | Citing Article: S12-1023.xml | Citation Marker Offset: ['234'] | Citation Marker: Curran, 2005 | Citation Offset: ['234'] | Citation Text: <S sid ="234" ssid = "15">A concept analogous to our notion of meta sense (i.e., senses beyond single words) has been used in previous work on class-based WSD (Yarowsky, 1992; Curran, 2005; Izquierdo et al., 2009), and indeed, the CAM might be used for class-based WSD as well.</S> | Reference Offset: ['65','61','6'] | Reference Text: <S sid="6" ssid="6">Lexical-semantic resources have been applied successful to a wide range of Natural Language Processing (NLP) problems ranging from collocation extraction (Pearce, 2001) and class-based smoothing (Clark and Weir, 2002), to text classification (Baker and McCallum, 1998) and question answering (Pasca and Harabagiu, 2001).</S> <S sid="61" ssid="14">Further, they also use the same vector-space techniques to label previously unseen words using the most common class assigned to the top 20 synonyms for that word.</S> <S sid="65" ssid="18">Ciaramita and Johnson (2003) implement a super- sense tagger based on the multi-class perceptron classifier (Crammer and Singer, 2001), which uses the standard collocation, spelling and syntactic features common in WSD and named entity recognition systems.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


Citance Number: 14 | Reference Article: P05-1004.xml | Citing Article: W06-1670.xml | Citation Marker Offset: ['94'] | Citation Marker: Curran, 2005 | Citation Offset: ['94'] | Citation Text: <S sid ="94" ssid = "12">Previous work on prediction at the supersense level (Ciaramita and Johnson, 2003; Curran, 2005) has focused on lexical acquisition (nouns exclusively), thus aiming at word type classification rather than tagging.</S> | Reference Offset: ['225','64','226'] | Reference Text: <S sid="64" ssid="17">This same technique as is used in our approach to supersense tagging.</S> <S sid="225" ssid="1">Our application of semantic similarity to supersense tagging follows earlier work by Hearst and SchuÃáẃ tze (1993) and Widdows (2003).</S> <S sid="226" ssid="2">To classify a previously unseen common noun our approach extracts synonyms which vote using their supersenses in WORDNET 1.6.</S> | Discourse Facet: Method_Citation | Annotator: Sweta Kumari


