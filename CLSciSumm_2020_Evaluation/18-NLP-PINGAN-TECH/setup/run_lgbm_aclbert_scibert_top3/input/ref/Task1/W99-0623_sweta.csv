Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,W99-0623,A00-2005,0,Henderson and Brill (1999),0,1 Introduct ion Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,144'," <S sid=""144"" ssid=""6"">Combining multiple highly-accurate independent parsers yields promising results.</S>",Method Citation
2,W99-0623,A00-2005,0,Henderson and Brill (1999),0,the collection of hypotheses ti =fi (Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999),"Given a novel sentence Stest E Ctest, combine the collection of hypotheses ti = fi(Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999)",125'," <S sid=""125"" ssid=""54"">The constituent voting and na&#239;ve Bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers.</S>",Method Citation
4,W99-0623,N10-1091,0,"(Henderson and Brill,1999)",0,"5 (Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","(Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers",125',"<S sid=""125"" ssid=""54"">The constituent voting and na&#239;ve Bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers.</S>",Method Citation
5,W99-0623,W05-1518,0,"(Henderson and Brill,1999)",0,"A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)",48',"    <S sid=""48"" ssid=""34"">&#8226; Similarly, when the na&#239;ve Bayes classifier is configured such that the constituents require estimated probabilities strictly larger than 0.5 to be accepted, there is not enough probability mass remaining on crossing brackets for them to be included in the hypothesis.</S>",Method Citation
6,W99-0623,W05-1518,0,"(Henderson and Brill,1999)",0,"This approach roughly corresponds to (Henderson and Brill, 1999)? s Na ?ve Bayes parse hybridization","This approach roughly corresponds to (Henderson and Brill, 1999)'s Naive Bayes parse hybridization",139'," <S sid=""139"" ssid=""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S>",Method Citation
7,W99-0623,W05-1518,0,Henderson and Brill (1999),0,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,134',"<S sid=""134"" ssid=""63"">As seen by the drop in average individual parser performance baseline, the introduced parser does not perform very well.</S>",Method Citation
8,W99-0623,W05-1518,0,"(Henderson and Brill,1999)",0,"(Henderson and Brill, 1999) improved their best parser? s F-measure of 89.7 to 91.3, using their na ?ve Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","(Henderson and Brill, 1999) improved their best parser's F-measure of 89.7 to 91.3, using their naive Bayes voting on the Penn TreeBank constituent structures (16% error reduction)",38'," <S sid=""38"" ssid=""24"">Under certain conditions the constituent voting and na&#239;ve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S>",Method Citation
10,W99-0623,P01-1005,0,"(Henderson and Brill,1999)",0,"Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)",120',"    <S sid=""120"" ssid=""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S>",Method Citation
11,W99-0623,D09-1161,0,Henderson and Brill (1999),0,"Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees",139',"<S sid=""139"" ssid=""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S>",Method Citation
12,W99-0623,D09-1161,0,Henderson and Brill (1999),0,"Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper",13',"<S sid=""13"" ssid=""9"">These three parsers have given the best reported parsing results on the Penn Treebank Wall Street Journal corpus (Marcus et al., 1993).</S>",Method Citation
13,W99-0623,D09-1161,0,"(Henderson and Brill,1999)",0,"Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)",108',"<S sid=""108"" ssid=""37"">From this we see that a finer-grained model for parser combination, at least for the features we have examined, will not give us any additional power.</S>",Method Citation
14,W99-0623,N06-2033,0,Henderson and Brill (1999),0,"Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees",139',"<S sid=""139"" ssid=""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S>",Method Citation
15,W99-0623,N09-2064,0,"(Henderson and Brill,1999)",0,"(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined",98',"<S sid=""98"" ssid=""27"">Adding the isolated constituents to our hypothesis parse could increase our expected recall, but in the cases we investigated it would invariably hurt our precision more than we would gain on recall.</S>",Method Citation
16,W99-0623,N09-2064,0,"(Henderson and Brill,1999)",0,"(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents",27',"<S sid=""27"" ssid=""13"">Another technique for parse hybridization is to use a na&#239;ve Bayes classifier to determine which constituents to include in the parse.</S>",Method Citation
17,W99-0623,N09-2064,0,"(Henderson and Brill,1999)",0,"output (Figure 3) .Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework. Third, we extend these parser combination methods from 1-best outputs to n-best outputs","Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework","80','81','82'","<S sid=""80"" ssid=""9"">For our experiments we also report the mean of precision and recall, which we denote by (P + R)I2 and F-measure.</S>
    <S sid=""81"" ssid=""10"">F-measure is the harmonic mean of precision and recall, 2PR/(P + R).</S>
    <S sid=""82"" ssid=""11"">It is closer to the smaller value of precision and recall when there is a large skew in their values.</S>",Method Citation
18,W99-0623,P09-1065,0,"(Henderson and Brill,1999)",0,"System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))",49',"<S sid=""49"" ssid=""35"">In general, the lemma of the previous section does not ensure that all the productions in the combined parse are found in the grammars of the member parsers.</S>",Method Citation
19,W99-0623,N03-1004,0,"(Henderson and Brill,1999)",0,"In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994)","In NLP, such methods have been applied to tasks such as POS tagging (Brill and Wu, 1998), word sense disambiguation (Pedersen, 2000), parsing (Henderson and Brill, 1999), and machine translation (Frederking and Nirenburg, 1994)",11',"<S sid=""11"" ssid=""7"">Similar advances have been made in machine translation (Frederking and Nirenburg, 1994), speech recognition (Fiscus, 1997) and named entity recognition (Borthwick et al., 1998).</S>",Method Citation
20,W99-0623,C10-1151,0,Henderson and Brill (1999),0,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,98',"<S sid=""98"" ssid=""27"">Adding the isolated constituents to our hypothesis parse could increase our expected recall, but in the cases we investigated it would invariably hurt our precision more than we would gain on recall.</S>",Method Citation
