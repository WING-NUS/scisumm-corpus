This paper proposes a framework for representing
the meaning of phrases and sentences
in vector space. Central to our approach is
vector composition which we operationalize
in terms of additive and multiplicative functions.
Under this framework, we introduce a
wide range of composition models which we
evaluate empirically on a sentence similarity
task. Experimental results demonstrate that
the multiplicative models are superior to the
additive alternatives when compared against
human judgments.