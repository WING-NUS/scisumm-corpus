This paper talks about Exploiting Diversity in Natural Language Processing: Combining Parsers. Two general approaches are presented and two combination techniques are described for each approach. Here both parametric and non-parametric models are explored. One can trivially create situations in which strictly binary-branching trees are combined to create a tree with only the root node and the terminal nodes, a completely flat structure. The three parsers were trained and tuned by their creators on various sections of the WSJ portion of the Penn Treebank. Through parser combination we have reduced the precision error rate by 30% and the recall error rate by 6% compared to the best previously published result. Combining multiple highly-accurate independent parsers yields promising results. 