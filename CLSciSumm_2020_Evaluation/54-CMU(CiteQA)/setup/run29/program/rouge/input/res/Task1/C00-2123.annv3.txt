Citance Number: 1 | Reference Article: C00-2123.xml | Citing Article: C02-1050.xml | Citation Marker Offset: ['41'] | Citation Marker: 2000 | Citation Offset: ['41'] | Citation Text: <S sid ="39" ssid = "19">Under this constraint, many researchers had contributed algorithms and associated pruning strategies, such as Berger et al.</S><S sid ="40" ssid = "20">(1996), Och et al.</S><S sid ="41" ssid = "21">(2001), Wang and Waibel (1997), Tillmann and Ney (2000) GarciaVarea and Casacuberta (2001) and Germann et al.</S> | Reference Offset: ['173','23','180'] | Reference Text: <S sid="23" ssid="7">In many cases, there is an even stronger restriction: over large portions of the source string, the alignment is monotone.</S> <S sid="173" ssid="33">Here, the pruning threshold t0 = 10:0 is used.</S> <S sid="180" ssid="40">The effect of the pruning threshold t0 is shown in Table 5.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 2 | Reference Article: C00-2123.xml | Citing Article: C02-1050.xml | Citation Marker Offset: ['8'] | Citation Marker: Tillman and Ney, 2000 | Citation Offset: ['8'] | Citation Text: <S sid ="8" ssid = "8">There exists stack decoding algorithm (Berger et al., 1996), A* search algorithm (Och et al., 2001; Wang and Waibel, 1997) and dynamic-programming algorithms (Tillmann and Ney, 2000; GarciaVarea and Casacuberta, 2001), and all translate a given input string word-by-word and render the translation in left-to-right, with pruning technologies assuming almost linearly aligned translation source and target texts.</S> | Reference Offset: ['5','124','82'] | Reference Text: <S sid="5" ssid="5">The goal of machine translation is the translation of a text given in some source language into a target language.</S> <S sid="82" ssid="45">The complexity of the algorithm is O(E3 J2 2J), where E is the size of the target language vocabulary.</S> <S sid="124" ssid="87">Source sentence words are aligned with hypothesized target sentence words, where the choice of a new source word, which has not been aligned with a target word yet, is restricted1.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 3 | Reference Article: C00-2123.xml | Citing Article: C02-1050.xml | Citation Marker Offset: ['43'] | Citation Marker: 2000 | Citation Offset: ['43'] | Citation Text: <S sid ="43" ssid = "1">The decoding methods presented in this paper explore the partial candidate translation hypotheses greedily, as presented in Tillmann and Ney (2000) and Och et al.</S> | Reference Offset: ['192','105','3'] | Reference Text: <S sid="3" ssid="3">A search restriction especially useful for the translation direction from German to English is presented.</S> <S sid="105" ssid="68">A position is presented by the word at that position.</S> <S sid="192" ssid="1">In this paper, we have presented a new, eÃÂcient DP-based search procedure for statistical machine translation.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 4 | Reference Article: C00-2123.xml | Citing Article: C02-1050.xml | Citation Marker Offset: ['80'] | Citation Marker: 2000 | Citation Offset: ['80'] | Citation Text: <S sid ="80" ssid = "38">The computational complexity for the left-to-right and right-to-left is the same, O(|E|3m22m ), as reported by Tillmann and Ney (2000), in which |E| is the size of the vocabulary for output sentences 3.</S> | Reference Offset: ['82','94','91'] | Reference Text: <S sid="82" ssid="45">The complexity of the algorithm is O(E3 J2 2J), where E is the size of the target language vocabulary.</S> <S sid="91" ssid="54">In German, the verbgroup usually consists of a left and a right verbal brace, whereas in English the words of the verbgroup usually form a sequence of consecutive words.</S> <S sid="94" ssid="57">When translating the sentence monotonically from left to right, the translation of the German finite verb &apos;kann&apos;, which is the left verbal brace in this case, is postponed until the German noun phrase &apos;mein Kollege&apos; is translated, which is the subject of the sentence.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 5 | Reference Article: C00-2123.xml | Citing Article: C04-1091.xml | Citation Marker Offset: ['22'] | Citation Marker: Tillman and Ney, 2000 | Citation Offset: ['22'] | Citation Text: <S sid ="22" ssid = "22">Tillman and Ney showed how to improve the complexity of the Held-Karp algorithm for restricted word reordering and gave a O (l3m4) ÃḃÂÂ O (m7) algo rithm for French-English translation (Tillman and Ney, 2000).</S> | Reference Offset: ['43','82','3'] | Reference Text: <S sid="3" ssid="3">A search restriction especially useful for the translation direction from German to English is presented.</S> <S sid="43" ssid="6">However, dynamic programming can be used to find the shortest tour in exponential time, namely in O(n22n), using the algorithm by Held and Karp.</S> <S sid="82" ssid="45">The complexity of the algorithm is O(E3 J2 2J), where E is the size of the target language vocabulary.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 6 | Reference Article: C00-2123.xml | Citing Article: E06-1004.xml | Citation Marker Offset: ['22'] | Citation Marker: Tillman, 2000 | Citation Offset: ['22'] | Citation Text: <S sid ="21" ssid = "21">ÃáẁÃḃÂáṠĠÃáẁ Conditional Probability Given the model parameters and a sentence pair (f , e), compute P (f |e).</S><S sid ="22" ssid = "22">1997), (Tillman, 2000), (Och et al., 2001), (Germann et al., 2003), (Udupa et al., 2004).</S> | Reference Offset: ['21','172','112'] | Reference Text: <S sid="21" ssid="5">The alignment model uses two kinds of parameters: alignment probabilities p(aj jajÃṀÂÂÂ1; I; J), where the probability of alignment aj for position j depends on the previous alignment position ajÃṀÂÂÂ1 (Ney et al., 2000) and lexicon probabilities p(fj jeaj ).</S> <S sid="112" ssid="75">Covering the first uncovered position in the source sentence, we use the language model probability p(ej$; $).</S> <S sid="172" ssid="32">The computing time is given in terms of CPU time per sentence (on a 450MHz PentiumIIIPC).</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 7 | Reference Article: C00-2123.xml | Citing Article: H01-1062.xml | Citation Marker Offset: ['113'] | Citation Marker: 20 | Citation Offset: ['113'] | Citation Text: <S sid ="113" ssid = "16">To summarize these experimental tests, we briefly report experimental offline results for the following translation approaches: ÃáẁÃḃÂáṠĠÃáẁ single-word based approach [20];</S> | Reference Offset: ['4','122','194'] | Reference Text: <S sid="4" ssid="4">The experimental tests are carried out on the Verbmobil task (GermanEnglish, 8000-word vocabulary), which is a limited-domain spoken-language task.</S> <S sid="122" ssid="85">Restrictions We compare our new approach with the word reordering used in the IBM translation approach (Berger et al., 1996).</S> <S sid="194" ssid="3">The approach has been successfully tested on the 8 000-word Verbmobil task.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 8 | Reference Article: C00-2123.xml | Citing Article: J03-1005.xml | Citation Marker Offset: ['117'] | Citation Marker: 2000 | Citation Offset: ['115','117'] | Citation Text: <S sid ="115" ssid = "73">This article will present a DP-based beam search decoder for the IBM4 translation model.</S><S sid ="117" ssid = "75">A preliminary version of the work presented here was published in Tillmann and Ney (2000).</S> | Reference Offset: ['192','105','2'] | Reference Text: <S sid="2" ssid="2">Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÃÂcient search algorithm.</S> <S sid="105" ssid="68">A position is presented by the word at that position.</S> <S sid="192" ssid="1">In this paper, we have presented a new, eÃÂcient DP-based search procedure for statistical machine translation.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 9 | Reference Article: C00-2123.xml | Citing Article: J04-2003.xml | Citation Marker Offset: ['35'] | Citation Marker: Tillmann and Ney 2000 | Citation Offset: ['35'] | Citation Text: <S sid ="35" ssid = "35">Many existing systems for statistical machine translation 1 1 (GarcÃáṗÃáẁa-Varea and Casacuberta 2001; Germann et al. 2001; NieÃÂen et al. 1998; Och, Tillmann, and Ney 1999) implement models presented by Brown, Della Pietra, Della Pietra, and Mercer (1993): The correspondence between the words in the source and the target strings is described by alignments that assign target word positions to each source word position.</S> | Reference Offset: ['105','124','9'] | Reference Text: <S sid="9" ssid="9">The model is often further restricted so that each source word is assigned to exactly one target word (Brown et al., 1993; Ney et al., 2000).</S> <S sid="105" ssid="68">A position is presented by the word at that position.</S> <S sid="124" ssid="87">Source sentence words are aligned with hypothesized target sentence words, where the choice of a new source word, which has not been aligned with a target word yet, is restricted1.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 10 | Reference Article: C00-2123.xml | Citing Article: J04-2003.xml | Citation Marker Offset: ['235'] | Citation Marker: Tillmann and Ney 2000 | Citation Offset: ['235'] | Citation Text: <S sid ="235" ssid = "35">Some recent publications deal with the automatic detection of multiword phrases (Och and Weber 1998; Tillmann and Ney 2000).</S> | Reference Offset: ['157','94','158'] | Reference Text: <S sid="94" ssid="57">When translating the sentence monotonically from left to right, the translation of the German finite verb &apos;kann&apos;, which is the left verbal brace in this case, is postponed until the German noun phrase &apos;mein Kollege&apos; is translated, which is the subject of the sentence.</S> <S sid="157" ssid="17">On average, 6 reference translations per automatic translation are available.</S> <S sid="158" ssid="18">The Levenshtein distance between the automatic translation and each of the reference translations is computed, and the minimum Levenshtein distance is taken.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 11 | Reference Article: C00-2123.xml | Citing Article: J04-4002.xml | Citation Marker Offset: ['282'] | Citation Marker: Tillmann and Ney 2000 | Citation Offset: ['282'] | Citation Text: <S sid ="282" ssid = "48">We call this selection of highly probable words observation pruning (Tillmann and Ney 2000).</S> | Reference Offset: ['22','173','180'] | Reference Text: <S sid="22" ssid="6">When aligning the words in parallel texts (for language pairs like SpanishEnglish, French-English, ItalianGerman,...), we typically observe a strong localization effect.</S> <S sid="173" ssid="33">Here, the pruning threshold t0 = 10:0 is used.</S> <S sid="180" ssid="40">The effect of the pruning threshold t0 is shown in Table 5.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 12 | Reference Article: C00-2123.xml | Citing Article: N03-1010.xml | Citation Marker Offset: ['16'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['16'] | Citation Text: <S sid ="16" ssid = "16">Och et al. report word error rates of 68.68% for optimal search (based on a variant of the A* algorithm), and 69.65% for the most restricted version of a decoder that combines dynamic programming with a beam search (Tillmann and Ney, 2000).</S> | Reference Offset: ['174','39','50'] | Reference Text: <S sid="39" ssid="2">In order to handle the necessary word reordering as an optimization problem within our dynamic programming approach, we describe a solution to the traveling salesman problem (TSP) which is based on dynamic programming (Held, Karp, 1962).</S> <S sid="50" ssid="13">The advantage is that we can recombine search hypotheses by dynamic programming.</S> <S sid="174" ssid="34">Translation errors are reported in terms of multireference word error rate (mWER) and subjective sentence error rate (SSER).</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 13 | Reference Article: C00-2123.xml | Citing Article: P01-1027.xml | Citation Marker Offset: ['127'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['127'] | Citation Text: <S sid ="127" ssid = "34">We use the top-10 list of hypothesis provided by the translation system described in (Tillmann and Ney, 2000) for rescoring the hypothesis using the ME models and sort them according to the new maximum entropy score.</S> | Reference Offset: ['169','173','59'] | Reference Text: <S sid="59" ssid="22">For ÃÂ = 1, a new target language word is generated using the trigram language model p(eje0; e00).</S> <S sid="169" ssid="29">For each source word f, the list of its possible translations e is sorted according to p(fje) puni(e), where puni(e) is the unigram probability of the English word e. It is suÃÂcient to consider only the best 50 words.</S> <S sid="173" ssid="33">Here, the pruning threshold t0 = 10:0 is used.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 14 | Reference Article: C00-2123.xml | Citing Article: P03-1039.xml | Citation Marker Offset: ['113'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['113'] | Citation Text: <S sid ="113" ssid = "22">The decoding algorithm employed for this chunk + weight ÃÂÃḃÂÂ j f req(EA j , J j ) based statistical translation is based on the beam search algorithm for word alignment statistical in which Ptm(J|E) and Plm (E) are translationmodel and language model probability, respec translation presented in (Tillmann and Ney, 2000), tively1 , f req(EA j , J j ) is the frequency for the which generates outputs in left-to-right order by consuming input in an arbitrary order.</S> | Reference Offset: ['192','2','1'] | Reference Text: <S sid="1" ssid="1">In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</S> <S sid="2" ssid="2">Starting from a DP-based solution to the traveling salesman problem, we present a novel technique to restrict the possible word reordering between source and target language in order to achieve an eÃÂcient search algorithm.</S> <S sid="192" ssid="1">In this paper, we have presented a new, eÃÂcient DP-based search procedure for statistical machine translation.</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 15 | Reference Article: C00-2123.xml | Citing Article: P03-1039.xml | Citation Marker Offset: ['120'] | Citation Marker: Tillman and Ney, 2000 | Citation Offset: ['120'] | Citation Text: <S sid ="120" ssid = "29">The generation of possible output chunks is estimated through an inverted lexicon model and sequences of inserted strings (Tillmann and Ney, 2000).</S> | Reference Offset: ['28','35','59'] | Reference Text: <S sid="28" ssid="12">The inverted alignment probability p(bijbiÃṀÂÂÂ1; I; J) and the lexicon probability p(fbi jei) are obtained by relative frequency estimates from the Viterbi alignment path after the final training iteration.</S> <S sid="35" ssid="19">An extended lexicon model is defined, and its likelihood is compared to a baseline lexicon model, which takes only single-word dependencies into account.</S> <S sid="59" ssid="22">For ÃÂ = 1, a new target language word is generated using the trigram language model p(eje0; e00).</S> | Discourse Facet: ['Implication_Citation','Method_Citation'] | Annotator: Swastika Bhattacharya


Citance Number: 16 | Reference Article: C00-2123.xml | Citing Article: W01-0505.xml | Citation Marker Offset: ['13'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['13'] | Citation Text: <S sid ="13" ssid = "13">They were usually incorporated in the EM algorithm (Brown et al., 1993; Kupiec, 1993; Tillmann and Ney, 2000; Och et al., 2000).</S> | Reference Offset: ['91','82','46'] | Reference Text: <S sid="46" ssid="9">The algorithm works due to the fact that not all permutations of cities have to be considered explicitly.</S> <S sid="82" ssid="45">The complexity of the algorithm is O(E3 J2 2J), where E is the size of the target language vocabulary.</S> <S sid="91" ssid="54">In German, the verbgroup usually consists of a left and a right verbal brace, whereas in English the words of the verbgroup usually form a sequence of consecutive words.</S> | Discourse Facet: Implication_Citation | Annotator: Swastika Bhattacharya


Citance Number: 17 | Reference Article: C00-2123.xml | Citing Article: W01-1404.xml | Citation Marker Offset: ['5'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['5'] | Citation Text: <S sid ="5" ssid = "5">Some of these studies have concentrated on finite-state or extended finite-state machinery, such as (Vilar and others, 1999), others have chosen models closer to context-free grammars and context-free transduction, such as (Alshawi et al., 2000; Watanabe et al., 2000; Yamamoto and Matsumoto, 2000), and yet other studies cannot be comfortably assigned to either of these two frameworks, such as (Brown and others, 1990) and (Tillmann and Ney, 2000).</S> | Reference Offset: ['137','195','128'] | Reference Text: <S sid="128" ssid="91">During the search process, a partial hypothesis is extended by choosing a source sentence position, which has not been aligned with a target sentence position yet.</S> <S sid="137" ssid="100">In this case, we have no finite-state restrictions for the search space.</S> <S sid="195" ssid="4">Future extensions of the system might include: 1) An extended translation model, where we use more context to predict a source word.</S> | Discourse Facet: Implication_Citation | Annotator: Swastika Bhattacharya


Citance Number: 18 | Reference Article: C00-2123.xml | Citing Article: W01-1407.xml | Citation Marker Offset: ['110'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['110'] | Citation Text: <S sid ="110" ssid = "26">We used a translation system called ÃáẁÃḃÂáṠĠÃÂsingle- word based approachÃáẁÃḃÂáṠĠ described in (Tillmann and Ney, 2000) and compared to other approaches in (Ney et al., 2000).</S> | Reference Offset: ['122','8','1'] | Reference Text: <S sid="1" ssid="1">In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</S> <S sid="8" ssid="8">Our approach uses word-to-word dependencies between source and target words.</S> <S sid="122" ssid="85">Restrictions We compare our new approach with the word reordering used in the IBM translation approach (Berger et al., 1996).</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 19 | Reference Article: C00-2123.xml | Citing Article: W01-1408.xml | Citation Marker Offset: ['47'] | Citation Marker: Tillmann, 2001; Tillmann and Ney, 2000 | Citation Offset: ['47'] | Citation Text: <S sid ="47" ssid = "23">Search algorithms We evaluate the following two search algorithms: ÃáẁÃḃÂáṠĠÃáẁ beam search algorithm (BS): (Tillmann, 2001; Tillmann and Ney, 2000) In this algorithm the search space is explored in a breadth-first manner.</S> | Reference Offset: ['82','184','186'] | Reference Text: <S sid="82" ssid="45">The complexity of the algorithm is O(E3 J2 2J), where E is the size of the target language vocabulary.</S> <S sid="184" ssid="44">Depending on the threshold t0, the search algorithm may miss the globally optimal path which typically results in additional translation errors.</S> <S sid="186" ssid="46">Table 5: Effect of the beam threshold on the number of search errors (147 sentences).</S> | Discourse Facet: Method_Citation | Annotator: Swastika Bhattacharya


Citance Number: 20 | Reference Article: C00-2123.xml | Citing Article: W02-1020.xml | Citation Marker Offset: ['62'] | Citation Marker: Tillmann and Ney, 2000 | Citation Offset: ['61','62'] | Citation Text: <S sid ="61" ssid = "19">It is faster because the search problem for noisy- channel models is NP-complete (Knight, 1999), and even the fastest dynamic-programming heuristics used in statistical MT (Niessen et al., 1998; Till- mann and Ney, 2000), are polynomial in J ÃḃÂÂfor in p(v1, w2</S><S sid ="62" ssid = "20">, wmÃḃÂÂ1, um|h, s) = stance O(mJ 4V 3) in (Tillmann and Ney, 2000).</S> | Reference Offset: ['1','39','12'] | Reference Text: <S sid="1" ssid="1">In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP).</S> <S sid="12" ssid="12">A simple extension will be used to handle this problem.</S> <S sid="39" ssid="2">In order to handle the necessary word reordering as an optimization problem within our dynamic programming approach, we describe a solution to the traveling salesman problem (TSP) which is based on dynamic programming (Held, Karp, 1962).</S> | Discourse Facet: ['Aim_Citation','Method_Citation'] | Annotator: Swastika Bhattacharya


