Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P11-1061,P11-1144,0,2011,0,Subramanya et al? s model was extended by Das and Petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers,Subramanya et al's model was extended by Das and Petrov (2011) to induce part-of-speech dictionaries for unsupervised learning of taggers,"'0','74','29'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""74"">This stage of label propagation results in a tag distribution ri over labels y, which encodes the proportion of times the middle word of ui E Vf aligns to English words vy tagged with label y: The second stage consists of running traditional label propagation to propagate labels from these peripheral vertices Vf� to all foreign language vertices in the graph, optimizing the following objective: 5 POS Induction After running label propagation (LP), we compute tag probabilities for foreign word types x by marginalizing the POS tag distributions of foreign trigrams ui = x− x x+ over the left and right context words: where the qi (i = 1, ... , |Vf|) are the label distributions over the foreign language vertices and µ and ν are hyperparameters that we discuss in §6.4.</S><S ssid=""1"" sid=""29"">To establish a soft correspondence between the two languages, we use a second similarity function, which leverages standard unsupervised word alignment statistics (§3.3).3 Since we have no labeled foreign data, our goal is to project syntactic information from the English side to the foreign side.</S>",['method_citation']
3,P11-1061,P14-1126,0,2011,0,"Fortunately, some recently proposed POS taggers, such as the POStagger of Das and Petrov (2011), rely only on labeled training data for English and the same kind of parallel text in our approach","Fortunately, some recently proposed POS taggers, such as the POS tagger of Das and Petrov (2011), rely only on labeled training data for English and the same kind of parallel text in our approach","'0','24','25'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""24"">The focus of this work is on building POS taggers for foreign languages, assuming that we have an English POS tagger and some parallel text between the two languages.</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S>",['method_citation']
4,P11-1061,N12-1086,0,"Das and Petrov, 2011",0,"Applications have ranged from domain adaptation of part-of-speech (POS) taggers (Subramanya et al, 2010), unsupervised learning ofPOS taggers by using bilingual graph-based projections (Das and Petrov, 2011), and shallow semantic parsing for unknown predicates (Das and Smith,2011)","Applications have ranged from domain adaptation of part-of-speech (POS) taggers (Subramanya et al, 2010), unsupervised learning of POS taggers by using bilingual graph-based projections (Das and Petrov, 2011), and shallow semantic parsing for unknown predicates (Das and Smith,2011)","'25','0','23'","<S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S><S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""23"">Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%).</S>",['method_citation']
5,P11-1061,N12-1086,0,2011,0,"Following Das and Petrov (2011) and Subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics","Following Das and Petrov (2011) and Subramanya et al (2010), a similarity score between two trigram types was computed by measuring the cosine similarity between their empirical sentential context statistics","'0','25','27'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S><S ssid=""1"" sid=""27"">Graph construction does not require any labeled data, but makes use of two similarity functions.</S>",['method_citation']
6,P11-1061,N12-1086,0,"Das and Petrov, 2011",0,"Sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type is unavailable (e.g., Das and Petrov, 2011)","Sparsity is desirable in settings where labeled development data for tuning thresholds that select the most probable labels for a given type is unavailable (e.g., Das and Petrov, 2011)","'0','74','25'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""74"">This stage of label propagation results in a tag distribution ri over labels y, which encodes the proportion of times the middle word of ui E Vf aligns to English words vy tagged with label y: The second stage consists of running traditional label propagation to propagate labels from these peripheral vertices Vf� to all foreign language vertices in the graph, optimizing the following objective: 5 POS Induction After running label propagation (LP), we compute tag probabilities for foreign word types x by marginalizing the POS tag distributions of foreign trigrams ui = x− x x+ over the left and right context words: where the qi (i = 1, ... , |Vf|) are the label distributions over the foreign language vertices and µ and ν are hyperparameters that we discuss in §6.4.</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S>",['method_citation']
7,P11-1061,N12-1052,0,2011,0,"Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. Below, we extend this approach to universal parsing by adding cross-lingual word cluster features","Specifically, by replacing fine-grained language specific part-of-speech tags with universal part-of-speech tags, generated with the method described by Das and Petrov (2011), a universal parser is achieved that can be applied to any language for which universal part-of-speech tags are available. Below, we extend this approach to universal parsing by adding cross-lingual word cluster features","'0','81','1'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""81"">Instead, we resort to an iterative update based method.</S><S ssid=""1"" sid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S>","['aim_citation', 'method_citation']"
8,P11-1061,N12-1052,0,2011,0,"We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters","We study the impact of using cross-lingual cluster features by comparing the strong delexicalized baseline model of McDonald et al (2011), which only has features derived from universal part-of-speech tags, projected from English with the method of Das and Petrov (2011), to the same model when adding features derived from cross-lingual clusters","'0','25','23'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S><S ssid=""1"" sid=""23"">Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%).</S>",['method_citation']
9,P11-1061,N12-1090,0,"Das and Petrov, (2011)",0,"MT-based projection has been applied to various NLP tasks, such as part of-speech tagging (e.g., Das and Petrov (2011)), mention detection (e.g., Zitouni and Florian (2008)), and sentiment analysis (e.g., Mihalcea et al (2007)) .There have been two initial attempts to apply projection to create co reference-annotated data for aresource-poor language, both of which involve projecting hand-annotated co reference data from English to Romanian via a parallel corpus","MT-based projection has been applied to various NLP tasks, such as part of-speech tagging (e.g., Das and Petrov (2011)), mention detection (e.g., Zitouni and Florian (2008)), and sentiment analysis (e.g., Mihalcea et al (2007))","'0','23','25'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""23"">Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%).</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S>",['method_citation']
10,P11-1061,W11-2205,0,2011,0,"For example, the multilingual PoS induction approach of Das and Petrov (2011) assumes no supervision for the language whose PoS tags are being 35 induced, but it assumes access to a labeled dataset of a different language. We begin by surveying recent work on unsupervised PoS tagging, focusing on the issue of evaluation (Section 2)","For example, the multilingual PoS induction approach of Das and Petrov (2011) assumes no supervision for the language whose PoS tags are being 35 induced, but it assumes access to a labeled dataset of a different language. We begin by surveying recent work on unsupervised PoS tagging, focusing on the issue of evaluation (Section 2)","'0','23','25'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""23"">Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%).</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S>",['method_citation']
11,P11-1061,P13-1155,0,"Das and Petrov, 2011",0,"(Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages","(Das and Petrov, 2011) used graph-based label propagation for cross-lingual knowledge transfers to induce POS tags between two languages","'0','74','16'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""74"">This stage of label propagation results in a tag distribution ri over labels y, which encodes the proportion of times the middle word of ui E Vf aligns to English words vy tagged with label y: The second stage consists of running traditional label propagation to propagate labels from these peripheral vertices Vf� to all foreign language vertices in the graph, optimizing the following objective: 5 POS Induction After running label propagation (LP), we compute tag probabilities for foreign word types x by marginalizing the POS tag distributions of foreign trigrams ui = x− x x+ over the left and right context words: where the qi (i = 1, ... , |Vf|) are the label distributions over the foreign language vertices and µ and ν are hyperparameters that we discuss in §6.4.</S><S ssid=""1"" sid=""16"">To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from English to the foreign language (§4).</S>",['method_citation']
12,P11-1061,D12-1127,0,2011,0,Recent work by Das and Petrov (2011 )buildsa dictionary for a particular language by transfer ring annotated data from a resource-rich language through the use of word alignments in parallel text,Recent work by Das and Petrov (2011 ) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in parallel text,"'29','0','25'","<S ssid=""1"" sid=""29"">To establish a soft correspondence between the two languages, we use a second similarity function, which leverages standard unsupervised word alignment statistics (§3.3).3 Since we have no labeled foreign data, our goal is to project syntactic information from the English side to the foreign side.</S><S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S>",['method_citation']
13,P11-1061,D12-1127,0,"Das and Petrov, 2011",0,"Theseapproaches build a dictionary by transferring labeled data from a resource rich language (English) to a re source poor language (Das and Petrov, 2011)","These approaches build a dictionary by transferring labeled data from a resource rich language (English) to a resource poor language (Das and Petrov, 2011)","'25','16','0'","<S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S><S ssid=""1"" sid=""16"">To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from English to the foreign language (§4).</S><S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S>",['method_citation']
14,P11-1061,P12-3012,0,"Das and Petrov, 2011",0,"In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages ,infact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntactico semantic (Peirsman and Pado?, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al, 2011)","In recent years research in Natural Language Processing (NLP) has been steadily moving towards multilingual processing: the availability of ever growing amounts of text in different languages, in fact, has been a major driving force behind research on multilingual approaches, from morphosyntactic (Das and Petrov, 2011) and syntactico semantic (Peirsman and Pado?, 2010) phenomena to high-end tasks like textual entailment (Mehdad et al., 2011) and sentiment analysis (Lu et al, 2011)","'25','16','87'","<S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S><S ssid=""1"" sid=""16"">To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from English to the foreign language (§4).</S><S ssid=""1"" sid=""87"">This locally normalized log-linear model can look at various aspects of the observation x, incorporating overlapping features of the observation.</S>",['method_citation']
15,P11-1061,D11-1006,0,2011,0,"Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of Das and Petrov (2011) .2 This tagger relies only onlabeled training data for English, and achieves accuracies around 85% on the languages that we con sider","Furthermore, we evaluate with both gold-standard part-of-speech tags, as well as predicted part-of speech tags from the projected part-of-speech tagger of Das and Petrov (2011). This tagger relies only on labeled training data for English, and achieves accuracies around 85% on the languages that we consider","'0','1','24'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""1"">We describe a novel approach for inducing unsupervised part-of-speech taggers for languages that have no labeled training data, but have translated text in a resource-rich language.</S><S ssid=""1"" sid=""24"">The focus of this work is on building POS taggers for foreign languages, assuming that we have an English POS tagger and some parallel text between the two languages.</S>","['aim_citation', 'method_citation']"
16,P11-1061,D11-1006,0,2011,0,"In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language","In the first, we assumed that the test set for each target language had gold part-of-speech tags, and in the second we used predicted part-of-speech tags from the projection tagger of Das and Petrov (2011), which also uses English as the source language","'0','16','25'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""16"">To this end, we construct a bilingual graph over word types to establish a connection between the two languages (§3), and then use graph label propagation to project syntactic information from English to the foreign language (§4).</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S>",['method_citation']
17,P11-1061,P13-2112,0,2011,0,"This parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised POS taggers. In this paper, we propose an unsupervised approach to POS tagging in a similar vein to the work of Das and Petrov (2011)","This parallel data can be exploited to bridge languages, and in particular, transfer information from a highly-resourced language to a lesser-resourced language, to build unsupervised POS taggers. In this paper, we propose an unsupervised approach to POS tagging in a similar vein to the work of Das and Petrov (2011)","'0','24','23'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""24"">The focus of this work is on building POS taggers for foreign languages, assuming that we have an English POS tagger and some parallel text between the two languages.</S><S ssid=""1"" sid=""23"">Our final average POS tagging accuracy of 83.4% compares very favorably to the average accuracy of Berg-Kirkpatrick et al.’s monolingual unsupervised state-of-the-art model (73.0%), and considerably bridges the gap to fully supervised POS tagging performance (96.6%).</S>","['aim_citation', 'method_citation']"
18,P11-1061,P13-2112,0,2011,0,Das and Petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language,Das and Petrov (2011) achieved the current state-of-the-art for unsupervised tagging by exploiting high confidence alignments to copy tags from the source language to the target language,"'0','29','25'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""29"">To establish a soft correspondence between the two languages, we use a second similarity function, which leverages standard unsupervised word alignment statistics (§3.3).3 Since we have no labeled foreign data, our goal is to project syntactic information from the English side to the foreign side.</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S>",['method_citation']
19,P11-1061,P13-2112,0,"Das and Petrov, 2011",0,"We have proposed a method for unsupervised POStagging that performs on par with the current state of-the-art (Das and Petrov, 2011), but is subs tan tially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM)","We have proposed a method for unsupervised POS tagging that performs on par with the current state of-the-art (Das and Petrov, 2011), but is substantially less-sophisticated (specifically not requiring convex optimization or a feature-based HMM)","'0','81','25'","<S ssid=""1"" sid=""0"">Unsupervised Part-of-Speech Tagging with Bilingual Graph-Based Projections</S><S ssid=""1"" sid=""81"">Instead, we resort to an iterative update based method.</S><S ssid=""1"" sid=""25"">Central to our approach (see Algorithm 1) is a bilingual similarity graph built from a sentence-aligned parallel corpus.</S>",['method_citation']
