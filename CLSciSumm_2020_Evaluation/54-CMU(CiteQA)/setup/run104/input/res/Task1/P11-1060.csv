Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P11-1060,D11-1039,0,2011,0,"Clarkeet al (2010) and Liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while Goldwasser et al (2011) presents work on unsupervised learning","Clarke et al (2010) and Liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while Goldwasser et al (2011) presents work on unsupervised learning","'1','13','5'","<S ssid=""1"" sid=""1"">Compositional question answering begins by mapping questions to logical forms, but training a semantic parser to perform this mapping typically requires the costly annotation of the target logical forms.</S><S ssid=""1"" sid=""13"">We want to induce latent logical forms z (and parameters 0) given only question-answer pairs (x, y), which is much cheaper to obtain than (x, z) pairs.</S><S ssid=""1"" sid=""5"">What is the total population of the ten largest capitals in the US?</S>",['method_citation']
2,P11-1060,P13-1092,0,2011,0,"In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance","In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance",,,"['implication_citation', 'result_citation']"
3,P11-1060,P13-1092,0,2011,0,"To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation 1Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments","To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation. Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments","'73','3','26'","<S ssid=""1"" sid=""73"">If the last (or first) child is connected via a mark relation E, C (or Q), then we strip off that child and put the appropriate information in the store by invoking M. We now define the operations mj,j0, E, Xi, M. Some helpful notation: For a sequence v = (v1,... , vn) and indices i = (i1, ... , ik), let vi = (vi1, ... , vik) be the projection of v onto i; we write v−i to mean v�1 i.</S><S ssid=""1"" sid=""3"">In tackling this challenging learning problem, we introduce a new semantic representation which highlights a parallel between dependency syntax and efficient evaluation of logical forms.</S><S ssid=""1"" sid=""26"">We then introduce the full version (Section 2.2), which handles linguistic phenomena such as quantification, where syntactic and semantic scope diverge.</S>",['method_citation']
4,P11-1060,P13-1092,0,2011,0,"More recently, Liang et al (2011 )proposedDCS for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins","More recently, Liang et al (2011) proposed DCS for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins","'51','40','65'","<S ssid=""1"" sid=""51"">It is impossible to represent the semantics of this phrase with just a CSP, so we introduce a new aggregate relation, notated E. Consider a tree hE:ci, whose root is connected to a child c via E. If the denotation of c is a set of values s, the parent’s denotation is then a singleton set containing s. Formally: Figure 3(a) shows the DCS tree for our running example.</S><S ssid=""1"" sid=""40"">The CSP has two types of constraints: (i) x ∈ w(p) for each node x labeled with predicate p ∈ P; and (ii) xj = yj0 (the j-th component of x must equal the j'-th component of y) for each edge (x, y) labeled with j0j ∈ R. A solution to the CSP is an assignment of nodes to values that satisfies all the constraints.</S><S ssid=""1"" sid=""65"">Formally, a denotation is defined as follows (see Figure 5 for an example): Definition 2 (Denotations) Let D be the set of denotations, where each d E D consists of where each store a contains a mark relation a.r E {E, Q, C, 0}, a base denotation a.b E D U{0}, and a child denotation a.c E D U{0}.</S>",['method_citation']
5,P11-1060,P13-1092,0,"Liang et al, 2011",0,"GUSP represents meaning by a semantic tree, which is similar to DCS (Liang et al, 2011)","GUSP represents meaning by a semantic tree, which is similar to DCS (Liang et al, 2011)","'51','25'","<S ssid=""1"" sid=""51"">It is impossible to represent the semantics of this phrase with just a CSP, so we introduce a new aggregate relation, notated E. Consider a tree hE:ci, whose root is connected to a child c via E. If the denotation of c is a set of values s, the parent’s denotation is then a singleton set containing s. Formally: Figure 3(a) shows the DCS tree for our running example.</S><S ssid=""1"" sid=""25"">We first present a basic version (Section 2.1) of dependency-based compositional semantics (DCS), which captures the core idea of using trees to represent formal semantics.</S>",['method_citation']
6,P11-1060,W12-2802,0,2011,0,"Matuszek et al [2010], Liang et al [2011] and Chen and Mooney [2011] describe models that learn compositional semantics, but word meanings are symbolic structures rather than patterns of features in the external world","Matuszek et al [2010], Liang et al [2011] and Chen and Mooney [2011] describe models that learn compositional semantics, but word meanings are symbolic structures rather than patterns of features in the external world",,,"['implication_citation', 'result_citation']"
7,P11-1060,P13-2009,0,"Liang et al, 2011",0,"It is well-studied in NLP, and a wide variety of methods have been proposed to tackle it ,e.g. rule-based (Popescu et al, 2003), super vised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al, 2011)","It is well-studied in NLP, and a wide variety of methods have been proposed to tackle it ,e.g. rule-based (Popescu et al, 2003), super vised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al, 2011)","'87','172','93'","<S ssid=""1"" sid=""87"">For example, in Figure 4(a), before execution, the denotation of the DCS tree is hh{[(CA, OR), (OR)],... }; ø; (E, Qhstatei�w, ø)ii; after applying X1, we have hh{[(OR)], ... }; øii.</S><S ssid=""1"" sid=""172"">Free from the burden It also allows us to easily add new lexical triggers of annotating logical forms, we hope to use our without becoming mired in the semantic formalism. techniques in developing even more accurate and Quantifiers and superlatives significantly compli- broader-coverage language understanding systems. cate scoping in lambda calculus, and often type rais- Acknowledgments We thank Luke Zettlemoyer ing needs to be employed.</S><S ssid=""1"" sid=""93"">We then superlative ambiguity based on where the scopeapply d.ci to these two sets (technically, denota- determining execute relation is placed. tions) and project away the first column: Xi(d) = 3 Semantic Parsing ((d.ci ./1,1 A) ./2,1 B) [−1].</S>",['method_citation']
8,P11-1060,D12-1069,0,Liangetal2011,0,"One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010)","One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Lianget al 2011) or even a binary correct/incorrect signal (Clarke et al2010)","'13','4','1'","<S ssid=""1"" sid=""13"">We want to induce latent logical forms z (and parameters 0) given only question-answer pairs (x, y), which is much cheaper to obtain than (x, z) pairs.</S><S ssid=""1"" sid=""4"">On two stansemantic parsing benchmarks our system obtains the highest published accuracies, despite requiring no annotated logical forms.</S><S ssid=""1"" sid=""1"">Compositional question answering begins by mapping questions to logical forms, but training a semantic parser to perform this mapping typically requires the costly annotation of the target logical forms.</S>",['method_citation']
9,P11-1060,N12-1049,0,2011,0,"For example, Liang et al (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form","For example, Liang et al (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form",'127',"<S ssid=""1"" sid=""127"">Our lexical triggers L include the following: (i) predicates for a small set of ≈ 20 function words (e.g., (most, argmax)), (ii) (x, x) for each value predicate x in w (e.g., (Boston, Boston)), and (iii) predicates for each POS tag in {JJ, NN, NNS} (e.g., (JJ, size), (JJ, area), etc.</S>",['method_citation']
10,P11-1060,P12-1045,0,2011,0,Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers,Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers,,,"['implication_citation', 'result_citation']"
11,P11-1060,P14-1008,0,"Liang et al,2011",0,"Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al, 2011)","Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al, 2011)","'127','1'","<S ssid=""1"" sid=""127"">Our lexical triggers L include the following: (i) predicates for a small set of ≈ 20 function words (e.g., (most, argmax)), (ii) (x, x) for each value predicate x in w (e.g., (Boston, Boston)), and (iii) predicates for each POS tag in {JJ, NN, NNS} (e.g., (JJ, size), (JJ, area), etc.</S><S ssid=""1"" sid=""1"">Compositional question answering begins by mapping questions to logical forms, but training a semantic parser to perform this mapping typically requires the costly annotation of the target logical forms.</S>",['method_citation']
12,P11-1060,P14-1008,0,"Liang et al, 2011",0,"DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al, 2011) (Figure 1)","DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al, 2011) (Figure 1)","'51','49','46'","<S ssid=""1"" sid=""51"">It is impossible to represent the semantics of this phrase with just a CSP, so we introduce a new aggregate relation, notated E. Consider a tree hE:ci, whose root is connected to a child c via E. If the denotation of c is a set of values s, the parent’s denotation is then a singleton set containing s. Formally: Figure 3(a) shows the DCS tree for our running example.</S><S ssid=""1"" sid=""49"">Aggregate relation DCS trees that only use join relations can represent arbitrarily complex compositional structures, but they cannot capture higherorder phenomena in language.</S><S ssid=""1"" sid=""46"">Formally: Definition 1 (DCS trees) Let Z be the set of DCS trees, where each z ∈ Z consists of (i) a predicate for each child i, the ji-th component of v must equal the j'i-th component of some t in the child’s denotation (t ∈ JciKw).</S>",['method_citation']
13,P11-1060,P14-1008,0,"Liang et al, 2011",0,"are explained in? 2.5. 5http: //nlp.stanford.edu/software/corenlp.shtml 6 In (Liang et al, 2011) DCS trees are learned from QApairs and database entries","In (Liang et al, 2011) DCS trees are learned from QA pairs and database entries","'51','87','135'","<S ssid=""1"" sid=""51"">It is impossible to represent the semantics of this phrase with just a CSP, so we introduce a new aggregate relation, notated E. Consider a tree hE:ci, whose root is connected to a child c via E. If the denotation of c is a set of values s, the parent’s denotation is then a singleton set containing s. Formally: Figure 3(a) shows the DCS tree for our running example.</S><S ssid=""1"" sid=""87"">For example, in Figure 4(a), before execution, the denotation of the DCS tree is hh{[(CA, OR), (OR)],... }; ø; (E, Qhstatei�w, ø)ii; after applying X1, we have hh{[(OR)], ... }; øii.</S><S ssid=""1"" sid=""135"">SEMRESP requires a lexicon of 1.42 words per non-value predicate, WordNet features, and syntactic parse trees; DCS requires only words for the domain-independent predicates (overall, around 0.5 words per non-value predicate), POS tags, and very simple indicator features.</S>",['method_citation']
14,P11-1060,P14-1008,0,"Liang et al, 2011",0,"as in the sentence? Tropi cal storm Debby is blamed for death?, which is a tropical storm, is Debby, etc. Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al, 2011) of that variable","Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al, 2011) of that variable",,,"['implication_citation', 'result_citation']"
15,P11-1060,D11-1140,0,2011,0,Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available,Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available,,,"['implication_citation', 'result_citation']"
16,P11-1060,D11-1140,0,"Liang et al, 2011",0,"and Collins, 2005, 2007),? -WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al, 2010) systems and DCS (Liang et al, 2011)","WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al, 2010) systems and DCS (Liang et al, 2011)","'127','21','1'","<S ssid=""1"" sid=""127"">Our lexical triggers L include the following: (i) predicates for a small set of ≈ 20 function words (e.g., (most, argmax)), (ii) (x, x) for each value predicate x in w (e.g., (Boston, Boston)), and (iii) predicates for each POS tag in {JJ, NN, NNS} (e.g., (JJ, size), (JJ, area), etc.</S><S ssid=""1"" sid=""21"">The main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (DCS), which is both simple and expressive (Section 2).</S><S ssid=""1"" sid=""1"">Compositional question answering begins by mapping questions to logical forms, but training a semantic parser to perform this mapping typically requires the costly annotation of the target logical forms.</S>",['method_citation']
17,P11-1060,P13-1007,0,2011,0,"In general, every plural NPpotentially introduces an implicit universal, ranging 1For example, Liang et al (2011) in their state-of-the-art statistical semantic parser within the domain of natural language queries to databases, explicitly devise quantifier scoping in the semantic model","For example, Liang et al (2011) in their state-of-the-art statistical semantic parser within the domain of natural language queries to databases, explicitly devise quantifier scoping in the semantic model","'172','65','40'","<S ssid=""1"" sid=""172"">Free from the burden It also allows us to easily add new lexical triggers of annotating logical forms, we hope to use our without becoming mired in the semantic formalism. techniques in developing even more accurate and Quantifiers and superlatives significantly compli- broader-coverage language understanding systems. cate scoping in lambda calculus, and often type rais- Acknowledgments We thank Luke Zettlemoyer ing needs to be employed.</S><S ssid=""1"" sid=""65"">Formally, a denotation is defined as follows (see Figure 5 for an example): Definition 2 (Denotations) Let D be the set of denotations, where each d E D consists of where each store a contains a mark relation a.r E {E, Q, C, 0}, a base denotation a.b E D U{0}, and a child denotation a.c E D U{0}.</S><S ssid=""1"" sid=""40"">The CSP has two types of constraints: (i) x ∈ w(p) for each node x labeled with predicate p ∈ P; and (ii) xj = yj0 (the j-th component of x must equal the j'-th component of y) for each edge (x, y) labeled with j0j ∈ R. A solution to the CSP is an assignment of nodes to values that satisfies all the constraints.</S>",['method_citation']
18,P11-1060,D11-1022,0,2011,0,"DD-ADMM may be useful in other frameworks involving logical constraints, such as the models for compositional semantics presented by Liang et al (2011)","DD-ADMM may be useful in other frameworks involving logical constraints, such as the models for compositional semantics presented by Liang et al (2011)",,,"['implication_citation', 'result_citation']"
19,P11-1060,P12-1051,0,2011,0,"In fact, for any CFG G, it 1See Liang et al (2011) for work in representing lambda calculus expressions with trees","In fact, for any CFG G, it 1See Liang et al (2011) for work in representing lambda calculus expressions with trees",,,"['implication_citation', 'result_citation']"
