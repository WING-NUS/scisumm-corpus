Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P08-1043,C10-1045,0,2008,0,"Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew","Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew",,,"['implication_citation', 'result_citation']"
2,P08-1043,P11-1141,0,2008,0,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,"'19','123','0'","<S ssid=""1"" sid=""19"">Here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.</S><S ssid=""1"" sid=""123"">Previous work on morphological and syntactic disambiguation in Hebrew used different sets of data, different splits, differing annotation schemes, and different evaluation measures.</S><S ssid=""1"" sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S>",['method_citation']
3,P08-1043,P10-1074,0,2008,0,"Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMMbased approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of He brew, based on lattice parsing","Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMM-based approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of Hebrew, based on lattice parsing","'4','188','171'","<S ssid=""1"" sid=""4"">Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.</S><S ssid=""1"" sid=""188"">The overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a Treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.</S><S ssid=""1"" sid=""171"">Secondly, for all our models we provide better fine- and coarse-grained POS-tagging accuracy, and all pruned models outperform the Oracle results reported by them.12 In terms of syntactic disambiguation, even the simplest grammar pruned with HSPELL outperforms their non-Oracle results.</S>","['method_citation', 'result_citation']"
4,P08-1043,P11-1089,0,2008,0,Goldberg and Tsarfaty (2008) pro pose a generative joint model,Goldberg and Tsarfaty (2008) propose a generative joint model,"'0','19','186'","<S ssid=""1"" sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S ssid=""1"" sid=""19"">Here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.</S><S ssid=""1"" sid=""186"">This fully generative model caters for real interaction between the syntactic and morphological levels as a part of a single coherent process.</S>",['method_citation']
5,P08-1043,W10-1404,0,2008,0,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,"'4','165','188'","<S ssid=""1"" sid=""4"">Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.</S><S ssid=""1"" sid=""165"">The table makes clear that enriching our grammar improves the syntactic performance as well as morphological disambiguation (segmentation and POS tagging) accuracy.</S><S ssid=""1"" sid=""188"">The overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a Treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.</S>","['method_citation', 'result_citation']"
6,P08-1043,P11-2124,0,2008,0,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrewtext,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrew text,"'188','0','163'","<S ssid=""1"" sid=""188"">The overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a Treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.</S><S ssid=""1"" sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S ssid=""1"" sid=""163"">The accuracy results for segmentation, tagging and parsing using our different models and our standard data split are summarized in Table 1.</S>","['method_citation', 'result_citation']"
7,P08-1043,P11-2124,0,"Goldberg and Tsarfaty, 2008",0,"Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","'112','22','121'","<S ssid=""1"" sid=""112"">We first make use of our morphological analyzer to find all segmentation possibilities by chopping off all prefix sequence possibilities (including the empty prefix) and construct a lattice off of them.</S><S ssid=""1"" sid=""22"">Segmental morphology Hebrew consists of seven particles m(“from”) f(“when”/“who”/“that”) h(“the”) w(“and”) k(“like”) l(“to”) and b(“in”). which may never appear in isolation and must always attach as prefixes to the following open-class category item we refer to as stem.</S><S ssid=""1"" sid=""121"">In such cases we use the non-pruned lattice including all (possibly ungrammatical) segmentation, and let the statistics (including OOV) decide.</S>",['method_citation']
8,P08-1043,P12-2002,0,2008,0,2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),,,"['implication_citation', 'result_citation']"
9,P08-1043,D12-1046,0,"Goldberg and Tsarfaty, 2008",0,"A study that is closely related toours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","A study that is closely related to ours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","'0','19','188'","<S ssid=""1"" sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S ssid=""1"" sid=""19"">Here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.</S><S ssid=""1"" sid=""188"">The overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a Treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.</S>",['method_citation']
10,P08-1043,D12-1133,0,2008,0,"Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","'0','19','69'","<S ssid=""1"" sid=""0"">A Single Generative Model for Joint Morphological Segmentation and Syntactic Parsing</S><S ssid=""1"" sid=""19"">Here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.</S><S ssid=""1"" sid=""69"">We represent all morphological analyses of a given utterance using a lattice structure.</S>",['method_citation']
11,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008) (Sec","Parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008)",'163',"<S ssid=""1"" sid=""163"">The accuracy results for segmentation, tagging and parsing using our different models and our standard data split are summarized in Table 1.</S>",['result_citation']
12,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","It is the same grammar as described in (Goldberg and Tsarfaty, 2008)",,,"['implication_citation', 'result_citation']"
14,P08-1043,E09-1038,0,2008,0,"Several studies followed this line, (Cohen and Smith, 2007) the most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","The most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","'94','125','164'","<S ssid=""1"" sid=""94"">Our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the PCFG derivations.</S><S ssid=""1"" sid=""125"">Our primary goal is to exploit the resources that are most appropriate for the task at hand, and our secondary goal is to allow for comparison of our models’ performance against previously reported results.</S><S ssid=""1"" sid=""164"">In addition we report for each model its performance on goldsegmented input (GS) to indicate the upper bound 11Overt definiteness errors may be seen as a wrong feature rather than as wrong constituent and it is by now an accepted standard to report accuracy with and without such errors. for the grammars’ performance on the parsing task.</S>",['method_citation']
15,P08-1043,E09-1038,0,2008,0,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,"'4','67','136'","<S ssid=""1"" sid=""4"">Using a treebank grammar, a data-driven lexicon, and a linguistically motivated unknown-tokens handling technique our model outperforms previous pipelined, integrated or factorized systems for Hebrew morphological and syntactic processing, yielding an error reduction of 12% over the best published results so far.</S><S ssid=""1"" sid=""67"">Hence, we take the probability of the event fmnh analyzed as REL VB to be This means that we generate f and mnh independently depending on their corresponding PoS tags, and the context (as well as the syntactic relation between the two) is modeled via the derivation resulting in a sequence REL VB spanning the form fmnh. based on linear context.</S><S ssid=""1"" sid=""136"">Lexicon and OOV Handling Our data-driven morphological-analyzer proposes analyses for unknown tokens as described in Section 5.</S>",['method_citation']
16,P08-1043,E09-1038,0,2008,0,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,"'112','69','86'","<S ssid=""1"" sid=""112"">We first make use of our morphological analyzer to find all segmentation possibilities by chopping off all prefix sequence possibilities (including the empty prefix) and construct a lattice off of them.</S><S ssid=""1"" sid=""69"">We represent all morphological analyses of a given utterance using a lattice structure.</S><S ssid=""1"" sid=""86"">A morphological analyzer M : W—* L is a function mapping sentences in Hebrew (W E W) to their corresponding lattices (M(W) = L E L).</S>",['method_citation']
17,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units","Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parseval to use characters instead of space-delimited tokens as its basic units","'34','36','135'","<S ssid=""1"" sid=""34"">Lexical and Morphological Ambiguity The rich morphological processes for deriving Hebrew stems give rise to a high degree of ambiguity for Hebrew space-delimited tokens.</S><S ssid=""1"" sid=""36"">Furthermore, the systematic way in which particles are prefixed to one another and onto an open-class category gives rise to a distinct sort of morphological ambiguity: space-delimited tokens may be ambiguous between several different segmentation possibilities.</S><S ssid=""1"" sid=""135"">We construct a mapping from all the space-delimited tokens seen in the training sentences to their corresponding analyses.</S>",['method_citation']
