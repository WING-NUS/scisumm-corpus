Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,D10-1044,P11-2074,0,"Foster et al, 2010",0,"Another popular task in SMT is domain adaptation (Foster et al, 2010)","Another popular task in SMT is domain adaptation (Foster et al, 2010)","'1','4','0'","<S ssid=""1"" sid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S><S ssid=""1"" sid=""4"">Domain adaptation is a common concern when optimizing empirical NLP applications.</S><S ssid=""1"" sid=""0"">Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation</S>",['method_citation']
2,D10-1044,P12-1048,0,"Foster et al, 2010",0,"In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)","In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)","'29','0','2'","<S ssid=""1"" sid=""29"">This is a simple and effective alternative to setting weights discriminatively to maximize a metric such as BLEU.</S><S ssid=""1"" sid=""0"">Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation</S><S ssid=""1"" sid=""2"">This extends previous work on discriminative weighting by using a finer granularity, focusing on the properties of instances rather than corpus components, and using a simpler training procedure.</S>",['method_citation']
3,D10-1044,D12-1129,0,"Foster et al., 2010",0,"Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010) .Research in Word Sense Disambiguation (Navigli, 2009, WSD), the task aimed at the automatic labeling of text with word senses, has been oriented towards domain text understanding for several years now","Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010)","'9','4','133'","<S ssid=""1"" sid=""9"">In this paper we study the problem of using a parallel corpus from a background domain (OUT) to improve performance on a target domain (IN) for which a smaller amount of parallel training material—though adequate for reasonable performance—is also available.</S><S ssid=""1"" sid=""4"">Domain adaptation is a common concern when optimizing empirical NLP applications.</S><S ssid=""1"" sid=""133"">It is difficult to directly compare the Matsoukas et al results with ours, since our out-of-domain corpus is homogeneous; given heterogeneous training data, however, it would be trivial to include Matsoukas-style identity features in our instance-weighting model.</S>",['method_citation']
4,D10-1044,P14-2093,0,2010,0,"Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models","Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models","'62','89','1'","<S ssid=""1"" sid=""62"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S ssid=""1"" sid=""89"">We used 22 features for the logistic weighting model, divided into two groups: one intended to reflect the degree to which a phrase pair belongs to general language, and one intended to capture similarity to the IN domain.</S><S ssid=""1"" sid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S>",['method_citation']
5,D10-1044,E12-1055,0,2010,0,"However, such confounding factors do not affect the optimization algorithm, which works with a fixed set of phrase pairs, and merely varies? .Our main technical contributions are as fol lows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation. Also, we independently perform perplexity minimization for all four features of the standard SMTtranslation model: the phrase translation probabilities p (t|s) and p (s|t), and the lexical weights lex (t|s) and lex (s|t)","Our main technical contributions are as follows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation","'72','62','128'","<S ssid=""1"" sid=""72"">The original OUT counts co(s, t) are weighted by a logistic function wλ(s, t): To motivate weighting joint OUT counts as in (6), we begin with the “ideal” objective for setting multinomial phrase probabilities 0 = {p(s|t), dst}, which is the likelihood with respect to the true IN distribution pi(s, t).</S><S ssid=""1"" sid=""62"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S ssid=""1"" sid=""128"">Clearly, retaining the original frequencies is important for good performance, and globally smoothing the final weighted frequencies is crucial.</S>",['method_citation']
6,D10-1044,E12-1055,0,2010,0,"Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) ex tend this approach by weighting individual phrase pairs","Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) extend this approach by weighting individual phrase pairs","'152','133','68'","<S ssid=""1"" sid=""152"">We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.</S><S ssid=""1"" sid=""133"">It is difficult to directly compare the Matsoukas et al results with ours, since our out-of-domain corpus is homogeneous; given heterogeneous training data, however, it would be trivial to include Matsoukas-style identity features in our instance-weighting model.</S><S ssid=""1"" sid=""68"">First, we learn weights on individual phrase pairs rather than sentences.</S>",['method_citation']
7,D10-1044,E12-1055,0,2010,0,"These more fine-grained methods need not be seen as alternatives to coarse-grained ones. Foster et al (2010) combine the two, applying linear interpolation to combine the instance 542 weighted out-of-domain model with an in-domain model","Foster et al (2010) combine the two, applying linear interpolation to combine the instance weighted out-of-domain model with an in-domain model","'96','78','23'","<S ssid=""1"" sid=""96"">We used it to score all phrase pairs in the OUT table, in order to provide a feature for the instance-weighting model.</S><S ssid=""1"" sid=""78"">This has solutions: where pI(s|t) is derived from the IN corpus using relative-frequency estimates, and po(s|t) is an instance-weighted model derived from the OUT corpus.</S><S ssid=""1"" sid=""23"">Our second contribution is to apply instance weighting at the level of phrase pairs.</S>",['method_citation']
8,D10-1044,E12-1055,0,Foster et al 2010,0,Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN) Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011),Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN); Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011),"'133','144','145'","<S ssid=""1"" sid=""133"">It is difficult to directly compare the Matsoukas et al results with ours, since our out-of-domain corpus is homogeneous; given heterogeneous training data, however, it would be trivial to include Matsoukas-style identity features in our instance-weighting model.</S><S ssid=""1"" sid=""144"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S ssid=""1"" sid=""145"">Each out-of-domain phrase pair is characterized by a set of simple features intended to reflect how useful it will be.</S>",['method_citation']
9,D10-1044,E12-1055,0,Foster et al 2010,0,"We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translationmodels.15 We demonstrate perplexity optimization for weighted counts, which are a natural extension of unadapted MLE training, but are of little prominence in domain adaptation research",We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translation models,"'62','150','28'","<S ssid=""1"" sid=""62"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S ssid=""1"" sid=""150"">In both cases, the instanceweighting approach improved over a wide range of baselines, giving gains of over 2 BLEU points over the best non-adapted baseline, and gains of between 0.6 and 1.8 over an equivalent mixture model (with an identical training procedure but without instance weighting).</S><S ssid=""1"" sid=""28"">We train linear mixture models for conditional phrase pair probabilities over IN and OUT so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.</S>",['method_citation']
10,D10-1044,P12-1099,0,"Foster et al, 2010",0,"In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) 940 as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT","In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT","'28','72','150'","<S ssid=""1"" sid=""28"">We train linear mixture models for conditional phrase pair probabilities over IN and OUT so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.</S><S ssid=""1"" sid=""72"">The original OUT counts co(s, t) are weighted by a logistic function wλ(s, t): To motivate weighting joint OUT counts as in (6), we begin with the “ideal” objective for setting multinomial phrase probabilities 0 = {p(s|t), dst}, which is the likelihood with respect to the true IN distribution pi(s, t).</S><S ssid=""1"" sid=""150"">In both cases, the instanceweighting approach improved over a wide range of baselines, giving gains of over 2 BLEU points over the best non-adapted baseline, and gains of between 0.6 and 1.8 over an equivalent mixture model (with an identical training procedure but without instance weighting).</S>",['method_citation']
11,D10-1044,P12-1099,0,2010,0,m ?mpm (e? |f?) Our technique for setting? m is similar to that outlined in Foster et al (2010),Our technique for setting ? m is similar to that outlined in Foster et al (2010),"'72','115','92'","<S ssid=""1"" sid=""72"">The original OUT counts co(s, t) are weighted by a logistic function wλ(s, t): To motivate weighting joint OUT counts as in (6), we begin with the “ideal” objective for setting multinomial phrase probabilities 0 = {p(s|t), dst}, which is the likelihood with respect to the true IN distribution pi(s, t).</S><S ssid=""1"" sid=""115"">Table 2 shows results for both settings and all methods described in sections 2 and 3.</S><S ssid=""1"" sid=""92"">6One of our experimental settings lacks document boundaries, and we used this approximation in both settings for consistency.</S>",['method_citation']
12,D10-1044,P12-1099,0,"Foster et al., 2010",0,"m ?mpm (e? |f?) For efficiency and stability, we use the EMalgorithm to find??, rather than L-BFGS as in (Foster et al., 2010)","For efficiency and stability, we use the EM algorithm to find ?, rather than L-BFGS as in (Foster et al., 2010)","'138','68','137'","<S ssid=""1"" sid=""138"">However, for multinomial models like our LMs and TMs, there is a one to one correspondence between instances and features, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t).</S><S ssid=""1"" sid=""68"">First, we learn weights on individual phrase pairs rather than sentences.</S><S ssid=""1"" sid=""137"">At first glance, this seems only peripherally related to our work, since the specific/general distinction is made for features rather than instances.</S>",['method_citation']
13,D10-1044,P12-1099,0,2010,0,"Foster et al (2010), however, uses a different approach to select related sentences from OUT","Foster et al (2010), however, uses a different approach to select related sentences from OUT","'64','62','82'","<S ssid=""1"" sid=""64"">The sentence-selection approach is crude in that it imposes a binary distinction between useful and non-useful parts of OUT.</S><S ssid=""1"" sid=""62"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S ssid=""1"" sid=""82"">This is not unreasonable given the application to phrase pairs from OUT, but it suggests that an interesting alternative might be to use a plain log-linear weighting function exp(Ei Aifi(s, t)), with outputs in [0, oo].</S>",['method_citation']
14,D10-1044,P12-1099,0,2010,0,Foster et al (2010) propose asimilar method for machine translation that uses features to capture degrees of generality,Foster et al (2010) propose a similar method for machine translation that uses features to capture degrees of generality,"'153','131','22'","<S ssid=""1"" sid=""153"">Finally, we intend to explore more sophisticated instanceweighting features for capturing the degree of generality of phrase pairs.</S><S ssid=""1"" sid=""131"">The general-language features have a slight advantage over the similarity features, and both are better than the SVM feature.</S><S ssid=""1"" sid=""22"">Within this framework, we use features intended to capture degree of generality, including the output from an SVM classifier that uses the intersection between IN and OUT as positive examples.</S>",['method_citation']
15,D10-1044,P13-1126,0,"Foster et al, 2010",0,"As in (Foster et al, 2010), this approach works at the level of phrase pairs","As in (Foster et al, 2010), this approach works at the level of phrase pairs","'23','1','68'","<S ssid=""1"" sid=""23"">Our second contribution is to apply instance weighting at the level of phrase pairs.</S><S ssid=""1"" sid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S><S ssid=""1"" sid=""68"">First, we learn weights on individual phrase pairs rather than sentences.</S>",['method_citation']
16,D10-1044,D11-1033,0,2010,0,"The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)","The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)","'62','144','1'","<S ssid=""1"" sid=""62"">To approximate these baselines, we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S ssid=""1"" sid=""144"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S ssid=""1"" sid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S>",['method_citation']
17,D10-1044,D11-1033,0,2010,0,"Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and re port a decrease in performance","Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and report a decrease in performance","'42','144','134'","<S ssid=""1"" sid=""42"">The natural baseline approach is to concatenate data from IN and OUT.</S><S ssid=""1"" sid=""144"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S ssid=""1"" sid=""134"">Although these authors report better gains than ours, they are with respect to a non-adapted baseline.</S>",['method_citation']
18,D10-1044,D11-1033,0,2010,0,"Foster et al (2010) further perform this on extracted phrase pairs, not just sentences","Foster et al (2010) further perform this on extracted phrase pairs, not just sentences","'95','68','152'","<S ssid=""1"" sid=""95"">Phrase tables were extracted from the IN and OUT training corpora (not the dev as was used for instance weighting models), and phrase pairs in the intersection of the IN and OUT phrase tables were used as positive examples, with two alternate definitions of negative examples: The classifier trained using the 2nd definition had higher accuracy on a development set.</S><S ssid=""1"" sid=""68"">First, we learn weights on individual phrase pairs rather than sentences.</S><S ssid=""1"" sid=""152"">We will also directly compare with a baseline similar to the Matsoukas et al approach in order to measure the benefit from weighting phrase pairs (or ngrams) rather than full sentences.</S>",['method_citation']
19,D10-1044,P14-1012,0,"Foster et al, 2010",0,"To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments","To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments","'138','146','1'","<S ssid=""1"" sid=""138"">However, for multinomial models like our LMs and TMs, there is a one to one correspondence between instances and features, eg the correspondence between a phrase pair (s, t) and its conditional multinomial probability p(s1t).</S><S ssid=""1"" sid=""146"">The features are weighted within a logistic model to give an overall weight that is applied to the phrase pair’s frequency prior to making MAP-smoothed relative-frequency estimates (different weights are learned for each conditioning direction).</S><S ssid=""1"" sid=""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain, determined by both how similar to it they appear to be, and whether they belong to general language or not.</S>",['method_citation']
