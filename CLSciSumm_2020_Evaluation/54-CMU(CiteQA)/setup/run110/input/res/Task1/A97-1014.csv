Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,A97-1014,E99-1016,0,"Skut et al, 1997",0,"This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)","This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)","'4','14','170'","<S ssid=""1"" sid=""4"">The work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.</S><S ssid=""1"" sid=""14"">Corpora annotated with syntactic structures are commonly referred to as trctbank.5.</S><S ssid=""1"" sid=""170"">Our annotation tool supplies efficient manipulation and immediate visualization of argument structures.</S>",['method_citation']
2,A97-1014,E99-1016,0,"Skut et al, 1997",0,"For our experiments, we use the NEGRA corpus (Skut et al, 1997)","For our experiments, we use the NEGRA corpus (Skut et al, 1997)","'75','154','111'","<S ssid=""1"" sid=""75"">Modifiers are assigned the label MO (further classification with respect to thematic roles is planned).</S><S ssid=""1"" sid=""154"">Accuracy for these cases is 97%.</S><S ssid=""1"" sid=""111"">If the scope of such a word does not directly correspond to a tree node, the word is attached to the lowest node dominating all subconstituents appearing in its scope.</S>",['method_citation']
3,A97-1014,E12-1047,0,"Skut et al, 1997",0,"As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training ,devel 1 10 100 1000 10000 100000 3 4 5 6 7 8 9 Frequenc y Parsing complexity head-driven optimal head-driven Figure 6: The distribution of parsing complexity among productions in Markovized, head-driven grammars read off from NEGRA-25","As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training","'87','34','154'","<S ssid=""1"" sid=""87"">4, showing the structure of (3).</S><S ssid=""1"" sid=""34"">Treebanks of the format, described in the above section have been designed for English.</S><S ssid=""1"" sid=""154"">Accuracy for these cases is 97%.</S>",['method_citation']
5,A97-1014,I05-6010,0,1997,0,According to Skut et al (1997) tree banks have to meet the following requirements: 1,According to Skut et al (1997) tree banks have to meet the following requirements: 1,"'53','15','34'","<S ssid=""1"" sid=""53"">A tree meeting these requirements is given below: Adv V NP NP V CPL NP V damn wird ihn Anna erkennen, dais er 'vein!</S><S ssid=""1"" sid=""15"">Existing treebank annotation schemes exhibit a fairly uniform architecture, as they all have to meet the same basic requirements, namely: Descriptivity: Grammatical phenomena are to be described rather than explained.</S><S ssid=""1"" sid=""34"">Treebanks of the format, described in the above section have been designed for English.</S>",['method_citation']
7,A97-1014,C10-1061,0,"Skut et al, 1997",0,"In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997) .Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node","In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997). Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node","'39','55','47'","<S ssid=""1"" sid=""39"">Consider the German sentence (1) daran wird ihn Anna erkennen, &di er weint at-it will him Anna recognise that he cries 'Anna will recognise him at his cry' A sample constituent structure is given below: The fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes.</S><S ssid=""1"" sid=""55"">A uniform representation of local and non-local dependencies makes the structure more transparent'.</S><S ssid=""1"" sid=""47"">Argument structure can be represented in terms of unordered trees (with crossing branches).</S>",['method_citation']
8,A97-1014,C10-1061,0,"Skut et al, 1997",0,"Our data source is the German NeGra tree bank (Skut et al, 1997)","Our data source is the German NeGra tree bank (Skut et al, 1997)","'159','163','167'","<S ssid=""1"" sid=""159"">As the annotation scheme described in this paper focusses on annotating argument structure rather than constituent trees, it differs from existing treebanks in several aspects.</S><S ssid=""1"" sid=""163"">In general, the resulting interpreted data also are closer to semantic annotation and more neutral with respect to particular syntactic theories.</S><S ssid=""1"" sid=""167"">In the second phase of the project Verbmobil a. treebank for :30,000 German spoken sentences as well as for the same amount of English and Japanese sentences will be created.</S>",['method_citation']
9,A97-1014,P05-1039,0,"Skut et al, 1997",0,"The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences","The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences","'151','167','157'","<S ssid=""1"" sid=""151"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S ssid=""1"" sid=""167"">In the second phase of the project Verbmobil a. treebank for :30,000 German spoken sentences as well as for the same amount of English and Japanese sentences will be created.</S><S ssid=""1"" sid=""157"">Overall accuracy of the tagger is 95%.</S>",['result_citation']
10,A97-1014,P03-1013,0,"Skut et al, 1997",0,"The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German","The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German","'151','159','4'","<S ssid=""1"" sid=""151"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S ssid=""1"" sid=""159"">As the annotation scheme described in this paper focusses on annotating argument structure rather than constituent trees, it differs from existing treebanks in several aspects.</S><S ssid=""1"" sid=""4"">The work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.</S>",['result_citation']
11,A97-1014,P03-1013,0,"Skut et al, 1997",0,"The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences","The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences","'160','159','30'","<S ssid=""1"" sid=""160"">These differences can be illustrated by a comparison with the Penn Treebank annotation scheme.</S><S ssid=""1"" sid=""159"">As the annotation scheme described in this paper focusses on annotating argument structure rather than constituent trees, it differs from existing treebanks in several aspects.</S><S ssid=""1"" sid=""30"">Thus the context-free constituent backbone plays a pivotal role in the annotation scheme.</S>",['result_citation']
13,A97-1014,W04-1505,0,"Skut et al, 1997",0,"German is con sider ably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA an notation has been conceived to be quite at (Skut et al, 1997)","German is considerably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA annotation has been conceived to be quite at (Skut et al, 1997)","'127','168','41'","<S ssid=""1"" sid=""127"">As the need for certain functionalities becomes obvious with growing annotation experience, we have decided to implement the tool in two stages.</S><S ssid=""1"" sid=""168"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S ssid=""1"" sid=""41"">Apart from this rather technical problem, two further arguments speak against phrase structure as the structural pivot of the annotation scheme: Finally, the structural handling of free word order means stating well-formedness constraints on structures involving many trace-filler dependencies, which has proved tedious.</S>",['method_citation']
14,A97-1014,C04-1074,0,"Skut et al, 1997",0,"The factors used in the algorithms and the algorithms themselves are evaluated on a Germancorpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)","The factors used in the algorithms and the algorithms themselves are evaluated on a German corpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)","'151','163','39'","<S ssid=""1"" sid=""151"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S ssid=""1"" sid=""163"">In general, the resulting interpreted data also are closer to semantic annotation and more neutral with respect to particular syntactic theories.</S><S ssid=""1"" sid=""39"">Consider the German sentence (1) daran wird ihn Anna erkennen, &di er weint at-it will him Anna recognise that he cries 'Anna will recognise him at his cry' A sample constituent structure is given below: The fairly short sentence contains three non-local dependencies, marked by co-references between traces and the corresponding nodes.</S>",['method_citation']
16,A97-1014,P11-2067,0,"Skut et al, 1997",0,"CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)","CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)","'140','151','41'","<S ssid=""1"" sid=""140"">For the implementation, we used Tcl/Tk Version 4.1.</S><S ssid=""1"" sid=""151"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S ssid=""1"" sid=""41"">Apart from this rather technical problem, two further arguments speak against phrase structure as the structural pivot of the annotation scheme: Finally, the structural handling of free word order means stating well-formedness constraints on structures involving many trace-filler dependencies, which has proved tedious.</S>",['result_citation']
17,A97-1014,W08-1007,0,"Skut et al, 1997",0,"Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negratreebank (Skut et al, 1997) reports that lexicaliza tion of PCFGs decrease the parsing accuracy when parsing Negra? s flat constituent structures","Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al, 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra's flat constituent structures","'159','65','113'","<S ssid=""1"" sid=""159"">As the annotation scheme described in this paper focusses on annotating argument structure rather than constituent trees, it differs from existing treebanks in several aspects.</S><S ssid=""1"" sid=""65"">The tree resembles traditional constituent structures.</S><S ssid=""1"" sid=""113"">Since a precise structural description of non-constituent coordination would require a. rich inventory of incomplete phrase types, we have agreed on a sort of unde.rspe.cified representations: the coordinated units are assigned structures in which missing lexical material is not represented at the level of primary links.</S>",['method_citation']
19,A97-1014,D07-1066,0,"Skut et al, 1997",0,"A comparison of unlexicalised PCFG parsing (Ku ?bler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)","A comparison of unlexicalised PCFG parsing (Kubler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)","'160','151','154'","<S ssid=""1"" sid=""160"">These differences can be illustrated by a comparison with the Penn Treebank annotation scheme.</S><S ssid=""1"" sid=""151"">For evaluation, the already annotated sentences were divided into two disjoint sets, one for training (90% of the corpus), the other one for testing (10%).</S><S ssid=""1"" sid=""154"">Accuracy for these cases is 97%.</S>",['result_citation']
