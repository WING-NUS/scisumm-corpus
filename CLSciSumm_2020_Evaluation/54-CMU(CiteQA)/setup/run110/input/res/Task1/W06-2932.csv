Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
2,W06-2932,W06-2920,,"McDonald et al, 2006",0,"Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)","Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)","'87','49','77'","<S ssid=""1"" sid=""87"">Unfortunately, accuracy for other word types decreases somewhat, resulting in no significant net accuracy change.</S><S ssid=""1"" sid=""49"">Is this the first dependent to the left/right of the head?</S><S ssid=""1"" sid=""77"">Similar improvements are common across all languages, though not as dramatic.</S>",['method_citation']
3,W06-2932,W06-2920,0,2006,0,Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),"'36','80','56'","<S ssid=""1"" sid=""36"">However, in a two stage system we can incorporate features over the entire output of the unlabeled parser since that structure is fixed as input.</S><S ssid=""1"" sid=""80"">These words form 17% of the test corpus.</S><S ssid=""1"" sid=""56"">Results on the test set are given in Table 1.</S>",['method_citation']
4,W06-2932,W06-2920,0,2006,0,"Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences","Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences","'99','41','96'","<S ssid=""1"" sid=""99"">However, if we only look at performance for sentences of length less than 30, the labeled accuracy is still only 71%.</S><S ssid=""1"" sid=""41"">To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.</S><S ssid=""1"" sid=""96"">Each stage by itself is relatively accurate (unlabeled accuracy is 79% and labeling accuracy3 is also 79%), but since there is very little overlap in the kinds of errors each makes, overall labeled accuracy drops to 67%.</S>",['method_citation']
5,W06-2932,W08-1007,0,2006,0,"The high est score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)","The highest score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (and a different policy regarding the inclusion of punctuation). The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)","'33','76','99'","<S ssid=""1"" sid=""33"">Ideally one would like to make all parsing and labeling decisions jointly so that the shared knowledge of both decisions will help resolve any ambiguities.</S><S ssid=""1"" sid=""76"">For instance, sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S><S ssid=""1"" sid=""99"">However, if we only look at performance for sentences of length less than 30, the labeled accuracy is still only 71%.</S>",['method_citation']
6,W06-2932,W09-1210,0,2006,,McDonald et al (2006) use an additional algorithm,McDonald et al (2006) use an additional algorithm,"'23','78','22'","<S ssid=""1"" sid=""23"">That system uses MIRA, an online large-margin learning algorithm, to compute model parameters.</S><S ssid=""1"" sid=""78"">Even with this improvement, the labeling of verb dependents remains the highest source of error.</S><S ssid=""1"" sid=""22"">An exact projective and an approximate non-projective parsing algorithm are presented, since it is shown that nonprojective dependency parsing becomes NP-hard when features are extended beyond a single edge.</S>",['method_citation']
7,W06-2932,W12-3407,0,"McDonald et al, 2006",0,"Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)","Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)","'0','106','57'","<S ssid=""1"" sid=""0"">Multilingual Dependency Analysis with a Two-Stage Discriminative Parser</S><S ssid=""1"" sid=""106"">First, we plan on examining the performance difference between two-staged dependency parsing (as presented here) and joint parsing plus labeling.</S><S ssid=""1"" sid=""57"">Performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.</S>",['method_citation']
8,W06-2932,I08-1012,0,"McDonald et al, 2006",0,"In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)? s parser, (McDonald et al., 2006)? s parser, and so on","In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)'s parser, (McDonald et al., 2006)'s parser, and so on","'95','34','96'","<S ssid=""1"" sid=""95"">Note the difference in error between the unlabeled parser and the edge labeler: the former makes mistakes on edges into prepositions, conjunctions and verbs, and the latter makes mistakes on edges into nouns (subject/objects).</S><S ssid=""1"" sid=""34"">However, the parser is fundamentally limited by the scope of local factorizations that make inference tractable.</S><S ssid=""1"" sid=""96"">Each stage by itself is relatively accurate (unlabeled accuracy is 79% and labeling accuracy3 is also 79%), but since there is very little overlap in the kinds of errors each makes, overall labeled accuracy drops to 67%.</S>",['method_citation']
11,W06-2932,N07-1050,0,"McDonald et al, 2006",0,"We have shown that, for languages with a7McDonald et al (2006) use post-processing for non projective dependencies and for labeling",McDonald et al (2006) use post-processing for non-projective dependencies and for labeling,"'76','5','41'","<S ssid=""1"" sid=""76"">For instance, sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S><S ssid=""1"" sid=""5"">Often in language processing we require a deep syntactic representation of a sentence in order to assist further processing.</S><S ssid=""1"" sid=""41"">To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.</S>",['method_citation']
12,W06-2932,D07-1122,0,"McDonald et al, 2006",0,"As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem","As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem","'41','76','78'","<S ssid=""1"" sid=""41"">To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.</S><S ssid=""1"" sid=""76"">For instance, sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S><S ssid=""1"" sid=""78"">Even with this improvement, the labeling of verb dependents remains the highest source of error.</S>",['method_citation']
14,W06-2932,D07-1015,0,2006,0,5It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,"'64','65','80'","<S ssid=""1"" sid=""64"">N/P: Allow non-projective/Force projective, S/A: Sequential labeling/Atomic labeling, M/B: Include morphology features/No morphology features. assignment of edge labels instead of individual assignment, and a rich feature set that incorporates morphological properties when available.</S><S ssid=""1"" sid=""65"">The benefit of each of these is shown in Table 2.</S><S ssid=""1"" sid=""80"">These words form 17% of the test corpus.</S>","['aim_citation', 'method_citation']"
18,W06-2932,D10-1004,0,2006,0,"Entries marked with? are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)","Entries marked with are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)","'59','95','70'","<S ssid=""1"" sid=""59"">Only Arabic, Turkish and Slovene have parsing accuracies significantly below 80%, and these languages have relatively small training sets and/or are highly inflected with little to no word order constraints.</S><S ssid=""1"" sid=""95"">Note the difference in error between the unlabeled parser and the edge labeler: the former makes mistakes on edges into prepositions, conjunctions and verbs, and the latter makes mistakes on edges into nouns (subject/objects).</S><S ssid=""1"" sid=""70"">Allowing non-projective parses helped with freer word order languages like Dutch (78.8%/74.7% to 83.6%/79.2%, unlabeled/labeled accuracy).</S>",['method_citation']
19,W06-2932,P08-1108,0,"McDonald et al, 2006",0,"The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.2 2.3 Transition-Based Models","The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.","'57','54','95'","<S ssid=""1"" sid=""57"">Performance is measured through unlabeled accuracy, which is the percentage of words that modify the correct head in the dependency graph, and labeled accuracy, which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.</S><S ssid=""1"" sid=""54"">Based on performance from a held-out section of the training data, we used non-projective parsing algorithms for Czech, Danish, Dutch, German, Japanese, Portuguese and Slovene, and projective parsing algorithms for Arabic, Bulgarian, Chinese, Spanish, Swedish and Turkish.</S><S ssid=""1"" sid=""95"">Note the difference in error between the unlabeled parser and the edge labeler: the former makes mistakes on edges into prepositions, conjunctions and verbs, and the latter makes mistakes on edges into nouns (subject/objects).</S>",['result_citation']
20,W06-2932,P08-1108,0,"McDonald et al, 2006",0,"More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? Rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)","More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l) Rk, where f is typically a binary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)","'41','16','76'","<S ssid=""1"" sid=""41"">To model this we treat the labeling of the edges (i, j1), ... , (i, jM) as a sequence labeling problem, We use a first-order Markov factorization of the score s(l(i,jm), l(i,jm�1), i, y, x) in which each factor is the score of labeling the adjacent edges (i, jm) and (i, jm−1) in the tree y.</S><S ssid=""1"" sid=""16"">A dependency graph is represented by a set of ordered pairs (i, j) E y in which xj is a dependent and xi is the corresponding head.</S><S ssid=""1"" sid=""76"">For instance, sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S>",['method_citation']
