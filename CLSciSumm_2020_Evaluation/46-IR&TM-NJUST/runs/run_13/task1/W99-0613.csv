Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,W99-0613,N01-1023,0,"Collins and Singer, 1999",0,"Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)","Co-Training has been used before in applications like word-sense disambiguation (Yarowsky, 1995), web-page classification (Blum and Mitchell, 1998) and named entity identification (Collins and Singer, 1999)","'27','108','163'","<S sid=""27"" ssid=""21"">The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98).</S><S sid=""108"" ssid=""41"">In the cotraining case, (Blum and Mitchell 98) argue that the task should be to induce functions Ii and f2 such that So Ii and 12 must (1) correctly classify the labeled examples, and (2) must agree with each other on the unlabeled examples.</S><S sid=""163"" ssid=""30"">We now describe the CoBoost algorithm for the named entity problem.</S>",'Method_Citation'
2,W99-0613,N01-1023,0,"Collins and Singer, 1999",0,"They also discuss an application of classifying web pages by using their method of mutually constrained models. (Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms toAdaBoost which force the classifiers to agree (called Co Boosting)","(Collins and Singer, 1999) further extend the use of classifiers that have mutual constraints by adding terms to AdaBoost which force the classifiers to agree (called Co Boosting)","'131','174','182','206'","<S sid=""131"" ssid=""64"">In the next section we present an alternative approach that builds two classifiers while attempting to satisfy the above constraints as much as possible.</S><S sid=""174"" ssid=""41"">The two new terms force the two classifiers to agree, as much as possible, on the unlabeled examples.</S><S sid=""182"" ssid=""49"">Denote the unthresholded classifiers after t â€” 1 rounds by gitâ€”1 and assume that it is the turn for the first classifier to be updated while the second one is kept fixed.</S><S sid=""206"" ssid=""73"">We again adopt an approach where we alternate between two classifiers: one classifier is modified while the other remains fixed.</S>",'Method_Citation'
3,W99-0613,W03-1509,0,Collins and Singer 1999,0,"Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al 1999] and so on","Recent methods for English NER focus on machine-learning algorithms such as DL-CoTrain, CoBoost [Collins and Singer 1999], HMM [Daniel M. Bikel 1997], maximum entropy model [Borthwick, et al 1999] and so on","'79','202','214','246'","<S sid=""79"" ssid=""12"">2 We now introduce a new algorithm for learning from unlabeled examples, which we will call DLCoTrain (DL stands for decision list, the term Cotrain is taken from (Blum and Mitchell 98)).</S><S sid=""202"" ssid=""69"">The CoBoost algorithm just described is for the case where there are two labels: for the named entity task there are three labels, and in general it will be useful to generalize the CoBoost algorithm to the multiclass case.</S><S sid=""214"" ssid=""81"">This modification brings the method closer to the DL-CoTrain algorithm described earlier, and is motivated by the intuition that all three labels should be kept healthily populated in the unlabeled examples, preventing one label from dominating â€” this deserves more theoretical investigation.</S><S sid=""246"" ssid=""13"">(3) shows learning curves for CoBoost.</S>",'Method_Citation'
4,W99-0613,C02-1154,0,"Collins and Singer, 1999",0,"DL-CoTrain, (Collins and Singer, 1999), learns capitalized proper name NEs from a syn tactically analyzed corpus","DL-CoTrain, (Collins and Singer, 1999), learns capitalized proper name NEs from a syntactically analyzed corpus",'47',"<S sid=""47"" ssid=""1"">971,746 sentences of New York Times text were parsed using the parser of (Collins 96).1 Word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged NN).</S>",'Method_Citation'
5,W99-0613,C02-1154,0,"Collins and Singer, 1999",0,"(Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances itset out to classify","(Collins and Singer, 1999) also makes use of competing categories (person, organization, and location), which cover 96% of all the instances it set out to classify","'11','77','201','236'","<S sid=""11"" ssid=""5"">For example, a good classifier would identify Mrs. Frank as a person, Steptoe & Johnson as a company, and Honduras as a location.</S><S sid=""77"" ssid=""10"">In this paper k = 3 (the three labels are person, organization, location), and we set a = 0.1.</S><S sid=""201"" ssid=""68"">This allow the learners to ""bootstrap"" each other by filling the labels of the instances on which the other side has abstained so far.</S><S sid=""236"" ssid=""3"">We chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.</S>",'Method_Citation'
6,W99-0613,W06-2204,0,"Collins and Singer, 1999",0,"In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification","In (Collins and Singer, 1999) Collins and Singer show that unlabeled data can be used to reduce the level of supervision required for named entity classification","'76','128','176','227'","<S sid=""76"" ssid=""9"">The label for a test example with features x is then defined as In this paper we define h(x, y) as the following function of counts seen in training data: Count(x,y) is the number of times feature x is seen with label y in training data, Count(x) = EyEy Count(x, y). a is a smoothing parameter, and k is the number of possible labels.</S><S sid=""128"" ssid=""61"">At each iteration the algorithm increases the number of rules, while maintaining a high level of agreement between the spelling and contextual decision lists.</S><S sid=""176"" ssid=""43"">(7) is at 0 when: 1) Vi : sign(gi (xi)) = sign(g2 (xi)); 2) Ig3(xi)l oo; and 3) sign(gi (xi)) = yi for i = 1, , m. In fact, Zco provides a bound on the sum of the classification error of the labeled examples and the number of disagreements between the two classifiers on the unlabeled examples.</S><S sid=""227"" ssid=""6"">The likelihood of the observed data under the model is where P(yi, xi) is defined as in (9).</S>",'Method_Citation'
8,W99-0613,W03-1022,0,"Collins and Singer, 1999",0,"Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)","Collins and Singer (1999) for example report that 88% of the named entities occurring in their data set belong to these three categories (Collins and Singer, 1999)","'0','47','129','244'","<S sid=""0"" ssid=""1"">Unsupervised Models for Named Entity Classification Collins</S><S sid=""47"" ssid=""1"">971,746 sentences of New York Times text were parsed using the parser of (Collins 96).1 Word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged NN).</S><S sid=""129"" ssid=""62"">Inspection of the data shows that at n = 2500, the two classifiers both give labels on 44,281 (49.2%) of the unlabeled examples, and give the same label on 99.25% of these cases.</S><S sid=""244"" ssid=""11"">Note that on some examples (around 2% of the test set) CoBoost abstained altogether; in these cases we labeled the test example with the baseline, organization, label.</S>",'Method_Citation'
9,W99-0613,E09-1018,0,"Collinsand Singer, 1999",0,"While EM has worked quite well for a few tasks, notably ma chine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success inmost others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)","While EM has worked quite well for a few tasks, notably machine translations (starting with the IBM models 1-5 (Brown et al, 1993), it has not had success in most others, such as part-of-speech tagging (Merialdo, 1991), named-entity recognition (Collinsand Singer, 1999) and context-free-grammar induction (numerous attempts, too many to mention)","'7','222'","<S sid=""7"" ssid=""1"">Many statistical or machine-learning approaches for natural language problems require a relatively large amount of supervision, in the form of labeled training examples.</S><S sid=""222"" ssid=""1"">The Expectation Maximization (EM) algorithm (Dempster, Laird and Rubin 77) is a common approach for unsupervised training; in this section we describe its application to the named entity problem.</S>",'Method_Citation'
11,W99-0613,W07-1712,0,"Collins and Singer, 1999",0,"In addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (Collins and Singer, 1999)","In addition, we would also like to explore the semi-supervised techniques such as co-training and self-training (Collins and Singer, 1999)","'30','145','234'","<S sid=""30"" ssid=""24"">(Blum and Mitchell 98) offer a promising formulation of redundancy, also prove some results about how the use of unlabeled examples can help classification, and suggest an objective function when training with unlabeled examples.</S><S sid=""145"" ssid=""12"">AdaBoost is given access to a weak learning algorithm, which accepts as input the training examples, along with a distribution over the instances.</S><S sid=""234"" ssid=""1"">88,962 (spelling,context) pairs were extracted as training data.</S>",'Method_Citation'
12,W99-0613,W09-2208,0,"Collins and Singer, 1999",0,"Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky ?smethod (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)","Collins et al (Collins and Singer, 1999) proposed two algorithms for NER by modifying Yarowsky's method (Yarowsky, 1995) and the framework suggested by (Blum and Mitchell, 1998)","'8','33','41','140'","<S sid=""8"" ssid=""2"">Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.</S><S sid=""33"" ssid=""27"">The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).</S><S sid=""41"" ssid=""35"">(Hearst 92) describes a method for extracting hyponyms from a corpus (pairs of words in ""isa"" relations).</S><S sid=""140"" ssid=""7"">AdaBoost was first introduced in (Freund and Schapire 97); (Schapire and Singer 98) gave a generalization of AdaBoost which we will use in this paper.</S>",'Method_Citation'
13,W99-0613,W06-2207,0,"Collins and Singer, 1999",0,"This approach was shown to perform well on real-world natural language problems (Collins and Singer, 1999)","This approach was shown to perform well on real-world natural language problems (Collins and Singer, 1999)",'7',"<S sid=""7"" ssid=""1"">Many statistical or machine-learning approaches for natural language problems require a relatively large amount of supervision, in the form of labeled training examples.</S>",'Method_Citation'
15,W99-0613,W06-2207,0,"Collins and Singer, 1999",0,"(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here","(6) Similarly to (Collins and Singer, 1999) we used T= 0.95 for all experiments reported here","'0','140','203','230'","<S sid=""0"" ssid=""1"">Unsupervised Models for Named Entity Classification Collins</S><S sid=""140"" ssid=""7"">AdaBoost was first introduced in (Freund and Schapire 97); (Schapire and Singer 98) gave a generalization of AdaBoost which we will use in this paper.</S><S sid=""203"" ssid=""70"">Several extensions of AdaBoost for multiclass problems have been suggested (Freund and Schapire 97; Schapire and Singer 98).</S><S sid=""230"" ssid=""9"">In our experiments we set the parameter values randomly, and then ran EM to convergence.</S>",'Method_Citation'
16,W99-0613,P12-1065,0,1999,0,We use Collins and Singer (1999) for our exact specification of Yarowsky.2 It uses DL rule scores ?fj?| ?fj |+ |? f |+ L (1) where  is a smoothing constant,We use Collins and Singer (1999) for our exact specification of Yarowsky,"'33','47','89','204'","<S sid=""33"" ssid=""27"">The second algorithm builds on a boosting algorithm called AdaBoost (Freund and Schapire 97; Schapire and Singer 98).</S><S sid=""47"" ssid=""1"">971,746 sentences of New York Times text were parsed using the parser of (Collins 96).1 Word sequences that met the following criteria were then extracted as named entity examples: whose head is a singular noun (tagged NN).</S><S sid=""89"" ssid=""22"">The core of Yarowsky's algorithm is as follows: where h is defined by the formula in equation 2, with counts restricted to training data examples that have been labeled in step 2.</S><S sid=""204"" ssid=""71"">In this work we extended the AdaBoost.MH (Schapire and Singer 98) algorithm to the cotraining case.</S>",'Method_Citation'
