Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Reference Citation
1,W99-0623,A00-2005,0,1999,0,1 Introduct ion Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,"['12', '120', '1', '85', '135']","<S sid =""12"" ssid = ""8"">The corpus-based statistical parsing community has many fast and accurate automated parsing systems  including systems produced by Collins (1997)  Charniak (1997) and Ratnaparkhi (1997).</S><S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid =""1"" ssid = ""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses  as well as new bounds on achievable Treebank parsing accuracy.</S><S sid =""85"" ssid = ""14"">We then show that the combining techniques presented above give better parsing accuracy than any of the individual parsers.</S><S sid =""135"" ssid = ""64"">The average individual parser accuracy was reduced by more than 5% when we added this new parser  but the precision of the constituent voting technique was the only result that decreased significantly.</S>",['Results_Citation']
2,W99-0623,A00-2005,0,1999,0,the collection of hypotheses ti =fi (Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999),"Given a novel sentence Stest E Ctest, combine the collection of hypotheses ti = fi(Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999)","['120', '86', '74', '135', '17']","<S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid =""86"" ssid = ""15"">Finally we show the combining techniques degrade very little when a poor parser is added to the set.</S><S sid =""74"" ssid = ""3"">The development set contained 44088 constituents in 2416 sentences and the test set contained 30691 constituents in 1699 sentences.</S><S sid =""135"" ssid = ""64"">The average individual parser accuracy was reduced by more than 5% when we added this new parser  but the precision of the constituent voting technique was the only result that decreased significantly.</S><S sid =""17"" ssid = ""3"">The substructures that are unanimously hypothesized by the parsers should be preserved after combination  and the combination technique should not foolishly create substructures for which there is no supporting evidence.</S>",['Method_Citation']
4,W99-0623,N10-1091,0,"Henderson and Brill, 1999",0,"5 (Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","(Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","['14', '129', '127', '1', '139']","<S sid =""14"" ssid = ""10"">We used these three parsers to explore parser combination techniques.</S><S sid =""129"" ssid = ""58"">In the interest of testing the robustness of these combining techniques  we added a fourth  simple nonlexicalized PCFG parser.</S><S sid =""127"" ssid = ""56"">Parser 3  the most accurate parser  was chosen 71% of the time  and Parser 1  the least accurate parser was chosen 16% of the time.</S><S sid =""1"" ssid = ""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses  as well as new bounds on achievable Treebank parsing accuracy.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S>",['Method_Citation']
5,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","['120', '6', '9', '56', '139']","<S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid =""6"" ssid = ""2"">The machine learning community has been in a similar situation and has studied the combination of multiple classifiers (Wolpert  1992; Heath et al.  1996).</S><S sid =""9"" ssid = ""5"">Recently  combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al.  1998; Brill and Wu  1998).</S><S sid =""56"" ssid = ""42"">The combining algorithm is presented with the candidate parses and asked to choose which one is best.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S>",['Method_Citation']
6,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"This approach roughly corresponds to (Henderson and Brill, 1999)? s Na ?ve Bayes parse hybridization","This approach roughly corresponds to (Henderson and Brill, 1999)'s Naive Bayes parse hybridization","['16', '139', '27', '31', '58']","<S sid =""16"" ssid = ""2"">We call this approach parse hybridization.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S><S sid =""27"" ssid = ""13"">Another technique for parse hybridization is to use a na誰ve Bayes classifier to determine which constituents to include in the parse.</S><S sid =""31"" ssid = ""17"">For this reason  na誰ve Bayes classifiers are well-matched to this problem.</S><S sid =""58"" ssid = ""44"">We call this approach parser switching.</S>",['Method_Citation']
7,W99-0623,W05-1518,0,1999,0,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,"['120', '143', '84', '135', '23']","<S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid =""143"" ssid = ""5"">Through parser combination we have reduced the precision error rate by 30% and the recall error rate by 6% compared to the best previously published result.</S><S sid =""84"" ssid = ""13"">The first shows how constituent features and context do not help in deciding which parser to trust.</S><S sid =""135"" ssid = ""64"">The average individual parser accuracy was reduced by more than 5% when we added this new parser  but the precision of the constituent voting technique was the only result that decreased significantly.</S><S sid =""23"" ssid = ""9"">We call this technique constituent voting.</S>",['Method_Citation']
8,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) improved their best parser? s F-measure of 89.7 to 91.3, using their na ?ve Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","(Henderson and Brill, 1999) improved their best parser's F-measure of 89.7 to 91.3, using their naive Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","['120', '143', '4', '72', '135']","<S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid =""143"" ssid = ""5"">Through parser combination we have reduced the precision error rate by 30% and the recall error rate by 6% compared to the best previously published result.</S><S sid =""4"" ssid = ""4"">The resulting parsers surpass the best previously published performance results for the Penn Treebank.</S><S sid =""72"" ssid = ""1"">The three parsers were trained and tuned by their creators on various sections of the WSJ portion of the Penn Treebank  leaving only sections 22 and 23 completely untouched during the development of any of the parsers.</S><S sid =""135"" ssid = ""64"">The average individual parser accuracy was reduced by more than 5% when we added this new parser  but the precision of the constituent voting technique was the only result that decreased significantly.</S>",['Method_Citation']
10,W99-0623,P01-1005,0,"Henderson and Brill, 1999",0,"Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","['9', '120', '11', '6', '12']","<S sid =""9"" ssid = ""5"">Recently  combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al.  1998; Brill and Wu  1998).</S><S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid =""11"" ssid = ""7"">Similar advances have been made in machine translation (Frederking and Nirenburg  1994)  speech recognition (Fiscus  1997) and named entity recognition (Borthwick et al.  1998).</S><S sid =""6"" ssid = ""2"">The machine learning community has been in a similar situation and has studied the combination of multiple classifiers (Wolpert  1992; Heath et al.  1996).</S><S sid =""12"" ssid = ""8"">The corpus-based statistical parsing community has many fast and accurate automated parsing systems  including systems produced by Collins (1997)  Charniak (1997) and Ratnaparkhi (1997).</S>",['Method_Citation']
11,W99-0623,D09-1161,0,1999,0,"Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","['55', '139', '129', '61', '51']","<S sid =""55"" ssid = ""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S><S sid =""129"" ssid = ""58"">In the interest of testing the robustness of these combining techniques  we added a fourth  simple nonlexicalized PCFG parser.</S><S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid =""51"" ssid = ""37"">One can trivially create situations in which strictly binary-branching trees are combined to create a tree with only the root node and the terminal nodes  a completely flat structure.</S>",['Method_Citation']
12,W99-0623,D09-1161,0,1999,0,"Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","['1', '120', '143', '13', '72']","<S sid =""1"" ssid = ""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses  as well as new bounds on achievable Treebank parsing accuracy.</S><S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid =""143"" ssid = ""5"">Through parser combination we have reduced the precision error rate by 30% and the recall error rate by 6% compared to the best previously published result.</S><S sid =""13"" ssid = ""9"">These three parsers have given the best reported parsing results on the Penn Treebank Wall Street Journal corpus (Marcus et al.  1993).</S><S sid =""72"" ssid = ""1"">The three parsers were trained and tuned by their creators on various sections of the WSJ portion of the Penn Treebank  leaving only sections 22 and 23 completely untouched during the development of any of the parsers.</S>",['Method_Citation']
13,W99-0623,D09-1161,0,"Henderson and Brill, 1999",0,"Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","['11', '143', '9', '102', '73']","<S sid =""11"" ssid = ""7"">Similar advances have been made in machine translation (Frederking and Nirenburg  1994)  speech recognition (Fiscus  1997) and named entity recognition (Borthwick et al.  1998).</S><S sid =""143"" ssid = ""5"">Through parser combination we have reduced the precision error rate by 30% and the recall error rate by 6% compared to the best previously published result.</S><S sid =""9"" ssid = ""5"">Recently  combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al.  1998; Brill and Wu  1998).</S><S sid =""102"" ssid = ""31"">In Table 1 we see with very few exceptions that the isolated constituent precision is less than 0.5 when we use the constituent label as a feature.</S><S sid =""73"" ssid = ""2"">We used section 23 as the development set for our combining techniques  and section 22 only for final testing.</S>",['Method_Citation']
14,W99-0623,N06-2033,0,"Henderson and Brill, 1999",0,"Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","['55', '51', '139', '129', '70']","<S sid =""55"" ssid = ""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid =""51"" ssid = ""37"">One can trivially create situations in which strictly binary-branching trees are combined to create a tree with only the root node and the terminal nodes  a completely flat structure.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S><S sid =""129"" ssid = ""58"">In the interest of testing the robustness of these combining techniques  we added a fourth  simple nonlexicalized PCFG parser.</S><S sid =""70"" ssid = ""56"">In this case we are interested in finding' the maximum probability parse  ri  and Mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.</S>",['Method_Citation']
15,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","['70', '1', '78', '127', '120']","<S sid =""70"" ssid = ""56"">In this case we are interested in finding' the maximum probability parse  ri  and Mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.</S><S sid =""1"" ssid = ""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses  as well as new bounds on achievable Treebank parsing accuracy.</S><S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid =""127"" ssid = ""56"">Parser 3  the most accurate parser  was chosen 71% of the time  and Parser 1  the least accurate parser was chosen 16% of the time.</S><S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S>",['Results_Citation']
16,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","['139', '21', '27', '76', '16']","<S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S><S sid =""21"" ssid = ""7"">One hybridization strategy is to let the parsers vote on constituents' membership in the hypothesized set.</S><S sid =""27"" ssid = ""13"">Another technique for parse hybridization is to use a na誰ve Bayes classifier to determine which constituents to include in the parse.</S><S sid =""76"" ssid = ""5"">The standard measures for evaluating Penn Treebank parsing performance are precision and recall of the predicted constituents.</S><S sid =""16"" ssid = ""2"">We call this approach parse hybridization.</S>",['Method_Citation']
17,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"output (Figure 3) .Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework. Third, we extend these parser combination methods from 1-best outputs to n-best outputs","Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework","['64', '70', '27', '1', '127']","<S sid =""64"" ssid = ""50"">Furthermore  we know one of the original parses will be the hypothesized parse  so the direct method of determining which one is best is to compute the probability of each of the candidate parses using the probabilistic model we developed in Section 2.1.</S><S sid =""70"" ssid = ""56"">In this case we are interested in finding' the maximum probability parse  ri  and Mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.</S><S sid =""27"" ssid = ""13"">Another technique for parse hybridization is to use a na誰ve Bayes classifier to determine which constituents to include in the parse.</S><S sid =""1"" ssid = ""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses  as well as new bounds on achievable Treebank parsing accuracy.</S><S sid =""127"" ssid = ""56"">Parser 3  the most accurate parser  was chosen 71% of the time  and Parser 1  the least accurate parser was chosen 16% of the time.</S>",['Method_Citation']
18,W99-0623,P09-1065,0,"Henderson and Brill, 1999",0,"System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","['9', '12', '11', '6', '120']","<S sid =""9"" ssid = ""5"">Recently  combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al.  1998; Brill and Wu  1998).</S><S sid =""12"" ssid = ""8"">The corpus-based statistical parsing community has many fast and accurate automated parsing systems  including systems produced by Collins (1997)  Charniak (1997) and Ratnaparkhi (1997).</S><S sid =""11"" ssid = ""7"">Similar advances have been made in machine translation (Frederking and Nirenburg  1994)  speech recognition (Fiscus  1997) and named entity recognition (Borthwick et al.  1998).</S><S sid =""6"" ssid = ""2"">The machine learning community has been in a similar situation and has studied the combination of multiple classifiers (Wolpert  1992; Heath et al.  1996).</S><S sid =""120"" ssid = ""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser  and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S>",['Method_Citation']
20,W99-0623,C10-1151,0,1999,0,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,"['70', '1', '78', '127', '76']","<S sid =""70"" ssid = ""56"">In this case we are interested in finding' the maximum probability parse  ri  and Mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.</S><S sid =""1"" ssid = ""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses  as well as new bounds on achievable Treebank parsing accuracy.</S><S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid =""127"" ssid = ""56"">Parser 3  the most accurate parser  was chosen 71% of the time  and Parser 1  the least accurate parser was chosen 16% of the time.</S><S sid =""76"" ssid = ""5"">The standard measures for evaluating Penn Treebank parsing performance are precision and recall of the predicted constituents.</S>",['Aim_Citation']
