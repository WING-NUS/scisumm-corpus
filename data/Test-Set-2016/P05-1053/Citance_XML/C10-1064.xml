<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">While extensive studies on relation extraction have been conducted in the last decade, statistical systems based on supervised learning are still limited because they require large amounts of training data to achieve high performance.</S>
		<S sid ="2" ssid = "2">In this paper, we develop a cross-lingual annotation projection method that leverages parallel corpora to bootstrap a relation detector without significant annotation efforts for a resource-poor language.</S>
		<S sid ="3" ssid = "3">In order to make our method more reliable, we introduce three simple projection noise reduction methods.</S>
		<S sid ="4" ssid = "4">The merit of our method is demonstrated through a novel Korean relation detection task.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="5" ssid = "5">Relation extraction aims to identify semantic relations of entities in a document.</S>
			<S sid ="6" ssid = "6">Many relation extraction studies have followed the Relation Detection and Characterization (RDC) task organized by the Automatic Content Extraction project (Doddington et al., 2004) to make multilingual corpora of English, Chinese and Arabic.</S>
			<S sid ="7" ssid = "7">Although these datasets encourage the development and evaluation of statistical relation extractors for such languages, there would be a scarcity of labeled training samples when learning a new system for another language such as Korean.</S>
			<S sid ="8" ssid = "8">Since manual annotation of entities and their relations for such resource-poor languages is very expensive, we would like to consider instead a weakly-supervised learning technique in order to learn the relation extractor without significant annotation efforts.</S>
			<S sid ="9" ssid = "9">To do this, we propose to leverage parallel corpora to project the relation annotation on the source language (e.g. English) to the target (e.g. Korean).</S>
			<S sid ="10" ssid = "10">While many supervised machine learning approaches have been successfully applied to the RDC task (Kambhatla, 2004; Zhou et al., 2005; Zelenko et al., 2003; Culotta and Sorensen, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), few have focused on weakly-supervised relation extraction.</S>
			<S sid ="11" ssid = "11">For example, (Zhang, 2004) and (Chen et al., 2006) utilized weakly-supervised learning techniques for relation extraction, but they did not consider weak supervision in the context of cross-lingual relation extraction.</S>
			<S sid ="12" ssid = "12">Our key hypothesis on the use of parallel corpora for learning the relation extraction system is referred to as cross-lingual annotation projection.</S>
			<S sid ="13" ssid = "13">Early studies of cross-lingual annotation projection were accomplished for lexically-based tasks; for example part-of-speech tagging (Yarowsky and Ngai, 2001), named-entity tagging (Yarowsky et al., 2001), and verb classification (Merlo et al., 2002).</S>
			<S sid ="14" ssid = "14">Recently, there has been increasing interest in applications of annotation projection such as dependency parsing (Hwa et al., 2005), mention detection (Zitouni and Florian, 2008), and semantic role labeling (Pado and Lapata, 2009).</S>
			<S sid ="15" ssid = "15">However, to the best of our knowledge, no work has reported on the RDC task.</S>
			<S sid ="16" ssid = "16">In this paper, we apply a cross-lingual annotation projection approach to binary relation detection, a task of identifying the relation between two entities.</S>
			<S sid ="17" ssid = "17">A simple projection method propagates the relations in source language sentences to 564 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 564–571, Beijing, August 2010 word-aligned target sentences, and a target relation detector can bootstrap from projected annotation.</S>
			<S sid ="18" ssid = "18">However, this automatic annotation is unreliable because of mis-classification of source text and word alignment errors, so it causes a critical falling-off in annotation projection quality.</S>
			<S sid ="19" ssid = "19">To alleviate this problem, we present three noise reduction strategies: a heuristic filtering; an alignment correction with dictionary; and an instance selection based on assessment, and combine these to yield a better result.</S>
			<S sid ="20" ssid = "20">We provide a quantitive evaluation of our method on a new Korean RDC dataset.</S>
			<S sid ="21" ssid = "21">In our experiment, we leverage an EnglishKorean parallel corpus collected from the Web, and demonstrate that the annotation projection approach and noise reduction method are beneficial to build an initial Korean relation detection system.</S>
			<S sid ="22" ssid = "22">For example, the combined model of three noise reduction methods achieves F1-scores of 36.9% (59.8% precision and 26.7% recall), favorably comparing with the 30.5% shown by the supervised baseline.1 The remainder of this paper is structured as follows.</S>
			<S sid ="23" ssid = "23">In Section 2, we describe our cross-lingual annotation projection approach to relation detection task.</S>
			<S sid ="24" ssid = "24">Then, we present the noise reduction methods in Section 3.</S>
			<S sid ="25" ssid = "25">Our experiment on the proposed Korean RDC evaluation set is shown in Section 4 and Section 5, and we conclude this paper in Section 6.</S>
	</SECTION>
	<SECTION title="Cross-lingual Annotation Projection. " number = "2">
			<S sid ="26" ssid = "1">for Relation Detection The annotation projection from a resource-rich language L1 to a resource-poor language L2 is performed by a series of three subtasks: annotation, projection and assessment.</S>
			<S sid ="27" ssid = "2">The annotation projection for relation detection can be performed as follows: 1) For a given pair of bi-sentences in parallel corpora between a resource-rich language L1 and a target language L2, the relation detection task is carried out for the sentence in L1 . 1 The dataset and the parallel corpus are available on the author’s website, http://isoft.postech.ac.kr/∼megaup/research/resources/.</S>
			<S sid ="28" ssid = "3">2) The annotations obtained by analyzing the sentence in L1 are projected onto the sentence in L2 based on the word alignment information.</S>
			<S sid ="29" ssid = "4">3) The projected annotations on the sentence in L2 are utilized as resources to perform the relation detection task for the language L2.</S>
			<S sid ="30" ssid = "5">2.1 Annotation.</S>
			<S sid ="31" ssid = "6">The first step to projecting annotations from L1 onto L2 is obtaining annotations for the sentences in L1.</S>
			<S sid ="32" ssid = "7">Since each instance for relation detection is composed of a pair of entity mentions, the information about entity mentions on the given sentences should be identified first.</S>
			<S sid ="33" ssid = "8">We detect the entities in the L1 sentences of the parallel corpora.</S>
			<S sid ="34" ssid = "9">Entity identification generates a number of instances for relation detection by coupling two entities within each sentence.</S>
			<S sid ="35" ssid = "10">For each instance, the existence of semantic relation between entity mentions is explored, which is called relation detection.</S>
			<S sid ="36" ssid = "11">We assume that there exist available models or systems for all annotation processes, including not only an entity tagger and a relation detector themselves, but also required preprocessors such as a part-of-speech tagger, base-phrase chunker, and syntax parser for analyzing text in L1.Figure 1 shows an example of annotation pro jection for relation detection of a bitext in English and Korean.</S>
			<S sid ="37" ssid = "12">The annotation of the sentence in English shows that “Jan Mullins” and “Computer Recycler Incorporated” are entity mentions of a person and an organization, respectively.</S>
			<S sid ="38" ssid = "13">Furthermore, the result indicates that the pair of entities has a semantic relationship categorized as “ROLE.Owner” type.</S>
			<S sid ="39" ssid = "14">2.2 Projection.</S>
			<S sid ="40" ssid = "15">In order to project the annotations from the sentences in L1 onto the sentences in L2 , we utilize the information of word alignment which plays an important role in statistical machine translation techniques.</S>
			<S sid ="41" ssid = "16">The word alignment task aims to identify translational relationships among the words in a bitext and produces a bipartite graph with a set of edges between words with translational relationships as shown in Figure 1.</S>
			<S sid ="42" ssid = "17">In the same manner as the annotation in L1, entities are ROLE.Owner PER ORG Jan Mullins, owner of Computer Recycler Incorporated said that ... 컴퓨터리사이클러 (keompyu-teori-sa-i-keulreo) 의 (ui) 잔 (jan) 멀린스 (meolrin-seu) 사장 (sajang) 은 (eun) … 라고 (ra-go) 말했다 (malhaet-da) ORG PER ROLE.Owner Figure 1: An example of annotation projection for relation detection of a bitext in English and Korean considered as the first units to be projected.</S>
			<S sid ="43" ssid = "18">We assume that the words of the sentences in L2 aligned with a given entity mention in L1 inherit the information about the original entity in L1.</S>
			<S sid ="44" ssid = "19">After projecting the annotations of entity mentions, the projections for relational instances follow.</S>
			<S sid ="45" ssid = "20">A projection is performed on a projected instance in L2 which is a pair of projected entities by duplicating annotations of the original instance in L1 . Figure 1 presents an example of projection of a positive relational instance between “Jan Mullins” and “Computer Recycler Incorporated” in the English sentence onto its translational counterpart sentence in Korean.</S>
			<S sid ="46" ssid = "21">“Jan meolrin-seu” and “keompyu-teori-sa-i-keulreo” are labeled as entity mentions with types of a person’s name and an organization’s name respectively.</S>
			<S sid ="47" ssid = "22">In addition, the instance composed of the two projected entities is annotated as a positive instance, because its original instance on the English sentence also has a semantic relationship.</S>
			<S sid ="48" ssid = "23">As the description suggests, the annotation projection approach is highly dependant on the quality of word alignment.</S>
			<S sid ="49" ssid = "24">However, the results of automatic word alignment may include several noisy or incomplete alignments because of technical difficulties.</S>
			<S sid ="50" ssid = "25">We present details to tackle the problem by relieving the influence of alignment errors in Section 3.</S>
			<S sid ="51" ssid = "26">2.3 Assessment.</S>
			<S sid ="52" ssid = "27">The most important challenge for annotation projection approaches is how to improve the robust ness against the erroneous projections.</S>
			<S sid ="53" ssid = "28">The noise produced by not only word alignment but also monolingual annotations in L1 accumulates and brings about a drastic decline in the quality of projected annotations.</S>
			<S sid ="54" ssid = "29">The simplest policy of utilizing the projected annotations for relation detection in L2 is to consider that all projected instances are equivalently reliable and to employ entire projections as training instances for the task without any filtering.</S>
			<S sid ="55" ssid = "30">In contrast with this policy, which is likely to be substandard, we propose an alternative policy where the projected instances are assessed and only the instances judged as reliable by the assessment are utilized for the task.</S>
			<S sid ="56" ssid = "31">Details about the assessment are provided in Section 3.</S>
	</SECTION>
	<SECTION title="Noise Reduction Strategies. " number = "3">
			<S sid ="57" ssid = "1">The efforts to reduce noisy projections are considered indispensable parts of the projection-based relation detection method in a resource-poor language.</S>
			<S sid ="58" ssid = "2">Our noise reduction approach includes the following three strategies: heuristic-based alignment filtering, dictionary-based alignment correction, and assessment-based instance selection.</S>
			<S sid ="59" ssid = "3">3.1 Heuristic-based Alignment Filtering.</S>
			<S sid ="60" ssid = "4">In order to improve the performance of annotation projection approaches, we should break the bottleneck caused by the low quality of automatic word alignment results.</S>
			<S sid ="61" ssid = "5">As relation detection is carried out for each instance consisting of two entity mentions, the annotation projection for relation detection concerns projecting only entity mentions and their relational instances.</S>
			<S sid ="62" ssid = "6">Since this is different from other shallower tasks such as part-of-speech tagging, base phrase chunking, and dependency parsing which should consider projections for all word units, we define and apply some heuristics specialized to projections of entity mentions and relation instances to improve robustness of the method against erroneous alignments, as follows: In order to solve this problem, a dictionary- based alignment correction strategy is incorporated in our method.</S>
			<S sid ="63" ssid = "7">The strategy requires a bilingual dictionary for entity mentions.</S>
			<S sid ="64" ssid = "8">Each entry of the dictionary is a pair of entity mention in L1 and its translation or transliteration in L2.</S>
			<S sid ="65" ssid = "9">For each entity to be projected from the sentence in L1 , its counterpart in L2 is retrieved from the bilin gual dictionary.</S>
			<S sid ="66" ssid = "10">Then, we seek the retrieved entity • A projection for an entity mention should be based on alignments between contiguous mention from the sentence in L2 by finding the word sequences.</S>
			<S sid ="67" ssid = "11">If there are one or more gaps in the word sequence in L2 aligned with an entity mention in the sentence in L1, we assume that the corresponding alignments are likely to be erroneous.</S>
			<S sid ="68" ssid = "12">Thus, the alignments of non-contiguous words are excluded in projection.</S>
			<S sid ="69" ssid = "13">• Both an entity mention in L1 and its projection in L2 should include at least one base noun phrase.</S>
			<S sid ="70" ssid = "14">If no base noun phrase occurs in the original entity mention in L1, it may suggest some errors in annotation for the sentence in L1.</S>
			<S sid ="71" ssid = "15">The same case for the projected instance raises doubts about alignment errors.</S>
			<S sid ="72" ssid = "16">The alignments between word sequences without any base noun phrase are filtered out.</S>
			<S sid ="73" ssid = "17">• The projected instance in L2 should satisfy the clausal agreement with the original instance in L1.</S>
			<S sid ="74" ssid = "18">If entities of an instance are located in the same clause (or different clauses), its projected instance should be in the same manner.</S>
			<S sid ="75" ssid = "19">The instances without clausal agreement are ruled out.</S>
			<S sid ="76" ssid = "20">3.2 Dictionary-based Alignment Correction.</S>
			<S sid ="77" ssid = "21">The errors in word alignment are composed of not only imprecise alignments but also incomplete alignments.</S>
			<S sid ="78" ssid = "22">If an alignment of an entity among two entities of a relation instance is not provided in the result of the word alignment task, the projection for the corresponding instance is unavailable.</S>
			<S sid ="79" ssid = "23">Unfortunately, the above-stated alignment filtering heuristics for improving the quality of projections make the annotation loss problems worse by filtering out several alignments likely to be noisy.</S>
			<S sid ="80" ssid = "24">longest common subsequence.</S>
			<S sid ="81" ssid = "25">If a subsequence matched to the retrieved mention is found in the sentence in L2, we make a new alignment between it and its original entity on the L1 sentence.</S>
			<S sid ="82" ssid = "26">3.3 Assessment-based Instance Selection.</S>
			<S sid ="83" ssid = "27">The reliabilities of instances projected via a series of independent modules are different from each other.</S>
			<S sid ="84" ssid = "28">Thus, we propose an assessment strategy for each projected instance.</S>
			<S sid ="85" ssid = "29">To evaluate the reliability of a projected instance in L2, we use the confidence score of monolingual relation detection for the original counterpart instance in L1 . The acceptance of a projected instance is determined by whether the score of the instance is larger than a given threshold value θ.</S>
			<S sid ="86" ssid = "30">Only accepted instances are considered as the results of annotation projection and applied to solve the relation detection task in target language L2.</S>
	</SECTION>
	<SECTION title="Experimental Setup. " number = "4">
			<S sid ="87" ssid = "1">To demonstrate the effectiveness of our cross- lingual annotation projection approach for relation detection, we performed an experiment on relation detection in Korean text with propagated annotations from English resources.</S>
			<S sid ="88" ssid = "2">4.1 Annotation.</S>
			<S sid ="89" ssid = "3">The first step to evaluate our method was annotating the English sentences in a given parallel corpus.</S>
			<S sid ="90" ssid = "4">We use an EnglishKorean parallel corpus crawled from an EnglishKorean dictionary on the web.</S>
			<S sid ="91" ssid = "5">The parallel corpus consists of 454,315 bi- sentence pairs in English and Korean 2 . The English sentences in the parallel corpus were prepro 2 The parallel corpus collected and other resources are all available in our website http://isoft.postech.ac.kr/∼megaup/research/resources/ cessed by the Stanford Parser 3 (Klein and Manning, 2003) which provides a set of analyzed results including part-of-speech tag sequences, a dependency tree, and a constituent parse tree for a sentence.</S>
			<S sid ="92" ssid = "6">The annotation for English sentences is divided into two subtasks: entity mention recognition and relation detection.</S>
			<S sid ="93" ssid = "7">We utilized an off- the-shelf system, Stanford Named Entity Recognizer 4 (Finkel et al., 2005) for detecting entity mentions on the English sentences.</S>
			<S sid ="94" ssid = "8">The total number of English entities detected was 285,566.</S>
			<S sid ="95" ssid = "9">Each pair of recognized entities within a sentence was considered as an instance for relation detection.</S>
			<S sid ="96" ssid = "10">A classification model learned with the training set of the ACE 2003 corpus which consists of 674 documents and 9,683 relation instances was built for relation detection in English.</S>
			<S sid ="97" ssid = "11">In our implementation, we built a tree kernel- based SVM model using SVM-Light 5 (Joachims, 1998) and Tree Kernel Tools 6 (Moschitti, 2006).</S>
			<S sid ="98" ssid = "12">The subtree kernel method (Moschitti, 2006) for shortest path enclosed subtrees (Zhang et al., 2006) was adopted in our model.</S>
			<S sid ="99" ssid = "13">Our relation detection model achieved 81.2/69.8/75.1 in Precision/Recall/F-measure on the test set of the ACE 2003 corpus, which consists of 97 documents and 1,386 relation instances.</S>
			<S sid ="100" ssid = "14">The annotation of relations was performed by determining the existence of semantic relations for all 115,452 instances with the trained model for relation detection.</S>
			<S sid ="101" ssid = "15">The annotation detected 22,162 instances as positive which have semantic relations.</S>
			<S sid ="102" ssid = "16">4.2 Projection.</S>
			<S sid ="103" ssid = "17">The labels about entities and relations in the English sentences of the parallel corpora were propagated into the corresponding sentences in Korean.</S>
			<S sid ="104" ssid = "18">The Korean sentences were preprocessed by our part-of-speech tagger 7 (Lee et al., 2002) and a dependency parser implemented by MSTParser with 3 http://nlp.stanford.edu/software/lex-parser.shtml 4 http://nlp.stanford.edu/software/CRFNER.shtml 5 http://svmlight.joachims.org/ 6 http://disi.unitn.it/∼moschitt/Tree-Kernel.htm 7 http://isoft.postech.ac.kr/∼megaup/research/postag/ Filter Without assessing With assessing none 97,239 39,203 + heuristics 31,652 12,775 + dictionary 39,891 17,381 Table 1: Numbers of projected instances a model trained on the Sejong corpus (Kim, 2006).</S>
			<S sid ="105" ssid = "19">The annotation projections were performed on the bi-sentences of the parallel corpus followed by descriptions mentioned in Section 2.2.</S>
			<S sid ="106" ssid = "20">The bi-sentences were processed by the GIZA++ software (Och and Ney, 2003) in the standard configuration in both EnglishKorean and KoreanEnglish directions.</S>
			<S sid ="107" ssid = "21">The bidirecional alignments were joined by the grow-diag-final algorithm, which is widely used in bilingual phrase extraction (Koehn et al., 2003) for statistical machine translation.</S>
			<S sid ="108" ssid = "22">This system achieved 65.1/41.6/50.8 in Precision/Recall/F-measure in our evaluation of 201 randomly sampled EnglishKorean bi- sentences with manually annotated alignments.</S>
			<S sid ="109" ssid = "23">The number of projected instances varied with the applied strategies for reducing noise as shown in Table 1.</S>
			<S sid ="110" ssid = "24">Many projected instances were filtered out by heuristics, and only 32.6% of the instances were left.</S>
			<S sid ="111" ssid = "25">However, several instances were rescued by dictionary based alignment correction and the number of projected instances increased from 31,652 to 39,891.</S>
			<S sid ="112" ssid = "26">For all cases of noise reduction strategies, we performed the assessment- based instance selection with a threshold value θ of 0.7, which was determined empirically through the grid search method.</S>
			<S sid ="113" ssid = "27">About 40% of the projected instances were accepted by instance selection.</S>
			<S sid ="114" ssid = "28">4.3 Evaluation In order to evaluate our proposed method, we prepared a dataset for the Korean RDC task.</S>
			<S sid ="115" ssid = "29">The dataset was built by annotating the information about entities and relations in 100 news documents in Korean.</S>
			<S sid ="116" ssid = "30">The annotations were performed by two annotators following the guidelines for the ACE corpus processed by LDC.</S>
			<S sid ="117" ssid = "31">Our Korean RDC corpus consists of 835 sentences, 3,331 entity mentions, and 8,354 relation instances.</S>
			<S sid ="118" ssid = "32">The sen w/o assessing with assessing Table 2: Experimental Results tences of the corpus were preprocessed by equivalent systems used for analyzing Korean sentences for projection.</S>
			<S sid ="119" ssid = "33">We randomly divided the dataset into two subsets with the same number of instances for use as a training set to build the baseline system and for evaluation.</S>
			<S sid ="120" ssid = "34">For evaluating our approach, training instance sets to learn models were prepared for relation detection in Korean.</S>
			<S sid ="121" ssid = "35">The instances of the training set (half of the manually built Korean RDC corpufs) were used to train the baseline model.</S>
			<S sid ="122" ssid = "36">All other sets of instances include these baseline instances and additional instances propagated by the annotation projection approach.</S>
			<S sid ="123" ssid = "37">The training sets with projected instances are categorized into three groups by the level of applied strategies for noise reduction.</S>
			<S sid ="124" ssid = "38">While the first set included all projections without any noise reduction strategies, the second included only the instances accepted by the heuristics.</S>
			<S sid ="125" ssid = "39">The last set consisted of the results of a series of heuristic-based filtering and dictionary-based correction.</S>
			<S sid ="126" ssid = "40">For each training set with projected instances, an additional set was derived by performing assessment-based instance selection.</S>
			<S sid ="127" ssid = "41">We built the relation detection models for all seven training sets (a baseline set, three projected sets without assessing, and three projected sets with assessing).</S>
			<S sid ="128" ssid = "42">Our implementations are based on the SVM-Light and Tree Kernel Tools described in the former subsection.</S>
			<S sid ="129" ssid = "43">The shortest path dependency kernel (Bunescu and Mooney, 2005) implemented by the subtree kernel method (Moschitti, 2006) was adopted to learn all models.</S>
			<S sid ="130" ssid = "44">The performance for each model was evaluated with the predictions of the model on the test set, which was the other half of Korean RDC corpus.</S>
			<S sid ="131" ssid = "45">We measured the performances of the models on true entity mentions with true chaining of coreference.</S>
			<S sid ="132" ssid = "46">Precision, Recall and F-measure were adopted for our evaluation.</S>
	</SECTION>
	<SECTION title="Experimental Results. " number = "5">
			<S sid ="133" ssid = "1">Table 2 compares the performances of the different models which are distinguished by the applied strategies for noise reduction.</S>
			<S sid ="134" ssid = "2">It shows that: • The model with non-filtered projections achieves extremely poor performance due to a large number of erroneous instances.</S>
			<S sid ="135" ssid = "3">This indicates that the efforts for reducing noise are urgently needed.</S>
			<S sid ="136" ssid = "4">• The heuristic-based alignment filtering helps to improve the performance.</S>
			<S sid ="137" ssid = "5">However, it is much worse than the baseline performance because of a falling-off in recall.</S>
			<S sid ="138" ssid = "6">• The dictionary-based correction to our projections increased both precision and recall compared with the former models with projected instances.</S>
			<S sid ="139" ssid = "7">Nevertheless, it still fails to achieve performance improvement over the baseline model.</S>
			<S sid ="140" ssid = "8">• For all models with projection, the assessment-based instance selection boosts the performances significantly.</S>
			<S sid ="141" ssid = "9">This means that this selection strategy is crucial in improving the performance of the models by excluding unreliable instances with low confidence.</S>
			<S sid ="142" ssid = "10">• The model with heuristics and assessments finally achieves better performance than the baseline model.</S>
			<S sid ="143" ssid = "11">This suggests that the projected instances have a beneficial influence on the relation detection task when at least these two strategies are adopted for reducing noises.</S>
			<S sid ="144" ssid = "12">• The final model incorporating all proposed noise reduction strategies outperforms the baseline model by 6 in F-measure.</S>
			<S sid ="145" ssid = "13">This is due to largely increased recall by absorbing more useful features from the well-refined set of projected instances.</S>
			<S sid ="146" ssid = "14">The experimental results show that our proposed techniques effectively improve the performance of relation detection in the resource-poor Korean language with a set of annotations projected from the resource-rich English language.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "6">
			<S sid ="147" ssid = "1">This paper presented a novel cross-lingual annotation projection method for relation extraction in a resource-poor language.</S>
			<S sid ="148" ssid = "2">We proposed methods of propagating annotations from a resource-rich language to a target language via parallel corpora.</S>
			<S sid ="149" ssid = "3">In order to relieve the bad influence of noisy projections, we focused on the strategies for reducing the noise generated during the projection.</S>
			<S sid ="150" ssid = "4">We applied our methods to the relation detection task in Korean.</S>
			<S sid ="151" ssid = "5">Experimental results show that the projected instances from an EnglishKorean parallel corpus help to improve the performance of the task when our noise reduction strategies are adopted.</S>
			<S sid ="152" ssid = "6">We would like to introduce our method to the other subtask of relation extraction, which is relation categorization.</S>
			<S sid ="153" ssid = "7">While relation detection is a binary classification problem, relation categorization can be solved by a classifier for multiple classes.</S>
			<S sid ="154" ssid = "8">Since the fundamental approaches of the two tasks are similar, we expect that our projection-based relation detection methods can be easily adapted to the relation categorization task.</S>
			<S sid ="155" ssid = "9">For this further work, we are concerned about the problem of low performance for Korean, which was below 40 for relation detection.</S>
			<S sid ="156" ssid = "10">The relation categorization performance is mostly lower than detection because of the larger number of classes to be classified, so the performance of projection-based approaches has to be improved in order to apply them.</S>
			<S sid ="157" ssid = "11">An experimental result of this work shows that the most important factor in improving the performance is how to select the reliable instances from a large number of projections.</S>
			<S sid ="158" ssid = "12">We plan to develop more elaborate strategies for instance selection to improve the projection performance for relation extraction.</S>
	</SECTION>
	<SECTION title="Acknowledgement">
			<S sid ="159" ssid = "13">This research was supported by the MKE (The Ministry of Knowledge Economy), Korea, under the ITRC (Information Technology Research Center) support program supervised by the NIPA (National IT Industry Promotion Agency) (NIPA 2010C1090-10310009).</S>
	</SECTION>
</PAPER>
