<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Relation extraction is the task of recognizing semantic relations among entities.</S>
		<S sid ="2" ssid = "2">Given a particular sentence supervised approaches to Relation Extraction employed feature or kernel functions which usually have a single sentence in their scope.</S>
		<S sid ="3" ssid = "3">The overall aim of this paper is to propose methods for using knowledge and resources that are external to the target sentence, as a way to improve relation extraction.</S>
		<S sid ="4" ssid = "4">We demonstrate this by exploiting background knowledge such as relationships among the target relations, as well as by considering how target relations relate to some existing knowledge resources.</S>
		<S sid ="5" ssid = "5">Our methods are general and we suggest that some of them could be applied to other NLP tasks.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="6" ssid = "6">Relation extraction (RE) is the task of detecting and characterizing semantic relations expressed between entities in text.</S>
			<S sid ="7" ssid = "7">For instance, given the sentence “Cone, a Kansas City native, was originally signed by the Royals and broke into the majors with the team.”, one of the relations we might want to extract is the employment relation between the pair of entity mentions “Cone” and “Royals”.</S>
			<S sid ="8" ssid = "8">RE is important for many NLP applications such as building an ontology of entities, biomedical information extraction, and question answering.</S>
			<S sid ="9" ssid = "9">Prior work have employed diverse approaches towards resolving the task.</S>
			<S sid ="10" ssid = "10">One approach is to build supervised RE systems using sentences annotated with entity mentions and predefined target relations.</S>
			<S sid ="11" ssid = "11">When given a new sentence, the RE system has to detect and disambiguate the presence of any predefined relations that might exist between each of the mention pairs in the sentence.</S>
			<S sid ="12" ssid = "12">In building these systems, researchers used a wide variety of features (Kambhatla, 2004; Zhou et al., 2005; Jiang and Zhai, 2007).</S>
			<S sid ="13" ssid = "13">Some of the common features used to analyze the target sentence include the words appearing in the sentence, their part-of- speech (POS) tags, the syntactic parse of the sentence, and the dependency path between the pair of mentions.</S>
			<S sid ="14" ssid = "14">In a related line of work, researchers have also proposed various kernel functions based on different structured representations (e.g. dependency or syntactic tree parses) of the target sentences (Bunescu and Mooney, 2005; Zhou et al., 2007; Zelenko et al., 2003; Zhang et al., 2006).</S>
			<S sid ="15" ssid = "15">Additionally, researchers have tried to automatically extract examples for supervised learning from resources such as Wikipedia (Weld et al., 2008) and databases (Mintz et al., 2009), or attempted open information extraction (IE) (Banko et al., 2007) to extract all possible relations.</S>
			<S sid ="16" ssid = "16">In this work, we focus on supervised RE.</S>
			<S sid ="17" ssid = "17">In prior work, the feature and kernel functions employed are usually restricted to being defined on the various representations (e.g. lexical or structural) of the target sentences.</S>
			<S sid ="18" ssid = "18">However, in recognizing relations, humans are not thus constrained and rely on an abundance of implicit world knowledge or background information.</S>
			<S sid ="19" ssid = "19">What quantifies as world or background knowledge is rarely explored in the RE literature and we do not attempt to provide complete nor precise definitions in this paper.</S>
			<S sid ="20" ssid = "20">However, we show that by considering the relationship between our relations of interest, as 152 Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 152–160, Beijing, August 2010 well as how they relate to some existing knowledge resources, we improve the performance of RE.</S>
			<S sid ="21" ssid = "21">Specifically, the contributions of this paper are the following: • When our relations of interest are clustered or organized in a hierarchical ontology, we show how to use this information to improve performance.</S>
			<S sid ="22" ssid = "22">By defining appropriate con straints between the predictions of relations at different levels of the hierarchy, we obtain globally coherent predictions as well as improved performance.</S>
			<S sid ="23" ssid = "23">• Coreference is a generic relationship that might exists among entity mentions and we show how to exploit this information by assuming that co-referring mentions have no other interesting relations.</S>
			<S sid ="24" ssid = "24">We capture this intuition by using coreference information to constraint the predictions of a RE system.</S>
			<S sid ="25" ssid = "25">• When characterizing the relationship between a pair of mentions, one can use a large encyclopedia such as Wikipedia to infer more knowledge about the two mentions.</S>
			<S sid ="26" ssid = "26">In this work, after probabilistically mapping mentions to their respective Wikipedia pages, we check whether the mentions are related.</S>
			<S sid ="27" ssid = "27">Another generic relationship that might exists between a pair of mentions is whether they have a parent-child relation and we use this as additional information.</S>
			<S sid ="28" ssid = "28">• The sparsity of features (especially lexical features) is a common problem for supervised systems.</S>
			<S sid ="29" ssid = "29">In this work, we show that one can make fruitful use of unlabeled data, by using word clusters automatically gathered from unlabeled texts as a way of generalizing the lexical features.</S>
			<S sid ="30" ssid = "30">• We combine the various relational predictions and background knowledge through a global inference procedure, which we formalize via an Integer Linear Programming (ILP) framework as a constraint optimization problem (Roth and Yih, 2007).</S>
			<S sid ="31" ssid = "31">This allows us to easily incorporate various constraints that encode the background knowledge.</S>
			<S sid ="32" ssid = "32">Roth and Yih (2004) develop a relation extraction approach that exploits constraints among entity types and the relations allowed among them.</S>
			<S sid ="33" ssid = "33">We extend this view significantly, within a similar computational framework, to exploit relations among target relations, background information and world knowledge, as a way to improve relation extraction and make globally coherent predictions.</S>
			<S sid ="34" ssid = "34">In the rest of this paper, we first describe the features used in our basic RE system in Section 2.</S>
			<S sid ="35" ssid = "35">We then describe how we make use of background knowledge in Section 3.</S>
			<S sid ="36" ssid = "36">In Section 4, we show our experimental results and perform analysis in Section 5.</S>
			<S sid ="37" ssid = "37">In Section 6, we discuss related work, before concluding in Section 7.</S>
	</SECTION>
	<SECTION title="Relation Extraction System. " number = "2">
			<S sid ="38" ssid = "1">In this section, we describe the features used in our basic relation extraction (RE) system.</S>
			<S sid ="39" ssid = "2">Given a pair of mentions m1 and m2 occurring within the same sentence, the system predicts whether any of the predefined relation holds between the two mentions.</S>
			<S sid ="40" ssid = "3">Since relations are usually asymmetric in nature, hence in all of our experiments, unless otherwise stated, we distinguish between the argument ordering of the two mentions.</S>
			<S sid ="41" ssid = "4">For instance, we consider m1:emporg:m2 and m2:emporg:m1 to be distinct relation types.</S>
			<S sid ="42" ssid = "5">Most of the features used in our system are based on the work in (Zhou et al., 2005).</S>
			<S sid ="43" ssid = "6">In this paper, we propose some new collocation features inspired by word sense disambiguation (WSD).</S>
			<S sid ="44" ssid = "7">We give an overview of the features in Table 1.</S>
			<S sid ="45" ssid = "8">Due to space limitations, we only describe the collocation features and refer the reader to (Zhou et al., 2005) for the rest of the features.</S>
			<S sid ="46" ssid = "9">2.1 Collocation Features.</S>
			<S sid ="47" ssid = "10">Following (Zhou et al., 2005), we use a single word to represent the head word of a mention.</S>
			<S sid ="48" ssid = "11">Since single words might be ambiguous or polysemous, we incorporate local collocation features which were found to be very useful for WSD.</S>
			<S sid ="49" ssid = "12">Given the head word hwm of a mention m, the collocation feature Ci,j refers to the sequence of tokens in the immediate context of hwm.</S>
			<S sid ="50" ssid = "13">The offsets i and j denote the position (relative to hwm) Category Feature Lexical hw of m1 hw of m2 hw of m1 , m2 BOW in m1 BOW in m2 single word between m1 , m2 BOW in between m1 , m2 bigrams in between m1 , m2 first word in between m1 , m2 last word in between m1 , m2 Collocations C−1,−1 , C+1,+1 C−2,−1 , C−1,+1 , C+1,+2 Structural m1 -in-m2 m2 -in-m1 #mentions between m1 , m2 any word between m1 , m2 M-lvl M-lvl of m1 , m2 and m1 , m2 E-maintype E-type m1 , m2 E-subtype m1 , m2 M-lvl and E-maintype m1 , m2 M-lvl and E-subtype m1 , m2 E-subtype and m1 -in-m2 m1 , m2 E-subtype and m2 -in-m1 Dependency path between m1 , m2 bag-of dep labels between m1 , m2 hw of m1 and dep-parent hw of m2 and dep-parent Table 1: Features in the basic RE system.</S>
			<S sid ="51" ssid = "14">The abbreviations are as follows.</S>
			<S sid ="52" ssid = "15">hw: head word, M- lvl: mention level, E-type: entity type, dep-parent: the word’s parent in the dependency tree.</S>
			<S sid ="53" ssid = "16">of the first and last token of the sequence respectively.</S>
			<S sid ="54" ssid = "17">For instance, C−1,+1 denotes a sequence of three tokens, consisting of the single token on the immediate left of hwm, the token hwm itself, and the single token on the immediate right of hwm.</S>
			<S sid ="55" ssid = "18">For each mention, we extract 5 features: C−1,−1, C+1,+1, C−2,−1, C−1,+1, and C+1,+2.</S>
	</SECTION>
	<SECTION title="Using Background Knowledge. " number = "3">
			<S sid ="56" ssid = "1">Now we describe how we inject additional knowledge into our relation extraction system.</S>
			<S sid ="57" ssid = "2">3.1 Hierarchy of Relations.</S>
			<S sid ="58" ssid = "3">When our relations of interest are arranged in a hierarchical structure, one should leverage this information to learn more accurate relation predic- tors.</S>
			<S sid ="59" ssid = "4">For instance, assume that our relations are arranged in a two-level hierarchy and we learn two classifiers, one for disambiguating between the first level coarse-grained relations, and another for disambiguating between the second level fine-grained relations.</S>
			<S sid ="60" ssid = "5">Since there are a lot more fine-grained relation types than coarse-grained relation types, we propose using the coarse-grained predictions which should intuitively be more reliable, to improve the fine-grained predictions.</S>
			<S sid ="61" ssid = "6">We show how to achieve this through defining appropriate constraints between the coarse-grained and fine-grained relations, which can be enforced through the Constrained Conditional Models framework (aka ILP) (Roth and Yih, 2007; Chang et al., 2008).</S>
			<S sid ="62" ssid = "7">Due to space limitations, we refer interested readers to the papers for more information on the CCM framework.</S>
			<S sid ="63" ssid = "8">By doing this, not only are the predictions of both classifiers coherent with each other (thus obtaining better predictions from both classifiers), but more importantly, we are effectively using the (more reliable) predictions of the coarse-grained classifier to constrain the predictions of the fine- grained classifier.</S>
			<S sid ="64" ssid = "9">To the best of our knowledge, this approach for RE is novel.</S>
			<S sid ="65" ssid = "10">In this paper, we work on the NIST Automatic Content Extraction (ACE) 2004 corpus.</S>
			<S sid ="66" ssid = "11">ACE defines several coarse-grained relations such as employment/membership, geopolitical entity (GPE) affiliation, etc. Each coarse-grained relation is further refined into several fine-grained relations1 and each fine-grained relation has a unique parent coarse-grained relation.</S>
			<S sid ="67" ssid = "12">For instance, the fine- grained relations employed as ordinary staff, employed as an executive, etc. are children relations of employment/membership.</S>
			<S sid ="68" ssid = "13">Let mi and mj denote a pair of mentions i and j drawn from a document containing N mentions.</S>
			<S sid ="69" ssid = "14">Let Ri,j denote a relation between mi and mj , and let R = {Ri,j }, where 1≤i, j≤N ; i/=j denote the set of relations in the document.</S>
			<S sid ="70" ssid = "15">Also, we denote the set of predefined coarse-grained relation types and fine-grained relation types as LRc and LRf respectively.</S>
			<S sid ="71" ssid = "16">Since there could possibly be no relation between a mention pair, we add the null la bel to LRc and LRf , allowing our classifiers to predict null for Ri,j . Finally, for a fine-grained relation type rf , let V(rf ) denote its parent coarse grained relation type.</S>
			<S sid ="72" ssid = "17">1 With the exception of the Discourse coarse-grained relation.</S>
			<S sid ="73" ssid = "18">We learn two classifiers, one for disambiguating between the coarse-grained relations and one for disambiguating between the fine-grained relations.</S>
			<S sid ="74" ssid = "19">Let θc and θf denote the feature weights learned for predicting coarse-grained and fine- grained relations respectively.</S>
			<S sid ="75" ssid = "20">Let pR(rc) = logPc(rc|mi, mj ; θc) be the log probability that relation R is predicted to be of coarse-grained relation type rc.</S>
			<S sid ="76" ssid = "21">Similarly, let pR(rf ) = logPf (rf |mi, mj ; θf ) be the log probability thatrelation R is predicted to be of fine-grained re lation type rf . Let x(R,rc) be a binary variable which takes on the value of 1 if relation R is labeled with the coarse-grained label rc.</S>
			<S sid ="77" ssid = "22">Similarly, let y(R,rf ) be a binary variable which takes on the value of 1 if relation R is labeled with the fine- grained label rf . Our objective function is then: art: Ei ∈{gpe, org, per}, Ej ∈{fac, gpe, veh, wea} emporg: Ei ∈{gpe, org, per}, Ej ∈{gpe, org, per} gpeaff: Ei ∈{gpe, org, per}, Ej ∈{gpe, loc} other-aff: Ei ∈{gpe, org, per}, Ej ∈{gpe, loc} per-soc: Ei ∈{per}, Ej ∈{per} Table 2: Entity type constraints.</S>
			<S sid ="78" ssid = "23">which is a child of rc.</S>
			<S sid ="79" ssid = "24">The logical form of Equation (7) can be written as: y(R,rf ) ⇒ x(R,V(rf )).</S>
			<S sid ="80" ssid = "25">This captures the inverse relation and states that if we assign rf to R, then we must also assign to R the relation type V(rf ), which is the parent of rf . Together, Equations (6) and (7) constrain the predictions of the coarse-grained and fine-grained classifiers to be coherent with each other.</S>
			<S sid ="81" ssid = "26">Finally, max ) R∈R ) rc∈LRc pR(rc) · x (R,rc) we note that one could automatically translate logical constraints into linear inequalities (Chang et + ) R∈R ) rf ∈LRf pR(rf ) · y(R,rf ) (1) al., 2008).</S>
			<S sid ="82" ssid = "27">This method is general and is applicable to subject to the following constraints: other NLP tasks where a hierarchy exists, such as WSD and question answering.</S>
			<S sid ="83" ssid = "28">For instance, ) rc∈LRc ) x(R,rc) y = 1 ∀R ∈ R (2) = 1 ∀R ∈ R (3) in WSD, one can predict coarse grained and fine- grained senses using suitably defined sense inventories and then perform inference via ILP to obtain rf ∈LRf (R,rf ) coherent predictions . x(R,rc) ∈ {0, 1} ∀R ∈ R, rc ∈ LRc (4) y(R,rf ) ∈ {0, 1} ∀R ∈ R, rf ∈ LRf (5) Equations (2) and (3) require that each relation can only be assigned one coarse-grained label and one fine-grained label.</S>
			<S sid ="84" ssid = "29">Equations (4) and (5) indicate that x(R,rc) and y(R,rf ) are binary variables.</S>
			<S sid ="85" ssid = "30">Two more constraints follow: ) 3.2 Entity Type Constraints.</S>
			<S sid ="86" ssid = "31">Each mention in ACE-2004 is annotated with one of seven coarse-grained entity types: person (per), organization (org), location (loc), geopolitical entity (gpe), facility (fac), vehicle (veh), and weapon (wea).</S>
			<S sid ="87" ssid = "32">Roth and Yih (2007) had shown that entity type x(R,rc) ≤ {rf ∈LRf |V(rf )=rc} y(R,rf ) information is useful for constraining the possible labels that a relation R can assume.</S>
			<S sid ="88" ssid = "33">For instance, ∀R ∈ R , rc ∈ LRc (6)both mentions involved in a personal/social re per.</S>
			<S sid ="89" ssid = "34">In this work, y(R,rf ) ≤ x(R,V(rf )) ∀R ∈ R, rf ∈ LRf (7) The logical form of Equation (6) can be written as: x(R,rc) ⇒ y(R,rf1 ) ∨ y(R,rf2 ) . . .</S>
			<S sid ="90" ssid = "35">∨ y(R,rfn ), where rf1, rf2, . . .</S>
			<S sid ="91" ssid = "36">, rfn are (child) fine-grained relations of the coarse-grained relation rc.</S>
			<S sid ="92" ssid = "37">This states that if we assign rc to relation R, then we must also assign to R a fine-grained relation rf lation must be of entity type we gather such information from the ACE-2004 documentation and inject it as constraints (on the coarse-grained relations) into our system.</S>
			<S sid ="93" ssid = "38">Due to space limitations, we do not state the constraint equations or objective function here, but we list the entity type constraints we imposed for each coarse-grained relation mi-R-mj in Table 22, where Ei (Ej ) denotes the allowed set of entity types for mention mi (mj ).</S>
			<S sid ="94" ssid = "39">Applying the entity type information improves the predictions of the coarse-grained classifier and this in turn could improve the predictions of the fine-grained classifier.</S>
			<S sid ="95" ssid = "40">3.3 Using Coreference Information.</S>
			<S sid ="96" ssid = "41">We can also utilize the coreference relations among entity mentions.</S>
			<S sid ="97" ssid = "42">Assuming that we know mentions mi and mj are coreferent with each other, then there should be no relation between are represented in Wikipedia), we could use the content on their Wikipedia pages to check whether they are related.</S>
			<S sid ="98" ssid = "43">In this work, we use a Wiki system (Ratinov et al., 2010) which performs context-sensitive mapping of mentions to Wikipedia pages.</S>
			<S sid ="99" ssid = "44">In their work, the authors first identify phrases or mentions that could be mapped.</S>
			<S sid ="100" ssid = "45">The correct Wikipedia article for each mention is then probabilistically predicted using a combination of features based on Wikipedia hyperlink structure, semantic coherence, etc. The authors’ own evalua them3.</S>
			<S sid ="101" ssid = "46">Let z be a binary variable which takes tion results indicate that the performance of theiron the value of 1 if mentions mi and mj are coref erent, and 0 if they are not.</S>
			<S sid ="102" ssid = "47">When z(i,j)=1, we capture the above intuition with the following con straints: system ranges from 70–80%.</S>
			<S sid ="103" ssid = "48">When given a pair of mentions and the system returns the Wikipedia page for either one of the mentions, we introduce a feature: z(i,j) ≤ x(Ri,j ,null) (8)  i z(i,j) ≤ y(Ri,j ,null) (9) which can be written in logical form as: z(i,j) ⇒ w1(mi, mj ) =  1, if Am (mj ) or Amj (mi)  0, otherwise x(Ri,j ,null), and z(i,j) ⇒ y(Ri,j ,null).</S>
			<S sid ="104" ssid = "49">We add the following to our objective function in Equation (1): where Ami (mj ) returns true if the head extent of mj is found (via simple string matching) inthe predicted Wikipedia article of mi.</S>
			<S sid ="105" ssid = "50">The in terpretation of Amj (mi) is similar.</S>
			<S sid ="106" ssid = "51">We introduce ) mi ,mj ∈m2 co(i,j) · z(i,j) + c¯o (i,j) · (1 − z(i,j) ) (10) a new feature into the RE system by combining w1(mi, mj ) with mi, mj E maintype (defined as in Table 1).</S>
			<S sid ="107" ssid = "52">where m is the set of mentions in a document, co(i,j) and c¯o(i,j) are the log probabilities of predicting that mi and mj are coreferent and not coreferent respectively.</S>
			<S sid ="108" ssid = "53">In this work, we assume we are given coreference information, which is available from the ACE annotation.</S>
			<S sid ="109" ssid = "54">3.4 Using Knowledge from Wikipedia.</S>
			<S sid ="110" ssid = "55">We propose two ways of using Wikipedia to gather features for relation extraction.</S>
			<S sid ="111" ssid = "56">Wikipedia is a huge online encyclopedia and mainly contains articles describing entities or concepts.</S>
			<S sid ="112" ssid = "57">The first intuition is that if we are able to correctly map a pair of mentions mi and mj to their corresponding Wikipedia article (assuming they 2 We do not impose entity type constraints on the coarse- grained relations disc and phys.</S>
			<S sid ="113" ssid = "58">3 In this work, we assume that no relations are reflexive.</S>
			<S sid ="114" ssid = "59">After the experiments in this paper are performed, we ver The second feature based on Wikipedia is as follows.</S>
			<S sid ="115" ssid = "60">It will be useful to check whether there is any parent-child relationship between two mentions.</S>
			<S sid ="116" ssid = "61">Intuitively, this will be useful for recognizing several relations such as physical part-whole (e.g. a city is part of a state), subsidiary (a company is a child-company of another), citizenship (a person is a citizen of a country), etc. Given a pair of mentions mi and mj , we use a Parent-Child system (Do and Roth, 2010) to predict whether they have a parent-child relation.</S>
			<S sid ="117" ssid = "62">To achieve this, the system first gathers all Wikipedia articles that are related to mi and mj . It then uses the words in these pages and the category ontology of Wikipedia to make its parent-child predictions, while respecting certain defined constraints.</S>
			<S sid ="118" ssid = "63">In this work, we use its prediction as follows: ( 1, if parent-child(m , m ) ified that in the ACE corpus we used, less than 1% of the relations are reflexive.</S>
			<S sid ="119" ssid = "64">w2(mi, mj ) = i j 0, otherwise Figure 1: An example of Brown word cluster hierarchy from (Koo et al., 2008).</S>
			<S sid ="120" ssid = "65">where we combine w2(mi, mj ) with mi, mj E- maintype, introducing this as a new feature into our RE system.</S>
			<S sid ="121" ssid = "66">3.5 Using Word Clusters.</S>
			<S sid ="122" ssid = "67">An inherent problem faced by supervised systems is that of data sparseness.</S>
			<S sid ="123" ssid = "68">To mitigate such issues in the lexical features, we use word clusters which are automatically generated from unlabeled texts.</S>
			<S sid ="124" ssid = "69">In this work, we use the Brown clustering algorithm (Brown et al., 1992), which has been shown to improve performance in various NLP applications such as dependency parsing (Koo et al., 2008), named entity recognition (Ratinov and Roth, 2009), and relation extraction (Boschee et al., 2005).</S>
			<S sid ="125" ssid = "70">The algorithm performs a hierarchical clustering of the words and represents them as a binary tree.</S>
			<S sid ="126" ssid = "71">Each word is uniquely identified by its path from the root and every path is represented with a bit string.</S>
			<S sid ="127" ssid = "72">Figure 1 shows an example clustering where the maximum path length is 3.</S>
			<S sid ="128" ssid = "73">By using path prefixes of different lengths, one can obtain clusterings at different granularity.</S>
			<S sid ="129" ssid = "74">For instance, using prefixes of length 2 will put apple and pear into the same cluster, Apple and IBM into the same cluster, etc. In our work, we use clusters generated from New York Times text and simply use a path prefix of length 10.</S>
			<S sid ="130" ssid = "75">When Brown clusters are used in our system, all lexical features consisting of single words will be duplicated.</S>
			<S sid ="131" ssid = "76">For instance, for the feature hw of m1, one new feature which is the length-10 bit string path representing the original lexical head word of m1, will be introduced and presented to the classifier as a string feature.</S>
	</SECTION>
	<SECTION title="Experiments. " number = "4">
			<S sid ="132" ssid = "1">We used the ACE-2004 dataset (catalog LDC2005T09 from the Linguistic Data Consortium) to conduct our experiments.</S>
			<S sid ="133" ssid = "2">ACE-2004 defines 7 coarse-grained relations and 23 fine- grained relations.</S>
			<S sid ="134" ssid = "3">In all of our experiments, unless otherwise stated, we explicitly model the argument order (of the mentions) when asked to disambiguate the relation between a pair of mentions.</S>
			<S sid ="135" ssid = "4">Hence, we built our coarse-grained classifier with 15 relation labels to disambiguate between (two for each coarse-grained relation type and a null label when the two mentions are not related).</S>
			<S sid ="136" ssid = "5">Likewise, our fine-grained classifier has to disambiguate between 47 relation labels.</S>
			<S sid ="137" ssid = "6">In the dataset, relations do not cross sentence boundaries.</S>
			<S sid ="138" ssid = "7">For our experiments, we trained regularized averaged perceptrons (Freund and Schapire, 1999), implemented within the Sparse Network of Winnow framework (Carlson et al., 1999), one for predicting the coarse-grained relations and another for predicting the fine-grained relations.</S>
			<S sid ="139" ssid = "8">Since the dataset has no split of training, development, and test sets, we followed prior work (Jiang and Zhai, 2007) and performed 5-fold cross validation to obtain our performance results.</S>
			<S sid ="140" ssid = "9">For simplicity, we used 5 rounds of training and a regularization parameter of 1.5 for the perceptrons in all our experiments.</S>
			<S sid ="141" ssid = "10">Finally, we concentrate on the evaluation of fine-grained relations.</S>
			<S sid ="142" ssid = "11">4.1 Performance of the Basic RE system.</S>
			<S sid ="143" ssid = "12">As a gauge on the performance of our basic relation extraction system BasicRE using only the features described in Section 2, we compare against the state-of-the-art feature-based RE system of Jiang and Zhai (2007).</S>
			<S sid ="144" ssid = "13">However, we note that in that work, the authors performed their evaluation using undirected coarse-grained relations.</S>
			<S sid ="145" ssid = "14">That is, they do not distinguish on argument order of mentions and the classifier has to decide among 8 relation labels (7 coarse-grained relation types and a null label).</S>
			<S sid ="146" ssid = "15">Performing 5-fold cross validation on the news wire (nwire) and broadcast news (bnews) corpora in the ACE-2004 dataset, they reported a F-measure of 71.5 using a maximum entropy classifier4.</S>
			<S sid ="147" ssid = "16">Evaluating BasicRE on the same setting, 4 After they heuristically performed feature selection and applied the heuristics giving the best evaluation performance, they obtained a result of 72.9.</S>
			<S sid ="148" ssid = "17">Fe atu res A l l n w i r e R ec % Pre% F1% 1 0 % o f n w i r e R ec % Pre% F1% Ba sic RE + Hi er + Hi er +r elE nt C + Co ref + Wi ki + Clu ste r 4 9.</S>
			<S sid ="149" ssid = "18">9 51.0 50.5 + 1.</S>
			<S sid ="150" ssid = "19">3 +1.3 +1.3 + 1.</S>
			<S sid ="151" ssid = "20">5 +2.0 +1.8 ∼ +1.4 +0.7 + 0.</S>
			<S sid ="152" ssid = "21">2 +1.9 +1.0 − 0.</S>
			<S sid ="153" ssid = "22">2 +3.2 +1.4 33 .2 29.0 31.0 + 1.1 +1.2 +1.1 + 3.3 +3.5 +3.4 − 0.</S>
			<S sid ="154" ssid = "23">1 +1.0 +0.5 + 1.5 +2.5 +2.0 − 0.</S>
			<S sid ="155" ssid = "24">7 +3.9 +1.7 + AL L + 1.5 +6.7 +3.9 + 4.7 +10.2 +7.6 Table 3: BasicRE gives the performance of our basic RE system on predicting fine-grained relations, obtained by performing 5-fold cross validation on only the news wire corpus of ACE-2004.</S>
			<S sid ="156" ssid = "25">Each subsequent row +Hier, +Hier+relEntC, +Coref, +Wiki, and +Cluster gives the individual contribution from using each knowledge.</S>
			<S sid ="157" ssid = "26">The bottom row +ALL gives the performance improvements from adding +Hier+relEntC+Coref+Wiki+Cluster.</S>
			<S sid ="158" ssid = "27">∼ indicates no change in score.</S>
			<S sid ="159" ssid = "28">we obtained a competitive F-measure of 71.25.</S>
			<S sid ="160" ssid = "29">4.2 Experimental Settings for Evaluating.</S>
			<S sid ="161" ssid = "30">Fine-grained Relations Two of our knowledge sources, the Wiki system described in Section 3.4 and the word clusters described in Section 3.5, assume inputs of mixed- cased text.</S>
			<S sid ="162" ssid = "31">We note that the bnews corpus of ACE-2004 is entirely in lower-cased text.</S>
			<S sid ="163" ssid = "32">Hence, we use only the nwire corpus for our experiments here, from which we gathered 28,943 relation instances and 2,226 of those have a valid (non-null) relation6.</S>
			<S sid ="164" ssid = "33">We also propose the following experimental setting.</S>
			<S sid ="165" ssid = "34">First, since we made use of coreference information, we made sure that while performing our experiments, all instances from the same document are either all used as training data or all used as test data.</S>
			<S sid ="166" ssid = "35">Prior work in RE had not ensured this, but we argue that this provides a more realistic setting.</S>
			<S sid ="167" ssid = "36">Our own experiments indicate that this results in a 12% lower performance on fine-grained relations.</S>
			<S sid ="168" ssid = "37">Secondly, prior work calculate their performance on relation extraction at the level of mentions.</S>
			<S sid ="169" ssid = "38">That is, each mention pair extracted is scored individually.</S>
			<S sid ="170" ssid = "39">An issue with this way of scoring on the ACE corpus is that ACE annota 5 Using 10 rounds of training and a regularization parameter of 2.5 improves the result to 72.2.</S>
			<S sid ="171" ssid = "40">In general, we found that more rounds of training and a higher regularization value tors rarely duplicate a relation link for coreferent mentions.</S>
			<S sid ="172" ssid = "41">For instance, assume that mentions mi, mj , and mk exist in a given sentence, mentions mi and mj are coreferent, and the annotator establishes a particular relation type r between mj and mk . The annotator will not usually duplicate the same relation r between mi and mk and thus the label between these two mentions is then null.</S>
			<S sid ="173" ssid = "42">We are not suggesting that this is an incorrect approach, but clearly there is an issue since an important goal of performing RE is to populate or build an ontology of entities and establish the relations existing among the entities.</S>
			<S sid ="174" ssid = "43">Thus, we evaluate our performance at the entity-level.7 That is, given a pair of entities, we establish the set of relation types existing between them, based on their mention annotations.</S>
			<S sid ="175" ssid = "44">Then we calculate recall and precision based on these established relations.</S>
			<S sid ="176" ssid = "45">Of course, performing such an evaluation requires knowledge about the coreference relations and in this work, we assume we are given this information.</S>
			<S sid ="177" ssid = "46">4.3 Knowledge-Enriched System.</S>
			<S sid ="178" ssid = "47">Evaluating our system BasicRE (trained only on the features described in Section 2) on the nwire corpus, we obtained a F1 score of 50.5, as shown in Table 3.</S>
			<S sid ="179" ssid = "48">Next, we exploited the relation hierarchy as in Section 3.1 and obtained an improvement of 1.3, as shown in the row +Hier.</S>
			<S sid ="180" ssid = "49">Next, we added the entity type constraints of Section benefits coarse-grained relation classification, but not fine- grained relation classification.</S>
			<S sid ="181" ssid = "50">6 The number of relation instances in the nwire and bnews corpora are about the same.</S>
			<S sid ="182" ssid = "51">7 Our experiments indicate that performing the usual eval-.</S>
			<S sid ="183" ssid = "52">uation on mentions gives similar performance figures and the trend in Table 3 stays the same.</S>
			<S sid ="184" ssid = "53">3.2.</S>
			<S sid ="185" ssid = "54">Remember that these constraints are imposed.</S>
			<S sid ="186" ssid = "55">on the coarse-grained relations.</S>
			<S sid ="187" ssid = "56">Thus, they would only affect the fine-grained relation predictions if we also exploit the relation hierarchy.</S>
			<S sid ="188" ssid = "57">In the table, we show that all the background knowledge helped to improve performance, providing a total improvement of 3.9 to our basic RE system.</S>
			<S sid ="189" ssid = "58">Though the focus of this work is on fine-grained relations, our approach also improves the performance of coarse-grained relation predictions.</S>
			<S sid ="190" ssid = "59">BasicRE obtains a F1 score of 65.3 on coarse-grained relations and exploiting background knowledge gives a total improvement of 2.9.</S>
	</SECTION>
	<SECTION title="Analysis. " number = "5">
			<S sid ="191" ssid = "1">We explore the situation where we have very little training data.</S>
			<S sid ="192" ssid = "2">We assume during each cross validation fold, we are given only 10% of the training data we originally had.</S>
			<S sid ="193" ssid = "3">Previously, when performing 5-fold cross validation on 2,226 valid relation instances, we had about 1780 as training instances in each fold.</S>
			<S sid ="194" ssid = "4">Now, we assume we are only given about 178 training instances in each fold.</S>
			<S sid ="195" ssid = "5">Under this condition, BasicRE gives a F1 score of 31.0 on fine-grained relations.</S>
			<S sid ="196" ssid = "6">Adding all the background knowledge gives an improvement of 7.6 and this represents an error reduction of 39% when measured against the performance difference of 50.5 (31.0) when we have 1780 training instances vs. 178 training instances.</S>
			<S sid ="197" ssid = "7">On the coarse-grained relations, BasicRE gives a F1 score of 51.1 and exploiting background knowledge gives a total improvement of 5.0.</S>
			<S sid ="198" ssid = "8">We also tabulated the list of fine-grained relations that improved by more than 1 F1 score when we incorporated +Wiki, on the experiment using all of nwire data: phys:near (physically near), other-aff:ideology (ideology affiliation), art:user-or-owner (user or owner of artifact), per- soc:business (business relationship), phys:part- whole (physical part-whole), emporg:subsidiary (organization subsidiary), and gpeaff:citizen-or- resident (citizen or resident).</S>
			<S sid ="199" ssid = "9">Most of these intuitively seemed to be information one would find being mentioned in an encyclopedia.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "6">
			<S sid ="200" ssid = "1">Few prior work has explored using background knowledge to improve relation extraction performance.</S>
			<S sid ="201" ssid = "2">Zhou et al.</S>
			<S sid ="202" ssid = "3">(2008) took advantage of the hierarchical ontology of relations by proposing methods customized for the perceptron learning algorithm and support vector machines.</S>
			<S sid ="203" ssid = "4">In contrast, we propose a generic way of using the relation hierarchy which at the same time, gives globally coherent predictions and allows for easy injection of knowledge as constraints.</S>
			<S sid ="204" ssid = "5">Recently, Jiang (2009) proposed using features which are common across all relations.</S>
			<S sid ="205" ssid = "6">Her method is complementary to our approach, as she does not consider information such as the relatedness between different relations.</S>
			<S sid ="206" ssid = "7">On using semantic resources, Zhou et al.</S>
			<S sid ="207" ssid = "8">(2005) gathered two gazettes, one containing country names and another containing words indicating personal relationships.</S>
			<S sid ="208" ssid = "9">In relating the tasks of RE and coreference resolution, Ji et al.</S>
			<S sid ="209" ssid = "10">(2005) used the output of a RE system to rescore coreference hypotheses.</S>
			<S sid ="210" ssid = "11">In our work, we reverse the setting and explore using coreference to improve RE.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "7">
			<S sid ="211" ssid = "1">In this paper, we proposed a broad range of methods to inject background knowledge into a relation extraction system.</S>
			<S sid ="212" ssid = "2">Some of these methods, such as exploiting the relation hierarchy, are general in nature and could be easily applied to other NLP tasks.</S>
			<S sid ="213" ssid = "3">To combine the various relation predictions and knowledge, we perform global inference within an ILP framework.</S>
			<S sid ="214" ssid = "4">Besides allowing for easy injection of knowledge as constraints, this ensures globally coherent models and predictions.</S>
			<S sid ="215" ssid = "5">Acknowledgements This research was partly sponsored by Air Force Research Laboratory (AFRL) under prime contract no.</S>
			<S sid ="216" ssid = "6">FA875009- C-0181.</S>
			<S sid ="217" ssid = "7">We thank MingWei Chang and James Clarke for discussions on this research.</S>
	</SECTION>
</PAPER>
