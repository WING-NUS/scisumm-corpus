<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Distant supervision, heuristically labeling a corpus using a knowledge base, has emerged as a popular choice for training relation extractors.</S>
		<S sid ="2" ssid = "2">In this paper, we show that a significant number of “negative“ examples generated by the labeling process are false negatives because the knowledge base is incomplete.</S>
		<S sid ="3" ssid = "3">Therefore the heuristic for generating negative examples has a serious flaw.</S>
		<S sid ="4" ssid = "4">Building on a state-of-the-art distantly-supervised extraction algorithm, we proposed an algorithm that learns from only positive and unlabeled labels at the pair-of-entity level.</S>
		<S sid ="5" ssid = "5">Experimental results demonstrate its advantage over existing algorithms.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="6" ssid = "6">Relation Extraction is a well-studied problem (Miller et al., 2000; Zhou et al., 2005; Kambhatla, 2004; Min et al., 2012a).</S>
			<S sid ="7" ssid = "7">Recently, Distant Supervision (DS) (Craven and Kumlien, 1999; Mintz et al., 2009) has emerged to be a popular choice for training relation extractors without using manually labeled data.</S>
			<S sid ="8" ssid = "8">It automatically generates training examples by labeling relation mentions1 in the source corpus according to whether the argument pair is listed in the target relational tables in a knowledge base (KB).</S>
			<S sid ="9" ssid = "9">This method significantly reduces human efforts for relation extraction.</S>
			<S sid ="10" ssid = "10">The labeling heuristic has a serious flaw.</S>
			<S sid ="11" ssid = "11">Knowledge bases are usually highly incomplete.</S>
			<S sid ="12" ssid = "12">For exam 1 An occurrence of a pair of entities with the source sentence..</S>
			<S sid ="13" ssid = "13">ple, 93.8% of persons from Freebase2 have no place of birth, and 78.5% have no nationality (section 3).</S>
			<S sid ="14" ssid = "14">Previous work typically assumes that if the argument entity pair is not listed in the KB as having a relation, all the corresponding relation mentions are considered negative examples.3 This crude assumption labeled many entity pairs as negative when in fact some of their mentions express a relation.</S>
			<S sid ="15" ssid = "15">The number of such false negative matches even exceeds the number of positive pairs, by 3 to 10 times, leading to a significant problem for training.</S>
			<S sid ="16" ssid = "16">Previous approaches (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) bypassed this problem by heavily under-sampling the “negative“ class.</S>
			<S sid ="17" ssid = "17">We instead deal with a learning scenario where we only have entity-pair level labels that are either positive or unlabeled.</S>
			<S sid ="18" ssid = "18">We proposed an extension to Surdeanu et al.</S>
			<S sid ="19" ssid = "19">(2012) that can train on this dataset.</S>
			<S sid ="20" ssid = "20">Our contribution also includes an analysis on the incompleteness of Freebase and the false negative match rate in two datasets of labeled examples generated by DS.</S>
			<S sid ="21" ssid = "21">Experimental results on a realistic and challenging dataset demonstrate the advantage of the algorithm over existing solutions.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "2">
			<S sid ="22" ssid = "1">Distant supervision was first proposed by Craven and Kumlien (1999) in the biomedical domain.</S>
			<S sid ="23" ssid = "2">2 Freebase is a large collaboratively-edited KB.</S>
			<S sid ="24" ssid = "3">It is available at http://www.freebase.com.</S>
	</SECTION>
	<SECTION title="There are variants of labeling heuristics. For example, Sur-. " number = "3">
			<S sid ="25" ssid = "1">deanu et al.</S>
			<S sid ="26" ssid = "2">(2011) and Sun et al.</S>
			<S sid ="27" ssid = "3">(2011) use a pair &lt; e, v &gt; as a negative example, when it is not listed in Freebase, but e is listed with a different v′ . These assumptions are also problematic in cases where the relation is not functional.</S>
			<S sid ="28" ssid = "4">777 Proceedings of NAACLHLT 2013, pages 777–782, Atlanta, Georgia, 9–14 June 2013.</S>
			<S sid ="29" ssid = "5">Qc 2013 Association for Computational Linguistics Since then, it has gain popularity (Mintz et al., 2009; Bunescu and Mooney, 2007; Wu and Weld, 2007; Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012; Nguyen and Moschitti, 2011).</S>
			<S sid ="30" ssid = "6">To tolerate noisy labels in positive examples, Riedel et al.</S>
			<S sid ="31" ssid = "7">(2010) use Multiple Instance Learning (MIL), which assumes only at-least-one of the relation mentions in each “bag“ of mentions sharing a pair of argument entities which bears a relation, indeed expresses the target relation.</S>
			<S sid ="32" ssid = "8">MultiR (Hoffmann et al., 2011) and Multi-Instance Multi-Label (MIML) learning (Surdeanu et al., 2012) further improve it to support multiple relations expressed by different sentences in a bag.</S>
			<S sid ="33" ssid = "9">Takamatsu et al.</S>
			<S sid ="34" ssid = "10">(2012) models the probabilities of a pattern showing relations, estimated from the heuristically labeled dataset.</S>
			<S sid ="35" ssid = "11">Their algorithm removes mentions that match low- probability patterns.</S>
			<S sid ="36" ssid = "12">Sun et al.</S>
			<S sid ="37" ssid = "13">(2011) and Min et al.</S>
			<S sid ="38" ssid = "14">(2012b) also estimate the probablities of patterns showing relations, but instead use them to relabel examples to their most likely classes.</S>
			<S sid ="39" ssid = "15">Their approach can correct highly-confident false negative matches.</S>
			<S sid ="40" ssid = "16">3 Problem Definition.</S>
			<S sid ="41" ssid = "17">Distant Supervision: Given a KB D (a collection nor stay current.</S>
			<S sid ="42" ssid = "18">We took frequent relations, which involve an entity of type PERSON, from Freebase for analysis.</S>
			<S sid ="43" ssid = "19">We define the incompleteness ∂(r) of a relation r as follows: ∂(r) = |{e}|−|{e|∃e′ ,s.t.r(e,e′ )ǫD}| |{e}| ∂(r) is the percentage of all persons {e} that do not have an attribute e′ (with which r(e, e′) holds).</S>
			<S sid ="44" ssid = "20">Table 1 shows that 93.8% of persons have no place of birth, and 78.5% of them have no nationality.</S>
			<S sid ="45" ssid = "21">These are must-have attributes for a person.</S>
			<S sid ="46" ssid = "22">This shows that Freebase is highly incomplete.</S>
			<S sid ="47" ssid = "23">Freebase relation types Incompleteness /people/person/education 0.792 /people/person/employment history 0.923 /people/person/nationality* 0.785 /people/person/parents* 0.988 /people/person/place of birth* 0.938 /people/person/places lived* 0.966 Table 1: The incompleteness of Freebase (* are must- have attributes for a person).</S>
			<S sid ="48" ssid = "24">We further investigate the rate of false negative matches, as the percentage of entity-pairs that are not listed in Freebase but one of its mentions generated by DS does express a relation in the target set of types.</S>
			<S sid ="49" ssid = "25">We randomly picked 200 unla 5 of relational tables r(e1, e2), in which rǫR (R is the beled bags from each of the two datasets (Riedel set of relation labels), and &lt; e1, e2 &gt; is a pair of entities that is known to have relation r) and a corpus C , the key idea of distant supervision is that we align D to C , label each bag4 of relation mentionsthat share argument pair &lt; e1, e2 &gt; with r, other wise OTHER.</S>
			<S sid ="50" ssid = "26">This generates a dataset that has labels on entity-pair (bag) level.</S>
			<S sid ="51" ssid = "27">Then a relation extractor is trained with single-instance learning (by assuming all mentions have the same label as the bag), or Multiple-Instance Learning (by assuming at-least- one of the mentions expresses the bag-level label), or Multi-Instance Multi-Label learning (further assuming a bag can have multiple labels) algorithms.</S>
			<S sid ="52" ssid = "28">All of these works treat the OTHER class as examples that are labeled as negative.</S>
			<S sid ="53" ssid = "29">The incomplete KB problem: KBs are usually incomplete because they are manually constructed, and it is not possible to cover all human knowledge et al., 2010; Surdeanu et al., 2012) generated by DS, and we manually annotate all relation mentions in these bags.</S>
			<S sid ="54" ssid = "30">The result is shown in Table 2, along with a few examples that indicate a relation holds in the set of false negative matches (bag-level).</S>
			<S sid ="55" ssid = "31">Both datasets have around 10% false negative matches in the unlabeled set of bags.</S>
			<S sid ="56" ssid = "32">Taking into consideration that the number of positive bags and unlabeled bags are highly imbalanced (1:134 and 1:37 in the Riedel and KBP dataset respectively, before under- sampling the unlabeled class), the number of false negative matches are 11 and 4 times the number of positive bags in Reidel and KBP dataset, respectively.</S>
			<S sid ="57" ssid = "33">Such a large ratio shows false negatives do have a significant impact on the learning process.</S>
	</SECTION>
	<SECTION title="A semi-supervised MIML algorithm" number = "4">
			<S sid ="58" ssid = "1">Our goal is to model the bag-level label noise, caused by the incomplete KB problem, in addition 4 A bag is defined as a set of relation mentions sharing the same entity pair as relation arguments.</S>
			<S sid ="59" ssid = "2">We will use the terms bag and entity pair interchangeably in this paper.</S>
			<S sid ="60" ssid = "3">have only one relation mention.</S>
			<S sid ="61" ssid = "4">Dataset (training) # positive bags # positive : # unlabeled % are false negatives # positive : # false negative has human assessment Examples of false negative mentions Riedel 4,700 1:134(BD*) 8.5% 1:11.4 no (/location/location/contains)... in Brooklyn ’s Williamsburg.</S>
			<S sid ="62" ssid = "5">(/people/person/place lived) Cheryl Rogowski , a farmer from Orange County ...</S>
			<S sid ="63" ssid = "6">KBP 183,062 1:37(BD*) 11.5% 1:4 yes (per:city of birth) Juan Martn Maldacena (born September 10, 1968) is a theoretical physicist born in Buenos Aires (per:employee of)Dave Matthews, from the ABC News, ...</S>
			<S sid ="64" ssid = "7">Table 2: False negative matches on the Riedel (Riedel et al., 2010) and KBP dataset (Surdeanu et al., 2012).</S>
			<S sid ="65" ssid = "8">All numbers are on bag (pairs of entities) level.</S>
			<S sid ="66" ssid = "9">BD* are the numbers before downsampling the negative set to 10% and 5% in Riedel and KBP dataset, respectively.</S>
			<S sid ="67" ssid = "10">to modeling the instance-level noise using a 3-layer MIL or MIML model (e.g., Surdeanu et al.</S>
			<S sid ="68" ssid = "11">(2012)).</S>
			<S sid ="69" ssid = "12">We propose a 4-layer model as shown in Figure 1.</S>
			<S sid ="70" ssid = "13">The input to the model is a list of n bags with a vector of binary labels, either Positive (P), or Unlabled (U) for each relation r. Our model can be • ℓr ǫ{P, N }: a hidden variable that denotes whether r holds for the ith bag.</S>
			<S sid ="71" ssid = "14">• θ is an observed constant controlling the total number of bags whose latent label is positive.</S>
			<S sid ="72" ssid = "15">We define the following conditional probabilities:  1/2 if yr = P ∧ ℓr = P ; i i viewed as a semi-supervised6 framework that ex-   1/2 if yr = U ∧ ℓr = P ; tends a state-of-the-art Multi-Instance Multi-Label • p(yr r i i i |ℓi ) = 1 if yr = U ∧ ℓr = N ; (MIML) model (Surdeanu et al., 2012).</S>
			<S sid ="73" ssid = "16">Since the input to previous MIML models are bags with per- relation binary labels of either Positive (P) or Neg  0 i ; i otherwiseIt encodes the constraints between true bag level labels and the entity pair labels in the KB.</S>
			<S sid ="74" ssid = "17">n r ative (N), we add a set of latent variables ℓ which models the true bag-level labels, to bridge the observed bag labels y and the MIML layers.</S>
			<S sid ="75" ssid = "18">We consider this as our main contribution to the model.</S>
			<S sid ="76" ssid = "19">Our hierarchical model is shown in Figure 1.</S>
			<S sid ="77" ssid = "20">Figure 1: Plate diagram of our model.</S>
			<S sid ="78" ssid = "21">Let i, j be the index in the bag and mention level, respectively.</S>
			<S sid ="79" ssid = "22">Following Surdeanu et al.</S>
			<S sid ="80" ssid = "23">(2012), we model mention-level extraction p(zr |xij ; wz ) and multi-instance multi-label aggregation p(ℓr |zi; wr ) in the bottom 3 layers.</S>
			<S sid ="81" ssid = "24">We define: • p(θ|ℓ) ∼ N ( i=1 rǫR i , 1 ) where n k δ(x, y) = 1 if x = y, 0 otherwise.</S>
			<S sid ="82" ssid = "25">k is a large number.</S>
			<S sid ="83" ssid = "26">θ is the fraction of the bags that are positive.</S>
			<S sid ="84" ssid = "27">It is an observed parameter that depends on both the source corpus and the KB used.</S>
			<S sid ="85" ssid = "28">Similar to Surdeanu et al.</S>
			<S sid ="86" ssid = "29">(2012), we also define the following parameters and conditional probabilities (details are in Surdeanu et al.</S>
			<S sid ="87" ssid = "30">(2012)):• zij ǫR ∪ {OT H ER}: a latent variable that de notes the relation type of the jth mention in the ith bag.• xij is the feature representation of the jth rela tion mention in the ith bag.</S>
			<S sid ="88" ssid = "31">We use the set of features in Surdeanu et al.</S>
			<S sid ="89" ssid = "32">(2012).• wz is the weight vector for the multi-class rela tion mention-level classifier.• wℓ is the weight vector for the rth binary top i ℓlevel aggregation classifier (from mention la • r is a relation label.</S>
			<S sid ="90" ssid = "33">rǫR ∪ {OT H ER}, in which OTHER denotes no relation expressed.</S>
			<S sid ="91" ssid = "34">• yr ǫ{P, U }: r holds for ith bag or the bag is bels to bag-level prediction).</S>
			<S sid ="92" ssid = "35">We use wℓ to represent w1, w2, ...w|R|.</S>
			<S sid ="93" ssid = "36">ℓ ℓ ℓ r r r i unlabeled.</S>
			<S sid ="94" ssid = "37">6 We use the term semi-supervised because the algorithm uses unlabeled bags but existing solutions requires bags to be labeled either positive or negative.</S>
			<S sid ="95" ssid = "38">• p(ℓi |zi; wℓ ) ∼ Bern (fℓ(wℓ , zi)) where fℓ isprobability produced by the rth top-level clas sifier, from the mention-label level to the bag- label level.</S>
			<S sid ="96" ssid = "39">• p(zr |xij ; wz ) ∼ Multi (fz (wz , xij )) where fz is probability produced by the mention-level classifier, from the mentions to the mention In the E-step, we do a greedy search (steps 58 in algorithm 1) in all p(ℓr |xi; wz , wℓ) and update ℓr label level.7 i until the second term is maximized.</S>
			<S sid ="97" ssid = "40">wz , wℓ i are the 4.1 Training.</S>
			<S sid ="98" ssid = "41">We use hard Expectation-Maximization (EM) algorithm for training the model.</S>
			<S sid ="99" ssid = "42">Our objective function is to maximize log-likelihood: L(wz , wℓ) = logp(y, θ|x; wz , wℓ) model weights learned from the previous iteration.</S>
			<S sid ="100" ssid = "43">After fixed ℓ, we seek to maximize: n logp(ℓ|xi; wz , wℓ) = ) logp(ℓi|xi; wz , wℓ) i=1 n = ) log ) p(ℓi, zi|xi; wz , wℓ) = log ) p(y, θ, ℓ|x; wz , wℓ) ℓ which can i=1 be zisolved with an approxi Since solving it exactly involves exploring an exponential assignment space for ℓ, we approximate and iteratively set ℓ∗ = argℓ max p(ℓ|y, θ, x; wz , wℓ) p(ℓ|y, θ, x; wz , wℓ) ∝ p(y, θ, ℓ|x; wz , wℓ) = p(y, θ|ℓ, x)p(ℓ|x; wz , wℓ) = p(y|ℓ)p(θ|ℓ)p(ℓ|x; wz , wℓ) Rewriting in log form: logp(ℓ|y, θ, x; wz , wℓ) = logp(y|ℓ) + logp(θ|ℓ) + logp(ℓ|x; wz , wℓ) mate solution in Surdeanu et al.</S>
			<S sid ="101" ssid = "44">(2012) (step 911): update zi independently with: zi = arg maxzi p(zi|ℓi, xi; wz , wℓ).</S>
			<S sid ="102" ssid = "45">More details can be found in Surdeanu et al.</S>
			<S sid ="103" ssid = "46">(2012).</S>
			<S sid ="104" ssid = "47">In the M-step, we retrain both of the mention- level and the aggregation level classifiers.</S>
			<S sid ="105" ssid = "48">The full EM algorithm is shown in algorithm 1.</S>
			<S sid ="106" ssid = "49">4.2 Inference.</S>
			<S sid ="107" ssid = "50">Inference on a bag xi is trivial.</S>
			<S sid ="108" ssid = "51">For each mention: n n � � δ(ℓr , P ) ∗ = arg zij ǫR∪{OT H ER} max p(zij |xij , wz ) i Followed by the aggregation (directly with wℓ): = ) ) logp(yr |ℓr ) − k( i=1 rǫR − θ)2 r(∗) r r i i n yi = argyr max p(y |zi; w ) i=1 rǫR n + ) ) logp(ℓr |xi; wz , wℓ) + const i i=1 rǫR Algorithm 1 Training (E-step:211; M-step:1215) 1: for i = 1, 2 to T do 2: ℓr ← N for all yr = U and rǫR i ǫ{P,N } i ℓ 4.3 Implementation details.</S>
			<S sid ="109" ssid = "52">We implement our model on top of the MIML(Surdeanu et al., 2012) code base.8 We use the same mention-level and aggregate-level feature sets as Surdeanu et al.</S>
			<S sid ="110" ssid = "53">(2012).</S>
			<S sid ="111" ssid = "54">We adopt i 3: ℓr ← P i for all yr = P and rǫR the same idea of using cross validation for the E I = {&lt; i, r &gt; |ℓr = N }; I ′ = {&lt; i, r &gt; |ℓr = P } and M steps to avoid overfitting.</S>
			<S sid ="112" ssid = "55">We initialize our 4: i i 5: for k = 0, 1 to θn − |I ′| do 6: &lt; i′, r′ &gt;= arg max&lt;i,r&gt;ǫI p(ℓr |xi; wz , wℓ) 7: ℓr′ ← P ; I = I \{&lt; i′, r′ &gt;} 8: end for 9: for i = 1, 2 to n do algorithm by sampling 5% unlabeled examples as negative, in essence using 1 epoch of MIML to initialize.</S>
			<S sid ="113" ssid = "56">Empirically it performs well.</S>
	</SECTION>
	<SECTION title="Experiments. " number = "5">
			<S sid ="114" ssid = "1">10: z∗ = arg maxzi end for p(zi|ℓi, xi; wz , wℓ) Data set: We use the KBP (Ji et al., 2011) dataset9 prepared and publicly released by Surdeanu 11: 12: w∗ = arg maxw n xi logp(zij |xij , wz ) et al.</S>
			<S sid ="115" ssid = "2">(2012) for our experiment since it is 1) large � �| | z z i=1 = j 1 13: for all rǫR do 14: wr(∗) �n and realistic, 2) publicly available, 3) most im portantly, it is the only dataset that has associated ℓ = arg maxwr i=1 p(ℓr |zi, wr ) ℓ i ℓ 15: end for 16: end for 17: return wz, wℓ 7 All classifiers are implemented with L2-regularized logistic regression with Stanford CoreNLP package.</S>
			<S sid ="116" ssid = "3">human-labeled ground truth.</S>
			<S sid ="117" ssid = "4">Any KB held-out evaluation without manual assessment will be significantly affected by KB incompleteness.</S>
			<S sid ="118" ssid = "5">In KBP 8 Available at http://nlp.stanford.edu/software/mimlre.shtml.</S>
			<S sid ="119" ssid = "6">9 Available from Linguistic Data Consortium (LDC).</S>
			<S sid ="120" ssid = "7">http://projects.ldc.upenn.edu/kbp/data/ Figure 2: Performance on the KBP dataset.</S>
			<S sid ="121" ssid = "8">The figures on the left, middle and right show MIML, Hoffmann, and Mintz++ compared to the same MIML-Semi curve, respectively.</S>
			<S sid ="122" ssid = "9">MIML-Semi is shown in red curves (lighter curves in black and white) while other algorithms are shown in black curves (darker curves in black and white).</S>
			<S sid ="123" ssid = "10">dataset, the training bags are generated by mapping Wikipedia (http://en.wikipedia.org) infoboxes (after merging similar types following the KBP 2011 task definition) into a large unlabeled corpus (consisting of 1.5M documents from the KBP source corpus and a complete snapshot of Wikipedia).</S>
			<S sid ="124" ssid = "11">The KBP shared task provided 200 query named entities with their associated slot values (in total several thousand pairs).</S>
			<S sid ="125" ssid = "12">We use 40 queries as development dataset (dev), and the rest (160 queries) as evaluation dataset.</S>
			<S sid ="126" ssid = "13">We set θ = 0.25 by tuning on the dev set and use it in the experiments.</S>
			<S sid ="127" ssid = "14">For a fair comparison, we follow Surdeanu et al.</S>
			<S sid ="128" ssid = "15">(2012) and begin by downsampling the “negative“ class to 5%.</S>
			<S sid ="129" ssid = "16">We also set T=8 and use the following noisy-or (for ith bag) of mention-level probability to rank predicted types (r) of pairs and plot the precision-recall curves for all experiments.</S>
			<S sid ="130" ssid = "17">P robi(r) = 1 − n (1 − p(zij = r|xij ; wz )) j Evaluation: We compare our algorithm (MIML- semi) to three algorithms: 1) MIML (Surdeanu et al., 2012), the Multiple-Instance Multiple Label algorithm which labels the bags directly with the KB (y = ℓ).</S>
			<S sid ="131" ssid = "18">2) MultiR (denoted as Hoffmann) (Hoffmann et al., 2011), a Multiple-Instance algorithm that supports overlapping relations.</S>
			<S sid ="132" ssid = "19">It also imposes y = ℓ.</S>
			<S sid ="133" ssid = "20">3) Mintz++ (Surdeanu et al., 2012), a variant of the single-instance learning algorithm (section 3).</S>
			<S sid ="134" ssid = "21">The first two are stat-of-the-art Multi-Instance Multi-Label algorithms.</S>
			<S sid ="135" ssid = "22">Mintz++ is a strong baseline (Surdeanu et al., 2012) and an improved version of Mintz et al.</S>
			<S sid ="136" ssid = "23">(2009).</S>
			<S sid ="137" ssid = "24">Figure 2 shows that our algorithm consistently outperforms all three al gorithms at almost all recall levels (with the exception of a very small region in the PR-curve).</S>
			<S sid ="138" ssid = "25">This demonstrates that by treating unlabeled data set differently and leveraging the missing positive bags, MIML-semi is able to learn a more accurate model for extraction.</S>
			<S sid ="139" ssid = "26">Although the proposed solution is a specific algorithm, we believe the idea of treating unlabeled data differently can be incorporated into any of these algorithms that only use unlabeled data as negative examples.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "6">
			<S sid ="140" ssid = "1">We show that the distant-supervision labeling process generates a significant number of false negatives because the knowledge base is incomplete.</S>
			<S sid ="141" ssid = "2">We proposed an algorithm that learns from only positive and unlabeled bags.</S>
			<S sid ="142" ssid = "3">Experimental results demonstrate its advantage over existing algorithms.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="143" ssid = "4">Supported in part by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Interior National Business Center contract number D11PC20154.</S>
			<S sid ="144" ssid = "5">The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.</S>
			<S sid ="145" ssid = "6">The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of IARPA, DoI/NBC, or the U.S. Government.</S>
	</SECTION>
</PAPER>
