<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">This paper examines the extent to which verb diathesis alternations are empirically attested in corpus data.</S>
		<S sid ="2" ssid = "2">We automatically acquire alternating verbs from large balanced corpora by using partial­ parsing methods and taxonomic information, and discuss how corpus data can be used to quantify lin­ guistic generalizations.</S>
		<S sid ="3" ssid = "3">We estimate the productiv­ ity of an alternation and the typicality of its mem­ bers using type and token frequencies.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="4" ssid = "4">Diathesis alternations are changes in the realization of the argument structure of a verb that are some­ times accompanied by changes in meaning (Levin, 1993).</S>
			<S sid ="5" ssid = "5">The phenomenon in English is illustrated in (I)-(2) below.</S>
			<S sid ="6" ssid = "6">The objective of this paper is to investigate the ex­ tent to which diathesis alternations are empirically attested in corpus data.</S>
			<S sid ="7" ssid = "7">Using the dative and bene­ factive alternations as a test case we attempt to de­ termine: (a) if some alternations are more frequent than others, (b) if alternating verbs have frame pref­ erences and (c) what the representative members of an alternation are.</S>
			<S sid ="8" ssid = "8">In section 2 we describe and evaluate the set of automatic methods we used to acquire verbs under­ going the dative and benefactive alternations.</S>
			<S sid ="9" ssid = "9">We assess the acquired frames using a filtering method presented in section 3.</S>
			<S sid ="10" ssid = "10">The results are detailed in section 4.</S>
			<S sid ="11" ssid = "11">Sections 5 and 6 discuss how the derived type and token frequencies can be used to estimate how productive an alternation is for a given verb se­ mantic class and how typical its members are.</S>
			<S sid ="12" ssid = "12">Fi­ nally, section 7 offers some discussion on future (I) a. b.</S>
			<S sid ="13" ssid = "13">(2) a. b. John offers shares to his employe es.</S>
			<S sid ="14" ssid = "14">John offers his empl oyees share s. Leave a note for her.</S>
			<S sid ="15" ssid = "15">Leave her a note.</S>
			<S sid ="16" ssid = "16">work and section 8 conclusi ve remarks . 2 Me thod 2.1 T he parser Example ( 1) illustrates the dative alternation, which is characterized by an alternation between the prepositional frame &apos;V NPl to NP2&apos; and the double object frame &apos;V NPl NP2&apos;.</S>
			<S sid ="17" ssid = "17">The benefactive alterna­ tion (cf.</S>
			<S sid ="18" ssid = "18">(2)) is structurally similar to the dative, the difference being that it involves the preposition for rather than to.</S>
			<S sid ="19" ssid = "19">Levin (1993) assumes that the syntactic realiza­ tion of a verb&apos;s arguments is directly correlated with its meaning (cf.</S>
			<S sid ="20" ssid = "20">also Pinker (1989) for a similar pro­ posal).</S>
			<S sid ="21" ssid = "21">Thus one would expect verbs that undergo the same alternations to form a semantically co­ herent class.</S>
			<S sid ="22" ssid = "22">Levin&apos;s study on diathesis alternations has influenced recent work on word sense disam­ biguation (Dorr and Jones, 1996), machine transla­ tion (Dang et al., 1998), and automatic lexical ac­ quisition (McCarthy and Korhonen, 1998; Schulte im Walde, 1998).</S>
			<S sid ="23" ssid = "23">The part-of-speech tagged version of the British Na­ tional Corpus (BNC), a 100 million word collec­ tion of written and spoken British English (Burnard, 1995), was used to acquire the frames characteris­ tic of the dative and benefactive alternations.</S>
			<S sid ="24" ssid = "24">Sur­ face syntactic structure was identified using Gsearch (Keller et al., 1999), a tool which allows the search of arbitrary POS-tagged corpora for shallow syntac­ tic patterns based on a user-specified context-free grammar and a syntactic query.</S>
			<S sid ="25" ssid = "25">It achieves this by combining a left-comer parser with a regular ex­ pression matcher.</S>
			<S sid ="26" ssid = "26">Depending on the grammar specification (i.e., re­ cursive or not) Gsearch can be used as a full context­ free parser or a chunk parser.</S>
			<S sid ="27" ssid = "27">Depending on the syn­ tactic query, Gsearch can parse full sentences, iden­ tify syntactic relations (e.g., verb-object, adjective­ noun) or even single words (e.g., all indefinite pro nouns in the corpus).</S>
			<S sid ="28" ssid = "28">Gsearch outputs all corpus sentences containing substrings that match a given syntactic query.</S>
			<S sid ="29" ssid = "29">Given two possible parses that begin at the same point in the sentence, the parser chooses the longest match.</S>
			<S sid ="30" ssid = "30">If there are two possible parses that can be produced for the same substring, only one parse is returned.</S>
			<S sid ="31" ssid = "31">This means that if the number of ambiguous rules in the grammar is large, the correctness of the parsed output is not guaranteed.</S>
			<SUBSECTION>2.2 Acquisition.</SUBSECTION>
			<S sid ="32" ssid = "32">We used Gsearch to extract tokens matching the patterns &apos;V NPl NP2&apos;, &apos;VP NPl to NP2&apos;, and &apos;V NPl for NP2&apos; by specifying a chunk grammar for recognizing the verbal complex and NPs.</S>
			<S sid ="33" ssid = "33">POS-tags were retained in the parser&apos;s output which was post­ processed to remove adverbials and interjections.</S>
			<S sid ="34" ssid = "34">Examples of the parser&apos;s output are given in (3).</S>
			<S sid ="35" ssid = "35">Although there are cases where Gsearch produces the right parse (cf.</S>
			<S sid ="36" ssid = "36">(3a)), the parser wrongly iden­ tifies as instances of the double object frame to­ kens containing compounds (cf.</S>
			<S sid ="37" ssid = "37">(3b)), bare relative clauses (cf.</S>
			<S sid ="38" ssid = "38">(3c)) and NPs in apposition (cf.</S>
			<S sid ="39" ssid = "39">(3d)).</S>
			<S sid ="40" ssid = "40">Sometimes the parser attaches prepositional phrases to the wrong site (cf.</S>
			<S sid ="41" ssid = "41">(3e)) and cannot distinguish between arguments and adjuncts (cf.</S>
			<S sid ="42" ssid = "42">(3f)) or be­ tween different types of adjuncts (e.g., temporal (cf.</S>
			<S sid ="43" ssid = "43">(3f)) versus benefactive (cf.</S>
			<S sid ="44" ssid = "44">(3g))).</S>
			<S sid ="45" ssid = "45">Erroneous output also arises from tagging mistakes.</S>
			<S sid ="46" ssid = "46">(3) a. The police driver [v shot] [NP Jamie] [NP a look of enquiry] which he missed.</S>
			<S sid ="47" ssid = "47">b. Some also [v offer] [NPa free bus] [NP ser­ vice], to encourage customers who do not have their own transport.</S>
			<S sid ="48" ssid = "48">c. A Jaffna schoolboy [v shows] [NP a draw­ ing] [NP he] made of helicopters strafing his home town.</S>
			<S sid ="49" ssid = "49">&apos; d. For the latter catalogue Barr [v chose] [NP the Surrealist writer] [NP Georges Hugnet] to write a historical essay.</S>
			<S sid ="50" ssid = "50">e. It [v controlled] [NP access] (pp to [NP the vault]].</S>
			<S sid ="51" ssid = "51">PPs (cf.</S>
			<S sid ="52" ssid = "52">(3e)) using Hindle and Roath&apos;s (1993) lex­ ical association score (cf.</S>
			<S sid ="53" ssid = "53">section 2.4).</S>
			<S sid ="54" ssid = "54">Finally, we recognized benefactive PPs (cf.</S>
			<S sid ="55" ssid = "55">(3g)) by exploiting the WordNet taxonomy (cf.</S>
			<S sid ="56" ssid = "56">section 2.5).</S>
			<SUBSECTION>2.3 Guessing the double object frame.</SUBSECTION>
			<S sid ="57" ssid = "57">We developed a process which assesses whether the syntactic patterns (called cues below) derived from the corpus are instances of the double object frame.</S>
			<S sid ="58" ssid = "58">Linguistic Heuristics.</S>
			<S sid ="59" ssid = "59">We applied several heuris­ tics to the parser&apos;s output which determined whether corpus tokens were instances of the double object frame.</S>
			<S sid ="60" ssid = "60">The &apos;Reject&apos; heuristics below identified er­ roneous matches (cf.</S>
			<S sid ="61" ssid = "61">(3b-d)), whereas the &apos;Accept&apos; heuristics identified true instances of the double ob­ ject frame (cf.</S>
			<S sid ="62" ssid = "62">(3a)).</S>
			<S sid ="63" ssid = "63">1.</S>
			<S sid ="64" ssid = "64">Reject if cue contains at least two proper.</S>
			<S sid ="65" ssid = "65">names adjacent to each other (e.g., killed Henry Phipps).</S>
	</SECTION>
	<SECTION title="Reject if cue contains possessive noun phrases. " number = "2">
			<S sid ="66" ssid = "1">(e.g., give a showman&apos;s award).</S>
			<S sid ="67" ssid = "2">anaphor (e.g., ask the subjects themselves).</S>
			<S sid ="68" ssid = "3">4.</S>
			<S sid ="69" ssid = "4">Accept if verb is followed by a personal or in­.</S>
			<S sid ="70" ssid = "5">definite pronoun (e.g., found him a home).</S>
			<S sid ="71" ssid = "6">5.</S>
			<S sid ="72" ssid = "7">Accept if verb is followed by an anaphor.</S>
			<S sid ="73" ssid = "8">(e.g., made herself a snack).</S>
			<S sid ="74" ssid = "9">6.</S>
			<S sid ="75" ssid = "10">Accept if cue&apos;s surface structure is either &apos;V.</S>
			<S sid ="76" ssid = "11">MOD 1 NP MOD NP&apos; or &apos;V NP MOD NP&apos; (e.g., send Bailey a postcard).</S>
			<S sid ="77" ssid = "12">7.</S>
			<S sid ="78" ssid = "13">Cannot decide if cue&apos;s surface structure is. &apos;V MOD* N N+&apos; (e.g., offer a free bus ser­ vice).</S>
			<S sid ="79" ssid = "14">Compound Noun Detection.</S>
			<S sid ="80" ssid = "15">Tokens identified by heuristic (7) were dealt with separately by a pro­ cedure which guesses whether the nouns following the verb are two distinct arguments or parts of a compound.</S>
			<S sid ="81" ssid = "16">This procedure was applied only to noun sequences of length 2 and 3 which were extracted 2 f. Yesterday he [v rang] [NP the bell] (pp for from the parser&apos;s output and compared against a [NP a long time]].</S>
			<S sid ="82" ssid = "17">g. Don&apos;t [v save] [NP the bread] [pp for [NP the birds]].</S>
			<S sid ="83" ssid = "18">We identified erroneous subcategorization frames (cf.</S>
			<S sid ="84" ssid = "19">(3b)-(3d)) by using linguistic heuristics and a process for compound noun detection (cf.</S>
			<S sid ="85" ssid = "20">sec­ tion 2.3).</S>
			<S sid ="86" ssid = "21">We disambiguated the attachment site of compound noun dictionary (48,661 entries) com­ piled from WordNet.</S>
			<S sid ="87" ssid = "22">13.9% of the noun sequences were identified as compounds in the dictionary.</S>
			<S sid ="88" ssid = "23">1Here MOD represents any prenominal modifier (e.g., arti­ cles, pronouns, adjectives, quantifiers, ordinals).</S>
			<S sid ="89" ssid = "24">2Tokens containing noun sequences with length larger than 3 (450 in total) were considered negative instances of the double object frame.</S>
			<S sid ="90" ssid = "25">I G-score II 2-word compound 1967.68 bank manager 775.21 tax liability 87.02 income tax 45.40 book reviewer 30.58 designer gear 29.94 safety plan 24.04 drama school Table I: Random sample of two word compounds For sequences of length 2 not found in WordNet, G-score II 3-word compound 574.48 [[energy efficiency] office] 382.92 [[council tax] bills] 77.78 [alcohol [education course]] 48.84 [hospital [outpatient department] 36.44 [[tumour suppressor] function] 32.35 [[nature conservation] resources] 23.98 [[quality amplifier] circuits] Table 2: Random sample of three word compounds Method Kappa we used the log-likelihood ratio (G-score) to esti­ mate the lexical association between the nouns, in order to determine if they formed a compound noun.</S>
			<S sid ="91" ssid = "26">We preferred the log-likelihood ratio to other statis­ tical scores, such as the association ratio (Church and Hanks, I990) or x 2 , since it adequately takes into account the frequency of the co-occurring words and is less sensitive to rare events and corpus­ Reject heuristics Accept heuristics 2-word compounds 3-word compounds Verb attach-to Noun attach-to Verb attach-for Noun attach-for K = 0.76, N = 1000 K = 0.82, N = 1000 K = 0.83, N = 553 K = 0.70, N = 447 K=0.78,N=494 K = 0.80, N = 500 K = 0.85, N = 630 K = 0.88, N = 500 size (Dunning, 1993; Daille, 1996).</S>
			<S sid ="92" ssid = "27">We assumed that two nouns cannot be disjoint arguments of the verb if they are lexically associated.</S>
			<S sid ="93" ssid = "28">On this basis, tokens were rejected as instances of the double ob­ ject frame if they contained two nouns whose G­ score had a p-value less than 0.05.</S>
			<S sid ="94" ssid = "29">A two-step process was applied to noun se­ quences of length 3: first their bracketing was de­ termined and second the G-score was computed be­ tween the single noun and the 2-noun sequence.</S>
			<S sid ="95" ssid = "30">We inferred the bracketing by modifying an al­ gorithm initially proposed by Pustejovsky et a!.</S>
			<S sid ="96" ssid = "31">( I993).</S>
			<S sid ="97" ssid = "32">Given three nouns n 1 ,n2 , n3, if either [n 1 n2] or [n2 n3 ] are in the compound noun dictionary, we built structures [[n 1 n2] n3] or [n 1 [n2 n3]] accord­ ingly; if both [n 1 nz] and [nz n 3 ] appear in the dic­ tionary, we chose the most frequent pair; if neither Table 3: Precision of heuristics, compound noun de­ tection and lexical association Castellan, I988) which measures inter-rater agree­ ment among a set of coders making category judg­ ments.</S>
			<S sid ="98" ssid = "33">The Kappa coefficient of agreement (K) is the ra­ tio of the proportion of times, P(A), that k raters agree to the proportion of times, P(E), that we would expect the raters to agree by chance (cf.</S>
			<S sid ="99" ssid = "34">(4)).</S>
			<S sid ="100" ssid = "35">If there is a complete agreement among the raters, then K =I. ) K _ P(A) - P(E) 4 I- P(E) 3 [n 1 nz] nor [nz n3] appear in WordNet, we computed Precision figures (Prec) and inter-judge agreement the G-score for [n 1 n 2] and [n 2 n3] and chose the pair with highest value (p 0.05).</S>
			<S sid ="101" ssid = "36">Tables 1 and 2 display a random sample of the compounds the method found (p 0.05).</S>
			<S sid ="102" ssid = "37">2.3.1 Evaluation The performance of the linguistic heuristics and the compound detection procedure were evaluated by randomly selecting approximately 3,000 corpus to­ kens which were previously accepted or rejected as instances of the double object frame.</S>
			<S sid ="103" ssid = "38">Two judges de­ cided whether the tokens were classified correctly.</S>
			<S sid ="104" ssid = "39">The judges&apos; agreement on the classification task was calculated using the Kappa coefficient (Siegel and (Kappa) are summarized in table 3.</S>
			<S sid ="105" ssid = "40">In sum, the heuristics achieved a high accuracy in classifying cues for the double object frame.</S>
			<S sid ="106" ssid = "41">Agreement on the classification was good given that the judges were given minimal instructions and no prior training.</S>
			<S sid ="107" ssid = "42">2.4 Guessing the prepositional frames.</S>
			<S sid ="108" ssid = "43">In order to consider verbs with prepositional frames as candidates for the dative and benefactive alterna­ tions the following requirements needed to be met: 1.</S>
			<S sid ="109" ssid = "44">the PP must be attached to the verb; 3Throught the paper the reported percentages are the aver­ age of the judges&apos; individual classifications.</S>
			<S sid ="110" ssid = "45">2.</S>
			<S sid ="111" ssid = "46">in the case ofthe &apos;V NP1 to NP2&apos; structure, the to-PP must be an argument of the verb; 3.</S>
			<S sid ="112" ssid = "47">in the case of the &apos;V NP1 for NP2&apos; structure, the for-PP must be benefactive.4 In order to meet requirements (1)-(3), we first de­ termined the attachment site (e.g., verb or noun) of the PP and secondly developed a procedure for dis­ tinguishing benefactive from non-benefactive PPs.</S>
			<S sid ="113" ssid = "48">Several approaches have statistically addressed the problem of prepositional phrase ambiguity, with comparable results (Hindle and Rooth, 1993; Collins and Brooks, 1995; Ratnaparkhi, 1998).</S>
			<S sid ="114" ssid = "49">Hin­ dle and Rooth (1993) used a partial parser to extract ( v, n, p) tuples from a corpus, where p is the prepo­ sition whose attachment is ambiguous between the verb v and the noun n. We used a variant of the method described in Hindle and Rooth (1993), the main difference being that we applied their lexical association score (a log-likelihood ratio which com­ pares the probability of noun versus verb attach­ ment) in an unsupervised non-iterative manner.</S>
			<S sid ="115" ssid = "50">Fur­ thermore, the procedure was applied to the special case of tuples containing the prepositions to and for only.</S>
			<S sid ="116" ssid = "51">2.4.1 Evaluation We evaluated the procedure by randomly select­ ing 2,124 tokens containing to-PPs and for-PPs for which the procedure guessed verb or noun at­ tachment.</S>
			<S sid ="117" ssid = "52">The tokens were disambiguated by two judges.</S>
			<S sid ="118" ssid = "53">Precision figures are reported in table 3.</S>
			<S sid ="119" ssid = "54">The lexical association score was highly accu­ rate on guessing both verb and noun attachment for to-PPs.</S>
			<S sid ="120" ssid = "55">Further evaluation revealed that for 98.6% (K = 0.9, N = 494, k = 2) of the tokens clas­ sified as instances of verb attachment, the to-PP was an argument of the verb, which meant that the log-likelihood ratio satisfied both requirements (1) and (2) for to-PPs.</S>
			<S sid ="121" ssid = "56">A low precision of 36% was achieved in detecting instances of noun attachment for for-PPs.</S>
			<S sid ="122" ssid = "57">One rea­ son for this is the polysemy of the preposition for: for-PPs can be temporal, purposive, benefactive or causal adjuncts and consequently can attach to var­ ious sites.</S>
			<S sid ="123" ssid = "58">Another difficulty is that benefactive for­ PPs semantically license both attachment sites.</S>
			<S sid ="124" ssid = "59">To further analyze the poor performance of thelog-likelihood ratio on this task, 500 tokens con 4 Syntactically speaking, benefactive for-PPs are not argu­ ments but adjuncts (Jackendoff, 1990) and can appear on any verb with which they are semantically compatible.</S>
			<S sid ="125" ssid = "60">tammg for-PPs were randomly selected from the parser&apos;s output and disambiguated.</S>
			<S sid ="126" ssid = "61">Of these 73.9% (K = 0.9, N = 500, k = 2) were instances of verb attachment, which indicates that verb attachments outnumber noun attachments for for-PPs, and there­ fore a higher precision for verb attachment (cf.</S>
			<S sid ="127" ssid = "62">re­ quirement (1)) can be achieved without applying the log-likelihood ratio, but instead classifying all in­ stances as verb attachment.</S>
			<S sid ="128" ssid = "63">2.5 Benefactive PPs.</S>
			<S sid ="129" ssid = "64">Although surface syntactic cues can be important for determining the attachment site of prepositional phrases, they provide no indication of the semantic role of the preposition in question.</S>
			<S sid ="130" ssid = "65">This is particu­ larly the case for the preposition for which can have several roles, besides the benefactive.</S>
			<S sid ="131" ssid = "66">Two judges discriminated benefactive from non­ benefactive PPs for 500 tokens, randomly selected from the parser&apos;s output.</S>
			<S sid ="132" ssid = "67">Only 18.5% (K = 0.73, N = 500, k = 2) of the sample contained bene­ factive PPs.</S>
			<S sid ="133" ssid = "68">An analysis of the nouns headed by the preposition for revealed that 59.6% were animate, 17% were collective, 4.9% denoted locations, and the remaining 18.5% denoted events, artifacts, body parts,&apos; or actions.</S>
			<S sid ="134" ssid = "69">Animate, collective and location nouns account for 81.5% of the benefactive data.</S>
			<S sid ="135" ssid = "70">We used the WordNet taxonomy (Miller et al., 1990) to recognize benefactive PPs (cf.</S>
			<S sid ="136" ssid = "71">require­ ment (3)).</S>
			<S sid ="137" ssid = "72">Nouns in WordNet are organized into an inheritance system defined by hypemymic rela­ tions.</S>
			<S sid ="138" ssid = "73">Instead of being contained in a single hier­ archy, nouns are partitioned into a set of seman­ tic primitives (e.g., act, animal, time) which are treated as the unique beginners of separate hier­ archies.</S>
			<S sid ="139" ssid = "74">We compiled a &quot;concept dictionary&quot; from WordNet (87,642 entries), where each entry con­ sisted of the noun and the semantic primitive dis­ tinguishing each noun sense (cf.</S>
			<S sid ="140" ssid = "75">table 4).</S>
			<S sid ="141" ssid = "76">We considered a for-PP to be benefactive if the noun headed by for was listed in the concept dic­ tionary and the semantic primitive of its prime sense (Sense 1) was person, animal, group or lo­ cation.</S>
			<S sid ="142" ssid = "77">PPs with head nouns not listed in the dictio­ nary were considered benefactive only if their head nouns were proper names.</S>
			<S sid ="143" ssid = "78">Tokens containing per­ sonal, indefinite and anaphoric pronouns were also considered benefactive (e.g., build a home for him).</S>
			<S sid ="144" ssid = "79">Two judges evaluated the procedure by judging 1,000 randomly selected tokens, which were ac­ cepted or rejected as benefactive.</S>
			<S sid ="145" ssid = "80">The procedure achieved a precision of 48.8% (K = 0.89, N = L II Sense 1 Sense 2 Sense 3 Table 4: Sample entries from WordNet concept dic­ tionary 500, k = 2) in detecting benefactive tokens and 90.9% (K = .94, N = 499, k = 2) in detecting non-benefactive ones.</S>
	</SECTION>
	<SECTION title="Filtering. " number = "3">
			<S sid ="146" ssid = "1">Filtering assesses how probable it is for a verb to be associated with a wrong frame.</S>
			<S sid ="147" ssid = "2">Erroneous frames can be the result of tagging errors, parsing mistakes, or errors introduced by the heuristics and proce­ dures we used to guess syntactic structure.</S>
			<S sid ="148" ssid = "3">We discarded verbs for which we had very little evidence (frame frequency= 1) and applied a rela­ tive frequency cutoff: the verb&apos;s acquired frame fre­ quency was compared against its overall frequency in the BNC.</S>
			<S sid ="149" ssid = "4">Verbs whose relative frame frequency was lower than an empirically established thresh­ old were discarded.</S>
			<S sid ="150" ssid = "5">The threshold values varied from frame to frame but not from verb to verb and were determined by taking into account for each frame its overall frame frequency which was es­ timated from the COMLEX subcategorization dic­ tionary (6,000 verbs) (Grishman et al., 1994).</S>
			<S sid ="151" ssid = "6">This meant that the threshold was higher for less frequent frames (e.g., the double object frame for which only 79 verbs are listed in COMLEX).</S>
			<S sid ="152" ssid = "7">We also experimented with a method suggested by Brent (1993) which applies the binomial test on frame frequency data.</S>
			<S sid ="153" ssid = "8">Both methods yielded comparable results.</S>
			<S sid ="154" ssid = "9">However, the relative frequency threshold worked slightly better and the results re­ ported in the following section are based on this method.</S>
	</SECTION>
	<SECTION title="Results. " number = "4">
			<S sid ="155" ssid = "1">We acquired 162 verbs for the double object frame, 426 verbs for the &apos;V NPl to NP2&apos; frame and 962 for the &apos;V NP1 for NP2&apos; frame.</S>
			<S sid ="156" ssid = "2">Membership in al­ ternations was judged as follows: (a) a verb partic­ ipates in the dative alternation if it has the double object and &apos;V NP1 to NP2&apos; frames and (b) a verb Table 5: Verbs common in corpus and Levin participates in the benefactive alternation if it has the double object and &apos;V NPl for NP2&apos; frames.</S>
			<S sid ="157" ssid = "3">Ta­ ble 5 shows a comparison of the verbs found in the corpus against Levin&apos;s list of verbs;5 rows &apos;V NPl to NP2&apos; and &apos;V NP1 for NP2&apos; contain verbs listed as alternating in Levin but for which we acquired only one frame.</S>
			<S sid ="158" ssid = "4">In Levin 115 verbs license the dative and 103 license the benefactive alternation.</S>
			<S sid ="159" ssid = "5">Of these we acquired 68 for the dative and 43 for the benefactive alternation (in both cases including verbs for which only one frame was acquired).</S>
			<S sid ="160" ssid = "6">The dative and benefactive alternations were also acquired for 52 verbs not listed in Levin.</S>
			<S sid ="161" ssid = "7">Of these, 10 correctly alternate (cause, deliver, hand, refuse, report and set for the dative alternation and cause, spoil, afford and prescribe for the benefactive), and 12 can appear in either frame but do not alter­ nate (e.g., appoint, fix, proclaim).</S>
			<S sid ="162" ssid = "8">For 18 verbs two frames were acquired but only one was correct (e.g., swap and forgive which take only the double object frame), and finally 12 verbs neither alternated nor had the acquired frames.</S>
			<S sid ="163" ssid = "9">A random sample of the acquired verb frames and their (log transformed) frequencies is shown in figure 1.</S>
			<S sid ="164" ssid = "10">5The comparisons reported henceforth exclude verbs listed in Levin with overall corpus frequency less than I per million.</S>
			<S sid ="165" ssid = "11">8 0 ..</S>
			<S sid ="166" ssid = "12">class the number of verbs acquired from the cor­ pus against the number of verbs listed in Levin.</S>
			<S sid ="167" ssid = "13">As can be seen in figure 2, Levin and the corpus ap­ proximate each other for verbs of FUTURE HAVING (e.g., guarantee), verbs of MESSAGE TRANSFER (e.g., tell) and BRING TAKE verbs (e.g., bring).</S>
			<S sid ="168" ssid = "14">The semantic classes of GIVE (e.g., sell), CARRY (e.g., drag), SEND (e.g., ship), GET (e.g., buy) and PREPARE (e.g., bake) verbs are also fairly well rep­ resented in the corpus, in contrast to SLIDE verbs (e.g., bounce) for which no instances were found.</S>
			<S sid ="169" ssid = "15">Note that the corpus and Levin did not agree with respect to the most popular classes licensing the dative and benefactive alternations: THROWING ..</S>
			<S sid ="170" ssid = "16">..!: .J:J u&quot;., .J:J biggest classes in Levin allowing the dative and c C&gt; ·;;; ] &apos;E ..c &quot;5l &quot;c0 1 . : : .:1.</S>
			<S sid ="171" ssid = "17">(e.g., toss) and BUILD verbs (e.g., carve) are the benefactive alternations respectively, in contrast to Figure 1: Random sample of acquired frequencies for the dative and benefactive alternations 30 ..C..l 20 &apos;Q e 2&quot;: 10 w t I FUTURE HAVING and GET verbs in the corpus.</S>
			<S sid ="172" ssid = "18">This can be explained by looking at the average cor­ pus frequency of the verbs belonging to the seman­ tic classes in question: FUTURE HAVING and GET verbs outnumber THROWING and BUILD verbs by a factor of two to one.</S>
			<S sid ="173" ssid = "19">5 Productivity The relative productivity of an alternation for a se­ mantic class can be estimated by calculating the ra­ tio of acquired to possible verbs undergoing the al ternation (Aronoff, 1976; Briscoe and Copestake, 1996): /(acquired, class) (5) P(acquiredlclass) = -----­ :4 &quot; ...</S>
			<S sid ="174" ssid = "20">I In rnl Ill f(class) : 0 ..</S>
			<S sid ="175" ssid = "21">-.g. ..</S>
			<S sid ="176" ssid = "22">u &quot;&apos; :5!</S>
			<S sid ="177" ssid = "23">= !... u...</S>
			<S sid ="178" ssid = "24">We express the productivity of an alternation for a given class as f(acquired, class), the number of ..</S>
			<S sid ="179" ssid = "25">c ... c li &quot; c ·;;: (3 ...</S>
			<S sid ="180" ssid = "26">;g ....</S>
			<S sid ="181" ssid = "27">·;;: .:1.</S>
			<S sid ="182" ssid = "28">·;; c :c ...</S>
			<S sid ="183" ssid = "29">.C.&gt;.</S>
			<S sid ="184" ssid = "30">u &quot;&apos; Q J. ..: .e..</S>
			<S sid ="185" ssid = "31">u:i ...</S>
			<S sid ="186" ssid = "32">...c. c ! = ·;;: &apos;&quot;&quot; verbs which were found in the corpus and are mem &amp;: bers of the class, over f(class), the total number of verbs which are listed in Levin as members of Figure 2: Semantic classes for the dative and bene factive alternations Levin defines 10 semantic classes of verbs for which the dative alternation applies (e.g., GIVE verbs, verbs of FUTURE HAVING, SEND verbs), and 5 classes for which the benefactive alternation ap plies (e.g., BUILD, CREATE, PREPARE verbs), as suming that verbs participating in the same class share certain meaning components.</S>
			<S sid ="187" ssid = "33">We partitioned our data according to Levin&apos;s pre defined classes.</S>
			<S sid ="188" ssid = "34">Figure 2 shows for each semantic the class (Total).</S>
			<S sid ="189" ssid = "35">The productivity values (Prod) for both the dative and the benefactive alternation (Alt) are summarized in table 6.</S>
			<S sid ="190" ssid = "36">Note that productivity is sensitive to class size.</S>
			<S sid ="191" ssid = "37">The productivity of BRING-TAKE verbs is esti­ mated to be 1 since it contains only 2 members which were also found in the corpus.</S>
			<S sid ="192" ssid = "38">This is intu­ itively correct, as we would expect the alternation to be more productive for specialized classes.</S>
			<S sid ="193" ssid = "39">The productivity estimates discussed here can be potentially useful for treating lexical rules proba­ bilistically, and for quantifying the degree to which language users are willing to apply&apos; a rule in order Dativ e alter natio n Class Total AI t Pr od Ty p B R I N G T A K E F U T U R E H A V I N G G I V E M . T R A N S F E R C A R R Y D R I V E T H R O W I N G S E N D lN ST R. C O M. SL ID E 2 19 15 17 15 11 30 23 18 5 2 17 9 10 6 3 7 3 1 0 1 0.</S>
			<S sid ="194" ssid = "40">89 0.</S>
			<S sid ="195" ssid = "41">6 0.</S>
			<S sid ="196" ssid = "42">58 0.</S>
			<S sid ="197" ssid = "43">4 0.</S>
			<S sid ="198" ssid = "44">27 0.</S>
			<S sid ="199" ssid = "45">23 0.</S>
			<S sid ="200" ssid = "46">13 0.</S>
			<S sid ="201" ssid = "47">05 0 0.</S>
			<S sid ="202" ssid = "48">32 7 0.</S>
			<S sid ="203" ssid = "49">31 3 0.</S>
			<S sid ="204" ssid = "50">55 0.</S>
			<S sid ="205" ssid = "51">66 0.</S>
			<S sid ="206" ssid = "52">05 6 0.</S>
			<S sid ="207" ssid = "53">03 0.</S>
			<S sid ="208" ssid = "54">65 8 0.1 81 0.</S>
			<S sid ="209" ssid = "55">64 8 0 Benefa ctive alternat ion Cl ass To tal AI t Pr od Ty p G E T P R E P A R E B U I L D P E R F O R M A N C E C R E A T E 33 26 35 19 20 17 9 12 1 2 0.</S>
			<S sid ="210" ssid = "56">51 0.</S>
			<S sid ="211" ssid = "57">34 6 0.</S>
			<S sid ="212" ssid = "58">34 2 0.</S>
			<S sid ="213" ssid = "59">05 0.</S>
			<S sid ="214" ssid = "60">1 0.</S>
			<S sid ="215" ssid = "61">54 0.</S>
			<S sid ="216" ssid = "62">55 0.</S>
			<S sid ="217" ssid = "63">34 0.</S>
			<S sid ="218" ssid = "64">56 0.</S>
			<S sid ="219" ssid = "65">05 Table 6: Productivity estimates and typicality values for the dative and benefactive alternation to produce a novel form (Briscoe and Copestake, 1996).</S>
			<S sid ="220" ssid = "66">6 Typicality.</S>
			<S sid ="221" ssid = "67">Estimating the productivity of an alternation for a given class does not incorporate information about the frequency of the verbs undergoing the alterna­ tion.</S>
			<S sid ="222" ssid = "68">We propose to use frequency data to quantify the typicality of a verb or verb class for a given alter­ nation.</S>
			<S sid ="223" ssid = "69">The underlying assumption is that a verb is typical for an alternation if it is equally frequent for both frames which are characteristic for the alter­ nation.</S>
			<S sid ="224" ssid = "70">Thus the typicality of a verb can be defined as the conditional probability of the frame given the verb: f(framei, verb) (6) P(framedverb) = &quot; L f(framen, verb) n We calculate P(framedverb) by dividing f(framei, verb), the number of times the verb was attested in the corpus with frame i, by f(frame,&quot; verb), the overall number of times the verb was attested.</S>
			<S sid ="225" ssid = "71">In our case a verb has two frames, hence P(framedverb) is close to 0.5 for typical verbs (i.e., verbs with balanced frequencies) and close to either 0 or 1 for peripheral verbs, depending on their preferred frame.</S>
			<S sid ="226" ssid = "72">Consider the verb owe as an example (cf.</S>
			<S sid ="227" ssid = "73">figure 1).</S>
			<S sid ="228" ssid = "74">648 instances of owe were found, of which 309 were instances of the double object frame.</S>
			<S sid ="229" ssid = "75">By dividing the latter by the former we can see that owe is highly typical of the dative alternation: its typicality score for the double object frame is 0.48.</S>
			<S sid ="230" ssid = "76">By taking the average of P(framei, verb) for all verbs which undergo the alternation and belong to the same semantic class, we can estimate how typi­ cal this class is for the alternation.</S>
			<S sid ="231" ssid = "77">Table 6 illustrates the typicality (Typ) of the semantic classes for the two alternations.</S>
			<S sid ="232" ssid = "78">(The typicality values were com­ puted for the double object frame).</S>
			<S sid ="233" ssid = "79">For the dative alternation, the most typical class is GIVE, and the most peripheral is DRIVE (e.g., ferry).</S>
			<S sid ="234" ssid = "80">For the bene­ factive alternation, PERFORMANCE (e.g., sing), PREPARE (e.g., bake) and GET (e.g., buy) verbs are the most typical, whereas CREATE verbs (e.g., com­ pose) are peripheral, which seems intuitively cor­ rect.</S>
			<S sid ="235" ssid = "81">7 Future Work.</S>
			<S sid ="236" ssid = "82">The work reported in this paper relies on frame frequencies acquired from corpora using partial­ parsing methods.</S>
			<S sid ="237" ssid = "83">For instance, frame frequency data was used to estimate whether alternating verbs ex­ hibit different preferences for a given frame (typi­ cality).</S>
			<S sid ="238" ssid = "84">However, it has been shown that corpus id­ iosyncrasies can affect subcategorization frequen­ cies (cf.</S>
			<S sid ="239" ssid = "85">Roland and Jurafsky (1998) for an exten­ sive discussion).</S>
			<S sid ="240" ssid = "86">This suggests that different corpora may give different results with respect to verb al­ ternations.</S>
			<S sid ="241" ssid = "87">For instance, the to-PP frame is poorly&apos; represented in the syntactically annotated version of the Penn Treebank (Marcus et al., 1993).</S>
			<S sid ="242" ssid = "88">There are only 26 verbs taking the to-PP frame, of which 20 have frame frequency of 1.</S>
			<S sid ="243" ssid = "89">This indicates that a very small number of verbs undergoing the dative alter­ nation can be potentially acquired from this corpus.</S>
			<S sid ="244" ssid = "90">In future work we plan to investigate the degree to which corpus differences affect the productivity and typicality estimates for verb alternations.</S>
			<S sid ="245" ssid = "91">8 Conclusions.</S>
			<S sid ="246" ssid = "92">This paper explored the degree to which diathesis alternations can be identified in corpus data via shal­ low syntactic processing.</S>
			<S sid ="247" ssid = "93">Alternating verbs were ac­ quired from the BNC by using Gsearch as a chunk parser.</S>
			<S sid ="248" ssid = "94">Erroneous frames were discarded by apply­ ing linguistic heuristics, statistical scores (the log­ likelihood ratio) and large-scale lexical resources (e.g., WordNet).</S>
			<S sid ="249" ssid = "95">We have shown that corpus frequencies can be used to quantify linguistic intuitions and lexical generalizations such as Levin&apos;s (1993) semantic classification.</S>
			<S sid ="250" ssid = "96">Furthermore, corpus frequencies can make explicit predictions about word use.</S>
			<S sid ="251" ssid = "97">This was demonstrated by using the frequencies to estimate the productivity of an alternation for a given seman­ tic class and the typicality of its members.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="252" ssid = "98">The author was supported by the Alexander S. Onassis Foundation and the UK Economic and Social Research Council.</S>
			<S sid ="253" ssid = "99">Thanks to Chris Brew, Frank Keller, Alex Lascarides and Scott McDonald for valuable comments.</S>
	</SECTION>
</PAPER>
