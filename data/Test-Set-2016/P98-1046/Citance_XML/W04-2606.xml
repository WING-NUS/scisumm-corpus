<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Lexical-semantic verb classifications have proved useful in supporting various natural language processing (NL P) tasks.</S>
		<S sid ="2" ssid = "2">The largest and the most widely deployed classification in English is Levin’s (1993) taxonomy of verbs and their classes.</S>
		<S sid ="3" ssid = "3">While this resource is attractive in being extensive enough for some NL P use, it is not comprehensive.</S>
		<S sid ="4" ssid = "4">In this paper, we present a substantial extension to Levin’s taxonomy which incorporates 57 novel classes for verbs not covered (comprehensively) by Levin.</S>
		<S sid ="5" ssid = "5">We also introduce 106 novel diathesis alternations, created as a side product of constructing the new classes.</S>
		<S sid ="6" ssid = "6">We demonstrate the utility of our novel classes by using them to support automatic subcategorization acquisition and show that the resulting extended classification has extensive coverage over the English verb lexicon.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="7" ssid = "7">Lexical-semantic classes which aim to capture the close relationship between the syntax and semantics of verbs have attracted considerable interest in both linguistics and computational linguistics (e.g.</S>
			<S sid ="8" ssid = "8">(Pinker, 1989; Jackendoff, 1990; Levin, 1993; Dorr, 1997; Dang et al., 1998; Merlo and Stevenson, 2001)).</S>
			<S sid ="9" ssid = "9">Such classes can capture generalizations over a range of (cross-)linguistic properties, and can therefore be used as a valuable means of reducing redundancy in the lexicon and for filling gaps in lexical knowledge.Verb classes have proved useful in various (multilin gual) natural language processing (NL P) tasks and applications, such as computational lexicography (Kipper et al., 2000), language generation (Stede, 1998), machine translation (Dorr, 1997), word sense disambigua tion (Prescher et al., 2000), document classification (Kla- vans and Kan, 1998), and subcategorization acquisition (Korhonen, 2002).</S>
			<S sid ="10" ssid = "10">Fundamentally, such classes define the mapping from surface realization of arguments to predicate-argument structure and are therefore a critical component of any NL P system which needs to recover predicate-argument structure.</S>
			<S sid ="11" ssid = "11">In many operational contexts, lexical information must be acquired from small application- and/or domain-specific corpora.</S>
			<S sid ="12" ssid = "12">The predictive power of classes can help compensate for lack of sufficient data fully exemplifying the behaviour of relevant words, through use of back-off smoothing or similar techniques.</S>
			<S sid ="13" ssid = "13">Although several classifications are now available for English verbs (e.g.</S>
			<S sid ="14" ssid = "14">(Pinker, 1989; Jackendoff, 1990; Levin, 1993)), they are all restricted to certain class types and many of them have few exemplars with each class.</S>
			<S sid ="15" ssid = "15">For example, the largest and the most widely deployed classification in English, Levin’s (1993) taxonomy, mainly deals with verbs taking noun and prepositional phrase complements, and does not provide large numbers of exemplars of the classes.</S>
			<S sid ="16" ssid = "16">The fact that no comprehensive classification is available limits the usefulness of the classes for practical NL P. Some experiments have been reported recently which indicate that it should be possible, in the future, to automatically supplement extant classifications with novel verb classes and member verbs from corpus data (Brew and Schulte im Walde, 2002; Merlo and Stevenson, 2001; Korhonen et al., 2003).</S>
			<S sid ="17" ssid = "17">While the automatic approach will avoid the expensive overhead of manual classification, the very development of the technology capable of large-scale automatic classification will require access to a target classification and gold standard exemplification of it more extensive than that available currently.</S>
			<S sid ="18" ssid = "18">In this paper, we address these problems by introducing a substantial extension to Levin’s classification which incorporates 57 novel classes for verbs not covered (com prehensively) by Levin.</S>
			<S sid ="19" ssid = "19">These classes, many of them drawn initially from linguistic resources, were created semi-automatically by looking for diathesis alternations shared by candidate verbs.</S>
			<S sid ="20" ssid = "20">106 new alternations not covered by Levin were identified for this work.</S>
			<S sid ="21" ssid = "21">We demonstrate the usefulness of our novel classes by using them to improve the performance of our extant subcategorization acquisition system.</S>
			<S sid ="22" ssid = "22">We show that the resulting extended classification has good coverage over the English verb lexicon.</S>
			<S sid ="23" ssid = "23">Discussion is provided on how the classification could be further refined and extended in the future, and integrated as part of Levin’s extant taxonomy.</S>
			<S sid ="24" ssid = "24">We discuss Levin’s classification and its extensions in section 2.</S>
			<S sid ="25" ssid = "25">Section 3 describes the process of creating the new verb classes.</S>
			<S sid ="26" ssid = "26">Section 4 reports the experimental evaluation and section 5 discusses further work.</S>
			<S sid ="27" ssid = "27">Conclusions are drawn in section 6.</S>
	</SECTION>
	<SECTION title="Levin’s Classification. " number = "2">
			<S sid ="28" ssid = "1">Levin’s classification (Levin, 1993) provides a summary of the variety of theoretical research done on lexical- semantic verb classification over the past decades.</S>
			<S sid ="29" ssid = "2">In this classification, verbs which display the same or similar set of diathesis alternations in the realization of their argument structure are assumed to share certain meaning components and are organized into a semantically coherent class.</S>
			<S sid ="30" ssid = "3">Although alternations are chosen as the primary means for identifying verb classes, additional properties related to subcategorization, morphology and extended meanings of verbs are taken into account as well.</S>
			<S sid ="31" ssid = "4">For instance, the Levin class of “Break Verbs” (class 45.1), which refers to actions that bring about a change in the material integrity of some entity, is characterized by its participation (13) or non-participation (46) in the following alternations and other constructions (78): 1.</S>
			<S sid ="32" ssid = "5">Causative/inchoative alternation:.</S>
			<S sid ="33" ssid = "6">Tony broke the window The window broke 2.</S>
			<S sid ="34" ssid = "7">Middle alternation:.</S>
			<S sid ="35" ssid = "8">Tony broke the window The window broke easily</S>
	</SECTION>
	<SECTION title="Instrument subject alternation:. " number = "3">
			<S sid ="36" ssid = "1">Tony broke the window with the hammer The hammer broke the window 4.</S>
			<S sid ="37" ssid = "2">*With/against alternation: Tony broke the cup against the wall *Tony broke the wall with the cup 5.</S>
			<S sid ="38" ssid = "3">*Conative alternation: Tony broke the window *Tony broke at the window 6.</S>
			<S sid ="39" ssid = "4">*Body-Part possessor ascension alternation: *Tony broke herself on the arm Tony broke her arm 7.</S>
			<S sid ="40" ssid = "5">Unintentional interpretation available (some verbs):.</S>
			<S sid ="41" ssid = "6">Reflexive object: *Tony broke himself Body-part object: Tony broke his finger 8.</S>
			<S sid ="42" ssid = "7">Resultative phrase:.</S>
			<S sid ="43" ssid = "8">Tony broke the piggy bank open, Tony broke the glass to pieces Levin’s taxonomy provides a classification of 3,024 verbs (4,186 senses) into 48 broad and 192 fine-grained classes according to their participation in 79 alternations involving NP and PP complements.</S>
			<S sid ="44" ssid = "9">Some extensions have recently been proposed to this resource.</S>
			<S sid ="45" ssid = "10">Dang et al.</S>
			<S sid ="46" ssid = "11">(1998) have supplemented the taxonomy with intersective classes: special classes for verbs which share membership of more than one Levin class because of regular polysemy.</S>
			<S sid ="47" ssid = "12">Bonnie Dorr (University of Maryland) has provided a reformulated and extended version of Levin’s classification in her L CS database (http://www.umiacs.umd.edu/ bonnie/verbs- English.lcs).</S>
			<S sid ="48" ssid = "13">This resource groups 4,432 verbs (11,000 senses) into 466 Levin-based and 26 novel classes.</S>
			<S sid ="49" ssid = "14">The latter are Levin classes refined according to verbal telicity patterns (Olsen et al., 1997), while the former are additional classes for non-Levin verbs which do not fall into any of the Levin classes due to their distinctive syntactic behaviour (Dorr, 1997).</S>
			<S sid ="50" ssid = "15">As a result of this work, the taxonomy has gained considerably in depth, but not to the same extent in breadth.</S>
			<S sid ="51" ssid = "16">Verbs taking ADJP, ADVP, ADL, particle, predicative, control and sentential complements are still largely excluded, except where they show interesting behaviour with respect to NP and PP complementation.</S>
			<S sid ="52" ssid = "17">As many of these verbs are highly frequent in language, NL P applications utilizing lexical-semantic classes would benefit greatly from a linguistic resource which provides adequate classification of their senses.</S>
			<S sid ="53" ssid = "18">When extending Levin’s classification with new classes, we particularly focussed on these verbs.</S>
			<S sid ="54" ssid = "19">3 Creating Novel Classes.</S>
			<S sid ="55" ssid = "20">Levin’s original taxonomy was created by 1.</S>
			<S sid ="56" ssid = "21">selecting a set of diathesis alternations from linguistic resources, 2.</S>
			<S sid ="57" ssid = "22">classifying a large number of verbs according to their participation in these alternations, 3.</S>
			<S sid ="58" ssid = "23">grouping the verbs into semantic classes based on their participation in sets of alternations.</S>
			<S sid ="59" ssid = "24">We adopted a different, faster approach.</S>
			<S sid ="60" ssid = "25">This involved 1.</S>
			<S sid ="61" ssid = "26">composing a set of diathesis alternations for verbs not covered comprehensively by Levin, 2.</S>
			<S sid ="62" ssid = "27">selecting a set of candidate lexical-semantic classes for these verbs from linguistic resources, 3.</S>
			<S sid ="63" ssid = "28">examining whether (sub)sets of verbs in each candidate class could be related to each other via alternations and thus warrant creation of a new class.</S>
			<S sid ="64" ssid = "29">In what follows, we will describe these steps in detail.</S>
			<S sid ="65" ssid = "30">3.1 Novel Diathesis Alternations.</S>
			<S sid ="66" ssid = "31">When constructing novel diathesis alternations, we took as a starting point the subcategorization classification of Briscoe (2000).</S>
			<S sid ="67" ssid = "32">This fairly comprehensive classification incorporates 163 different subcategorization frames (SCFs), a superset of those listed in the ANLT (Boguraev et al., 1987) and COML E X Syntax dictionaries (Grishman et al., 1994).</S>
			<S sid ="68" ssid = "33">The SCFs define mappings from surface arguments to predicate-argument structure for bounded dependency constructions, but abstract over specific particles and prepositions, as these can be trivially instantiated when the a frame is associated with a specific verb.</S>
			<S sid ="69" ssid = "34">As most diathesis alternations are only semi-predictable on a verb-by-verb basis, a distinct SCF is defined for every such construction, and thus all alternations can be represented as mappings between such SCFs.</S>
			<S sid ="70" ssid = "35">We considered possible alternations between pairs of SCFs in this classification, focusing in particular on those SCFs not covered by Levin.</S>
			<S sid ="71" ssid = "36">The identification of alternations was done manually, using criteria similar to Levin’s: the SCFs alternating should preserve the sense in question, or modify it systematically.</S>
			<S sid ="72" ssid = "37">106 new alternations were discovered using this method and grouped into different, partly overlapping categories.</S>
			<S sid ="73" ssid = "38">Table 1 shows some example alternations and their corresponding categories.</S>
			<S sid ="74" ssid = "39">The alternating patterns are indicated using an arrow ( ).</S>
			<S sid ="75" ssid = "40">The SCFs are marked using number codes whose detailed description can be found in (Briscoe, 2000) (e.g. SCF 53.</S>
			<S sid ="76" ssid = "41">refers to the COM- L E X subcategorization class NP-TO-INFOC).</S>
			<S sid ="77" ssid = "42">3.2 Candidate Lexical-Semantic Classes.</S>
			<S sid ="78" ssid = "43">Starting off from set of candidate classes accelerated the work considerably as it enabled building on extant linguistic research.</S>
			<S sid ="79" ssid = "44">Although a number of studies are available on verb classes not covered by Levin, many of these assume a classification system completely different to that of Levin’s, and/or incorporate sense distinctions too fine-grained for easy integrations with Levin’s classification.</S>
			<S sid ="80" ssid = "45">We therefore restricted our scope to a few classifications of a suitable style and granularity: 3.2.1 The LCS Database The L CS database includes 26 classes for verbs which could not be mapped into any of the Levin classes due to their distinctive syntactic behaviour.</S>
			<S sid ="81" ssid = "46">These classes were originally created by an automatic verb classification algorithm described in (Dorr, 1997).</S>
			<S sid ="82" ssid = "47">Although they appear semantically meaningful, their syntactic-semantic properties have not been systematically studied in terms of diathesis alternations, and therefore re-examination is warranted.</S>
			<S sid ="83" ssid = "48">3.2.2 Rudanko’s Classification Rudanko (1996, 2000) provides a semantically motivated classification for verbs taking various types of sentential complements (including predicative and control constructions).</S>
			<S sid ="84" ssid = "49">His relatively fine-grained classes, organized into sets of independent taxonomies, have been created in a manner similar to Levin’s. We took 43 of Run- danko’s verb classes for consideration.</S>
			<S sid ="85" ssid = "50">3.2.3 Sager’s Classification Sager (1981) presents a small classification consisting of 13 classes, which groups verbs (mostly) on the basis of their syntactic alternations.</S>
			<S sid ="86" ssid = "51">While semantic properties are largely ignored, many of the classes appear distinctive also in terms of semantics.</S>
			<S sid ="87" ssid = "52">3.2.4 Levin’s Classification At least 20 (broad) Levin classes involve verb senses which take sentential complements.</S>
			<S sid ="88" ssid = "53">Because full treatment of these senses requires considering sentential complementation, we reevaluated these classes using our method.</S>
			<S sid ="89" ssid = "54">3.3 Method for Creating Classes.</S>
			<S sid ="90" ssid = "55">Each candidate class was evaluated as follows: 1.</S>
			<S sid ="91" ssid = "56">We extracted from its class description (where one.</S>
			<S sid ="92" ssid = "57">was available) and/or from the COML E X Syntax dictionary (Grishman et al., 1994) all the SCFs taken by its member verbs.</S>
			<S sid ="93" ssid = "58">2.</S>
			<S sid ="94" ssid = "59">We extracted from Levin’s taxonomy and from our.</S>
			<S sid ="95" ssid = "60">novel list of 106 alternations all the alternations where these SCFs were involved.</S>
			<S sid ="96" ssid = "61">3.</S>
			<S sid ="97" ssid = "62">Where one or several alternations where found.</S>
			<S sid ="98" ssid = "63">which captured the sense in question, and where the minimum of two member verbs were identified, a new verb class was created.</S>
			<S sid ="99" ssid = "64">Steps 12 were done automatically and step 3 manually.</S>
			<S sid ="100" ssid = "65">Identifying relevant alternations helped to identify additional SCFs, which in turn often led to the discovery of additional alternations.</S>
			<S sid ="101" ssid = "66">The SCFs and alternations discovered in this way were used to create the syntactic- semantic description of each novel class.</S>
			<S sid ="102" ssid = "67">For those candidate classes which had an insufficient number of member verbs, new members were searched for in WordNet (Miller, 1990).</S>
			<S sid ="103" ssid = "68">Although WordNet classifies verbs on a purely semantic basis, the syntactic regularities studied by Levin are to some extent reflected Ca te go ry Ex am ple Al ter na tio ns Al ter nat in g SC Fs Eq ui I ad vis ed M ary to go I advised Mary He hel pe d her ba ke the ca ke He helped bake the cake 53 24 33 142 Ra isi ng Jul ie stri ke s me as fo oli sh Julie strikes me as a fool He ap pe are d to her to be ill It appeared to her that he was ill 14 3 29 99 12 Ca teg or y sw itc he s He fai led in att em pti ng to cli mb He failed in the climb I pro mi se d M ary to go I promised Mary that I will go 63 87 54 52 PP del eti on Ph il ex pla ine d to hi m ho w to do it Phil explained how to do it He co ntr act ed wit h hi m for the ma n to go He contracted for the man to go 90 17 88 15 P/ C del eti on I pre fer for her to do it I prefer her to do it Th ey as ke d ab out wh at to do They asked what to do 15 53 73 116 Table 1: Examples of new alternations by semantic relatedness as it is represented by Word- Net’s particular structure (e.g.</S>
			<S sid ="104" ssid = "69">(Fellbaum, 1999)).</S>
			<S sid ="105" ssid = "70">New member verbs were frequently found among the synonyms, troponyms, hypernyms, coordinate terms and/or antonyms of the extant member verbs.</S>
			<S sid ="106" ssid = "71">For example, using this method, we gave the following description to one of the candidate classes of Rudanko (1996), which he describes syntactically with the single SCF 63 (see the below list) and semantically by stating that verbs in this class (e.g. succeed, manage, fail) have approximate meaning1 “perform the act of ” or “carry out the activity of ”: 20.</S>
			<S sid ="107" ssid = "72">SUCCE E D VE RBS.</S>
			<S sid ="108" ssid = "73">SCF 22: John succeeded SCF 87: John succeeded in the climb SCF 63: John succeeded in attempting the climb SCF 112: John succeeded to climb Alternating SCFs: 22 87, 87 63, 22 112 Some of the candidate classes, particularly those of Rudanko, proved too fine-grained to be helpful for a Levin type of classification, and were either combined with other classes or excluded from consideration.</S>
			<S sid ="109" ssid = "74">Some other classes, particularly the large ones in the L CS database, proved too coarse-grained after our method was applied, and were split down to subclasses.</S>
			<S sid ="110" ssid = "75">For example, the L CS class of Coerce Verbs (002) was divided into four subclasses according to the particular syntactic-semantic properties of the subsets of its member verbs.</S>
			<S sid ="111" ssid = "76">One of these subclasses was created for verbs such as force, induce, and seduce, which share the ap 1 Rudanko does not assign unique labels to his classes, and the descriptions he gives - when taken out of the context - cannot be used to uniquely identify the meaning involved in a specific class.</S>
			<S sid ="112" ssid = "77">For details of this class, see his description in (Rudanko, 1996) page 28.</S>
			<S sid ="113" ssid = "78">proximate meaning of “urge or force (a person) to an action”.</S>
			<S sid ="114" ssid = "79">The sense gives rise to object equi SCFs and alternations: 2.</S>
			<S sid ="115" ssid = "80">FORCE VE RBS.</S>
			<S sid ="116" ssid = "81">SCF 24: John forced him SCF 40: John forced him into coming SCF 49: John forced him into it SCF 53: John forced him to come Alternating SCFs: 24 53, 40 49, 49 24 Another subclass was created for verbs such as order and require, which share the approximate meaning of “direct somebody to do something”.</S>
			<S sid ="117" ssid = "82">These verbs take object raising SCFs and alternations: 3.</S>
			<S sid ="118" ssid = "83">ORDE R VE RBS.</S>
			<S sid ="119" ssid = "84">SCF 57: John ordered him to be nice SCF 104: John ordered that he should be nice SCF 106: John ordered that he be nice Alternating SCFs: 57 104, 104 106 New subclasses were also created for those Levin classes which did not adequately account for the variation among their member verbs.</S>
			<S sid ="120" ssid = "85">For example, a new class was created for those 37.</S>
			<S sid ="121" ssid = "86">Verbs of Communication which have an approximate meaning of “make a proposal” (e.g. suggest, recommend, propose).</S>
			<S sid ="122" ssid = "87">These verbs take a rather distinct set of SCFs and alternations, which differ from those taken by other communication verbs.</S>
			<S sid ="123" ssid = "88">This class is somewhat similar in meaning to Levin’s 37.9 Advise Verbs.</S>
			<S sid ="124" ssid = "89">In fact, a subset of the verbs in 37.9 (e.g. advise, instruct) participate in alternations prototypical to this class (e.g. 104 106) but not, for example, in the ones involving PPs (e.g. 103 116).</S>
			<S sid ="125" ssid = "90">47.</S>
			<S sid ="126" ssid = "91">SUGGE ST VE RBS.</S>
			<S sid ="127" ssid = "92">SCF 16: John suggested how she could do it SCF 17: John suggested how to do it SCF 24: John suggested it SCF 49: John suggested it to her SCF 89: John suggested to her how she could do it SCF 90: John suggested to her how to do it SCF 97: John suggested to her that she would do it SCF 98: John suggested to her that she do it SCF 101: John suggested to her what she could do SCF 103: John suggested to her what to do SCF 104: John suggested that she could do it SCF 106: John suggested that she do it SCF 114: John suggested what she could do SCF 116: John suggested what to do Alternating SCFs: 16 17, 24 49, 89 16, 90 17, 97 104, 98 106, 101 114, 103 116, 104 106 Our work resulted in accepting, rejecting, combining and refining the 102 candidate classes and - as a byproduct - identifying 5 new classes not included in any of the resources we used.</S>
			<S sid ="128" ssid = "93">In the end, 57 new verb classes were formed, each associated with 245 member verbs.</S>
			<S sid ="129" ssid = "94">Those Levin or Dorr classes which were examined but found distinctive enough as they stand are not included in this count.</S>
			<S sid ="130" ssid = "95">However, their possible subclasses are, as well as any of the classes adapted from the resources of Rudanko or Sager.</S>
			<S sid ="131" ssid = "96">The new classes are listed in table 2, along with example verbs.</S>
	</SECTION>
	<SECTION title="Evaluation. " number = "4">
			<S sid ="132" ssid = "1">4.1 Task-Based Evaluation.</S>
			<S sid ="133" ssid = "2">We performed an experiment in the context of automatic SCF acquisition to investigate whether the new classes can be used to support an important NL P task.</S>
			<S sid ="134" ssid = "3">The task is to associate classes to specific verbs along with an estimate of the conditional probability of a SCF given a specific verb.</S>
			<S sid ="135" ssid = "4">The resulting valency or subcategorization lexicon can be used by a (statistical) parser to recover predicate-argument structure.</S>
			<S sid ="136" ssid = "5">Our test data consisted of a total of 35 verbs from 12 new verb classes.</S>
			<S sid ="137" ssid = "6">The classes were chosen at random, subject to the constraint that their member verbs were frequent enough in corpus data.</S>
			<S sid ="138" ssid = "7">A minimum of 300 corpus occurrences per verb is required to yield a reliable SCF distribution for a polysemic verb with multiple SCFs (Korhonen, 2002).</S>
			<S sid ="139" ssid = "8">We took a sample of 20 million words of the British National Corpus (BNC) (Leech, 1992) and extracted all sentences containing an occurrence of one of the test verbs.</S>
			<S sid ="140" ssid = "9">After the extraction process, we retained Table 2: New Verb Classes 1000 citations, on average, for each verb.</S>
			<S sid ="141" ssid = "10">Our method for SCF acquisition (Korhonen, 2002) involves first using the system of Briscoe and Carroll (1997) to acquire a putative SCF distribution for each test verb from corpus data.</S>
			<S sid ="142" ssid = "11">This system employs a robust statistical parser (Briscoe and Carroll, 2002) which yields complete though shallow parses from the PoS tagged data.</S>
			<S sid ="143" ssid = "12">The parse contexts around verbs are passed to a comprehensive SCF classifier, which selects one of the 163 SCFs.</S>
			<S sid ="144" ssid = "13">The SCF distribution is then smoothed with the back-off distribution corresponding to the semantic class of the predominant sense of a verb.</S>
			<S sid ="145" ssid = "14">Although many of the test verbs are polysemic, we relied on the knowledge that the majority of English verbs have a single predominating sense in balanced corpus data (Korhonen and Preiss, 2003).</S>
			<S sid ="146" ssid = "15">The back-off estimates were obtained by the following method: (i) A few individual verbs were chosen from a new verb class whose predominant sense according to the WordNet frequency data belongs to this class, (ii) SCF distributions were built for these verbs by manually analysing c. 300 occurrences of each verb in the BNC, (iii) the resulting SCF distributions were merged.</S>
			<S sid ="147" ssid = "16">An empirically-determined threshold was finally set on the probability estimates from smoothing to reject noisy SCFs caused by errors during the statistical parsing phase.</S>
			<S sid ="148" ssid = "17">This method for SCF acquisition is highly sensitive to the accuracy of the lexical-semantic classes.</S>
			<S sid ="149" ssid = "18">Where a class adequately predicts the syntactic behaviour of the predominant sense of a test verb, significant improvement is seen in SCF acquisition, as accurate back-off estimates help to correct the acquired SCF distribution and deal with sparse data.</S>
			<S sid ="150" ssid = "19">Incorrect class assignments or choice of classes can, however, degrade performance.</S>
			<S sid ="151" ssid = "20">The SCFs were evaluated against manually analysed corpus data.</S>
			<S sid ="152" ssid = "21">This was obtained by annotating a maximum of 300 occurrences for each test verb in the BNC data.</S>
			<S sid ="153" ssid = "22">We calculated type precision (the percentage of SCF types that the system proposes which are correct), type recall (the percentage of SCF types in the gold standard that the system proposes) and F -measure2.</S>
			<S sid ="154" ssid = "23">To investigate how well the novel classes help to deal with sparse data, we recorded the total number of SCFs missing in the distributions, i.e. false negatives which did not even occur in the unthresholded distributions and were, therefore, never hypothesized by the parser and classifier.</S>
			<S sid ="155" ssid = "24">We also compared the similarity between the acquired unthresholded 2 M ea su res M e t h o d Ba sel ine Ne w Cl ass es Pr eci sio n (% ) 6 7 . 1 7 1 . 0 Re cal l (% ) 5 3 . 9 6 5 . 0 F m ea su re (% ) 6 0 . 0 6 8 . 0 R C 0 . 6 5 0 . 7 4 K L 1 . 1 0 0 . 9 1 JS 0 . 9 0 0 . 0 7 C E 2 . 2 2 2 . 1 0 IS 0 . 6 1 0 . 8 3 U ns ee n S C Fs 1 9 6 1 1 5 Table 3: Average results for 35 verbs and gold standard SCF distributions using several measures of distributional similarity: the Spearman rank correlation (RC), KullbackLeibler distance (KL), JensenShannon divergence (JS), cross entropy (CE), and intersection (IS)3.</S>
			<S sid ="156" ssid = "25">Table 3 shows average results for the 35 verbs with the the baseline system and for the system which employs the novel classes.</S>
			<S sid ="157" ssid = "26">We see that the performance improves when the novel classes are employed, according to all measures used.</S>
			<S sid ="158" ssid = "27">The method yields 8% absolute improvement in F -measure over the baseline method.</S>
			<S sid ="159" ssid = "28">The measures of distributional similarity show likewise improved performance.</S>
			<S sid ="160" ssid = "29">For example, the results with IS indicate that there is a large intersection between the acquired and gold standard SCFs when the method is used, and those with RC demonstrate that the method clearly improves the ranking of SCFs according to the conditional probability distributions of SCFs given each test verb.</S>
			<S sid ="161" ssid = "30">From the total of 193 gold standard SCFs unseen in the unsmoothed lexicon, only 115 are unseen after using the new classification.</S>
			<S sid ="162" ssid = "31">This demonstrates the usefulness of the novel classes in helping the system to deal with sparse data.</S>
			<S sid ="163" ssid = "32">While these results demonstrate clearly that the new classes can be used to support a critical NL P task, the improvement over the baseline is not as impressive as that reported in (Korhonen, 2002) where Levin’s original classes are employed4.</S>
			<S sid ="164" ssid = "33">While it is possible that the new classes require further adjustment until optimal accuracy can be obtained, it is clear that many of our test verbs (and verbs in our new classes in general) are more polysemic on average and thus more ‘difficult’ than those employed by Korhonen (2002).</S>
			<S sid ="165" ssid = "34">Our subcategorization acquisition method, based on predominant sense heuristics, is less adequate for these verbs – rather, a method based on word sense disambiguation and the use of multi 3 For the details of these measures and their application to this task see Korhonen and Krymolowski (2002).</S>
			<S sid ="166" ssid = "35">4 Korhonen (2002) reports 17.8% absolute improvement in. F -measure with the back-off scheme on 45 test verbs.</S>
			<S sid ="167" ssid = "36">ple classes should be employed to establish the true upper bound on performance.</S>
			<S sid ="168" ssid = "37">Korhonen and Preiss (2003) have proposed such a method, but the method is not currently applicable to our test data.</S>
			<S sid ="169" ssid = "38">4.2 Evaluation of Coverage.</S>
			<S sid ="170" ssid = "39">Investigating the coverage of the current extended classification over the English verb lexicon is not straightforward because no fully suitable gold standard is available.</S>
			<S sid ="171" ssid = "40">We conducted a restricted evaluation against the comprehensive semantic classification of WordNet.</S>
			<S sid ="172" ssid = "41">As WordNet incorporates particularly fine-grained sense distinctions, some of its senses are too idiomatic or marginal for classification at this level of granularity.</S>
			<S sid ="173" ssid = "42">We aimed to identify and disregard these senses from our investigation.</S>
			<S sid ="174" ssid = "43">All the WordNet senses of 110 randomly chosen verbs were manually linked to classes in our extended classification (i.e. to Levin’s, Dorr’s or our new ones).</S>
			<S sid ="175" ssid = "44">From the total of 253 senses exemplified in the data, 238 proved suitable (of right granularity) for our evaluation.</S>
			<S sid ="176" ssid = "45">From these, 21 were left unclassified because no class was found for them in the extended resource.</S>
			<S sid ="177" ssid = "46">After we evaluated these senses using the method described in section 3, only 7 of them turned out to warrant classes of their own which should be added to the extended classification.</S>
	</SECTION>
	<SECTION title="Discussion. " number = "5">
			<S sid ="178" ssid = "1">The evaluation reported in the previous section shows that the novel classes can used to support a NL P task and that the extended classification has good coverage over the English verb lexicon and thus constitutes a resource suitable for large-scale NL P use.</S>
			<S sid ="179" ssid = "2">Although the classes resulting from our work can be readily employed for NL P purposes, we plan, in the future, to further integrate them into Levin’s taxonomy to yield a maximally useful resource for the research community.</S>
			<S sid ="180" ssid = "3">While some classes can simply be added to her taxonomy as new classes or subclasses of extant classes (e.g. our 47.</S>
			<S sid ="181" ssid = "4">SUGGE ST VE RBS can be added as a subclass to Levin’s 37.</S>
			<S sid ="182" ssid = "5">Verbs of Communication), others will require modifying extant Levin classes.</S>
			<S sid ="183" ssid = "6">The latter classes are mostly those whose members classify more naturally in terms of their sentential rather than NP and PP complementation (e.g. ones related to Levin’s 29.</S>
			<S sid ="184" ssid = "7">Verbs with Predicative Complements).</S>
			<S sid ="185" ssid = "8">This work will require resolving some conflicts between our classification and Levin’s. Because lexical- semantic classes are based on partial semantic descriptions manifested in alternations, it is clear that different, equally viable classification schemes can be constructed using the same data and methodology.</S>
			<S sid ="186" ssid = "9">One can grasp this easily by looking at intersective Levin classes (Dang et al., 1998), created by grouping together subsets of existing classes with overlapping members.</S>
			<S sid ="187" ssid = "10">Given that there is strong potential for cross-classification, we will aim to resolve any conflicts by preferring those classes which show the best balance between the accuracy in capturing syntactic-semantic features and the ability to generalize to as many lexical items as possible.</S>
			<S sid ="188" ssid = "11">An issue which we did not address in the present work (as we worked on candidate classes), is the granularity of the classification.</S>
			<S sid ="189" ssid = "12">It is clear that the ‘suitable’ level of granularity varies from one NL P task to another.</S>
			<S sid ="190" ssid = "13">For example, tasks which require maximal accuracy from the classification are likely to benefit the most from fine- grained classes (e.g. refined versions of Levin’s classes (Green et al., 2001)), while tasks which rely more heavily on the capability of a classification to capture adequate generalizations over a set of lexical items benefit the most from broad classes.</S>
			<S sid ="191" ssid = "14">Therefore, to provide a general purpose classification suitable for various NL P use, we intend to refine and organize our novel classes into taxonomies which incorporate different degrees of granularity.</S>
			<S sid ="192" ssid = "15">Finally, we plan to supplement the extended classification with additional novel information.</S>
			<S sid ="193" ssid = "16">In the absence of linguistic resources exemplifying further candidate classes we will search for additional novel classes, inter- sective classes and member verbs using automatic methods, such as clustering (e.g.</S>
			<S sid ="194" ssid = "17">(Brew and Schulte im Walde, 2002; Korhonen et al., 2003)).</S>
			<S sid ="195" ssid = "18">For example, clustering sense disambiguated subcategorization data (acquired e.g. from the SemCor corpus) should yield suitable (sense specific) data to work with.</S>
			<S sid ="196" ssid = "19">We will also include in the classification statistical information concerning the relative likelihood of different classes, SCFs and alternations for verbs in corpus data, using e.g. the automatic methods proposed by McCarthy (2001) and Korhonen (2002).</S>
			<S sid ="197" ssid = "20">Such information can be highly useful for statistical NL P systems utilizing lexical-semantic classes.</S>
	</SECTION>
	<SECTION title="Conclusions. " number = "6">
			<S sid ="198" ssid = "1">This paper described and evaluated a substantial extension to Levin’s widely employed verb classification, which incorporates 57 novel classes and 106 diathesis alternations for verbs not covered comprehensively by Levin.</S>
			<S sid ="199" ssid = "2">The utility of the novel classes was demonstrated by using them to support automatic subcategorization acquisition.</S>
			<S sid ="200" ssid = "3">The coverage of the resulting extended classification over the English verb lexicon was shown to be good.</S>
			<S sid ="201" ssid = "4">Discussion was provided on how the classification could be further refined and extended in the future, and integrated into Levin’s extant taxonomy, to yield a single, comprehensive resource.</S>
	</SECTION>
	<SECTION title="Acknowledgements">
			<S sid ="202" ssid = "5">This work was supported by UK EPSRC project GR/N36462/93: ‘Robust Accurate Statistical Parsing (RASP)’.</S>
	</SECTION>
</PAPER>
