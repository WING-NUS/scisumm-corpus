<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">When translating from languages with hardly any inl1ectional morphology like English into morphologically rich lan­ guages, the English word forms often do not contain enough information for producing the correct fullform in the target language.</S>
		<S sid ="2" ssid = "2">We investigate meth­ ods for improving the quality of such translations by making usc of part-of­ speech information and maximum en­ tropy modeling.</S>
		<S sid ="3" ssid = "3">Results Cor translations from English into Spanish and Catalan are presented on the LC-STAR corpus which consists of spontaneously spoken dialogues in the domain of appointment scheduling and travel planning.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="4" ssid = "4">In this paper, we address the question of how part­ of-speech ( POS) information can help improv­ ing the quality of Statistical Machine Translation (SMT).</S>
			<S sid ="5" ssid = "5">One of the main problems when translat­ ing from a language with hm·dly any inflectional morphology (which is English in our experiments) into one with richer morphology (here: Spanish and Catalan) is the production of the correct in­ flected form in the target lan guage.</S>
			<S sid ="6" ssid = "6">We introduce transformations to the English string that are based on the part-of-speech information and show how this knowledge source can help SMT.</S>
			<S sid ="7" ssid = "7">Systematic evaluations will show that the quality of the gen erated translations is improved.</S>
			<S sid ="8" ssid = "8">The transfonnations we apply arc the following: Treatment of verbs In Catalan and Spanish, the pronoun before a verb is often omitted and in­ stead, the person is expressed via the ending of the verb.</S>
			<S sid ="9" ssid = "9">The smne holds for future tense and for the modes expressed through &apos;would &apos; and &apos;should&apos; in English.</S>
			<S sid ="10" ssid = "10">Since this makes it hard to generate the correct translation of a given English verb, we propose a method re­ sulting in English word forms containing suf­ ficient infonnation.</S>
			<S sid ="11" ssid = "11">Question inversion In English, interrogative phrases have a word order that is different from declarative sentences: Either an auxil­ iary &apos;do·is inserted or the order of verb and pronoun is inverted.</S>
			<S sid ="12" ssid = "12">Since this is dilTerent in Spanish and Catalan, we modify the word order in English to make it more similar to the Spanish/Catalan one and to help the verb treatment mentioned above.</S>
			<S sid ="13" ssid = "13">The paper is organized as follows: Related work is treated in Section 2.</S>
			<S sid ="14" ssid = "14">In Section 3, we shortly review the statistical approach to machine transla­ tion.</S>
			<S sid ="15" ssid = "15">Then, we introduce the transfonnations that we apply to the less inflected language of the two under consideration (namely English) in Section 4.</S>
			<S sid ="16" ssid = "16">After describing the maximum entropy approach and the training procedure we use for the statisti­ cal lexicon in Section 5, we present results on the trilingual LC-STAR corpus in Section 6.</S>
			<S sid ="17" ssid = "17">Then, we conclude and present ideas about future work in Section 7.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "2">
			<S sid ="18" ssid = "1">Publications dealing with the integration of lin­ guistic information into the process of statisti­ cal machine translation are rather few allhough this had already been suggested in (Brown et al., 1992).</S>
			<S sid ="19" ssid = "2">(NieBen and Ney, 200 Ib) introduce hier­ archical lexicon models including baseform and POS information for translation from German into English.</S>
			<S sid ="20" ssid = "3">Information contained in the German en­ tries that are not relevant for the generation of the English translation arc omitted.</S>
			<S sid ="21" ssid = "4">Unlike this, we investigate methods for enriching English with knowledge to help selecting the correct fullform in a morphologically richer language.</S>
			<S sid ="22" ssid = "5">(NieBen and Ney, 200 l a) propose reordering oper­ ations for the language pair GennanEnglish that help SMT by harmonizing word order between source and target.</S>
			<S sid ="23" ssid = "6">The question inversion we apply was inspired by this; nevertheless, we do not per­ form a full morpho-syntactic analysis, but make use only of POS information which can be ob­ tained from freely available tools.</S>
			<S sid ="24" ssid = "7">(GarciaVarea et al..</S>
			<S sid ="25" ssid = "8">2001) apply a maximum en­ tropy approach for training the statistical lexicon, but do not take any linguistic information into ac­ count.</S>
			<S sid ="26" ssid = "9">The use ofPOS information for improving statisti­ cal alignment quality is described in (Toutanova et al..</S>
			<S sid ="27" ssid = "10">2002), but no translation results are presented.</S>
	</SECTION>
	<SECTION title="Statistical Machine Translation. " number = "3">
			<S sid ="28" ssid = "1">The goal of machine translation is the translation of an input string -&quot;1, ...</S>
			<S sid ="29" ssid = "2">, SJ in the source language into a target language string L1, . . .</S>
			<S sid ="30" ssid = "3">, l r. We choose the string that has maximal probability given the source string, Pr ( t{[ s{).</S>
			<S sid ="31" ssid = "4">Applying Bayes&apos; deci­ sion rule yields the following criterion: arg max Pr ( t{ [s{ ) tf = arg m x{Pr( l{) · Pr( s{l l{)} (1) tl Through this decomposition of the probability, we obtain two knowledge sources: the translation and the language model.</S>
			<S sid ="32" ssid = "5">Those two can be modelled independently of each other.</S>
			<S sid ="33" ssid = "6">The cotTespondence between the words in the source and the target string is described by align­ ments that assign target word positions to each source word position.</S>
			<S sid ="34" ssid = "7">The probability of a certain target language word to occur in the target string is assumed to depend basically only on the source words aligned to it.</S>
			<S sid ="35" ssid = "8">The search is denoted by the arg rna.x operation in Eq. 1, i.e. it explores the space of all possible target language strings and all possible alignments between the source and the target language string to find the one with maximal probability.</S>
			<S sid ="36" ssid = "9">The input string can be preprocessed before being passed to the search algorithm.</S>
			<S sid ="37" ssid = "10">If necessary, the inverse of these transformations will be applied to the generated output string.</S>
			<S sid ="38" ssid = "11">In the work pre­ sented here, we restrict ourselves to transfotming only one language of the two: the source, which has the less inflected morphology.</S>
			<S sid ="39" ssid = "12">For descriptions of SMT systems see for exam­ ple (Germann et al., 2001; Och et al., 1999; Till­ mann and Ney, 2002; Vogel et al..</S>
			<S sid ="40" ssid = "13">2000; Wang and Waibel, 1997).</S>
	</SECTION>
	<SECTION title="Transformations in the Less. " number = "4">
			<S sid ="41" ssid = "1">Inflected Language When translating from English into languages with a highly inflected morphology, the production of the cotTect fullfonn often causes problems.</S>
			<S sid ="42" ssid = "2">Our experience on several corpora shows that the error rate or a translation from English into morpholog­ ically richer languages decreases by 10% relative if we aim at producing only the correct baseform instead of the fully inflected word.</S>
			<S sid ="43" ssid = "3">The transfer of the meaning expressed in the baseform is easier than deciding on the correct inOecLed form.</S>
			<S sid ="44" ssid = "4">4.1 Treatment of.</S>
			<S sid ="45" ssid = "5">Verbs Especially the translation of verbs is difficult since there are many different inflections in Spanish and Catalan whereas there are only few in En­ glish.</S>
			<S sid ="46" ssid = "6">Moreover, the pronouns and modals are of­ ten omiued in Spanish and CaLalan and this infor­ mation is expressed through the suffix.</S>
			<S sid ="47" ssid = "7">This makes it very hard for word-based systems to generate the correct inflection from the English verb which docs not contain sufficient information.</S>
			<S sid ="48" ssid = "8">Thus, sev­ eral English words will have to be aligned to the Spanish or Catalan verbs.</S>
			<S sid ="49" ssid = "9">This process is rela tively difficult for the algorithm and causes noise in the statistical lexicon i C English pronouns are re­ garded as translations of Spanish or Catalan verbs.</S>
			<S sid ="50" ssid = "10">In order to enrich the English verb with the needed information, we combine pronouns and/or modals with following verbs and treat those combinations as &apos;new&apos; Cullform words in English.</S>
			<S sid ="51" ssid = "11">Thus we can obtain the information needed to select the con·ect verb form in the target language from one single English word.</S>
			<S sid ="52" ssid = "12">The identif1cation or English pro­ nouns, modals and verbs was done by POS tag­ ging applied to the English part of the corpus.</S>
			<S sid ="53" ssid = "13">We decided to transform the source language in­ stead of the target language, because in this case we need only the POS tags of the source language as additional knowledge source and nothing else.</S>
			<S sid ="54" ssid = "14">Another possible approach would have been to split the suffix in the target language (e.g. &apos;esta&apos; into &apos;estar P3S&apos;).</S>
			<S sid ="55" ssid = "15">This would require postprocess­ ing tools that are able to generate the correct verb ronn !&apos;rom the haserorm and the person and tense information.</S>
			<S sid ="56" ssid = "16">Table 1 gives examples of words that have been spliced to fonn new entries ol&apos; the English lexi­ con.</S>
			<S sid ="57" ssid = "17">For example, we splice the phrase &apos;you think&apos; to form the single entry &apos;you_think&apos; which con­ tains sufficient information for producing the cor­ rect Spanish verb form &apos;crees&apos; or the Catalan &apos;creus&apos;.</S>
			<S sid ="58" ssid = "18">Similarly, the modal auxiliaries can be added as well, like in the entry &apos;you_wilLhave&apos; which is much better suited for being translated into &apos;tendnis&apos; (Spanish) or &apos;tindras&apos; (Catalan) than the verb &apos;have&apos; alone.</S>
			<S sid ="59" ssid = "19">Moreover, in a single word based lexicon, three single entries would have to be added Cor the translation of &apos;you will have&apos; into &apos;tendras&apos;: (you,tendras), (will,tendras) and (have,tendnis), which spreads the translation prob­ ability over far too many entries and makes the probability distribution unfocused.</S>
			<S sid ="60" ssid = "20">As the last example in Table l shows, &apos;you can go&apos; is spliced only into two words instead of one in order to better match the Spanish/Catalan form.</S>
			<S sid ="61" ssid = "21">4.2 Question Treatment.</S>
			<S sid ="62" ssid = "22">In English interrogative phrases, either an auxil­ iary &apos;do&apos; is inserted or the order of verb and pro­ noun is inverted.</S>
			<S sid ="63" ssid = "23">The au x iliary &apos;do&apos; does not carry information that is relevant when translating into Table 1: Examples of spliced words in the English vocabulary I original I POS tags I spliced words I yo u go P R P V B P yo u_ go yo u we nt PR P V B D yo u we nt yo u thi nk PR P V BP yo u_ thi nk yo u wi ll ha ve P R P M D V B yo u wi ll ha ve yo u ca n go P R P M D V B yo u ca n go Spanish or Catalan.</S>
			<S sid ="64" ssid = "24">Thus, we can remove it from the sentence without hanning the translation pro­ cess (as described in (NicBen and Ney, 200la) for the language pair GermanEnglish).</S>
			<S sid ="65" ssid = "25">However, we do not remove a question supporting &apos;do&apos; in past tense, i. e. &apos;did&apos; is kept in the phrase, because this is the only word containing the tense information.</S>
			<S sid ="66" ssid = "26">Afterwards, we can merge the pronoun and verb as depicted in Table 2: &apos;did you go&apos; is transformed into &apos;you_did go&apos;.</S>
			<S sid ="67" ssid = "27">We do not splice &apos;you_did&apos; and &apos;go&apos;, because the English simple past is translated into present perfect in Catalan; and it is very likel y to he translated into present perl&apos;ect in Spanish, es­ pecially in colloquial language as it is present in this task.</S>
			<S sid ="68" ssid = "28">The form &apos;you_did go&apos; is well suited to be translated into the Spanish &apos;has ido&apos; or the Cata­ lan &apos;has anat&apos;.</S>
			<S sid ="69" ssid = "29">IC there is no question supporting &apos;do&apos; and the or­ der of pronoun and verb is inverted see the exam­ ple &apos;how are you?&apos; in Table 3 - we first swap the two words and then perform the splicing step.</S>
			<S sid ="70" ssid = "30">This is done in order to avoid having two lexical entries with the same translation: for example, &apos;you_are &apos; and the interrogative &apos;are_you &apos; hoth have the same translation in Spanish or Catalan, respectively.</S>
			<S sid ="71" ssid = "31">Table 3 presents examples of transformed EngIish queslions.</S>
			<S sid ="72" ssid = "32">Comparing them to the Spanish and Catalan reference, we see that it is easier to find a word-to word mapping for the modified English sentences.</S>
	</SECTION>
	<SECTION title="Maximum Entropy. " number = "5">
			<S sid ="73" ssid = "1">Training If we merge the pronouns/modals and verbs as de­ scribed above, it might happen thalthe verh itsell&apos; (or one of its inflections) has never been seen in training except fi·om its appearance in the new en­ tries in the lexicon which result from the splic Table 2: Examples of spliced words in the English vocabulary after question inversion ori gi na l PO S ta gs spl ice d w or ds do yo u go V BP PR P V B yo u_ go di d yo u go V B D P R P V B yo u_ di d go ha ve yo u go ne V B P P R P V B N yo u_ ha ve go ne wi ll yo u go M D P R P V B yo u_ wi lL go ca n yo u go P R P M D V B yo u_ ca n go Table 3: Examples of transformed English sentences Or igi na l ho w are yo u?</S>
			<S sid ="74" ssid = "2">Q ue sti on In ve rsi on ho w yo u ar c&apos;!</S>
			<S sid ="75" ssid = "3">Ve rb Tr eat m en t ho w yo u_ are ? Ca tal an Se nt en ce co m es ta ? Sp ani sh Se nt en ce i., co m o est as ? Or igi na l or do yo u thi nk we wa nt to sta y [..</S>
			<S sid ="76" ssid = "4">] ? Q ue sti on In ve rsi on or yo u thi nk we wa nt to st a y[ ...</S>
			<S sid ="77" ssid = "5">] ? Ve rb Tr ea tm en t or yo u_ thi nk we _w ant to sta y [..</S>
			<S sid ="78" ssid = "6">] ? Ca tal an Se nt en ce o cre u qu e vo ldr em qu edar no s [..</S>
			<S sid ="79" ssid = "7">Sp ani sh Se nt en ce (, o cre e qu e qu err e m os qu ed ar no s [.</S>
			<S sid ="80" ssid = "8">] ? Or igi na l di d yo u sa y the ei gh tee nt h ? Qu est ion In ve rsi on yo u di d sa y the eig hte ent h ? Ve rb Tr eat m en t yo u_ di d sa y the ei gh te en th ? Ca tal an Se nt en ce has dit el div uit ? Sp ani sh Se nt en ce (, ha s dic ho el di ec io ch o ? ing operation.</S>
			<S sid ="81" ssid = "9">This makes it impossible to trans­ late the verb itself, because it is then unknown to the system.</S>
			<S sid ="82" ssid = "10">The same holds for combinations of pronouns and verbs that are unseen in train­ ing, e. g. the training corpus contains the bigram &apos;1 went&apos;, but not the one &apos;she went&apos;.</S>
			<S sid ="83" ssid = "11">In order to overcome this problem, we train our lexicon model using maximum entropy.</S>
			<S sid ="84" ssid = "12">5.1 The Maximum Entropy Approach.</S>
			<S sid ="85" ssid = "13">The maximum entropy approach (Berger et al., 1996) presents a powerful framework for the com­ bination or several knowledge sources.</S>
			<S sid ="86" ssid = "14">This prin­ ciple recommends to choose the distribution which preserves as much uncertainty as possible in terms or maximizing the entropy.</S>
			<S sid ="87" ssid = "15">The distribution is re­ quired to satisfy constraints, which represent facts known from the data.</S>
			<S sid ="88" ssid = "16">These constraints are ex­ pressed on the basis of feature functions hm ( s , t), where ( s, t) is a pair of source and target word.</S>
			<S sid ="89" ssid = "17">The lexicon probability of a source word given the target word has the following functional form p(si L ) = .%&apos;t ) exp [LAmhm(s , L) l U l with the normalization factor where /\ = {Am} is the set of model parameters with one weight Am Cor each feature function hm.</S>
			<S sid ="90" ssid = "18">The features we usc in our model arc • a lexical feature (Cor the entries of Lhe trans­ formed vocabulary): hs&apos;,t&apos;(s , t ) = 8(s , s&apos; ) ·8(t, t&apos;) • the verb contained in a transformed lexicon entry (e.g. &apos;go&apos; Cor &apos;you_go&apos; or &apos;you_wi!Lgo): where 1, ift contains the verb v Verb(t, v) = { 0, otherwise This enables us to translate the verb alone even if it occurs in the training corpus only as a spliced entry.</S>
			<S sid ="91" ssid = "19">For an introduction to maximum entropy modeling and training procedures, the reader is refened to the corresponding literature, for instance (Berger et al., 1996) or (Ratnapark:hi, 1997).</S>
			<S sid ="92" ssid = "20">5.2 Training.</S>
			<S sid ="93" ssid = "21">We performed the following training steps: • transform the English (= source language) part or the corpus as described in Seclions 4.1 and 4.2 • train the statistical translation system using this modi fled source language corpus 1 • with the resuiLing alignment, train the lexicon model using maximum entropy with the fea­ tures described in Section 5.1 This training can be pelformed using converg­ ing iterative training procedures like described by (Darroch and Ratcliff.</S>
			<S sid ="94" ssid = "22">1972) or (Della Pietra et al., 1997) 2 . The basic training procedures for the translation system and the language model need not be changed.</S>
			<S sid ="95" ssid = "23">5.3 Translation process.</S>
			<S sid ="96" ssid = "24">For translation, we can use an SMT system where the search algorithm does not have to be modified.</S>
			<S sid ="97" ssid = "25">Before the translation process, we transform the input in the same way as the training corpus be­ fore training the alignment (see Section 5.2).</S>
			<S sid ="98" ssid = "26">We simply have to exclude those words from splicing where the splicing operation yields an unknown word.</S>
			<S sid ="99" ssid = "27">1Tbis training was done using the GIZA++ toolkit which c;m be downloaded from http://wwwi6.infmmatik.rwth­ aachcn.dcroch/softwarc/GTZA++.html 6 Result s 6.1 Corpora We performed experiments on the trilingual corpus which is successively built within the LC-STAR project.</S>
			<S sid ="100" ssid = "28">It comprises the languages English, Spanish and Catalan, whereof we used English as source and Spanish and Catalan as tar­ get languages.</S>
			<S sid ="101" ssid = "29">At the time of our experiments, we had about 13k sentences per language available; the statistics are given in Table 4.</S>
			<S sid ="102" ssid = "30">The corpus consists of transcriptions of sponta­ neously spoken dialogues.</S>
			<S sid ="103" ssid = "31">Thus, the sentences often lack correct syntactic structure.</S>
			<S sid ="104" ssid = "32">The domain of this task is appointment scheduling and travel arrangements.</S>
			<S sid ="105" ssid = "33">The POS information for the English part of the corpus was generated using the Brill tagger3.</S>
			<S sid ="106" ssid = "34">As Table 4 shows, the splicing operation increases the cardinality of the English vocabulary as well as the number of singletons significantly.</S>
			<S sid ="107" ssid = "35">Nevertheless, they are still below those numbers for Spanish and Catalan.</S>
			<SUBSECTION>6.2 Evaluation.</SUBSECTION>
			<S sid ="108" ssid = "36">Metrics The quality of the output of our machine transla­ tion system is measured automatically by compar­ ing the generated translation to a given reference translation.</S>
			<S sid ="109" ssid = "37">The two following criteria are used: • WER (word error rate): The word error rate is based on Lhe Leven­ shtein distance.</S>
			<S sid ="110" ssid = "38">It is computed as the min­ imum number of substitution, insertion and deletion operations that have to be performed to convert the generated string into the ref­ erence string.</S>
			<S sid ="111" ssid = "39">Since some sentences in the develop and test set occur several times with different reference translations (which holds especially !&apos;or short sentences like &apos;okay, goodbye&apos;), we calculate the minimal dis­ tance to this set of references as proposed in (NieBen et al., 2000).</S>
			<S sid ="112" ssid = "40">• BLEU (bilingual evaluation understudy): (Papineni et al., 2002) have proposed a 2We made use of the toolkit YASMET which can be downloaded from http://v,·wwi6.informatik.rwth­ aachen.derochlsoftware/YASME&apos;l.html 3The Brill tagger can be downloaded ti&quot;om http://www.research.microsoft.com/users/brill/ Table 4: Statistics of the training, develop and test set of the EnglishSpanish-Catalan LC-STAR corpus (*number of words without punctuation marks) E n g l i s h I I Spa nish Catalan I II O ri gi na l I Transformed I Tr ai ni ng Sentences W o r d s W o r d s * 1 3 3 5 2 123 454 I 114099 II 118 534 II 118 137 1017 38 I 92383 II 96997 II 96503 V oc ab ul ar y Size S i n g l e t o n s 215 4 j 2776 jj 3933 jj 3572 79o C37%) 1 l 165 (42%) II 1 844 (47%) II I 658 (47%) De ve lo p Sentences W o r d s U n k n o w n W o r d s 2 7 2 226 7 j 2096 jj 2217 jj 2211 21 I 22 II 34 II 34 Te st Sentences W o r d s U n k n o w n W o r d s 2 6 2 262 17 I 18 II 30 II 35 method of automatic machine translation evaluation, which they call &quot;BLEU&quot;.</S>
			<S sid ="113" ssid = "41">It is based on the notion of modified n-gram pre­ cision, for which all candidate n-gram counts in the translation are collected and clipped against their corresponding maximum refer­ ence counts.</S>
			<S sid ="114" ssid = "42">These clipped candidate counts are summed and normalized by the total num­ ber of candidate n-grams.</S>
			<S sid ="115" ssid = "43">Since BLEU ex­ presses quality, we determine 100BLEU to transform it into an error measure.</S>
			<S sid ="116" ssid = "44">Although these measures are only approximations, they seem to be surflcient at the present level or petformance of machine translation systems.</S>
			<SUBSECTION>6.3 Experimental Results.</SUBSECTION>
			<S sid ="117" ssid = "45">We compared the two statistical lexica obtained from the baseline system and from the maximum entropy training on the transformed corpus.</S>
			<S sid ="118" ssid = "46">For the baseline lexicon, we observed an average of 5.82 Catalan translation candidates per English.</S>
			<S sid ="119" ssid = "47">word and 6.16 Spanish translation candidates.</S>
			<S sid ="120" ssid = "48">These numbers are significantly reduced in the lexicon which was trained on the transformed corpus using maximum entropy: there, we have an average of 4.20 for Catalan and 4.46 for Spanish.</S>
			<S sid ="121" ssid = "49">Especially for (nominative) English pronouns (which have many verbs as translation candidates in the baseline lexicon), the number of translation candidates was substantially scaled down by a factor around 4.</S>
			<S sid ="122" ssid = "50">This shows that our method was successful in producing a more focused lexicon probability distribution.</S>
			<S sid ="123" ssid = "51">We performed translation experiments with an implementation of the IBM4 translation model (Brown et al., 1993).</S>
			<S sid ="124" ssid = "52">A description of the system can be found in (Tillmann and Ney, 20 02 ).</S>
			<S sid ="125" ssid = "53">Table 5 presents an assessment or translation qual­ ity for both the language pairs English--Catalan and EnglishSpanish.</S>
			<S sid ="126" ssid = "54">We see that there is a signif­ icant decrease in error rate for the translation into Catalan.</S>
			<S sid ="127" ssid = "55">This change is consistent across bother­ ror rates, the WER and 100BLEU.</S>
			<S sid ="128" ssid = "56">For translations from English into Spanish, the improvement is less substantial.</S>
			<S sid ="129" ssid = "57">A reason for this might be that the Spanish vocabulary contains more entries and the ratio between l&apos;uHrorms and baseforms is higher: 1.57 for Spanish versus 1.53 for Catalan4 • This makes it more difficult for the system to choose the correct inflection when gen­ erating a Spanish sentence.</S>
			<S sid ="130" ssid = "58">We assume that the extension or our approach to other word classes than verbs will yield a quality gain for translations into Spanish.</S>
			<S sid ="131" ssid = "59">Table 6 shows several sentences from the English LC-STAR develop and test corpus that were trans 4 The lemmatization of Spanish and CaLalan was produced using the analyser from UPC Barcelona: MACO+ andRE­ LAX.</S>
			<S sid ="132" ssid = "60">Table 5: Translation error rates[%] for EnglishCatalan and for EnglishSpanish I Develop I Test I WER I 100BLEU WER I I 00BLEU Ca tal an Baseline 3 7 . 6 5 8 . 2 3 3 . 0 4 9 . 2 + T r a n s f o r m a t i o n s 3 5 . 0 5 5 . 1 3 0 . 8 4 6 . 6 Sp an is h Baseline 3 5 . 4 5 7 . 6 3 2 . 1 4 8 . 9 + T r a n s f o r m a t i o n s 3 5 . 0 5 5 . 8 3 1 . 5 4 7 . 6 lated into Catalan.</S>
			<S sid ="133" ssid = "61">We see that it is easier for the system to generate the correct verb inflection in Catalan if the verb is enriched with the pronoun.</S>
			<S sid ="134" ssid = "62">In the baseline system, it happens that words are inserted- like &apos;far&apos; as translation of &apos;will&apos; in the second example which is incorrect.</S>
			<S sid ="135" ssid = "63">This can be avoided by the splicing of words.</S>
			<S sid ="136" ssid = "64">In the last example, we see that the baseline system generates one word each for the English &apos;I prefer&apos; and does not find the correct translation, whereas transformations yield an accurate transla­ tion of this expression, because the spliced word contains sul&apos;ficienl inl&apos;ormalion.</S>
			<S sid ="137" ssid = "65">7 Conclusion and Future Work.</S>
			<S sid ="138" ssid = "66">We presented a method for improving quality of statistical machine translation from English into morphologically richer languages like Spanish and Catalan.</S>
			<S sid ="139" ssid = "67">Using POS tags as additional knowledge source, we enrich the English verbs such that they contain more information relevant for selecting the conect inflected form in the target language.</S>
			<S sid ="140" ssid = "68">The lexicon model was then trained using the maxi­ mum entropy approach, taking the verbs as addi­ tional features.</S>
			<S sid ="141" ssid = "69">Results were given for translation from English into Spanish and Catalan on the LC-STAR cor­ pus which consists of spontaneously spoken dia­ logues in the domain of appointment scheduling and travel arrangement.</S>
			<S sid ="142" ssid = "70">Our experiments show that translation quality can be signif1cantly in­ creased through the use of our approach: the word error rate on the Catalan development set for ex­ ample decreased by 2.5% absolute.</S>
			<S sid ="143" ssid = "71">We plan to investigate other methods of enrich­ ing the English words with information.</S>
			<S sid ="144" ssid = "72">It will be interesting to see how other word classes, e. g. nouns, can be handled in order to improve quality of translations into languages with a highly inflected morphology.</S>
			<S sid ="145" ssid = "73">8</S>
	</SECTION>
	<SECTION title="Acknowledgement">
</PAPER>
