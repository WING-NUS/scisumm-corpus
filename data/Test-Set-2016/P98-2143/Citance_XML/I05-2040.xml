<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">This paper proposes a unified Transformation Based Learning (TBL, Brill, 1995) framework for Chinese Entity Detection and Tracking (EDT).</S>
		<S sid ="2" ssid = "2">It consists of two sub models: a mention detection model and an entity tracking/coreference model.</S>
		<S sid ="3" ssid = "3">The first sub-model is used to adapt existing Chinese word segmentation and Named Entity (NE) recognition results to a specific EDT standard to find all the mentions.</S>
		<S sid ="4" ssid = "4">The second sub-model is used to find the coreference relation between the mentions.</S>
		<S sid ="5" ssid = "5">In addition, a feedback technique is proposed to further improve the performance of the system.</S>
		<S sid ="6" ssid = "6">We evaluated our methods on the Automatic Content Extraction (ACE, NIST, 2003) Chinese EDT corpus.</S>
		<S sid ="7" ssid = "7">Results show that it outperforms the baseline, and achieves comparable performance with the state- of-the-art methods.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="8" ssid = "8">The task of Entity Detection and Tracking (EDT) is suggested by the Automatic Content Extraction (ACE) project (NIST, 2003).</S>
			<S sid ="9" ssid = "9">The goal is to detect all entities in a given text and track all mentions that refer to the same entity.</S>
			<S sid ="10" ssid = "10">The task is a fundamental to many Natural LanguageProcessing (NLP) applications, such as informa tion retrieval and extraction, text classification, summarization, question answering, and machine translation.</S>
			<S sid ="11" ssid = "11">EDT is an extension of the task of coreference resolution in that in EDT we not only resolve the coreference between mentions but also detect the entities.</S>
			<S sid ="12" ssid = "12">Each of those entities may have one or more mentions.</S>
			<S sid ="13" ssid = "13">In the ACE project, there are five types of entities defined in EDT: person (PER), geography political Entity (GPE), organization (ORG), location (LOC), and facility (FAC).</S>
			<S sid ="14" ssid = "14">Many traditional coreference techniques can be extended to EDT for entity tracking.</S>
			<S sid ="15" ssid = "15">Early work on pronoun anaphora resolution usually uses rule-based methods (e.g. Hobbs 1976; Ge et al., 1998; Mitkov, 1998), which try to mine the cues of the relation between the pronouns and its antecedents.</S>
			<S sid ="16" ssid = "16">Recent research (Soon et al., 2001; Yang et al., 2003; Ng and Cardie, 2002; Ittycherah et al., 2003; Luo et al., 2004) focuses on the use of statistical machine learning methods and tries to resolve references among all kinds of noun phases, including name,nominal and pronoun phrase.</S>
			<S sid ="17" ssid = "17">One common ap proach applied by them is to first train a binary statistical model to measure how likely a pair of * This work is done while the first author is visiting Microsoft Research Asia.</S>
			<S sid ="18" ssid = "18">mentions corefer; and then followed by a greedy procedure to group the mentions into entities.</S>
			<S sid ="19" ssid = "19">Mention detection is to find all the named entity, noun or noun phrase, pronoun or pronoun phrase.</S>
			<S sid ="20" ssid = "20">Therefore, it needs Named Entity Rec ognition, but not only.</S>
			<S sid ="21" ssid = "21">Though the detection of entity mentions is an essential problem for EDT/coreference, there has been relatively less previous research.</S>
			<S sid ="22" ssid = "22">Ng and Cardie (2002) shows that improving the recall of noun phrase identification can improve the performance of a coreference system.</S>
			<S sid ="23" ssid = "23">Florian et al.</S>
			<S sid ="24" ssid = "24">(2004) formulate the mention detection problem as a character-based classification problem.</S>
			<S sid ="25" ssid = "25">They assign for each character in the text a label, indicating whether it is the start of a specific mention, inside a specific mention, or outside of any mention.</S>
			<S sid ="26" ssid = "26">In this paper, we propose a unified EDT model based on the Transformation Based Learning (TBL, Brill, 1995) framework for Chinese.</S>
			<S sid ="27" ssid = "27">The model consists of two sub models: a mention detection model and a coreference model.</S>
			<S sid ="28" ssid = "28">The first sub-model is used to adapt existing Chinese word segmentation and Named Entity (NE) recognition system to a specific EDT standard.</S>
			<S sid ="29" ssid = "29">TBL is a widely used machine learning method, but it is the first time it is applied to coreference resolution.</S>
			<S sid ="30" ssid = "30">In addition, a feedback technique is proposed to further improve the performance of the system.</S>
			<S sid ="31" ssid = "31">The rest of the paper is organized as follows.</S>
			<S sid ="32" ssid = "32">Raw Document MSRSeg&amp;POS Tagging Seg/POS/NE Document Coreference Model Mentions Entities Mention Detection Model In section 2, we propose the unified TBL Chinese EDT model framework.</S>
			<S sid ="33" ssid = "33">We describe the four key techniques of our Chinese EDT, the word segmentation adaptation model, the mention detection model, the coreference model and the feedback technique in section 3, 4, 5 and 6 accordingly.</S>
			<S sid ="34" ssid = "34">The experimental results on the ACE Chinese EDT corpus are shown in section 7.</S>
	</SECTION>
	<SECTION title="The Unified System Framework. " number = "2">
			<S sid ="35" ssid = "1">Our Chinese EDT system consists of two components, mention detection module and coreference module besides a feedback technique between them as illustrated in Figure 1.</S>
			<S sid ="36" ssid = "2">MSRSeg (Gao et al., 2003; Gao et al.), Microsoft Research Asia’s Chinese word segmen tation system that is integrated with named entity recognition, is used to segment Chinese words.</S>
			<S sid ="37" ssid = "3">However MSRSeg can’t well match the standard of ACE EDT evaluation for either types or boundaries.</S>
			<S sid ="38" ssid = "4">The difference of the standard of named entity between MSRSeg and ACE cause more than half of the errors for NAME mention detection.</S>
			<S sid ="39" ssid = "5">In order to overcome these problems, we integrate a segmentation adapter to mention detection model.</S>
			<S sid ="40" ssid = "6">The EDT system is a unified system that uses the TBL scheme.</S>
			<S sid ="41" ssid = "7">The idea of TBL is to learn a list of ordered rules while progressively improve upon the current state of the training set.</S>
			<S sid ="42" ssid = "8">An initial assignment is made based on simple statistics, and then rules are greedily learned to correct the mistakes, until no more improvement can be made.</S>
			<S sid ="43" ssid = "9">There are three main problems in the TBL framework: An initial state assignment, a set of allowable templates for rules, and an objective function for learning.</S>
			<S sid ="44" ssid = "10">Figure 1.</S>
			<S sid ="45" ssid = "11">Entity detection and tracking system flow.</S>
	</SECTION>
	<SECTION title="Word Segmentation Adaptation. " number = "3">
			<S sid ="46" ssid = "1">The method of applying TBL to adapt the Chinese word segmentation standard has been described in Gao et al.</S>
			<S sid ="47" ssid = "2">(2004).</S>
			<S sid ="48" ssid = "3">Our approach is slightly different for not have a correctly segmented corpus according to ACE standard.</S>
			<S sid ="49" ssid = "4">From the un-segmented ACE EDT corpus, we can only obtain mention boundary information.</S>
			<S sid ="50" ssid = "5">So the adapting objective is to detect the mention boundary instead of all words in text, correctly.</S>
			<S sid ="51" ssid = "6">In the corpus, very few mentions’ boundaries are crossing1.</S>
			<S sid ="52" ssid = "7">The initial state of the segmentation adaptation model is the output of MSRSeg.</S>
			<S sid ="53" ssid = "8">And we 1 The mentions’ extents are frequently crossing, while.</S>
			<S sid ="54" ssid = "9">heads not.</S>
			<S sid ="55" ssid = "10">define two actions in the model, inserting and removing a boundary.</S>
			<S sid ="56" ssid = "11">The prefix or suffix of current word is used to define the boundary of inserting.</S>
			<S sid ="57" ssid = "12">Both inserting and removing action consider the combination of POS tag and word string of current, left and right words.</S>
			<S sid ="58" ssid = "13">When inserting a boundary, the right part of the word keeps the old POS tag, and the left part introduces a special POS tag “new”.</S>
			<S sid ="59" ssid = "14">When removing a boundary, the new formed word introduces a special POS tag “new”.</S>
			<S sid ="60" ssid = "15">The following two examples illustrate the strategy.</S>
			<S sid ="61" ssid = "16">俄罗 斯 法院 /nt/court of Russia Æ 俄罗 斯 /new/Russia 法院/nt/court 波/nr/Bo 普/nr/Pu Æ波普/new/Bopu</S>
	</SECTION>
	<SECTION title="Mention Detection. " number = "4">
			<S sid ="62" ssid = "1">Since the word segmentation adaptation model has corrected the boundaries of mentions, our mention detection model bases on word and only tagging the entity mention types.</S>
			<S sid ="63" ssid = "2">The model detects the mentions by tagging sixteen tags (including the combination of five entity types and three mention types and “OTHER” tag) for all the words outputted by segmentation adaptation model.</S>
			<S sid ="64" ssid = "3">The templates, as illustrated in table 1, only refer to local features, such as POS tag and word string of left, right, and current words; the suffix, and single character feature of current word.</S>
			<S sid ="65" ssid = "4">Table 1.</S>
			<S sid ="66" ssid = "5">Templates for mention detection.</S>
			<S sid ="67" ssid = "6">MT1: P0 MT9: R4,P0 MT2: W0 MT10: R3,P0 MT3: P0,W0 MT11: R2,P0 MT4: P_1,W0 MT12: R1,P0 MT5: P_1,P0 MT13: S0,P0 MT6: W0,P1 MT14: T_1,W0 MT7: P0,P1 MT15: T_1,P0 MT8: W0,W1 MT16: P0,T1 Table 2.</S>
			<S sid ="68" ssid = "7">Examples of transformation rules of mention detection.</S>
			<S sid ="69" ssid = "8">MR1: MT13 0 ns GPE MR2: MT13 0 nr PER MR3: MT13 0 nt ORG MR4: MT16 n PER NPER MR5: MT16 new ORG GPE In table 1, “MT1” et al represent the id of the templates; “R1”, “R2”, “R3” and “R4” represent the suffix of current word and the number of character is 1, 2, 3 and 4 accordingly; other suffix “_1”, “0”, “1” means the left, current and right words’ feature; “W” represent the string of word; “P” represent POS tag; “T” represent mention tag; “S” represent the binary-value single character feature.</S>
			<S sid ="70" ssid = "9">Five best transformation rules are illustrated in Table 2.</S>
			<S sid ="71" ssid = "10">For example, MR3 means “if current word’s POS tag is nt, then it is a ORG”.</S>
			<S sid ="72" ssid = "11">Following example well describe the process of applying these rules.</S>
			<S sid ="73" ssid = "12">俄罗斯/new/Russia 法院/nt/court Æ俄罗斯/new/Russia [法院/nt/court]ORG (MR3) Æ[ 俄 罗 斯 /new/Russia]GPE [ 法 院 (MR5) /nt/court]ORG</S>
	</SECTION>
	<SECTION title="Entity Tracking. " number = "5">
			<S sid ="74" ssid = "1">In our entity tracking/coreference model, the initial state is let each mention in a document form an entity, as shown in Figure 2 (a).</S>
			<S sid ="75" ssid = "2">And the objective function directs the learning process to insert or remove chains between mentions (Figure 2 b and c) to approach the goal state (Figure 2 f).</S>
			<S sid ="76" ssid = "3">A list of rules is learned in greedy fashion, according to the objective function.</S>
			<S sid ="77" ssid = "4">When no rule that improves the current state of the train ing set beyond a preset threshold can be found, the training phrase ends.</S>
			<S sid ="78" ssid = "5">The objective function in our system is driven by the correctness of the binary classification for pairwise mention pairs.</S>
			<S sid ="79" ssid = "6">The TBL entity tracking model has more widely clustering/searching space as compare with previous strategies (Soon et al. 2001; Ng and Cardie, 2002; Luo et al., 2004).</S>
			<S sid ="80" ssid = "7">For example, the state shown in Figure 2 (d) is not reachable for them.</S>
			<S sid ="81" ssid = "8">Because they assume one mention should refer to its most confidential mentions or entities that before it, while A and B are obviously not in same entity, as we can see in Figure 2 (d).</S>
			<S sid ="82" ssid = "9">Thus C can refer to either A or B, but not both.</S>
			<S sid ="83" ssid = "10">While in TBL model, this state is allowed.</S>
			<S sid ="84" ssid = "11">In order to keep our system robust, the transformation templates refer to only six types of simple features, as described below.</S>
			<S sid ="85" ssid = "12">All these features do not need any high level tools (i.e. syntactic parser) and little external knowledge base.</S>
			<S sid ="86" ssid = "13">In fact, only a country name abbreviation list (171 entrances) and a Chinese province alias list (34 entrances) are used to detect “alias” relation for String Match feature.</S>
			<S sid ="87" ssid = "14">String Match feature (STRM): Its possible values are exact, alias, abbr, left, right, other.</S>
			<S sid ="88" ssid = "15">If two mentions are exact string matched, then re turn exact; else if one mention is an alias of the other, then return alias; else if one mention is the abbreviation of the other, then return abbr; else if one mention is the left substring of the other, then return left; else if one mention is the right substring of the other, then return right; else return other.</S>
			<S sid ="89" ssid = "16">Figure 2.</S>
			<S sid ="90" ssid = "17">The procedure of TBL entity tracking/coreference model Edit Distance feature I (ED1): Its possible values are true or false.</S>
			<S sid ="91" ssid = "18">If the edit distance of the two mentions are less than or equal to 1, then return true, else return false.</S>
			<S sid ="92" ssid = "19">Token Distance feature I (TD1): Its possible values are true or false.</S>
			<S sid ="93" ssid = "20">If the edit distance of the two mentions are less than or equal to 1(i.e., there are not more than one token between the two mentions), then return true, else return false.</S>
			<S sid ="94" ssid = "21">Mention Type (MT): Its possible values are NAME, NOMINAL, or PRONOUN..</S>
			<S sid ="95" ssid = "22">Entity Type (ET): Its possible values are PER, GPE, ORG, LOC, or FAC.</S>
			<S sid ="96" ssid = "23">Mention String (M): Its possible values are the actual mention string.</S>
			<S sid ="97" ssid = "24">These six features can be divided into two categories: mention pair features (the first three) and single mention features (the other three).</S>
			<S sid ="98" ssid = "25">And the single mention features are suffixed with “L” or “R” to differentiate for left or right mentions (i.e. ETL represent the left mention’s entity type).</S>
			<S sid ="99" ssid = "26">Based on the six kinds of basic features, four simple transformation templates are used in our system, as listed in table 3.</S>
			<S sid ="100" ssid = "27">Table 3.</S>
			<S sid ="101" ssid = "28">Templates for coreference model.</S>
			<S sid ="102" ssid = "29">CT1: MTL,MTR,STRM CT2: MTL,MTR,ETL,ETR,ED1 CT3: MTL,MTR,ETL,ETR,TD1 CT4: MTL,MTR,ML,MR Table 4.</S>
			<S sid ="103" ssid = "30">Examples of transformation rules of C D D E (a) (b) (c) A (d) D coreference model.</S>
			<S sid ="104" ssid = "31">CR1:CT1 NAME NAME EXACT LINK CR2:CT2 NOMINAL NAME PER PER 1 LINK CR3:CT1 NAME NAME ALIAS LINK CR4:CT1 PRONOUN PRONOUN EXACT LINK Though trained on different data set will learn different rules, the four rules listed in table 4 is the best rules that always been learned.</S>
			<S sid ="105" ssid = "32">For example, the first rule means that “If two NAME mentions are exact string matched, then insert a chain between them”.</S>
			<S sid ="106" ssid = "33">The following example illu stra tes the pro cess . [美国/US]GPE 墩促[俄罗斯/Russia] GPE 基 于 人道原 因释 放[ 美国 /US]GPE[ 商人 C D E (e) (f) /businessman]NPER[波普/ Bopu]PER Æ [ 美国 /US]GPE1 墩促 [ 俄罗 斯 /Russia]GPE 基于人道原因释放[ 美国 /US]GPE1[ 商人 /businessman]NPER[ 波普 /Bopu]PER Æ [ 美国 /US]GPE1 墩促 [ 俄罗 斯 /Russia]GPE 基于人道原因释放[ 美国 /US]GPE1[ 商人 /businessman]NPER2[ 波普 /Bopu]PER-2</S>
	</SECTION>
	<SECTION title="Feedback. " number = "6">
			<S sid ="107" ssid = "1">There are three reasons push us apply feedback technique in the EDT system.</S>
			<S sid ="108" ssid = "2">The first is to determine whether a signal character is an abbreviation is discourse depended.</S>
			<S sid ="109" ssid = "3">For example, Chinese character “ 中 ” can represents both a country name “China” and a common preposition “in”.</S>
			<S sid ="110" ssid = "4">If it can links to “ 中 国/China” by coreference model, it is likely to represent “China”.</S>
			<S sid ="111" ssid = "5">The second is the definition of mentions is hard to hold, especially the nominal mentions.</S>
			<S sid ="112" ssid = "6">An isolated mention is more likely not to be a mention.</S>
			<S sid ="113" ssid = "7">The third is to pick up lost men tion according to its multi-appearance in the discourse.</S>
			<S sid ="114" ssid = "8">In fact, [Ji and Crishman, 2004] has used five hubristic rules based on coreference results to improve the name recognition result.</S>
			<S sid ="115" ssid = "9">While in this section we will present an automatic method.</S>
			<S sid ="116" ssid = "10">The feedback technique is employed by using entity features in mention detection model.</S>
			<S sid ="117" ssid = "11">In our model, the transformation templates refer to the number of mentions in the entity, the sin gle character feature, the entity type feature, the mention type feature and mention string, as listed follows.</S>
			<S sid ="118" ssid = "12">SDD: Its possible values are the combination of the mention type and entity type of the mention string in discourse: PER, GPE, ORG, LOC, FAC, NPER (NOMINAL PER), NGPE, NORG, NLOC, NFAC, PPER (PROUNOUN PER), PGPE, PORG, PLOC, and PFAC.</S>
			<S sid ="119" ssid = "13">SC2, SC3, SC4: Their possible values are true or false.</S>
			<S sid ="120" ssid = "14">If the word string appear not less than 2 (3, 4) times in the discourse then return true, else return false.</S>
			<S sid ="121" ssid = "15">PDD: presents the combination of the mention type and entity type of the mention in discourse.</S>
			<S sid ="122" ssid = "16">Its possible values are same with “SDD”.</S>
			<S sid ="123" ssid = "17">PC2: Its possible values are true or false.</S>
			<S sid ="124" ssid = "18">If the mention belong to an entity has not less than 2 mentions then return true, else return false.</S>
			<S sid ="125" ssid = "19">S0: Its possible values are true or false.</S>
			<S sid ="126" ssid = "20">If the mention is a single character word then return true, else return false.</S>
			<S sid ="127" ssid = "21">W0: string of the mention.</S>
			<S sid ="128" ssid = "22">Table 5.</S>
			<S sid ="129" ssid = "23">Templates for feedback.</S>
			<S sid ="130" ssid = "24">FT1: SDD,SC2 FT4: PDD,PC2,S0 FT2: SDD,SC3 FT5: PDD,PC2,S0 FT3: SDD,SC4 FT6: PDD,PC2,W0 Table 6.</S>
			<S sid ="131" ssid = "25">Examples of transformation rules of feedback.</S>
			<S sid ="132" ssid = "26">FR1: FT1 PER T PER FR4: FT4 NORG F O The first rule means that “if a word in the document appears as person name more than two times, then it is a person name”.</S>
			<S sid ="133" ssid = "27">This rule can pick up lost person names.</S>
			<S sid ="134" ssid = "28">The second rule means that “if a GPE mention is isolated and it is a single character word, then it is not a mention”.</S>
			<S sid ="135" ssid = "29">This rule can throw away isolated abbre viation of GPE, as illustrated in the following example.</S>
			<S sid ="136" ssid = "30">…[波普/Bopu]PER-3 在星期三被[俄罗斯 /Russia]GPE2[ 法院/court]ORG4[ 以/by]GPE6 间谍罪判处 20 年徒刑 … Æ…[波普/Bopu]PER-3 在星期三被[俄罗 斯/Russia]GPE2[法院/court]ORG4 以/by 间 谍罪判处 20 年徒刑 …</S>
	</SECTION>
	<SECTION title="Experiments. " number = "7">
			<S sid ="137" ssid = "1">Our experiments are conducted on Chinese EDT corpus for ACE project from LDC.</S>
			<S sid ="138" ssid = "2">This corpus is the training data for ACE evaluation 2003.</S>
			<S sid ="139" ssid = "3">The corpus has two types, paper news (nwire) and broadcast news (bnews).</S>
			<S sid ="140" ssid = "4">the statistics of the corpus is shown in Table 7.</S>
			<S sid ="141" ssid = "5">Table 7.</S>
			<S sid ="142" ssid = "6">Statistics of the ACE corpus.</S>
			<S sid ="143" ssid = "7">nwire bnews Document 99 122 Character 55,000 45,000 Entity 2517 2050 Mention 5423 4506 Because the test data for ACE evaluation is not public, we randomly and equally divide the corpus into 3 subsets: set0, set1, set2.</S>
			<S sid ="144" ssid = "8">Each consists of about 73 documents and 33K Chinese Characters2.</S>
			<S sid ="145" ssid = "9">Cross experiments are conducted on these data sets.</S>
			<S sid ="146" ssid = "10">ACE-value is used to evaluate the EDT system; and precision (P), recall (R) and F (F=2*P*R/(P+R)) to evaluate the mention detection result.</S>
			<S sid ="147" ssid = "11">In the experiments, we first use one data set train the mention detection system; then use another set train the coreference model based on the output of the mention detection; finally use the other set test.</S>
			<S sid ="148" ssid = "12">In practice, we can retrain the mention detection model use the two train set to get higher performance.</S>
			<S sid ="149" ssid = "13">Table 8.</S>
			<S sid ="150" ssid = "14">EDT and mention detection results.</S>
			<S sid ="151" ssid = "15">EDT Mention Detection FR2: FT5 GPE F 1 O FR5: FT3 PGPE F O FR3: FT4 NFAC F OMethod ACE value R P F Tag 55.7±1.6 62.3±1.0 85.0±1.4 71.9±0.6 SegTag 61.6±3.6 70.9±4.5 81.9±1.0 75.9±2.6 SegTag+F 63.3±2.0 68.0±4.8 83.8±1.2 75.0±3.1 2 Two of the documents (CTS20001110.1300.0506, and.</S>
			<S sid ="152" ssid = "16">XIN20001102.2000.0207) in the corpus are not use for serious annotation error.</S>
			<S sid ="153" ssid = "17">In Table 8, “SegTag” represent the mention detection system integrated with segmentation adaptation, “Tag” represent the mention detection system without segmentation adaptation.</S>
			<S sid ="154" ssid = "18">“+F” means with feedback.</S>
			<S sid ="155" ssid = "19">The ACE-value of our Chinese EDT system is better than 58.8% of Florian et al.</S>
			<S sid ="156" ssid = "20">(2004).</S>
			<S sid ="157" ssid = "21">In fact, the two systems are not comparable for notbasing on the same training and test data.</S>
			<S sid ="158" ssid = "22">How ever both corpora are under the same standard from ACE project, and our training data (about 66K) is smaller than Florian et al.</S>
			<S sid ="159" ssid = "23">(2004) (about 80K).</S>
			<S sid ="160" ssid = "24">Therefore, it is an encouraging result.</S>
			<S sid ="161" ssid = "25">Segmentation adapting and feedback can improve 7.5% of ACE-value for the whole system.</S>
			<S sid ="162" ssid = "26">As we can see from Table 8, using TBL method to adapt standard or correct errors can improve the mention detection performance especially recall, and word segmentation adapting is essential for mention detection.</S>
			<S sid ="163" ssid = "27">Feedback can improve the precision of mention detection with loss of recall.</S>
			<S sid ="164" ssid = "28">The two techniques can significantly improve the EDT performance, since the p-value of the T-test for the performance of “SegTag” to “Tag” is 96.7%, while for “Seg- Tag+F” to “Tag” is 98.9%.</S>
			<S sid ="165" ssid = "29">The recall of mention detection is dropped after feedback because of the great effect of rule FR2, 3, 4 and 5 as illustrated in table 6.</S>
	</SECTION>
	<SECTION title="Conclusion. " number = "8">
			<S sid ="166" ssid = "1">In this paper, we integrate the mention detection model and entity tracking/coreference model into a unified TBL framework.</S>
			<S sid ="167" ssid = "2">Experimental results show segmentation adapting and feedback can significantly improve the performance of EDT system.</S>
			<S sid ="168" ssid = "3">And even with very limited knowledge and shallow NLP tools, our method can reach comparable performance with related work.</S>
	</SECTION>
</PAPER>
