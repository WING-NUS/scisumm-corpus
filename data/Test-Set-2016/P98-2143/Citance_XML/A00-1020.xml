<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">In this paper we present a new, multi­ lingual data-driven method for coreference resolution as implemented in the SWIZZLE system.</S>
		<S sid ="2" ssid = "2">The results obtained after training this system on a bilingual corpus of English and Romanian tagged texts, outperformed coreference resolution in each of the indi­ vidual languages.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="3" ssid = "3">The recent availability of large bilingual corpora has spawned interest in several areas of multilingual text processing.</S>
			<S sid ="4" ssid = "4">Most of the research has focused on bilingual terminology identification, either as par­ allel multiwords forms (e.g. the Champollion sys­ tem (Smadja et al.1996)), technical terminology (e.g. the Termight system (Dagan and Church, 1994) or broad-coverage translation lexicons (e.g. the SABLE system (Resnik and Melamed, 1997)).</S>
			<S sid ="5" ssid = "5">In addition, the Multilingual Entity Task (MET) from the TIP­ STER program1 (http://wwwnlpir.nist.govjrelated­ projectsjtipsterjmet.htm) challenged the partici­ pants in the Message Understanding Conference (MUC) to extract named entities across several for­ eign language corpora, such as Chinese, Japanese and Spanish.</S>
			<S sid ="6" ssid = "6">In this paper we present a new application of aligned multilingual texts.</S>
			<S sid ="7" ssid = "7">Since coreference reso­ lution is a pervasive discourse phenomenon causing performance impediments in current IE systems, we considered a corpus of aligned English and Roma­ nian texts to identify coreferring expressions.</S>
			<S sid ="8" ssid = "8">Our task focused on the same kind of coreference as considered in the past MUC competitions, namely 1The TIPSTER Text Program was a DARPA-led government effort to advance the state of the art in text processing technologies.</S>
			<S sid ="9" ssid = "9">Steven J. Maiorano IPO Washington, D.C. 20505 maiorano cais.com the identity coreference.</S>
			<S sid ="10" ssid = "10">Identity coreference links nouns, pronouns and noun phrases (including proper names) to their corresponding antecedents.</S>
			<S sid ="11" ssid = "11">We created our bilingual collection by translating the MUC6 and MUC7 coreference training texts into Romanian using native speakers.</S>
			<S sid ="12" ssid = "12">The train­ ing data set for Romanian coreference used, wher­ ever possible, the same coreference identifiers as the English data and incorporated additional tags as needed.</S>
			<S sid ="13" ssid = "13">Our claim is that by adding the wealth of coreferential features provided by multilingual data, new powerful heuristics for coreference resolu­ tion can be developed that outperform monolingual coreference resolution systems.</S>
			<S sid ="14" ssid = "14">For both languages, we resolved coreference by using SWIZZLE, our implementation of a bilingual coreference resolver.</S>
			<S sid ="15" ssid = "15">SWIZZLE is a multilingual en­ hancement of COCKTAIL (Harabagiu and Maiorano, 1999), a coreference resolution system that operates on a mixture of heuristics that combine semantic and textual cohesive information2 • When COCKTAIL was applied separately on the English and the Ro­ manian texts, coreferring links were identified for each English and Romanian document respectively.</S>
			<S sid ="16" ssid = "16">When aligned referential expressions corefer with nonaligned anaphors, SWIZZLE derived new heuris­ tics for coreference.</S>
			<S sid ="17" ssid = "17">Our experiments show that SWIZZLE outperformed COCKTAIL on both English and Romanian test documents.</S>
			<S sid ="18" ssid = "18">The rest of the paper is organized as follows.</S>
			<S sid ="19" ssid = "19">Sec­ tion 2 presents COCKTAIL, a monolingual coreference resolution system used separately on both the En­ glish and Romanian texts.</S>
			<S sid ="20" ssid = "20">Section 3 details the data-driven approach used in SWIZZLE and presents some of its resources.</S>
			<S sid ="21" ssid = "21">Section 4 reports and discusses the experimental results.</S>
			<S sid ="22" ssid = "22">Section 5 summarizes the 2 The name of COCKTAIL is a pun on CogNIAC be­ cause COCKTAIL combines a larger number of heuristics than those reported in (Baldwin, 1997).</S>
			<S sid ="23" ssid = "23">SWIZZLE, more­ over, adds new heuristics, discovered from the bilingual aligned corpus.</S>
			<S sid ="24" ssid = "24">conclusions.</S>
	</SECTION>
	<SECTION title="COCKTAIL. " number = "2">
			<S sid ="25" ssid = "1">Currently, some of the best-performing and most robust coreference resolution systems employ knowledge-based techniques.</S>
			<S sid ="26" ssid = "2">Traditionally, these techniques have combined extensive syntactic, se­ mantic, and discourse knowledge.</S>
			<S sid ="27" ssid = "3">The acquisition of such knowledge is time-consuming, difficult, and error-prone.</S>
			<S sid ="28" ssid = "4">Nevertheless, recent results show that knowledge-poor methods perform with amazing ac­ curacy (cf.</S>
			<S sid ="29" ssid = "5">(Mitkov, 1998), (Kennedy and Boguraev, 1996) (Kameyama, 1997)).</S>
			<S sid ="30" ssid = "6">For example, CogNIAC (Baldwin, 1997), a system based on seven ordered heuristics, generates high-precision resolution (over 90%) for some cases of pronominal reference.</S>
			<S sid ="31" ssid = "7">For this research, we used a coreference resolution sys­ tem ((Harabagiu and Maiorano, 1999)) that imple­ ments different sets of heuristics corresponding to various forms of coreference.</S>
			<S sid ="32" ssid = "8">This system, called COCKTAIL, resolves coreference by exploiting several textual cohesion constraints (e.g. term repetition) combined with lexical and textual coherence cues (e.g. subjects of communication verbs are more likely to refer to the last person mentioned in the text).</S>
			<S sid ="33" ssid = "9">These constraints are implemented as a set of heuristics ordered by their priority.</S>
			<S sid ="34" ssid = "10">Moreover, the COCKTAIL framework uniformly addresses the prob­ lem of interaction between different forms of coref­ erence, thus making the extension to multilingual coreference very natural.</S>
			<S sid ="35" ssid = "11">2.1 Data-Driven Coreference Resolution.</S>
			<S sid ="36" ssid = "12">In general, we define a data-driven methodology as a sequence of actions that captures the data pat­ terns capable of resolving a problem with both a high degree of precision and recall.</S>
			<S sid ="37" ssid = "13">Our data-driven methodology reported here generated sets of heuris­ tics for the coreference resolution problem.</S>
			<S sid ="38" ssid = "14">Precision is the number of correct references out of the total number of coreferences resolved, whereas the recall measures the number of resolved references out of the total number of keys, i.e., the annotated coref­ erence data.</S>
			<S sid ="39" ssid = "15">The data-driven methodology used in COCKTAIL is centered around the notion of a coreference chain.</S>
			<S sid ="40" ssid = "16">Due to the transitivity of coreference relations, k coreference relations having at least one common ar­ gument generate k + 1 core/erring expressions.</S>
			<S sid ="41" ssid = "17">The text position induces an order among coreferring ex­ pressions.</S>
			<S sid ="42" ssid = "18">A coreference structure is created when a set of coreferring expressions are connected in an oriented graph such that each node is related only to one of its preceding nodes.</S>
			<S sid ="43" ssid = "19">In turn, a corefer ence chain is the coreference structure in which ev­ ery node is connected to its immediately preceding node.</S>
			<S sid ="44" ssid = "20">Clearly, multiple coreference structures for the same set of coreferring expressions can be mapped to a single coreference chain.</S>
			<S sid ="45" ssid = "21">As an example, both coreference structures illustrated in Figure 1(a) and (c) are cast into the coreference chain illustrated in Figure 1(b).</S>
			<S sid ="46" ssid = "22">TEXT TEXT TEXT Figure 1: Three coreference structures.</S>
			<S sid ="47" ssid = "23">Given a corpus annotated with coreference data, the data-driven methodology first generates all coreference chains in the data set and then con­ siders all possible combinations of coreference re­ lations that would generate the same coreference chains.</S>
			<S sid ="48" ssid = "24">For a coreference chain of length l with nodes n1, n2, ... nl+1 , each node nk (1 k l) can be connected to any of the l - k nodes preceding it.</S>
			<S sid ="49" ssid = "25">From this observation, we find that a number of 1 x 2 x ... x (l - k)... x l = l!</S>
			<S sid ="50" ssid = "26">coreference struc­ tures can generate the same coreference chain.</S>
			<S sid ="51" ssid = "27">This result is very important, since it allows for the auto­ matic generation of coreference data.</S>
			<S sid ="52" ssid = "28">For each coref­ erence relation n from an annotated corpus we cre­ ated a median of (l- 1)!</S>
			<S sid ="53" ssid = "29">new coreference relations, where l is the length of the coreference chain contain­ ing relation n. This observation gave us the possi­ bility of expanding the test data provided by the coreference keys available in the MUC6 and MUC 7 competitions (MUC6 1996), (MUC7 1998).</S>
			<S sid ="54" ssid = "30">The MUC6 coreference annotated corpus contains 1626 coreference relations, while the MUC7 corpus has 2245 relations.</S>
			<S sid ="55" ssid = "31">The average length of a coreference chain is 7.21 for the MUC6 data, and 8.57 for the MUC7 data.</S>
			<S sid ="56" ssid = "32">We were able to expand the number of annotated coreference relations to 6,095,142 for the MUC6 corpus and to 8,269,403 relations for the MUC7 corpus; this represents an expansion factor of 3,710.</S>
			<S sid ="57" ssid = "33">We are not aware of any other automated way of creating coreference annotated data, and we believe that much of the COCKTAIL&apos;s impressive per­ formance is due to the plethora of data provided by this method.</S>
			<S sid ="58" ssid = "34">He uri sti cs for 3r d pe rs on pr on ou ns He uri sti cs for no mi na l ref er en ce oH eu ris tic 1 Pr on ou n( Hl Pr on ) Se ar ch in the sa me se nte nc e for the sa m e 3 r d p e r s o n p r o n o u n P r o n &apos; i f ( P r o n &apos; b e l o n g s t o c o r e f e r e n c e c h a i n C C ) a n d t h e r e i s a n e l e m e n t f r o m C C w h i c h i s c l o s e s t t o P r o n i n T e x t , P i c k t h a t e l e m e n t . e l s e P i c k P r o n &apos; . oH eur isti c 2 Pr on ou n( H2 Pr on ) Se ar ch for PN , the clo ses t pr op er na me fro m Pr on if (P N agr ees in nu mb er an d ge nd er wit h Pr on ) i f ( P N b e l o n g s t o c o r e f e r e n c e c h a i n C C ) t h e n P i c k t h e e l e m e n t f r o m C C w h i c h i s c l o s e s t t o P r o n i n T e x t . e l s e P i c k P N . o He uri sti c 3 Pr on ou n( H3 Pr on ) Se arc h for No un, the clo ses t no un fro m Pr on if (N ou n agr ees in nu mb er an d ge nd er wit h Pr on) i f ( N o u n b e l o n g s t o c o r e f e r e n c e c h a i n C C ) a n d t h e r e i s a n e l e m e n t f r o m C C w h i c h i s c l o s e s t t o P r o n i n T e x t , P i c k t h a t e l e m e n t . e l s e P i c k N o u n oH eu ris tic 1 No mi na lC Hl No m) if (N ou n is the he ad of an ap po siti ve ) t h e n P i c k t h e p r e c e d i n g N P . o He uri sti c 2 No mi nal (H 2N o m) if (N ou n bel on gs to an NP , Se ar ch for N P&apos; s u c h t h a t N o u n &apos; = s a m e _ n a m e ( h e a d ( N P ) , h e a d ( N P &apos; ) ) o r N o u n &apos; = s a m e _ n a m e ( a d j u n c t ( N P ) , a d j u n c t ( N P &apos; ) ) ) t h e n i f ( N o u n &apos; b e l o n g s t o c o r e f e r e n c e c h a i n C C ) t h e n P i c k t h e e l e m e n t f r o m C C w h i c h i s c l o s e s t t o N o u n i n T e x t . e l s e P i c k N o u n &apos; . oH eu ris tic 3 No mi na l( H3 No m) if No un is the he ad of an N P t h e n S e a r c h f o r p r o p e r n a m e P N s u c h t h a t h e a d ( P N ) = N o u n i f ( P N b e l o n g s t o c o r e f e r e n c e c h a i n C C ) a n d t h e r e i s a n e l e m e n t f r o m C C w h i c h i s c l o s e s t t o N o u n i n T e x t , P i c k t h a t e l e m e n t . e l s e P i c k P N . Table 1: Best performing heuristics implemented in COCKTAIL 2.2 Knowledge-Poor Coreference.</S>
			<S sid ="59" ssid = "35">Resolution The result of our data-driven methodology is the set of heuristics implemented in COCKTAIL which cover both nominal and pronoun coreference.</S>
			<S sid ="60" ssid = "36">Each heuristic represents a pattern of coreference that was mined from the large set of coreference data.</S>
			<S sid ="61" ssid = "37">COCKTAIL uses knowledge-poor methods because (a) it is based only on a limited number of heuristics and (b) text processing is limited to part-of-speech tagging, named-entity recognition, and approximate phrasal parsing.</S>
			<S sid ="62" ssid = "38">The heuristics from COCKTAIL can be classified along two directions.</S>
			<S sid ="63" ssid = "39">First of all, they can be grouped according to the type of corefer­ ence they resolve, e.g., heuristics that resolve the anaphors of reflexive pronouns operate differently than those resolving bare nominals.</S>
			<S sid ="64" ssid = "40">Currently, in COCKTAIL there are heuristics that resolve five types of pronouns (personal, possessive, reflexive, demon­ strative and relative) and three forms of nominals (definite, bare and indefinite).</S>
			<S sid ="65" ssid = "41">Secondly, for each type of coreference, there are three classes of heuristics categorized according to their suitability to resolve coreference.</S>
			<S sid ="66" ssid = "42">The first class is comprised of strong indicators of coreference.</S>
			<S sid ="67" ssid = "43">This class resulted from the analysis of the distribu­ tion of the antecedents in the MUC annotated data.</S>
			<S sid ="68" ssid = "44">For example, repetitions of named entities and ap­ positives account for the majority of the nominal coreferences, and, therefore, represent anchors for the first class of heuristics.</S>
			<S sid ="69" ssid = "45">The second class of coreference covers cases in which the arguments are recognized to be seman­ tically consistent.</S>
			<S sid ="70" ssid = "46">COCKTAIL&apos;s test of semantic con­ sistency blends together information available from WordNet and statistics gathered from Treebank.</S>
			<S sid ="71" ssid = "47">Different consistency checks are modeled for each of the heuristics.</S>
			<S sid ="72" ssid = "48">Ex a m pl e of th e ap pli ca tio n of he ur ist ic H 2 Pr on M r. A da m s 1 , 69 ye ar s ol d, is th e re tir ed ch ai r m an o f C a n a d ia n b a s e d E m c o L t d ., a m a k e r o f p l u m b i n g a n d p et r o le u m e q u i p m e n t; h e 1 h a s s e r v e d o n t h e W o o l w o rt h b o a r d si n c e 1 9 8 1.</S>
			<S sid ="73" ssid = "49">Ex a m pl e of th e ap pli ca tio n of he ur ist ic H 3 Pr on &quot; W e ha ve go t to st op po in ti ng ou r fi ng er s at th es e k i d s 2 w h o h a v e n o f u t u r e , &quot; h e s a i d , &quot; a n d r e a c h o u r h a n d s o u t t o t h e m 2 . Ex a m pl e of th e ap pli ca tio n of he ur ist ic H 2 N o m T he ch air m an an d th e ch ief ex ec uti ve of fi ce r3 o f W o o l w o r t h C o r p . h a v e t e m p o r a r i l y r e l i n q u i s h e d t h e i r p o s t s w h i l e t h e r e t a i l e r c o n d u c t s i t s i n v e s t i g a t i o n i n t o a l l e g e d a c c o u n t i n g i r r e g u l a r i t i e s 4 . W o o l w o rt h&apos; s b o a r d n a m e d J o h n W . A d a m s, a n o u ts i d e r, t o s e r v e a s i n t e ri m c h a ir m a n a n d e x e c u ti v e o ff i c e r 3 , w h il e a s p e c i a l c o m m it t e e, a p p o i n t e d b y t h e b o a r d l a st w e e k a n d l e d b y M r. A d a m s, i n v e st i g a t e s t h e al le g e d ir r e g u l a ri ti e s 4 . Table 2: Examples of coreference resolution.</S>
			<S sid ="74" ssid = "50">The same annotated index indicates coreference.</S>
			<S sid ="75" ssid = "51">The third class of heuristics resolves coreference by coercing nominals.</S>
			<S sid ="76" ssid = "52">Sometimes coercions involve only derivational morphology - linking verbs with their nominalizations.</S>
			<S sid ="77" ssid = "53">On other occasions, coercions are obtained as paths of meronyms (e.g. is-part re­ lations) and hypernyms (e.g. is-a relations).</S>
			<S sid ="78" ssid = "54">Con sistency checks implemented for this class of coref­ erence are conservative: either the adjuncts must be identical or the adjunct of the referent must be less specific than the antecedent.</S>
			<S sid ="79" ssid = "55">Table 1 lists the top performing heuristics of COCKTAIL for pronominal and nominal coreference.</S>
			<S sid ="80" ssid = "56">Examples of the heuristics operation on the MUC data are presented presented in Table 2.</S>
			<S sid ="81" ssid = "57">Details of the top performing heuris­ tics of COCKTAIL were reported in (Harabagiu and Maiorano, 1999).</S>
			<S sid ="82" ssid = "58">2.3 Bootstrapping for Coreference.</S>
			<S sid ="83" ssid = "59">Resolution One of the major drawbacks of existing corefer­ ence resolution systems is their inability to recog­ nize many forms of coreference displayed by many real-world texts.</S>
			<S sid ="84" ssid = "60">Recall measures of current systems range between 36% and 59% for both knowledge­ based and statistical techniques.</S>
			<S sid ="85" ssid = "61">Knowledge based­ systems would perform better if more coreference constraints were available whereas statistical meth­ ods would be improved if more annotated data were available.</S>
			<S sid ="86" ssid = "62">Since knowledge-based techniques out­ perform inductive methods, we used high-precision coreference heuristics as knowledge seeds for ma­ chine learning techniques that operate on large amounts of unlabeled data.</S>
			<S sid ="87" ssid = "63">One such technique is bootstrapping, which was recently presented in (Riloff and Jones 1999), (Jones et al.1999) as an ideal framework for text learning tasks that have knowledge seeds.</S>
			<S sid ="88" ssid = "64">The method does not require large training sets.</S>
			<S sid ="89" ssid = "65">We extended COCKTAIL by using meta­ bootstrapping of both new heuristics and clusters of nouns that display semantic consistency for corefer­ ence.</S>
			<S sid ="90" ssid = "66">The coreference heuristics are the seeds of our bootstrapping framework for coreference resolution.</S>
			<S sid ="91" ssid = "67">When applied to large collections of texts, the heuristics determine classes of coreferring expres­ sions.</S>
			<S sid ="92" ssid = "68">By generating coreference chains out of all these coreferring expressions, often new heuristics are uncovered.</S>
			<S sid ="93" ssid = "69">For example, Figure 2 illustrates the application of three heuristics and the generation of data for a new heuristic rule.</S>
			<S sid ="94" ssid = "70">In COCKTAIL, after a heuristic is applied, a new coreference chain is cal­ culated.</S>
			<S sid ="95" ssid = "71">For the example illustrated in Figure 2, if the reference of expression A is sought, heuristic Hl the FOIL-Gain measure, as introduced by the FOIL inductive algorithm (CameronJones and Quinlan 1993).</S>
			<S sid ="96" ssid = "72">Let H0 be the new heuristic and H1 a heuris­ tic that is already in the seed set.</S>
			<S sid ="97" ssid = "73">Let Po be the num­ ber of positive coreference examples of Hnew (i.e. the number of coreference relations produced by the heuristic that can be found in the test data) and n0 the number of negative examples of Hnew (i.e. the number of relations generated by the heuristic which cannot be found in the test data).</S>
			<S sid ="98" ssid = "74">Similarly, P1 and n1 are the positive and negative examples of H1 • The new heuristics are scored by their FOJL_Gain distance to the existing set of heuristics, and the best scoring one is added to the COCKTAIL system.</S>
			<S sid ="99" ssid = "75">The FOILGain formula is: FOILGain(H1,Ho) = k(log2 Pl log2 Po ) P1 + n1 Po+ no where k is the number of positive examples cov­ ered by both H1 and Ho.</S>
			<S sid ="100" ssid = "76">Heuristic Ho is added to the seed set if there is no other heuristic providing larger FOILGain to any of the seed heuristics.</S>
			<S sid ="101" ssid = "77">Figure 2: Bootstrapping new heuristics.</S>
			<S sid ="102" ssid = "78">Since in COCKTAIL, semantic consistency of core­ ferring expressions is checked by comparing the sim­ ilarity of noun classes, each new heuristic deter­ mines the adjustment of the similarity threshold of all known coreferring noun classes.</S>
			<S sid ="103" ssid = "79">The steps of the bootstrapping algorithm that learns both new heuristics and adjusts the similarity threshold of coreferential expressions is: MUTUAL BOOTSTRAPPING LOOP 1.</S>
			<S sid ="104" ssid = "80">Score all candidate heuristics with FOIL-.</S>
			<S sid ="105" ssid = "81">Gain 2.</S>
			<S sid ="106" ssid = "82">BesLh=closest candidate to.</S>
			<S sid ="107" ssid = "83">heuristics(COCKTAIL)</S>
	</SECTION>
	<SECTION title="Add BesLh to. " number = "3">
			<S sid ="108" ssid = "1">heuristics(COCKTAIL)</S>
	</SECTION>
	<SECTION title="Adjust semantic similarity threshold for. " number = "4">
			<S sid ="109" ssid = "1">semantic consistency of core/erring nouns</S>
	</SECTION>
	<SECTION title="Goto step 1 if the precision and recall did. " number = "5">
			<S sid ="110" ssid = "1">not degrade under minimal performance.</S>
			<S sid ="111" ssid = "2">indicates expression B to be the antecedent.</S>
			<S sid ="112" ssid = "3">When the coreference chain is built, expression A is di­ rectly linked to expression D, thus uncovering a new heuristic HO.</S>
			<S sid ="113" ssid = "4">As a rule of thumb, we do not consider a new heuristic unless there is massive evidence of its cov­ erage in the data.</S>
			<S sid ="114" ssid = "5">To measure the coverage we use (Riloff and Jones 1999) note that the bootstrap­ ping algorithm works well but its performance can deteriorate rapidly when non coreferring data enter as candidate heuristics.</S>
			<S sid ="115" ssid = "6">To make the algorithm more robust, a second level of bootstrapping can be intro­ duced.</S>
			<S sid ="116" ssid = "7">The outer bootstrapping mechanism, called metabootstrapping compiles the results of the inner (mutual) bootstrapping process and identifies the k most reliable heuristics, where k is a number de­ termined experimentally.</S>
			<S sid ="117" ssid = "8">These k heuristics are re­ tained and the rest of them are discarded.</S>
			<S sid ="118" ssid = "9">3 SWIZZLE.</S>
			<S sid ="119" ssid = "10">3.1 Multilingual Coreference Data.</S>
			<S sid ="120" ssid = "11">To study the performance of a data-driven multi­ lingual coreference resolution system, we prepared a corpus of Romanian texts by translating the MUC6 and MUC7 coreference training texts.</S>
			<S sid ="121" ssid = "12">The transla­ tions were performed by a group of four Romanian native speakers, and were checked for style by a cer­ tified translator from Romania.</S>
			<S sid ="122" ssid = "13">In addition, the Ro­ manian texts were annotated with coreference keys.</S>
			<S sid ="123" ssid = "14">Two rules were followed when the annotations were done: o1: Whenever an expression ER represents a trans­ lation of an expression EE from the corresponding English text, if EE is tagged as a coreference key with identification number ID, then the Romanian expression ER is also tagged with the same ID num­ ber.</S>
			<S sid ="124" ssid = "15">This rule allows for translations in which the textual position of the referent and the antecedent have been swapped.</S>
			<S sid ="125" ssid = "16">o2: Since the translations often introduce new coreferring expressions in the same chain, the new expressions are given new, unused ID numbers.</S>
			<S sid ="126" ssid = "17">For example, Table 3 lists corresponding English and Romanian fragments of coreference chains from the original MUC6 Wall Street Journal document DOCNO: 9307290143.</S>
			<S sid ="127" ssid = "18">Table 3 also shows the original MUC coreference SGML annotations.</S>
			<S sid ="128" ssid = "19">Whenever present, the REF tag indicates the ID of the antecedent, whereas the MIN tag indicates the minimal reference expression.</S>
			<S sid ="129" ssid = "20">3.2 Lexical Resources.</S>
			<S sid ="130" ssid = "21">The multilingual coreference resolution method im­ plemented in SWIZZLE incorporates the heuristics de­ rived from COKCTAIL&apos;s monolingual coreference res­ olution processing in both languages.</S>
			<S sid ="131" ssid = "22">To this end, COCKTAIL required both sets of texts to be tagged for part-of-speech and to recognize the noun phrases.</S>
			<S sid ="132" ssid = "23">The English texts were parsed with Brill&apos;s part-of­ speech tagger (Brill1992) and the noun phrases were identified by the grammar rules implemented in the phrasal parser of FASTUS (Appelt et al., 1993).</S>
			<S sid ="133" ssid = "24">Cor­ responding resources are not available in Romanian.</S>
			<S sid ="134" ssid = "25">To minimize COCKTAIL&apos;s configuration for process­ ing Romanian texts, we implemented a Romanian part-of-speech rule-based tagger that used the same Economic adviser Gene Sperling described &lt;COREF ID=&quot;29&quot; TYPE=&quot;IDENT&quot; REF=&quot;30&quot;&gt; it&lt; /COREF&gt; as &quot;a true full-court press&quot; to pass &lt;COREF ID=&quot;31&quot; TYPE=&quot;IDENT&quot; REF=&quot;26&quot; MIN=&quot;bill&quot;&gt;the &lt;COREF ID=&quot;32&quot; TYPE=&quot;IDENT&quot; REF=&quot;lO&quot; MIN=&quot;reduction&quot;&gt; &lt;COREF ID=&quot;33&quot; TYPE=&quot;IDENT&quot; REF=&quot;12&quot;&gt; deficit&lt; /COREF&gt;-reduction&lt; /COREF&gt; bill, the final version of which is now being hammered out by &lt;COREF ID=&quot;43&quot;&gt;House &lt; /COREF&gt; and &lt;COREF ID=&quot;41&quot; &gt;Senate &lt; JCOREF&gt;negotiators&lt; /COREF&gt;.</S>
			<S sid ="135" ssid = "26">&lt;COREF ID=&quot;34&quot; TYPE=&quot;IDENT&quot; REF=&quot;2&quot;&gt; The executives&lt; /COREF&gt;&apos; backing- however tepid - gives the administration a way to counter &lt;COREF ID=&quot;35&quot; TYPE=&quot;IDENT&quot; REF=&quot;36&quot;&gt; business&lt; /COREF&gt; critics of &lt;COREF ID=&quot;500&quot; TYPE=&quot;IDENT&quot; REF=&quot;31&quot; MIN=&quot;package&quot; STATUS=&quot;OPT&quot;&gt;the overall package &lt; JCOREF&gt;,...</S>
			<S sid ="136" ssid = "27">Consilierul cu probleme economice Gene Sperling a descris-&lt;COREF ID=&quot;29&quot; TYPE=&quot;IDENT&quot; REF=&quot;30&quot;&gt;o&lt; /COREF&gt; cape un efort de avengura menit sa promoveze &lt;COREF ID=&quot;1125&quot; TYPE=&quot;IDENT&quot; REF=&quot;26&quot; MIN=&quot;legea&quot;&gt;legea &lt; JCOREF&gt; pentru &lt;COREF TYPE=&quot;IDENT&quot; REF=&quot;10&quot; MIN=&quot;reducerea&quot; &gt; reducerea &lt; /COREF&gt;&lt;COREF ID=&quot;33&quot; TYPE=&quot;IDENT&quot; REF=&quot;12&quot;&gt; deficitului in bugetul SUA&lt; /COREF&gt;.</S>
			<S sid ="137" ssid = "28">Versiunea finala a acestei &lt;COREF ID=&quot;1126&quot; TYPE=&quot;IDENT&quot; REF=&quot;1125&quot; MIN=&quot;legi&quot;&gt;legi &lt; JCOREF&gt; este desfiin ata chiar in aceste zile in cadrul dezbaterilor ce au loc in &lt;COREF ID=&quot;43&quot; &gt;Camera Reprezentativilor &lt; /COREF&gt; §i in &lt;COREF ID=&quot; 41&quot; &gt; Senat&lt; /COREF&gt;&lt; /COREF&gt;.</S>
			<S sid ="138" ssid = "29">Sprijinirea &lt;COREF ID=&quot;127&quot; TYPE=&quot;IDENT&quot; REF=&quot;ll26&quot; MIN=&quot;legii&quot;&gt;legii&gt; /COREF&gt; de catre speciali§ti ineconomiede§i in maniera moderataofera administratiei o modalitate de a contrabalansa criticile aduse &lt;COREF ID=&quot;500&quot; TYPE=&quot;IDENT&quot; REF=&quot;31&quot; MIN=&quot;legii&quot; STATUS=&quot;OPT&quot;&gt;legii&lt; /COREF&gt; de catre companiile americane,...</S>
			<S sid ="139" ssid = "30">Table 3: Example of parallel English and Romanian text annotated for coreference.</S>
			<S sid ="140" ssid = "31">The elements from a coreference chain in the respective texts are under­ lined.</S>
			<S sid ="141" ssid = "32">The English text has only two elements in the coreference chain, whereas the Romanian text con­ tains four different elements.</S>
			<S sid ="142" ssid = "33">The two additional ele­ ments of the Romanian coreference chain are derived due to (1) the need to translate the relative clause from the English fragment into a separate sentence in Romanian; and (2) the reordering of words in the second sentence.</S>
			<S sid ="143" ssid = "34">146 tags as generated by the Brill tagger.</S>
			<S sid ="144" ssid = "35">In addition, we implemented rules that identify noun phrases in Romanian.</S>
			<S sid ="145" ssid = "36">To take advantage of the aligned corpus, SWIZZLE also relied on bilingual lexical resources that help translate the referential expressions.</S>
			<S sid ="146" ssid = "37">For this purpose, we used a core Romanian WordNet (Harabagiu, 1999) which encoded, wherever possi­ ble, links between the English synsets and their Ro­ manian counterparts.</S>
			<S sid ="147" ssid = "38">This resource also incorpo­ rated knowledge derived from several bilingual dic­ tionaries (e.g.</S>
			<S sid ="148" ssid = "39">(Banta§, 1969)).</S>
			<S sid ="149" ssid = "40">Having the parallel coreference annotations, we can easily identify their translations because they have the same identification coreference key.</S>
			<S sid ="150" ssid = "41">Look­ ing at the example given in Table 3, the expres­ sion &quot;legii&quot;, with ID=500 is the translation of the implemented, several other principles were applied.</S>
			<S sid ="151" ssid = "42">In our experiment, we were satisfied with the qual­ ity of the translations recognized by following only these two principles.</S>
			<S sid ="152" ssid = "43">3.3 Multilingual Coreference.</S>
			<S sid ="153" ssid = "44">Resolution The SWIZZLE system was run on a corpus of 2335 referential expressions in English (927 from MUC 6 and 1408 from MUC7) and 2851 Romanian ex­ pressions (1219 from MUC6 and 1632 from MUC 7).</S>
			<S sid ="154" ssid = "45">Initially, the heuristics implemented in COCKTAIL were applied separately to the two textual collec­ tions.</S>
			<S sid ="155" ssid = "46">Several special cases arose.</S>
			<S sid ="156" ssid = "47">English Text Romanian Text expression &quot;package&quot;, having the same ID in the English text.</S>
			<S sid ="157" ssid = "48">However, in the test set, the REF fields are intentionally voided, entrusting COCKTAIL to identify the antecedents.</S>
			<S sid ="158" ssid = "49">The bilingual corefer­ Reference &apos; &apos; ·- f«onre Translation ence resolution performed in SWIZZLE, however, re­ quires the translations of the English and Romanian antecedents.</S>
			<S sid ="159" ssid = "50">The principles guiding the translations of the English and Romanian antecedents (AE-R and ARE, respectively) are: • Circularity: Given an English antecedent, due to semantic ambiguity, it can belong to several English WordNet sysnsets.</S>
			<S sid ="160" ssid = "51">For each such sysnset Sf we con­ sider the Romanian corresponding sysnet(s) Sf.</S>
			<S sid ="161" ssid = "52">We filter out all Sf that do not contain AE-R.</S>
			<S sid ="162" ssid = "53">If only one Romanian sysnset is left, then we identified a translation.</S>
			<S sid ="163" ssid = "54">Otherwise, we start from the Roma­ nian antecedent, find all synsets Sf!</S>
			<S sid ="164" ssid = "55">to which it be­ longs, and obtain the corresponding English sysnets Sf.</S>
			<S sid ="165" ssid = "56">Similarly, all English synsets not containing the English antecedent are filtered out.</S>
			<S sid ="166" ssid = "57">If only one synset remains, we have again identified a transla­ tion.</S>
			<S sid ="167" ssid = "58">Finally, in the last case, the intersection of the multiple synsets in either language generates a legal translation.</S>
			<S sid ="168" ssid = "59">For example, the English synset sE ={bill, measure} translates into the Romanian synset sR ={lege}.</S>
			<S sid ="169" ssid = "60">First, none of the dictionary translations of bill into Romanian (e.g. politif., hac­ nota, afi§) translate back into any of the elements of sE.</S>
			<S sid ="170" ssid = "61">However the translation of measure into the Romanian lege translates back into bill, its synonym.</S>
			<S sid ="171" ssid = "62">• Semantic density: Given an English and a Roma­ nian antecedent, to establish whether they are trans­ lations of one another, we disambiguate them by first collapsing all sysnsets that have common elements.</S>
			<S sid ="172" ssid = "63">Then we apply the circularity principle, relying on the semantic alignment encoded in the Romanian WordNet.</S>
			<S sid ="173" ssid = "64">When this core lexical database was first Figure 3: Case 1 of multilingual coreference Case 1, which is the ideal case, is shown in Fig­ ure 3.</S>
			<S sid ="174" ssid = "65">It occurs when two referential expressions have antecedents that are translations of one an­ other.</S>
			<S sid ="175" ssid = "66">This situation occurred in 63.3% of the refer­ ential expressions from MUC6 and in 58.7% of the MUC7 references.</S>
			<S sid ="176" ssid = "67">Over 50% of these are pronouns or named entities.</S>
			<S sid ="177" ssid = "68">However, all the non-ideal cases are more interesting for SWIZZLE, since they port knowledge that enhances system performance.</S>
			<S sid ="178" ssid = "69">RA H4 R R Translation ER: English reference RR: Romanian reference EA: English antecedent RA: Romanian antecedent ET: English translation RT: Romanian translation of Romanian antecedent of English antecedent Figure 4: Case 2 of multilingual coreference Case 2 occurs when the antecedents are not trans­ lations, but belong to or corefer with elements of some coreference chains that were already estab­ lished.</S>
			<S sid ="179" ssid = "70">Moreover, one of the antecedents is textually 147 closer to its referent.</S>
			<S sid ="180" ssid = "71">Figure 4 illustrates the case when the English antecedent is closer to the referent than the Romanian one.</S>
			<S sid ="181" ssid = "72">SWIZZLE Solutions: (1) If the heuristic H(E) used to resolve the reference in the English text has higher priority than H(R), which was used to resolve the reference from the Romanian text, then we first search for RT, the Romanian translation of EA, the English antecedent.</S>
			<S sid ="182" ssid = "73">In the next step, we add heuris­ tic Hl that resolves RR into RT, and give it a higher priority than H(R).</S>
			<S sid ="183" ssid = "74">Finally, we also add heuristic H2 that links RT to RA when there is at least one trans­ lation between the elements of the coreference chains containing EA and ET respectively.</S>
			<S sid ="184" ssid = "75">(2) If H(R) has higher priority than H(E), heuris­ tic H3 is added while H(E) is removed.</S>
			<S sid ="185" ssid = "76">We also add H4 that relates ER to ET, the English translation of RA.</S>
			<S sid ="186" ssid = "77">Case 3 occurs when at least one of the antecedents starts a new coreference chain (i.e., no coreferring antecedent can be found in the current chains).</S>
			<S sid ="187" ssid = "78">SWIZZLE Solution: If one of the antecedents corefers with an element from a coreference chain, then the antecedent in the opposite language is its translation.</S>
			<S sid ="188" ssid = "79">Otherwise, SWIZZLE chooses the an­ tecedent returned by the heuristic with highest pri­ ority.</S>
			<S sid ="189" ssid = "80">4 Results.</S>
			<S sid ="190" ssid = "81">The foremost contribution of SWIZZLE was that it improved coreference resolution over both English and Romanian texts when compared to monolingual coreference resolution performance in terms of preci­ sion and recall.</S>
			<S sid ="191" ssid = "82">Also relevant was the contribution of SWIZZLE to the process of understanding the cultural differences expressed in language and the way these differences influence coreference resolution.</S>
			<S sid ="192" ssid = "83">Because we do not have sufficient space to discuss this issue in detail here, let us state, in short, that English is more economical than Romanian in terms of referen­ tial expressions.</S>
			<S sid ="193" ssid = "84">However the referential expressions in Romanian contribute to the resolution of some of the most difficult forms of coreference in English.</S>
			<S sid ="194" ssid = "85">4.1 Precision and Recall.</S>
			<S sid ="195" ssid = "86">Table 4 summarizes the precision results for both English and Romanian coreference.</S>
			<S sid ="196" ssid = "87">The results in­ dicate that the English coreference is more pre­ cise than the Romanian coreference, but SWIZZLE improves coreference resolution in both languages.</S>
			<S sid ="197" ssid = "88">There were 64% cases when the English coreference was resolved by a heuristic with higher priority than the corresponding heuristic for the Romanian coun terpart.</S>
			<S sid ="198" ssid = "89">This result explains why there is better pre­ cision enhancement for the English coreference.</S>
			<S sid ="199" ssid = "90">N o mi na l Pr on om ina l To tal E ng lis h 7 3 % 8 9 % 84 % R o m an ia n 6 6 % 7 8 % 72 % S W IZ Z L E on E ng lis h 7 6 % 9 3 % 87 % S W IZ Z L E on R o m an ia n 7 1 % 8 2 % 76 % Table 4: Coreference precision N o mi na l Pr on o mi nal To tal E ng lis h 6 9 % 8 9 78 % R o m an ia n 6 3 % 8 3 % 72 % S W IZ Z L E on E ng lis h 6 6 % 8 7 % 77 % S W IZ Z L E on R o m an ia n 6 1 % 8 0 % 70 % Table 5: Coreference recall Table 5 also illustrates the recall results.</S>
			<S sid ="200" ssid = "91">The advantage of the data-driven coreference resolution over other methods is based on its better recall per­ formance.</S>
			<S sid ="201" ssid = "92">This is explained by the fact that this method captures a larger variety of coreference pat­ terns.</S>
			<S sid ="202" ssid = "93">Even though other coreference resolution sys­ tems perform better for some specific forms of refer­ ence, their recall results are surpassed by the data­ driven approach.</S>
			<S sid ="203" ssid = "94">Multilingual coreference in turn improves more the precision than the recall of the monolingual data-driven coreference systems.</S>
			<S sid ="204" ssid = "95">In addition, Table 5 shows that the English coref­ erence results in better recall than Romanian coref­ erence.</S>
			<S sid ="205" ssid = "96">However, the recall shows a decrease for both languages for SWIZZLE because imprecise coreference links are deleted.</S>
			<S sid ="206" ssid = "97">As is usually the case, deleting data lowers the recall.</S>
			<S sid ="207" ssid = "98">All results were obtained by using the automatic scorer program developed for the MUC evaluations.</S>
			<S sid ="208" ssid = "99">5 Conclusions.</S>
			<S sid ="209" ssid = "100">We have introduced a new data-driven method for multilingual coreference resolution, implemented in the SWIZZLE system.</S>
			<S sid ="210" ssid = "101">The results of this method are encouraging since they show clear improvements over monolingual coreference resolution.</S>
			<S sid ="211" ssid = "102">Currently, we are also considering the effects of a bootstrap­ ping algorithm for multilingual coreference resolu­ tion.</S>
			<S sid ="212" ssid = "103">Through this procedure we would learn con­ currently semantic consistency knowledge and bet­ ter performing heuristic rules.</S>
			<S sid ="213" ssid = "104">To be able to de­ velop such a learning approach, we must first develop a method for automatic recognition of multilingual referential expressions.</S>
			<S sid ="214" ssid = "105">148 We also believe that a better performance evalu­ ation of SWIZZLE can be achieved by measuring its impact on several complex applications.</S>
			<S sid ="215" ssid = "106">We intend to analyze the performance of SWIZZLE when it is used as a module in an IE system, and separately in a Question/ Answering system.</S>
			<S sid ="216" ssid = "107">Acknowledgements This paper is dedicated to the memory of our friend Megumi Kameyama, who in­ spired this work.</S>
	</SECTION>
</PAPER>
