Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 70?74,
Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational Linguistics
Conversion of Procedural Morphologies to Finite-State Morphologies: a
Case Study of Arabic
Mans Hulden
University of the Basque Country
IXA Group
IKERBASQUE, Basque Foundation for Science
mhulden@email.arizona.edu
Younes Samih
Heinrich-Heine-Universita?t Du?sseldorf
samih@phil.uni-duesseldorf.de
Abstract
In this paper we describe a conversion of
the Buckwalter Morphological Analyzer for
Arabic, originally written as a Perl-script,
into a pure finite-state morphological ana-
lyzer. Representing a morphological ana-
lyzer as a finite-state transducer (FST) con-
fers many advantages over running a procedu-
ral affix-matching algorithm. Apart from ap-
plication speed, an FST representation imme-
diately offers various possibilities to flexibly
modify a grammar. In the case of Arabic, this
is illustrated through the addition of the abil-
ity to correctly parse partially vocalized forms
without overgeneration, something not possi-
ble in the original analyzer, as well as to serve
both as an analyzer and a generator.
1 Introduction
Many lexicon-driven morphological analysis sys-
tems rely on a general strategy of breaking down
input words into constituent parts by consulting cus-
tomized lexicons and rules designed for a particu-
lar language. The constraints imposed by the lex-
ica designed are then implemented as program code
that handles co-occurrence restrictions and analysis
of possible orthographic variants, finally producing
a parse of the input word. Some systems designed
along these lines are meant for general use, such as
the hunspell tool (Hala?csy et al, 2004) which allows
users to specify lexicons and constraints, while oth-
ers are language-dependent, such as the Buckwalter
Arabic Morphological Analyzer (BAMA) (Buckwal-
ter, 2004).
In this paper we examine the possibility of con-
verting such morphological analysis tools to FSTs
that perform the same task. As a case study, we have
chosen to implement a one-to-one faithful conver-
sion of the Buckwalter Arabic analyzer into a finite-
state representation using the foma finite state com-
piler (Hulden, 2009b), while also adding some ex-
tensions to the original analyzer. These are useful
extensions which are difficult to add to the original
Perl-based analyzer because of its procedural nature,
but very straightforward to perform in a finite-state
environment using standard design techniques.
There are several advantages to representing mor-
phological analyzers as FSTs, as is well noted in the
literature. Here, in addition to documenting the con-
version, we shall also discuss and give examples of
the flexibility, extensibility, and speed of application
which results from using a finite-state representation
of a morphology.1
2 The Buckwalter Analyzer
Without going into an extensive linguistic discus-
sion, we shall briefly describe the widely used Buck-
walter morphological analyzer for Arabic. The
BAMA accepts as input Arabic words, with or with-
out vocalization, and produces as output a break-
down of the affixes participating in the word, the
stem, together with information about conjugation
classes. For example, for the input word ktb/I. J?,
BAMA returns, among others:
LOOK-UP WORD: ktb
SOLUTION 1: (kataba) [katab-u_1]
katab/VERB_PERFECT
+a/PVSUFF_SUBJ:3MS
(GLOSS): + write + he/it <verb>
1The complete code and analyzer are available at
http://buckwalter-fst.googlecode.com/
70
Figure 1: The Buckwalter Arabic Morphological Analyzer?s lookup process exemplified for the word lilkitAbi.
2.1 BAMA lookup
In the BAMA system, every Arabic word is assumed
to consist of a sometimes optional prefix, an oblig-
atory stem, and a sometimes optional suffix.2 The
system for analysis is performed by a Perl-script that
carries out the following tasks:
1. Strips all diacritics (vowels) from the input
word (since Arabic words may contain vocal-
ization marks which are not included in the lex-
icon lookup). Example: kataba? ktb
2. Factors the input word into all possible
combinations of prefix-stem-suffix. Stems
may not be empty, while affixes are optional.
Example: ktb ? { <k,t,b>,< kt,b,?>,
<k,tb,?>, <?,k,tb>, <?,kt,b>,
<?,ktb,?> }.
3. Consults three lexicons (dictPrefixes, dict-
Stems, dictSuffixes) for ruling out impossi-
ble divisions. For example, <kt,b,?>, is
rejected since kt does not appear as a prefix
in dictPrefixes, while <k,tb,?> is accepted
since k appears in dictPrefixes, tb in dict-
Stems, and ? in dictSuffixes.
4. Consults three co-occurrence constraint lists
for further ruling out incompatible prefix-
stem combinations, stem-suffix combinations,
and prefix-suffix combinations. For example,
2In reality, these are often conjoined prefixes treated as a
single entry within the system.
<k,tb,?>, while accepted in the previous
step, is now rejected because the file dict-
Prefixes lists k as a prefix belonging to class
NPref-Bi, and the stem tb belonging to one of
PV V, IV V, NF, PV C, or IV C. However,
the compatibility file tableAB does not permit
a combination of prefix class NPref-Bi and any
of the above-mentioned stem classes.
5. In the event that the lookup fails, the analyzer
considers various alternative spellings of the in-
put word, and runs through the same steps us-
ing the alternate spellings.
The BAMA lookup process is illustrated using a
different example in figure 1.
3 Conversion
Our goal in the conversion of the Perl-code and the
lookup tables is to produce a single transducer that
maps input words directly to their morphological
analysis, including class and gloss information. In
order to do this, we break the process down into
three major steps:
(1) We construct a transducer Lexicon that ac-
cepts on its output side strings consisting of
any combinations of fully vocalized prefixes,
stems, and suffixes listed in dictPrefixes, dict-
Stems, and dictSuffixes. On the input side,
we find a string that represents the class each
morpheme on the output side corresponds to,
as well as the line number in the correspond-
71
LEXICON Root
Prefixes ;
LEXICON Prefixes
[Pref-%0]{P%:34}:0 Stems;
[Pref-Wa]{P%:37}:wa Stems;
...
LEXICON Stems
[Nprop]{S%:23}:|b Suffixes;
[Nprop]{S%:27}:%<ib? Suffixes;
...
LEXICON Suffixes
[Suff-%0]{X%:34}:0 #;
[CVSuff-o]{X%:37}:o #;
...
Figure 2: Skeleton of basic lexicon transducer in LEXC
generated from BAMA lexicons.
ing file where the morpheme appears. For ex-
ample, the Lexicon transducer would contain
the mapping:
[Pref-0]{P:34}[PV]{S:102658}[NSuff-a]{X:72}
kataba
indicating that for the surface form
kataba/ I.
J?, the prefix class is Pref-0
appearing on line 34 in the file dictPrefixes,
the stem class is PV, appearing on line
102,658 in dictStems, and that the suffix
class is NSuff-a, appearing on line 72 in
dictSuffixes.
To construct the Lexicon, we produced a
Perl-script that reads the contents of the BAMA
files and automatically constructs a LEXC-
format file (Beesley and Karttunen, 2003),
which is compiled with foma into a finite trans-
ducer (see figure 2).
(2) We construct rule transducers that filter out im-
possible combinations of prefix classes based
on the data in the constraint tables tableAB,
tableBC, and tableAC. We then iteratively
compose the Lexicon transducer with each
rule transducer. This is achieved by converting
each suffix class mentioned in each of the class
files to a constraint rule, which is compiled
into a finite automaton. For example, the file
tableBC, which lists co-occurrence constraints
between stems and suffixes contains only the
following lines beginning with Nhy:
Nhy NSuff-h
Nhy NSuff-iy
indicating that the Nhy-class only combines
with Nsuff-h or Nsuff-iy. These lines are
converted by our script into the constraint re-
striction regular expression:
def Rule193 "[Nhy]" => _ ?*
"[NSuff-h]"|"[NSuff-iy]"];
This in effect defines the language where each
instance [Nhy] is always followed some-
time later in the string by either [NSuff-h],
or [NSuff-iy]. By composing this, and
the other constraints, with the Lexicon-
transducer, we can filter out all illegitimate
combinations of morphemes as dictated by the
original Buckwalter files, by calculating:
def Grammar Lexicon.i .o.
Rule1 .o.
...
RuleNNN ;
In this step, it is crucial to note that one cannot
in practice build a separate, single transducer
(or automaton) that models the intersection of
all the lexicon constraints, i.e. Rule1 .o.
Rule2 .o. ... RuleNNN, and then
compose that transducer with the Lexicon
transducer. The reason for this is that the
size of the intersection of all co-occurrence
rules grows exponentially with each rule. To
avoid this intermediate exponential size, the
Lexicon transducer must be composed with
the first rule, whose composition is then com-
posed with the second rule, etc., as above.
(3) As the previous two steps leave us with a trans-
ducer that accepts only legitimate combina-
tions of fully vocalized prefixes, stems, and
suffixes, we proceed to optionally remove short
vowel diacritics as well as perform optional
normalization of the letter Alif ( @) from the
72
output side of the transducer. This means,
for instance, that an intermediate kataba/ I.
J?,
would be mapped to the surface forms kataba,
katab, katba, katb, ktaba, ktab, ktba, and
ktb. This last step assures that we can
parse partially vocalized forms, fully vocal-
ized forms, completely unvocalized forms, and
common variants of Alif.
def RemoveShortVowels
[a|u|i|o|%?|%?] (->) 0;
def NormalizeAlif
["|"|"<"|">"] (->) A .o.
"{" (->) [A|"<"] ;
def RemovefatHatAn [F|K|N] -> 0;
def BAMA 0 <- %{|%} .o.
Grammar .o.
RemoveShortVowels .o.
NormalizeAlif .o.
RemovefatHatAn;
4 Results
Converting the entire BAMA grammar as described
above produces a final FST of 855,267 states and
1,907,978 arcs, which accepts 14,563,985,397 Ara-
bic surface forms. The transducer occupies 8.5Mb.
An optional auxiliary transducer for mapping line
numbers to complete long glosses and class names
occupies an additional 10.5 Mb. This is slightly
more than the original BAMA files which occupy
4.0Mb. However, having a FST representation of
the grammar provides us with a number of advan-
tages not available in the original BAMA, some of
which we will briefly discuss.
4.1 Orthographical variants
The original BAMA deals with spelling variants and
substandard spelling by performing Perl-regex re-
placements to the input string if lookup fails. In the
BAMA documentation, we find replacements such
as:
- word final Y? should be y?
- word final Y? should be }
- word final y? should be }
In a finite-state system, once the grammar is con-
verted, we can easily build such search heuristics
into the FST itself using phonological replacement
rules and various composition strategies such as pri-
ority union (Kaplan, 1987). We can thus mimic the
behavior of the BAMA, albeit without incurring any
extra lookup time.
4.2 Vocalization
As noted above, by constructing the analyzer from
the fully vocalized forms and then optionally remov-
ing vowels in surface variants allows us to more ac-
curately parse partially vocalized Arabic forms. We
thus rectify one of the drawbacks of the original
BAMA, which makes no use of vocalization informa-
tion even when it is provided. For example, given an
input word qabol, BAMA would as a first step strip
off all the vocalization marks, producing qbl. Dur-
ing the parsing process, BAMA could then match qbl
with, for instance, qibal, an entirely different word,
even though vowels were indicated. The FST de-
sign addresses this problem elegantly: if the input
word is qabol, it will never match qibal because the
vocalized morphemes are used throughout the con-
struction of the FST and only optionally removed
from the surface forms, whereas BAMA used the un-
vocalized forms to match input. This behavior is in
line with other finite-state implementations of Ara-
bic, such as Beesley (1996), where diacritics, if they
happen to be present, are taken advantage of in order
to disambiguate and rule out illegitimate parses.
This is of practical importance when parsing Ara-
bic as writers often partially disambiguate words
depending on context. For example, the word
Hsbt/ I.?kis ambiguous (Hasabat = compute,
charge; Hasibat = regard, consider). One would
partially vocalize Hsbt as Hsibt to denote ?she
regards?, or as Hsabt to imply ?she computes.?
The FST-based system correctly narrows down the
parses accordingly, while BAMA would produce all
ambiguities regardless of the vocalization in the in-
put.
4.3 Surface lexicon extraction
Having the BAMA represented as a FST also al-
lows us to extract the output projection of the gram-
mar, producing an automaton that only accepts le-
gitimate words in Arabic. This can be then be
used in spell checking applications, for example,
by integrating the lexicon with weighted transduc-
73
ers reflecting frequency information and error mod-
els (Hulden, 2009a; Pirinen et al, 2010).
4.4 Constraint analysis
Interestingly, the BAMA itself contains a vast
amount of redundant information in the co-
occurrence constraints. That is, some suffix-stem-
lexicon constraints are entirely subsumed by other
constraints and could be removed without affecting
the overall system. This can be observed during the
chain of composition of the various transducers rep-
resenting lexicon constraints. If a constraint X fails
to remove any words from the lexicon?something
that can be ascertained by noting that the number
of paths through the new transducer is the same as
in the transducer before composition?it is an indi-
cation that a previous constraint Y has already sub-
sumed X . In short, the constraint X is redundant.
The original grammar cannot be consistently ana-
lyzed for redundancies as it stands. However, redun-
dant constraints can be detected when compiling the
Lexicon FST together with the set of rules, offer-
ing a way to streamline the original grammar.
5 Conclusion
We have shown a method for converting the table-
based and producedural constraint-driven Buckwal-
ter Arabic Morphological Analyzer into an equiva-
lent finite-state transducer. By doing so, we can take
advantage of established finite-state methods to pro-
vide faster and more flexible parsing and also use the
finite-state calculus to produce derivative applica-
tions that were not possible using the original table-
driven Perl parser, such as spell checkers, normaliz-
ers, etc. The finite-state transducer implementation
also allows us to parse words with any vocalization
without sacrificing accuracy.
While the conversion method in this case is spe-
cific to the BAMA, the general principle illustrated
in this paper can be applied to many other procedu-
ral morphologies that rule out morphological parses
by first consulting a base lexicon and subsequently
applying a batch of serial or parallel constraints over
affix occurrence.
References
Attia, M., Pecina, P., Toral, A., Tounsi, L., and
van Genabith, J. (2011). An open-source finite
state morphological transducer for modern stan-
dard Arabic. In Proceedings of the 9th Interna-
tional Workshop on Finite State Methods and Nat-
ural Language Processing, pages 125?133. Asso-
ciation for Computational Linguistics.
Beesley, K. R. (1996). Arabic finite-state morpho-
logical analysis and generation. In Proceedings
of COLING?96?Volume 1, pages 89?94. Associ-
ation for Computational Linguistics.
Beesley, K. R. and Karttunen, L. (2003). Finite State
Morphology. CSLI Publications, Stanford, CA.
Buckwalter, T. (2004). Arabic Morphological Ana-
lyzer 2.0. Linguistics Data Consortium (LDC).
Habash, N. (2010). Introduction to Arabic natural
language processing. Synthesis Lectures on Hu-
man Language Technologies.
Hala?csy, P., Kornai, A., Ne?meth, L., Rung, A., Sza-
kada?t, I., and Tro?n, V. (2004). Creating open lan-
guage resources for Hungarian. In Proceedings of
Language Resources and Evaluation Conference
(LREC04). European Language Resources Asso-
ciation.
Hulden, M. (2009a). Fast approximate string match-
ing with finite automata. Procesamiento del
lenguaje natural, 43:57?64.
Hulden, M. (2009b). Foma: a finite-state compiler
and library. In Proceedings of the 12th confer-
ence of the European Chapter of the Association
for Computational Linguistics,, pages 29?32. As-
sociation for Computational Linguistics.
Kaplan, R. M. (1987). Three seductions of computa-
tional psycholinguistics. In Whitelock, P., Wood,
M. M., Somers, H. L., Johnson, R., and Bennett,
P., editors, Linguistic Theory and Computer Ap-
plications, London. Academic Press.
Pirinen, T., Linde?n, K., et al (2010). Finite-state
spell-checking with weighted language and error
models. In Proceedings of LREC 2010 Workshop
on creation and use of basic lexical resources for
less-resourced languages.
74
