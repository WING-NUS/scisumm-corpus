Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 311?321,
Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational Linguistics
Exploring Representations from Unlabeled Data with Co-training
for Chinese Word Segmentation
Longkai Zhang Houfeng Wang? Xu Sun Mairgup Mansur
Key Laboratory of Computational Linguistics (Peking University) Ministry of Education, China
zhlongk@qq.com, wanghf@pku.edu.cn, xusun@pku.edu.cn, mairgup@gmail.com,
Abstract
Nowadays supervised sequence labeling
models can reach competitive performance
on the task of Chinese word segmenta-
tion. However, the ability of these mod-
els is restricted by the availability of an-
notated data and the design of features.
We propose a scalable semi-supervised fea-
ture engineering approach. In contrast
to previous works using pre-defined task-
specific features with fixed values, we dy-
namically extract representations of label
distributions from both an in-domain cor-
pus and an out-of-domain corpus. We
update the representation values with a
semi-supervised approach. Experiments
on the benchmark datasets show that our
approach achieve good results and reach
an f-score of 0.961. The feature engineer-
ing approach proposed here is a general
iterative semi-supervised method and not
limited to the word segmentation task.
1 Introduction
Chinese is a language without natural word
delimiters. Therefore, Chinese Word Segmen-
tation (CWS) is an essential task required by
further language processing. Previous research
shows that sequence labeling models trained on
labeled data can reach competitive accuracy on
the CWS task, and supervised models are more
accurate than unsupervised models (Xue, 2003;
Low et al, 2005). However, the resource of man-
ually labeled training corpora is limited. There-
fore, semi-supervised learning has become one
?Corresponding author
of the most natural forms of training for CWS.
Traditional semi-supervised methods focus on
adding new unlabeled instances to the training
set by a given criterion. The possible mislabeled
instances, which are introduced from the auto-
matically labeled raw data, can hurt the per-
formance and not easy to exclude by setting a
sound selecting criterion.
In this paper, we propose a simple and scal-
able semi-supervised strategy that works by pro-
viding semi-supervision at the level of represen-
tation. Previous works mainly assume that con-
text features are helpful to decide the potential
label of a character. However, when some of the
context features do not appear in the training
corpus, this assumption may fail. An example is
shown in table 1. Although the context of ???
and ??? is totally different, they share a homo-
geneous structure as ?verb-noun?. Therefore. A
much better way is to map the context informa-
tion to a kind of representation. More precisely,
the mapping should let the similar contexts map
to similar representations, while let the distinct
contexts map to distinct representations.
??? ???
Label B B
Character ? ? ? ? ? ?
Context C-1= ? C-1= ?
Features C0= ? C0= ?
C1= ? C1= ?
Table 1: Example of the context of ??? in ???
? (Eat fruits)? and the context of ??? in ????
(Play basketball)?
We use the label distribution information that
311
is extracted from the unlabeled corpus as this
representation to enhance the supervised model.
We add ?pseudo-labels? by tagging the unla-
beled data with the trained model on the train-
ing corpus. These ?pseudo-labels? are not accu-
rate enough. Therefore, we use the label distri-
bution, which is much more accurate.
To accurately calculate the precise label dis-
tribution, we use a framework similar to the co-
training algorithm to adjust the feature values
iteratively. Generally speaking, unlabeled data
can be classified as in-domain data and out-of-
domain data. In previous works these two kinds
of unlabeled data are used separately for differ-
ent purposes. In-domain data is mainly used to
solve the problem of data sparseness (Sun and
Xu, 2011). On the other hand, out-of domain
data is used for domain adaptation (Chang and
Han, 2010). In our work, we use in-domain and
out-of-domain data together to adjust the labels
of the unlabeled corpus.
We evaluate the performance of CWS on the
benchmark dataset of Peking University in the
second International Chinese Word Segmenta-
tion Bakeoff. Experiment results show that our
approach yields improvements compared with
the state-of-art systems. Even when the la-
beled data is insufficient, our methods can still
work better than traditional methods. Com-
pared to the baseline CWS model, which has
already achieved an f-score above 0.95, we fur-
ther reduce the error rate by 15%.
Our method is not limited to word segmen-
tation. It is also applicable to other problems
which can be solved by sequence labeling mod-
els. We also applied our method to the Chi-
nese Named Entity Recognition task, and also
achieved better results compared to traditional
methods.
The main contributions of our work are as fol-
lows:
? We proposed a general method to utilize
the label distribution given text contexts as
representations in a semi-supervised frame-
work. We let the co-training process ad-
just the representation values from label
distribution instead of using manually pre-
defined feature templates.
? Compared with previous work, our method
achieved a new state-of-art accuracy on the
CWS task as well as on the NER task.
The remaining part of this paper is organized
as follows. Section 2 describes the details of the
problem and our algorithm. Section 3 describes
the experiment and presents the results. Section
4 reviews the related work. Section 5 concludes
this paper.
2 System Architecture
2.1 Sequence Labeling
Nowadays the character-based sequence label-
ing approach is widely used for the Chinese word
segmentation problem. It was first proposed in
Xue (2003), which assigns each character a label
to indicate its position in the word. The most
prevalent tag set is the BMES tag set, which
uses 4 tags to carry word boundary information.
This tag set uses B, M, E and S to represent the
Beginning, the Middle, the End of a word and
a Single character forming a word respectively.
We use this tag set in our method. An example
of the ?BMES? representation is shown in table
2.
Character: ? ? ? ? ? ? ?
Tag: S S B E B M E
Table 2: An example for the ?BMES? representa-
tion. The sentence is ????????? (I love Bei-
jing Tian-an-men square), which consists of 4 Chi-
nese words: ??? (I), ??? (love), ???? (Beijing),
and ????? (Tian-an-men square).
2.2 Unlabeled Data
Unlabeled data can be divided into in-domain
data and out-of-domain data. In previous works,
these two kinds of unlabeled data are used sep-
arately for different purposes. In-domain data
only solves the problem of data sparseness (Sun
and Xu, 2011). Out-of domain data is used
only for domain adaptation (Chang and Han,
2010). These two functionalities are not contra-
dictory but complementary. Our study shows
312
that by correctly designing features and algo-
rithms, both in-domain unlabeled data and out-
of-domain unlabeled data can work together to
help enhancing the segmentation model. In our
algorithm, the dynamic features learned from
one corpus can be adjusted incrementally with
the dynamic features learned from the other cor-
pus.
As for the out-of-domain data, it will be even
better if the corpus is not limited to a specific
domain. We choose a Chinese encyclopedia cor-
pus which meets exactly this requirement. We
use the corpus to learn a large set of informative
features. In our experiment, two different views
of features on unlabeled data are considered:
Static Statistical Features (SSFs): These
features capture statistical information of char-
acters and character n-grams from the unlabeled
corpus. The values of these features are fixed
during the training process once the unlabeled
corpus is given.
Dynamic Statistical Features (DSFs):
These features capture label distribution infor-
mation from the unlabeled corpus given fixed
text contexts. As the training process proceeds,
the value of these features will change, since the
trained tagger at each training iteration may as-
sign different labels to the unlabeled data.
2.3 Framework
Suppose we have labeled data L, two unla-
beled corpora Ua and Ub (one is an in-domain
corpus and the other is an out-of-domain cor-
pus). Our algorithm is shown in Table 3.
During each iteration, we tag the unlabeled
corpus Ua using Tb to get pseudo-labels. Then
we extract features from the pseudo-labels. We
use the label distribution information as dy-
namic features. We add these features to the
training data to train a new tagger Ta. To adjust
the feature values, we extract features from one
corpus and then apply the statistics to the other
corpus. This is similar to the principle of co-
training (Yarowsky, 1995; Blum and Mitchell,
1998; Dasgupta et al, 2002). The difference is
that there are not different views of features, but
different kinds of unlabeled data. Detailed de-
scription of features is given in the next section.
Algorithm
Init:
Using baseline features only:
Train an initial tagger T0 based on L ()
Label Ua and Ub individually using T0
BEGIN LOOP:
Generate DSFs from tagged Ua
Augment L with DSFs to get La
Generate DSFs from tagged Ub
Augment L with DSFs to get Lb
Using baseline features, SSFs and DSFs:
Train new tagger Ta using La
Train new tagger Tb using Lb
Label Ua using Tb
Label Ub using Ta
LOOP until performance does not improve
RETURN the tagger which is trained with
in-domain features.
Table 3: Algorithm description
2.4 Features
2.4.1 Baseline Features
Our baseline feature templates include the
features described in previous works (Sun and
Xu, 2011; Sun et al, 2012). These features are
widely used in the CWS task. To be convenient,
for a character ci with context . . . ci?1cici+1 . . .,
its baseline features are listed below:
? Character uni-grams: ck (i? 3 < k < i+3)
? Character bi-grams: ckck+1 (i ? 3 < k <
i+ 2)
? Whether ck and ck+1 are identical (i? 2 <
k < i + 2)
? Whether ck and ck+2 are identical (i? 4 <
k < i + 2)
The last two feature templates are designed to
detect character reduplication, which is a mor-
phological phenomenon in Chinese language.
An example is ?????? (Perfect), which is
a Chinese idiom with structure ?ABAC?.
313
2.4.2 Static statistical features
Statistical features are statistics that distilled
from the large unlabeled corpus. They are
proved useful in the Chinese word segmenta-
tion task. We define Static Statistical Features
(SSFs) as features whose value do not change
during the training process. The SSFs in our
approach includes Mutual information, Punctu-
ation information and Accessor variety. Previ-
ous works have already explored the functions
of the three static statistics in the Chinese word
segmentation task, e.g. Feng et al (2004); Sun
and Xu (2011). We mainly follow their defini-
tions while considering more details and giving
some modification.
Mutual information
Mutual information (MI) is a quantity that
measures the mutual dependence of two random
variables. Previous works showed that larger MI
of two strings claims higher probability that the
two strings should be combined. Therefore, MI
can show the tendency of two strings forming
one word. However, previous works mainly fo-
cused on the balanced case, i.e., the MI of strings
with the same length. In our study we find that,
in Chinese, there remains large amount of imbal-
anced cases, like a string with length 1 followed
by a string with length 2, and vice versa. We
further considered the MI of these string pairs
to capture more information.
Punctuation information
Punctuations can provide implicit labels for
the characters before and after them. The char-
acter after punctuations must be the first char-
acter of a word. The character before punctua-
tions must be the last character of a word. When
a string appears frequently after punctuations,
it tends to be the beginning of a word. The situ-
ation is similar when a string appears frequently
preceding punctuations. Besides, the probabil-
ity of a string appears in the corpus also affects
this tendency. Considering all these factors,
we propose ?punctuation rate? (PR) to capture
this information. For a string with length len
and probability p in the corpus, we define the
left punctuation rate LPRlen as the number of
times the string appears after punctuations, di-
vided by p. Similarly, the right punctuation
rate RPRlen is defines as the number of times
it appears preceding punctuations divided by its
probability p. The length of string we consider
is from 1 to 4.
Accessor variety
Accessor variety (AV) is also known as letter
successor variety (LSV) (Harris, 1955; Hafer and
Weiss, 1974). If a string appears after or pre-
ceding many different characters, this may pro-
vide some information of the string itself. Pre-
vious work of Feng et al (2004), Sun and Xu
(2011) used AV to represent this statistic. Sim-
ilar to punctuation rate, we also consider both
left AV and right AV. For a string s with length
l, we define the left accessor variety (LAV) as
the types of distinct characters preceding s in
the corpus, and the right accessor variety (RAV)
as the types of distinct characters after s in the
corpus. The length of string we consider is also
from 1 to 4.
2.4.3 Dynamic statistical features
The unlabeled corpus lacks precise labels. We
can use the trained tagger to give the unla-
beled data ?pseudo-labels?. These labels can-
not guarantee an acceptable precision. How-
ever, the label distribution will not be largely
affected by small mistakes. Using the label dis-
tribution information is more accurate than us-
ing the pseudo-labels directly.
Based on this assumption, we propose ?dy-
namic statistical features? (DSFs). The DSFs
are intended to capture label distribution infor-
mation given a text context. The word ?Dy-
namic? is in accordance with the fact that these
feature values will change during the training
process.
We give a formal description of DSFs. Sup-
pose there are K labels in our task. For example,
K = 4 if we take BMES labeling method. We
define the whole character sequence with length
n as X = (x1, x2 ? ? ?xj ? ? ?xn). Given a text con-
text Ci, where i is current character position,
the DSFs can be represented as a list,
DSF (Ci) = (DSF (Ci)1, ? ? ? , DSF (Ci)K)
314
Each element in the list represents the proba-
bility of the corresponding label in the distribu-
tion.
For convenience, we further define function
?count(condition)? as the total number of times
a ?condition? is true in the unlabeled corpus.
For example, count (current=?a?) represents the
times the current character equals ?a?, which is
exactly the number of times character ?a? ap-
pears in the unlabeled corpus.
According to different types of text context
Ci, we can divide DSFs into 3 types:
1.Basic DSF
For Basic DSF of Ci, we define D(Ci):
D(Ci) = (D(Ci)1, . . . , D(Ci)K)
We define Basic DSF with current character po-
sition i, text context Ci and label l (the lth di-
mension in the list) as:
D(Ci)l = P (y = l|Ci = xi)
= count(Ci = xi ? y = l)count(Ci = xi)
In this equation, the numerator counts the num-
ber of times current character is xi with label l.
The denominator counts the number of times
current character is xi.
We use the term ?Basic? because this kind of
DSFs only considers the character of position i
as its context. The text context refers to the cur-
rent character itself. This feature captures the
label distribution information given the charac-
ter itself.
2.BigramDSF
Basic DSF is simple and very easy to imple-
ment. The weakness is that it is less power-
ful to describe word-building features. Although
characters convey context information, charac-
ters themselves in Chinese is sometimes mean-
ingless. Character bi-grams can carry more con-
text information than uni-grams. We modify
Basic DSFs to bi-gram level and propose Bigram
DSFs.
For Bigram DSF of Ci, we define B(Ci):
B(Ci) = (B(Ci)1, . . . , B(Ci)K)
We define Bigram DSF with current character
position i, text context Ci and label l (the lth
dimension in the list) as:
B(Ci)l = P (y = l|Ci = xi?jxi?j+1)
= count(Ci = xi?jxi?j+1 ? y = l)count(Ci = xi?jxi?j+1)
j can take value 0 and 1.
In this equation, the numerator counts the
number of times current context is xi?jxi?j+1
with label l. The denominator counts the num-
ber of times current context is xi?jxi?j+1.
3.WindowDSF
Considering Basic DSF and Bigram DSF only
might cause the over-fitting problem, therefore
we introduce another kind of DSF. We call it
Window DSF, which considers the surrounding
context of a character and omits the character
itself.
For Window DSF, we define W (Ci):
W (Ci) = (W (Ci)1, . . . ,W (Ci)K)
We define Window DSF with current character
position i, text context Ci and label l (the lth
dimension in the list) as:
W (Ci)l = P (y = l|Ci = xi?1xi+1)
= count(Ci = xi?1xi+1 ? y = l)count(Ci = xi?1xi+1)
In this equation, the numerator counts the
number of times current context is xi?1xi+1
with label l. The denominator counts the num-
ber of times current context is xi?1xi+1.
2.4.4 Discrete features VS. Continuous
features
The statistical features may be expressed as
real values. A more natural way is to use dis-
crete values to incorporate them into the se-
quence labeling models . Previous works like
Sun and Xu (2011) solve this problem by set-
ting thresholds and converting the real value
into boolean values. We use a different method
to solve this, which does not need to consider
tuning thresholds. In our method, we process
static and dynamic statistical features using dif-
ferent strategies.
315
For static statistical value:
For mutual information, we round the real
value to their nearest integer. For punctuation
rate and accessor variety, as the values tend to
be large, we first get the log value of the feature
and then use the nearest integer as the corre-
sponding discrete value.
For dynamic statistical value:
Dynamic statistical features are distributions
of a label. The values of DSFs are all percentage
values. We can solve this by multiply the proba-
bility by an integer N and then take the integer
part as the final feature value. We set the value
of N by cross-validation..
2.5 Conditional Random Fields
Our algorithm is not necessarily limited to
a specific baseline tagger. For simplicity and
reliability, we use a simple Conditional Ran-
dom Field (CRF) tagger, although other se-
quence labeling models like Semi-Markov CRF
Gao et al (2007) and Latent-variable CRF Sun
et al (2009) may provide better results than
a single CRF. Detailed definition of CRF can
be found in Lafferty et al (2001); McCallum
(2002); Pinto et al (2003).
3 Experiment
3.1 Data and metrics
We used the benchmark datasets provided by
the second International Chinese Word Segmen-
tation Bakeoff1 to test our approach. We chose
the Peking University (PKU) data in our exper-
iment. Although the benchmark provides an-
other three data sets, two of them are data of
traditional Chinese, which is quite different from
simplified Chinese. Another is the data from Mi-
crosoft Research (MSR). We experimented on
this data and got 97.45% in f-score compared
to the state-of-art 97.4% reported in Sun et al
(2012). However, this corpus is much larger
than the PKU corpus. Using the labeled data
alone can get a relatively good tagger and the
unlabeled data contributes little to the perfor-
mance. For simplicity and efficiency, our further
1http://www.sighan.org/bakeoff2005/
experiments are all conducted on the PKU data.
Details of the PKU data are listed in table 4.
We also used two un-segmented corpora as
unlabeled data. The first one is Chinese Giga-
word2 corpus. It is a comprehensive archive of
newswire data. The second one is articles from
Baike3 of baidu.com. It is a Chinese encyclope-
dia similar to Wikipedia but contains more Chi-
nese items and their descriptions. In the exper-
iment we used about 5 million characters from
each corpus for efficiency. Details of unlabeled
data can be found in table 5.
In our experiment, we did not use any ex-
tra resources such as common surnames, part-
of-speech or other dictionaries.
F-score is used as the accuracy measure. We
define precision P as the percentage of words
in the output that are segmented correctly. We
define recall R as the percentage of the words
in reference that are correctly segmented. Then
F-score is as follows:
F = 2 ? P ?RP +R
The recall of out-of-vocabulary is also taken into
consideration, which measures the ability of the
model to correctly segment out of vocabulary
words.
3.2 Main Results
Table 6 summarizes the segmentation results
on test data with different feature combinations.
We performed incremental evaluation. In this
table, we first present the results of the tagger
only using baseline features. Then we show the
results of adding SSF and DSF individually. In
the end we compare the results of combining
SSF and DSF with baseline features.
Because the baseline features is strong to
reach a relative good result, it is not easy to
largely enhance the performance. Neverthe-
less, there are significant increases in f-score and
OOV-Recall when adding these features. From
table 6 we can see that by adding SSF and DSF
individually, the F-score is improved by +1.1%
2http://www.ldc.upenn.edu/Catalog/
catalogEntry.jsp?catalogId=LDC2003T09
3http://baike.baidu.com/
316
Identical words Total word Identical Character Total character
5.5 ? 104 1.1 ? 106 5 ? 103 1.8 ? 106
Table 4: Details of the PKU data
Corpus Character used
Gigaword 5000193
Baike 5000147
Table 5: Details of the unlabeled data.
P R F OOV
Baseline 0.950 0.943 0.946 0.676
+SSF 0.961 0.953 0.957 0.728
+DSF 0.958 0.953 0.955 0.678
+SSF+DSF 0.965 0.958 0.961 0.731
Table 6: Segmentation results on test data with
different feature combinations. The symbol ?+?
means this feature configuration contains features set
containing the baseline features and all features after
?+?. The size of unlabeled data is fixed as 5 million
characters.
and +0.9%. The OOV-Recall is also improved,
especially after adding SSFs. When considering
SSF and DSF together, the f-score is improved
by +1.5% while the OOV-Recall is improved by
+5.5%.
To compare the contribution of unlabeled
data, we conduct experiments of using differ-
ent sizes of unlabeled data. Note that the SSFs
are still calculated using all the unlabeled data.
However, each iteration in the algorithm uses
unlabeled data with different sizes.
Table 7 shows the results when changing the
size of unlabeled data. We experimented on
three different sizes: 0.5 million, 1 million and 5
million characters.
P R F OOV
DSF(0.5M) 0.962 0.954 0.958 0.727
DSF(1M) 0.963 0.955 0.959 0.728
DSF(5M) 0.965 0.958 0.961 0.731
Table 7: Comparison of results when changing the
size of unlabeled data. (0.5 million, 1 million and 5
million characters).
We further experimented on unlabeled corpus
with larger size (up to 100 million characters).
However the performance did not change signif-
icantly. Besides, because the number of features
in our method is very large, using too large un-
labeled corpus is intractable in real applications
due to the limitation of memory.
Our method can keep working well even when
the labeled data are insufficient. Table 8 shows
the comparison of f-scores when changing the
size of labeled data. We compared the results
of using all labeled data with 3 different situa-
tions: using 1/10, 1/2 and 1/4 of all the labeled
data. In fact, the best system on the Second In-
ternational Chinese Word Segmentation bakeoff
reached 0.95 in f-score by using all labeled data.
From table 8 we can see that our algorithm only
needs 1/4 of all labeled data to achieve the same
f-score.
Baseline +SSF+DSF Improve
1/10 0.934 0.943 +0.96%
1/4 0.946 0.951 +0.53%
1/2 0.952 0.956 +0.42%
All 0.957 0.961 +0.42%
Table 8: Comparison of f-scores when changing the
size of labeled data. (1/10, 1/4, 1/2 and all labeled
data. The size of unlabeled data is fixed as 5 million
characters.)
We also explored how the performance
changes as iteration increases. Figure 1 shows
the change of F-score during the first 10 itera-
tions. From figure 1 we find that f-score has a
fast improvement in the first few iterations, and
then stables at a fixed point. Besides, as the size
of labeled data increases, it converges faster.
Using an in-domain corpus and an out-of-
domain corpus is better than use one corpus
alone. We compared our approach with the
method which uses only one unlabeled corpus.
To use only one corpus, we modify our algorithm
to extract DSFs from the Chinese Giga word
corpus and apply the learned features to itself.
317
Figure 1: Learning curve of using different size of
labeled data
Table 9 shows the result. We can see that our
method outperforms by +0.2% in f-score and
+0.7% in OOV-Recall.
Finally, we compared our method with the
state-of-art systems reported in the previous pa-
pers. Table 10 listed the results. Best05 repre-
sents the best system reported on the Second In-
ternational Chinese Word Segmentation Bake-
off. CRF + Rule system represents a combina-
tion of CRF model and rule based model pre-
sented in Zhang et al (2006). Other three sys-
tems all represent the methods using their cor-
responding model in the corresponding papers.
Note that these state-of-art systems are either
using complicated models with semi-Markov re-
laxations or latent variables, or modifying mod-
els to fit special conditions. Our system uses a
single CRF model. As we can see in table 10,
our method achieved higher F-scores than the
previous best systems.
3.3 Results on NER task
Our method is not limited to the CWS prob-
lem. It is applicable to all sequence labeling
problems. We applied our method on the Chi-
nese NER task. We used the MSR corpus of
the sixth SIGHAN Workshop on Chinese Lan-
guage Processing. It is the only NER corpus
using simplified Chinese in that workshop. We
compared our method with the pure sequence la-
beling approach in He and Wang (2008). We re-
implemented their method to eliminate the dif-
ference of various CRFs implementations. Ex-
periment results are shown in table 11. We can
see that our methods works better, especially
when handling the out-of-vocabulary named en-
tities;
4 Related work
Recent studies show that character sequence
labeling is an effective method of Chinese word
segmentation for machine learning (Xue, 2003;
Low et al, 2005; Zhao et al, 2006a,b). These su-
pervised methods show good results. Unsuper-
vised word segmentation (Maosong et al, 1998;
Peng and Schuurmans, 2001; Feng et al, 2004;
Goldwater et al, 2006; Jin and Tanaka-Ishii,
2006) takes advantage of the huge amount of raw
text to solve Chinese word segmentation prob-
lems. These methods need no annotated corpus,
and most of them use statistics to help model
the problem. However, they usually are less ac-
curate than supervised ones.
Currently ?feature-engineering? methods
have been successfully applied into NLP ap-
plications. Miller et al (2004) applied this
method to named entity recognition. Koo et al
(2008) applied this method to dependency pars-
ing. Turian et al (2010) applied this method to
both named entity recognition and text chunk-
ing. These papers shared the same concept of
word clustering. However, we cannot simply
equal Chinese character to English word because
characters in Chinese carry much less informa-
tion than words in English and the clustering
results is less meaningful.
Features extracted from large unlabeled cor-
pus in previous works mainly focus on statisti-
cal information of characters. Feng et al (2004)
used the accessor variety criterion to extract
word types. Li and Sun (2009) used punctua-
tion information in Chinese word segmentation
by introducing extra labels ?L? and ?R?. Chang
and Han (2010), Sun and Xu (2011) used rich
statistical information as discrete features in
a sequence labeling framework. All these ap-
proaches can be viewed as using static statistics
features in a supervised approach. Our method
is different from theirs. For the static statistics
features in our approach, we not only consider
richer string pairs with the different lengths, but
also consider term frequency when processing
318
P R F OOV
Using one corpus 0.963 0.955 0.959 0.724
Our method 0.965 0.958 0.961 0.731
Table 9: Comparison of our approach with using only the Gigaword corpus
Method P R F-score
Best05 (Chen et al (2005)) 0.953 0.946 0.950
CRF + rule-system (Zhang et al (2006)) 0.947 0.955 0.951
Semi-perceptron (Zhang and Clark (2007)) N/A N/A 0.945
Latent-variable CRF (Sun et al (2009)) 0.956 0.948 0.952
ADF-CRF (Sun et al (2012)) 0.958 0.949 0.954
Our method 0.965 0.958 0.961
Table 10: Comparison of our approach with the state-of-art systems
P R F OOV
Traditional 0.925 0.872 0.898 0.712
Our method 0.916 0.887 0.902 0.737
Table 11: Comparison of our approach with tradi-
tional NER systems
punctuation features.
There are previous works using features ex-
tracted from label distribution of unlabeled cor-
pus in NLP tasks. Schapire et al (2002) use a
set of features annotated with majority labels
to boost a logistic regression model. We are
different from their approach because there is
no pseudo-example labeling process in our ap-
proach. Qi et al (2009) investigated on large
set of distribution features and used these fea-
tures in a self-training way. They applied the
method on three tasks: named entity recogni-
tion, POS tagging and gene name recognition
and got relatively good results. Our approach is
different from theirs. Although we all consider
label distribution, the way we use features are
different. Besides, our approach uses two unla-
beled corpora which can mutually enhancing to
get better result.
5 Conclusion and Perspectives
In this paper, we presented a semi-supervised
method for Chinese word segmentation. Two
kinds of new features are used for the itera-
tive modeling: static statistical features and dy-
namic statistical features. The dynamic statis-
tical features use label distribution information
for text contexts, and can be adjusted automat-
ically during the co-training process. Experi-
mental results show that the new features can
improve the performance on the Chinese word
segmentation task. We further conducted exper-
iments to show that the performance is largely
improved, especially when the labeled data is
insufficient.
The proposed iterative semi-supervised
method is not limited to the Chinese word
segmentation task. It can be easily extended
to any sequence labeling task. For example, it
works well on the NER task as well. As our
future work, we plan to apply our method to
other natural language processing tasks, such
as text chunking.
Acknowledgments
This research was partly supported by Ma-
jor National Social Science Fund of China(No.
12&ZD227),National High Technology Research
and Development Program of China (863 Pro-
gram) (No. 2012AA011101) and National Natu-
ral Science Foundation of China (No.91024009).
We also thank Xu Sun and Qiuye Zhao for proof-
reading the paper.
319
References
Blum, A. and Mitchell, T. (1998). Combining
labeled and unlabeled data with co-training.
In Proceedings of the eleventh annual confer-
ence on Computational learning theory, pages
92?100. ACM.
Chang, B. and Han, D. (2010). Enhancing
domain portability of chinese segmentation
model using chi-square statistics and boot-
strapping. In Proceedings of the 2010 Con-
ference on Empirical Methods in Natural Lan-
guage Processing, pages 789?798. Association
for Computational Linguistics.
Chen, A., Zhou, Y., Zhang, A., and Sun, G.
(2005). Unigram language model for chinese
word segmentation. In Proceedings of the
4th SIGHAN Workshop on Chinese Language
Processing, pages 138?141. Association for
Computational Linguistics Jeju Island, Korea.
Dasgupta, S., Littman, M. L., and McAllester,
D. (2002). Pac generalization bounds for co-
training. Advances in neural information pro-
cessing systems, 1:375?382.
Feng, H., Chen, K., Deng, X., and Zheng, W.
(2004). Accessor variety criteria for chinese
word extraction. Computational Linguistics,
30(1):75?93.
Gao, J., Andrew, G., Johnson, M., and
Toutanova, K. (2007). A comparative study
of parameter estimation methods for statisti-
cal natural language processing. In ANNUAL
MEETING-ASSOCIATION FOR COMPU-
TATIONAL LINGUISTICS, volume 45, page
824.
Goldwater, S., Griffiths, T., and Johnson, M.
(2006). Contextual dependencies in unsuper-
vised word segmentation. In Proceedings of
the 21st International Conference on Compu-
tational Linguistics and the 44th annual meet-
ing of the Association for Computational Lin-
guistics, pages 673?680. Association for Com-
putational Linguistics.
Hafer, M. A. and Weiss, S. F. (1974). Word seg-
mentation by letter successor varieties. Infor-
mation storage and retrieval, 10(11):371?385.
Harris, Z. S. (1955). From phoneme to mor-
pheme. Language, 31(2):190?222.
He, J. and Wang, H. (2008). Chinese named en-
tity recognition and word segmentation based
on character. In Sixth SIGHAN Workshop on
Chinese Language Processing, page 128.
Jin, Z. and Tanaka-Ishii, K. (2006). Unsu-
pervised segmentation of chinese text by use
of branching entropy. In Proceedings of the
COLING/ACL on Main conference poster
sessions, pages 428?435. Association for Com-
putational Linguistics.
Koo, T., Carreras, X., and Collins, M. (2008).
Simple semi-supervised dependency parsing.
Lafferty, J., McCallum, A., and Pereira, F.
(2001). Conditional random fields: Proba-
bilistic models for segmenting and labeling se-
quence data.
Li, Z. and Sun, M. (2009). Punctuation
as implicit annotations for chinese word
segmentation. Computational Linguistics,
35(4):505?512.
Low, J., Ng, H., and Guo, W. (2005). A
maximum entropy approach to chinese word
segmentation. In Proceedings of the Fourth
SIGHAN Workshop on Chinese Language
Processing, volume 164. Jeju Island, Korea.
Maosong, S., Dayang, S., and Tsou, B. (1998).
Chinese word segmentation without using lex-
icon and hand-crafted training data. In Pro-
ceedings of the 17th international confer-
ence on Computational linguistics-Volume 2,
pages 1265?1271. Association for Computa-
tional Linguistics.
McCallum, A. (2002). Efficiently inducing fea-
tures of conditional random fields. In Proceed-
ings of the Nineteenth Conference on Uncer-
tainty in Artificial Intelligence, pages 403?410.
Morgan Kaufmann Publishers Inc.
Miller, S., Guinness, J., and Zamanian, A.
(2004). Name tagging with word clusters
and discriminative training. In Proceedings of
HLT-NAACL, volume 4.
Peng, F. and Schuurmans, D. (2001). Self-
supervised chinese word segmentation. Ad-
320
vances in Intelligent Data Analysis, pages
238?247.
Pinto, D., McCallum, A., Wei, X., and Croft,
W. (2003). Table extraction using conditional
random fields. In Proceedings of the 26th an-
nual international ACM SIGIR conference on
Research and development in informaion re-
trieval, pages 235?242. ACM.
Qi, Y., Kuksa, P., Collobert, R., Sadamasa,
K., Kavukcuoglu, K., and Weston, J. (2009).
Semi-supervised sequence labeling with self-
learned features. In Data Mining, 2009.
ICDM?09. Ninth IEEE International Confer-
ence on, pages 428?437. IEEE.
Schapire, R., Rochery, M., Rahim, M., and
Gupta, N. (2002). Incorporating prior
knowledge into boosting. In MACHINE
LEARNING-INTERNATIONAL WORK-
SHOP THEN CONFERENCE-, pages
538?545.
Sun, W. and Xu, J. (2011). Enhancing chi-
nese word segmentation using unlabeled data.
In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing,
pages 970?979. Association for Computational
Linguistics.
Sun, X., Wang, H., and Li, W. (2012). Fast on-
line training with frequency-adaptive learning
rates for chinese word segmentation and new
word detection. In Proceedings of the 50th An-
nual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers),
pages 253?262, Jeju Island, Korea. Associa-
tion for Computational Linguistics.
Sun, X., Zhang, Y., Matsuzaki, T., Tsuruoka,
Y., and Tsujii, J. (2009). A discriminative
latent variable chinese segmenter with hybrid
word/character information. In Proceedings of
Human Language Technologies: The 2009 An-
nual Conference of the North American Chap-
ter of the Association for Computational Lin-
guistics, pages 56?64. Association for Compu-
tational Linguistics.
Turian, J., Ratinov, L., and Bengio, Y. (2010).
Word representations: a simple and gen-
eral method for semi-supervised learning. In
Proceedings of the 48th Annual Meeting of
the Association for Computational Linguis-
tics, pages 384?394. Association for Compu-
tational Linguistics.
Xue, N. (2003). Chinese word segmentation as
character tagging. Computational Linguistics
and Chinese Language Processing, 8(1):29?48.
Yarowsky, D. (1995). Unsupervised word sense
disambiguation rivaling supervised methods.
In Proceedings of the 33rd annual meeting
on Association for Computational Linguistics,
pages 189?196. Association for Computational
Linguistics.
Zhang, R., Kikui, G., and Sumita, E. (2006).
Subword-based tagging by conditional ran-
dom fields for chinese word segmentation. In
Proceedings of the Human Language Technol-
ogy Conference of the NAACL, Companion
Volume: Short Papers, pages 193?196. Asso-
ciation for Computational Linguistics.
Zhang, Y. and Clark, S. (2007). Chi-
nese segmentation with a word-based percep-
tron algorithm. In ANNUAL MEETING-
ASSOCIATION FOR COMPUTATIONAL
LINGUISTICS, volume 45, page 840.
Zhao, H., Huang, C., and Li, M. (2006a). An
improved chinese word segmentation system
with conditional random field. In Proceed-
ings of the Fifth SIGHAN Workshop on Chi-
nese Language Processing, volume 117. Syd-
ney: July.
Zhao, H., Huang, C., Li, M., and Lu, B. (2006b).
Effective tag set selection in chinese word seg-
mentation via conditional random field mod-
eling. In Proceedings of PACLIC, volume 20,
pages 87?94.
321
