<PAPER>
	<ABSTRACT>
	<SECTION title="Introduction*. " number = "1">
			<S sid ="1" ssid = "1">Online discussion boards have become a popular and important medium for distance education.</S>
			<S sid ="2" ssid = "2">Students use discussion forums to collaborate, to exchange information, and to seek answers to problems from their instructors and classmates.</S>
			<S sid ="3" ssid = "3">Making use of the dialog to assess student understanding is an open research problem.</S>
			<S sid ="4" ssid = "4">As the class size increases and online interaction becomes heavier, automatic tools for analyzing student discussions are highly desirable for providing better assistance and promoting discussion participation.</S>
			<S sid ="5" ssid = "5">In this paper, we present an approach for automatically identifying discussions that have unresolved issues or unanswered questions.</S>
			<S sid ="6" ssid = "6">The resulting dis * cussions can be reported to instructors for further assistance.</S>
			<S sid ="7" ssid = "7">We present a two-phase machine learning approach where the first phase identifies high level dialogue features (speech acts such as question, issue raising, answer, and acknowledgement) that are appropriate for assessing student interactions.</S>
			<S sid ="8" ssid = "8">The second phase uses speech acts as features in creating thread classifiers that identify discussions with unanswered questions or unresolved issues.</S>
			<S sid ="9" ssid = "9">We also describe an approach where thread classifiers are created directly from the features in discussion messages.</S>
			<S sid ="10" ssid = "10">The preliminary results indicate that although the direct learning approach can identify threads with unanswered questions well, SA based learning provide a little better results in identifying threads with issues and threads with unresolved issues.</S>
	</SECTION>
	<SECTION title="Modeling Student Discussions. " number = "2">
			<S sid ="11" ssid = "1">Our study takes place in the context of an undergraduate course discussion board that is an integral component of an Operating Systems course in the Computer Science Department at the University of Southern California.</S>
			<S sid ="12" ssid = "2">We obtain our data from an existing online discussion board that hosts student technical discussions.</S>
			<S sid ="13" ssid = "3">Total 291 discussion threads (219 for training and 72 for test) with 1135 messages (848 for training and 287 for test) from two semesters’ discussions were used for this study.</S>
			<S sid ="14" ssid = "4">168 students participated in the discussions.</S>
			<S sid ="15" ssid = "5">2.1 Discussion Threads.</S>
			<S sid ="16" ssid = "6">Unlike prototypical collaborative argumentation where a limited number of members take part in the conversation with a strong focus on solving specific problems, student online discussions have much looser conversational structure, possibly involving multiple anonymous discussants.</S>
			<S sid ="17" ssid = "7">Student 84 discussions are very informal and noisy with respect to grammar, syntax and punctuation.</S>
			<S sid ="18" ssid = "8">There is a lot of variance in the way that students present similar information.</S>
			<S sid ="19" ssid = "9">Messages about programming assignments include various forms of references to programming code.</S>
			<S sid ="20" ssid = "10">Figure 1 shows an example discussion thread that is relatively technical and formal.</S>
			<S sid ="21" ssid = "11">The raw data include humorous messages and personal announcements as well as technical questions and answers.</S>
			<S sid ="22" ssid = "12">Figure 1.</S>
			<S sid ="23" ssid = "13">An example discussion thread The average number of messages per discussion thread in our undergraduate course is 3.9, and many discussion threads contain only two or three messages.</S>
			<S sid ="24" ssid = "14">Discussions often start with a question from a student on a project or an assignment.</S>
			<S sid ="25" ssid = "15">In some cases, the discussion ends with an answer that follows the question.</S>
			<S sid ="26" ssid = "16">In some other cases, the original poster may raise additional issues or ask questions about the answer.</S>
			<S sid ="27" ssid = "17">The discussion can continue with the following answer from another student as in Figure 1.</S>
			<S sid ="28" ssid = "18">However, sometimes the discussion ends with hanging issues or questions without an answer.</S>
			<S sid ="29" ssid = "19">2.2 Speech Acts in messages: Identifying roles.</S>
			<S sid ="30" ssid = "20">that a message plays For conversation analysis, we adopted the theory of Speech Acts (SAs) to capture relations between messages (Austin, 1962; Searle, 1969).</S>
			<S sid ="31" ssid = "21">Each message within a discussion thread may play a different role.</S>
			<S sid ="32" ssid = "22">A message could include a question for a particular problem, or it could contain an answer or suggestion with respect to a previous question in the thread.</S>
			<S sid ="33" ssid = "23">Messages can include question, answer, acknowledgement, and objection.</S>
			<S sid ="34" ssid = "24">Since SAs are useful in understanding contributions made by students in discussions, and are natural indicators for unanswered questions or unresolved issues, we use SAs as features for classifying discussion threads in a two phase learning as described below.</S>
			<S sid ="35" ssid = "25">Table 1.</S>
			<S sid ="36" ssid = "26">Speech Act Categories and Kappa values SA CategoryDescription kappaQUES A question about a problem, in cluding question about a previous message 0.94 ANS A simple or complex answer to a previous question.</S>
			<S sid ="37" ssid = "27">Suggestion or advice0.72ISSUE Report misunderstanding, unclear concepts or issues in solving prob lems 0.88 PosAckAn acknowledgement, compliment or support in response to a prev.</S>
			<S sid ="38" ssid = "28">message 0.87 NegAckA correction or objection (or complaint) to/on a previous message 0.85 We divide message roles into several SA categories, extending the approaches presented in (Kim et al., 2006; Kim and Ravi 2007).</S>
			<S sid ="39" ssid = "29">We focus on the categories that are relevant to the problem of identifying discussion threads with unanswered question or unresolved issues.</S>
			<S sid ="40" ssid = "30">The message might contain a question about a particular problem (QUES) or report a misunderstanding, unclear concepts or issues in solving a problem (ISSUE).</S>
			<S sid ="41" ssid = "31">It might propose an answer or suggestion with respect to a previous question in the thread (ANS).</S>
			<S sid ="42" ssid = "32">Finally, a message might acknowledge the previous message with support Message1: QUES Message2: ANS Poster1: I am still confused.</S>
			<S sid ="43" ssid = "33">I understand it is in thesame address space as the parent process, where do weallocate the 8 pages of mem for it?</S>
			<S sid ="44" ssid = "34">And how do wekeep track of .....?</S>
			<S sid ="45" ssid = "35">I am sure it is a simple concept thatI am just missing.</S>
			<S sid ="46" ssid = "36">Poster2: Have you read the student documentation forthe Fork syscall?</S>
			<S sid ="47" ssid = "37">É Poster1: The Professor gave us 2 methods for forkingthreads from the main program.</S>
			<S sid ="48" ssid = "38">One was .......</S>
			<S sid ="49" ssid = "39">Theother was to .........</S>
			<S sid ="50" ssid = "40">When you fork a thread where doesit get created and take its 8 pages from?</S>
			<S sid ="51" ssid = "41">Do you have tocalculate ......?</S>
			<S sid ="52" ssid = "42">If so how?</S>
			<S sid ="53" ssid = "43">Where does it store itsPCReg .......?</S>
			<S sid ="54" ssid = "44">Any suggestions would be helpfule.</S>
			<S sid ="55" ssid = "45">Poster3: If you use the first implementation....,then you&apos;ll have a hard limit on the number ofthreads....If you use the second implementation,you need to....</S>
			<S sid ="56" ssid = "46">Either way, you&apos;ll need to implement theAddrSpace::NewStack() function and make surethat there is memory available.</S>
			<S sid ="57" ssid = "47">… Message3: ISSUE, QUES Message4: ANS 85 (PosAck) or show disagreement or objection (NegAck).</S>
			<S sid ="58" ssid = "48">SAs relate a pair of messages that has a ‘reply-to’ relation.</S>
			<S sid ="59" ssid = "49">A pair of messages can be labeled with multiple SAs, and a message can have multiple SAs with more than one messages.</S>
			<S sid ="60" ssid = "50">This allows us to capture various relations among messages.</S>
			<S sid ="61" ssid = "51">Table 1 describes the categories we are focusing on and the kappa values from two annotators.</S>
			<S sid ="62" ssid = "52">Figure 1 shows SA relations between message pairs.</S>
			<S sid ="63" ssid = "53">During annotation of the corpus, the annotators marked the cues that are relevant to a particular SA category as well as the SA categories themselves.</S>
			<S sid ="64" ssid = "54">Such information provides hints on the kinds of features that are useful.</S>
			<S sid ="65" ssid = "55">We also interviewed the annotators to capture additional cues or indicators that they used during the annotation.</S>
			<S sid ="66" ssid = "56">We iterated with several different annotation approaches until we reach enough agreement among the annotators on a new dataset that was not seen by the annota-tors before.</S>
			<S sid ="67" ssid = "57">Table 2 shows the distribution statistics of each SA category among the whole training and test corpus.</S>
			<S sid ="68" ssid = "58">Since a message may have more than one SA, the percentage sum of all SAs doesn’t equal to 1.</S>
			<S sid ="69" ssid = "59">As we can see, PosAck and NegAck are experiencing lacking data problem which is one of the challenges we are facing for SA classification.</S>
			<S sid ="70" ssid = "60">Table 2.</S>
			<S sid ="71" ssid = "61">Statistics for each Speech Act Category Training set Test set SA Category # of msgs Percentage # of msgs Percentage QUES 469 55.31% 146 50.87% ANS 508 59.91% 176 61.32% ISSUE 136 16.03% 46 16.03% PosAck 78 9.20% 30 10.45% NegAck 23 2.71% 8 2.79%</S>
	</SECTION>
	<SECTION title="Message Speech Act Classifiers. " number = "3">
			<S sid ="72" ssid = "1">In this section, we first describe how raw discussion data is processed and show the features generated from the data, and we then present the current SA classifiers.</S>
			<S sid ="73" ssid = "2">3.1 Discussion Data Pre-processing.</S>
			<S sid ="74" ssid = "3">Besides typical data preprocessing steps, such as stemming and filtering, which are taken by most NLP systems, our system performs additional steps to reduce noise and variance (Ravi and Kim 2007).</S>
			<S sid ="75" ssid = "4">We first remove the text from previous messages that is automatically inserted by the discussion board system starting with righ angle braket (&gt;) when the user clicks on a “Reply to” button.</S>
			<S sid ="76" ssid = "5">We also apply a simple stemming algorithm that removes “s” and “es” for plurals.</S>
			<S sid ="77" ssid = "6">Apostrophes are also converted to their original forms.</S>
			<S sid ="78" ssid = "7">E.g., “I’m” is converted to “I am”.</S>
			<S sid ="79" ssid = "8">For discussions on programming assignment, the discussion included programming code fragments.</S>
			<S sid ="80" ssid = "9">Each section of programming code or code fragment is replaced with a single term called code.</S>
			<S sid ="81" ssid = "10">Similar substitution patterns were used for a number of categories like filetype extensions (“.html”, “.c”, “.c++”, “.doc”), URL links and others.</S>
			<S sid ="82" ssid = "11">Students also tend to use informal words (e.g. “ya”, “yeah”, “yup”).We substitute some of such words with one form (“yes”).</S>
			<S sid ="83" ssid = "12">For words like “which”, ”where”, ”when”, ”who” and ”how”, we used the term categ_wh.</S>
			<S sid ="84" ssid = "13">We do not replace pronouns (“I”, “we”, “they”,) since they may be useful for identifying some SAs.</S>
			<S sid ="85" ssid = "14">For example, “You can” may be a cue for ANS but “I can” may not.</S>
			<S sid ="86" ssid = "15">We also apply a simple sentence divider with simple cues (punctuation and white spaces such as newline) in order to captures the locations of the features in the message, such as cue words in the first sentence vs. cues in the last sentence.</S>
			<S sid ="87" ssid = "16">3.2 Features for Speech Act Classification.</S>
			<S sid ="88" ssid = "17">We have used six different types of features based on input from the annotators.</S>
			<S sid ="89" ssid = "18">F1: cue phases and their positions: In addition to SAs (e.g. QUES), the human annotators marked the parts within the message (cue phrases or sentences), which helped them identify the SAs in the message.</S>
			<S sid ="90" ssid = "19">In order to overcome data sparseness, we generate features from the marked phrases.</S>
			<S sid ="91" ssid = "20">That is, from each phrase, we extract all the unigrams, bi-grams, trigrams (sequence of 1/2/3 words) and add them to the feature set.</S>
			<S sid ="92" ssid = "21">We also added two separate unigrams, three separate unigrams and a unigram and a bigram combinations since the annotations in the training data indicated that they could be a useful pattern.</S>
			<S sid ="93" ssid = "22">All the cues including separate cues such as two unigrams are captured and used for a single sentence.</S>
			<S sid ="94" ssid = "23">Positions of the cues are included since in longer messages the cues in the beginning 86 sentences and the ones in the end sentences can indicate different SAs.</S>
			<S sid ="95" ssid = "24">For example, THANK in the beginning indicates a positive answer but THANK in latter part of the message usually means politeness (thank in advance).</S>
			<S sid ="96" ssid = "25">F2: Message Position: Position of current message within the discussion thread (e.g. the first message, the last message, or middle in the thread).</S>
			<S sid ="97" ssid = "26">F3: Previous Message Information: SAs in the previous message that the current message is replying to.</S>
			<S sid ="98" ssid = "27">F4: Poster Class: Student or Instructor.</S>
			<S sid ="99" ssid = "28">F5: Poster Change: Was the current message posted by the same person who posted the message that the current message is replying to?</S>
			<S sid ="100" ssid = "29">F6: Message Length: Values include Short(15words), Medium(630 words), and Long(&gt;30 words).</S>
			<S sid ="101" ssid = "30">F1 is a required feature since the annotators indicated cues as useful feature in most cases.</S>
			<S sid ="102" ssid = "31">All the others are optional.</S>
			<S sid ="103" ssid = "32">3.3 Speech Act Classifiers.</S>
			<S sid ="104" ssid = "33">We applied SVM in creating binary classifiers for each SA category using Chang and Lin (2001).</S>
			<S sid ="105" ssid = "34">Also, Transformation-based Learning (TBL) was applied as it has been successfully used in spoken dialogue act classification (Samuel 2000; Brill 1995).</S>
			<S sid ="106" ssid = "35">It starts with the unlabeled corpus and learns the best sequence of admissible “transformation rules” that must be applied to the training corpus to minimize the error for the task.</S>
			<S sid ="107" ssid = "36">The generated rules are easy to understand and useful for debugging the features used.</S>
			<S sid ="108" ssid = "37">TBL results are also used in generating dependencies among SA categories for F3, i.e. which SAs tend to follow which other SAs1, as describe below.</S>
			<S sid ="109" ssid = "38">SA Classification with TBL Each rule iRule is composed of two parts - (1) iRuleLHS - A combination of features that should be checked for applicability to the current message (2)iRuleTAGSA tag to apply, if the feature com bination is applicable to the current message.</S>
			<S sid ="110" ssid = "39">1 It is possible to collect related clues from SVM with distribution of feature values and information gain although dependencies can be easily recognized in TBL rules.</S>
			<S sid ="111" ssid = "40">iii RuleTAGRuleLHSRule !&quot;:: Whereii XRuleLHS ! )654321(; FFFFFFXXX i #####$% The iRuleLHS component can be instantiated from all the combination of the features F1, …,F6.</S>
			<S sid ="112" ssid = "41">iRuleTAG is any SA (single SA) chosen from a list of all the SA categories.</S>
			<S sid ="113" ssid = "42">An example rule used in Speech Act learning is shown below: Rule1 :: IF cue-phrase = {“not”, “work”} &amp; poster-info = Student &amp; post-length = Long =&gt; ISSUE Rule1 means if the post contains two unigrams “not” and “work”, the poster is a student, and the post length is long, then the Speech Act for the post is ISSUE.</S>
			<S sid ="114" ssid = "43">We apply each rule in the potential rule set on all the posts in the training corpus and transform the post label if the post is applicable.</S>
			<S sid ="115" ssid = "44">The rule with highest improvement by F score is selected into the optimal rule set and moved from the potential rule set.</S>
			<S sid ="116" ssid = "45">The iteration continues until there is no significant improvement with any rule.</S>
			<S sid ="117" ssid = "46">The training corpus was divided into 3 parts for 3-fold cross validation.</S>
			<S sid ="118" ssid = "47">The rules from 3 rule sets are merged and sorted by weighted Mean Reciprocal Rank (MRR) (Voorhees, 2001).</S>
			<S sid ="119" ssid = "48">For example, if we have 5 rules among 3 rule sets as follows, Rule set 1 (0.85 on test): R1 R2 R3 Rule set 2 (0.88 on test): R2 R1 R4 Rule set 3 (0.79 on test): R1 R4 R5 For R1, we calculate the weighted MRR as (0.85*1 + 0.88*(1/2) + 0.79*1) / 3.</S>
			<S sid ="120" ssid = "49">After sorting, we get top N rules from the merged rule set.</S>
			<S sid ="121" ssid = "50">Table 3 shows some of the rules learned.</S>
			<S sid ="122" ssid = "51">Table 3.</S>
			<S sid ="123" ssid = "52">TBL rule examples IF cue-phrase = {“?”} =&gt; QUES IF cue-phrase = {“yes you can”} &amp; poster-info = Instructor &amp; post-length = Medium =&gt; ANS IF cue-phrase = {“yes”} &amp; cue-position = CP_BEGIN &amp; prevSA = QUES =&gt; ANS IF cue-phrase = {“not know”} 87 &amp; poster-info = student &amp; poster-change = YES =&gt; ISSUE Based on the rules generated from TBL, we analyze dependencies among the SA categories for F3 (previous message SAs).</S>
			<S sid ="124" ssid = "53">In TBL rules, ANS depends on ISSUE and QUES, i.e. some ANS rules have QUES and ISSUE for F3.</S>
			<S sid ="125" ssid = "54">Also PosAck and NegAck tend to follow ANS.</S>
			<S sid ="126" ssid = "55">Both SVM and TBL classifiers use this information during testing.</S>
			<S sid ="127" ssid = "56">That is, we apply independent classifiers first and then use dependent classifiers according to the dependency order as following: Currently there is no loop in the selected rules but we plan to address potential issues with loops in SA dependencies.</S>
			<S sid ="128" ssid = "57">SA Classification with SVM Table 4.</S>
			<S sid ="129" ssid = "58">Some of the top selected features by Infor mation Gain SA Category Top features QUES “?” POST_POSITION “_category_wh_ … ?” PREV_SA_FIRST_NONE “to … ?” ANS POST_POSITION PREV_SA_QUESTION “?” POSTER_INFO ISSUE POSTER_INFO “not … sure” POST_POSITION FEATURE_LENGTH “error” PosAck PREV_SA_ANSWER POST_POSITION PREV_SA_FIRST_NONE “thanks” &amp; cue-position = CP_BEGIN “ok” &amp; cue-position = CP_BEGIN NegAck “yes, ” “, but” POST_POSITION “, but” “are … wrong”?</S>
			<S sid ="130" ssid = "59">Given all the combination of the features F1,…, F6, we use Information Gain (Yang and Pederson 1997) for pruning the feature space and selecting features.</S>
			<S sid ="131" ssid = "60">For each Speech Act, we sort all the features (lexical and non-lexical) by Information Gain and use the top N (=200) features.</S>
			<S sid ="132" ssid = "61">Table 4 shows the top features selected by Information Gain.</S>
			<S sid ="133" ssid = "62">The resulting features are used in representing a message in a vector format.</S>
			<S sid ="134" ssid = "63">We did 5-fold cross validation in the training.</S>
			<S sid ="135" ssid = "64">RBF (Radial Basis Function) is used as the kernel function.</S>
			<S sid ="136" ssid = "65">We performed grid search to get the best parameter (C and gamma) in training and applied them to the test corpus.</S>
			<S sid ="137" ssid = "66">Table 5.</S>
			<S sid ="138" ssid = "67">SA classification results SVM TBL SA Cat egory Prec.Re call F score Prec.</S>
			<S sid ="139" ssid = "68">Re call F score QUES 0.95 0.90 0.94 0.96 0.91 0.95 ANS 0.87 0.80 0.85 0.83 0.64 0.78 ISSUE 0.65 0.54 0.62 0.46 0.76 0.50 PosAck 0.57 0.44 0.54 0.58 0.56 0.57 NegAck 0 0 0 0.5 0.38 0.47 Table 5 shows the current classification accuracies with SVM and TBL.</S>
			<S sid ="140" ssid = "69">The main reason that ISSUE, PosAck and NegAck show low scores is that they have relatively small number of examples (see statistics in Table 2).</S>
			<S sid ="141" ssid = "70">We plan to add more examples as we collect more discussion annotations.</S>
			<S sid ="142" ssid = "71">For thread classification described below, we use features with QUES, ANS, ISSUE and Pos_Ack only.</S>
	</SECTION>
	<SECTION title="Identifying Discussions with Unan-. " number = "4">
			<S sid ="143" ssid = "1">swered or Unresolved Questions: Thread Classification Figure 2 shows typical patterns of interactions in our corpus.</S>
			<S sid ="144" ssid = "2">Many threads follow pattern (a) where the first message includes a question and the subsequent message provides an answer.</S>
			<S sid ="145" ssid = "3">In (b), after an answer, the student presents an additional question or misunderstanding (ISSUE), which is followed by another answer.</S>
			<S sid ="146" ssid = "4">Often students provide positive acknowledgement when an answer is sat ISSUE ANS QUES PosAck NegAck 88 isfying.</S>
			<S sid ="147" ssid = "5">Pattern (c) covers cases for when the question is unanswered.</S>
			<S sid ="148" ssid = "6">Figure 2.</S>
			<S sid ="149" ssid = "7">Example patterns in student discussion threads We are interested in the following assessment questions.</S>
			<S sid ="150" ssid = "8">(Q1) Were all questions answered?</S>
			<S sid ="151" ssid = "9">(Y/N) (Q2) Were there any issues or confusion?</S>
			<S sid ="152" ssid = "10">(Y/N) (Q3) Were those issues or confusions resolved?</S>
			<S sid ="153" ssid = "11">(Y/N) There can be multiple questions, and Q1 is false if there is any question that does not have a corresponding answer.</S>
			<S sid ="154" ssid = "12">That is, even when some questions were resolved, it could still be False (not resolved) if some were not resolved.</S>
			<S sid ="155" ssid = "13">If Q2 is False (i.e. there is no issue or question), then Q3 is also False.</S>
			<S sid ="156" ssid = "14">These questions are useful for distinguishing different interaction patterns, including threads with unanswered questions.</S>
			<S sid ="157" ssid = "15">In the second phase of learning, we use SA-based features.</S>
			<S sid ="158" ssid = "16">Our initial analysis of student interactions as above indicates that the following simple features can be useful in answering such questions: (T-F1) Whether there was an [SA] in the thread (T-F2) Whether the last message in the thread in cluded [SA] We used TBL rules for PosAck and SVM classifiers for other SA categories because of relatively higher score of PosAck from TBL and other categories from SVM.</S>
			<S sid ="159" ssid = "17">We use 8 (2 x 4) features created from T-F1 and T-F2.</S>
			<S sid ="160" ssid = "18">SVM settings are similar to the ones used in the SA classification.</S>
			<S sid ="161" ssid = "19">Table 6 shows the thread classification results.</S>
			<S sid ="162" ssid = "20">We checked SVM classification results with human annotated SAs since they can show how useful SA-based features are (T-F1 and T-F2 in particular) in answering Q1—Q3.</S>
			<S sid ="163" ssid = "21">The results shown in Table 6-(a) indicate that the features (T-F1 and T-F2) are in fact useful for the questions.</S>
			<S sid ="164" ssid = "22">When we used the SA classifiers and SVM in a pipeline, the system shows precisions (recalls) of 83%(84%), 77%(74%) and 68%(69%) for Q1, Q2, and Q3 respectively.</S>
			<S sid ="165" ssid = "23">Table 6.</S>
			<S sid ="166" ssid = "24">Thread Classification Results Precision Recall F score Q1 0.93 0.93 0.93 Q2 0.93 0.93 0.93 Q3 0.89 0.89 0.89 (a) Classification results with human annotated SAs Precision Recall F score Q1 0.83 0.84 0.83 Q2 0.77 0.74 0.76 Q3 0.68 0.69 0.68 (b) SVM classification results with system generated SAs The results with system generated SAs provide an average F score of 0.76.</S>
			<S sid ="167" ssid = "25">Although the ISSUE classifier has F score of 0.62, the score for Q2 is 0.76.</S>
			<S sid ="168" ssid = "26">Q2 checks one or more occurrences of ISSUE rather than identifying existence of ISSUE in a message, and it may become an easier problem when there are multiple occurrences of ISSUEs.</S>
	</SECTION>
	<SECTION title="Direct Thread Classification without. " number = "5">
			<S sid ="169" ssid = "1">SAs As an alternative to the SA-based two-phase learning, we crated thread classifiers directly from the features in discussion messages.</S>
			<S sid ="170" ssid = "2">We used SVM with the following features that we can capture directly from a discussion thread.</S>
			<S sid ="171" ssid = "3">F1’: cue phases and their positions in the thread: we use the same cue features in F1 but we use an optional thread level cue position: Last_message and Dont_Care.</S>
			<S sid ="172" ssid = "4">For example, for a given cue “ok”, if it appears in the the last message of the thread, we generate two features, &quot;ok&quot;_Last_message and &quot;ok&quot;_Dont_Care.</S>
			<S sid ="173" ssid = "5">Given a set of candidate features, we use Information Gain to select the top N (=200) features.</S>
			<S sid ="174" ssid = "6">The resulting features are used in creating vectors as described inS 3.3.</S>
			<S sid ="175" ssid = "7">Similar cross-validation and SVM settings are applied.</S>
			<S sid ="176" ssid = "8">89 Table 7.</S>
			<S sid ="177" ssid = "9">Results from Direct Thread Classification Precision Recall F score Q1 0.86 0.86 0.86 Q2 0.81 0.62 0.70 Q3 0.75 0.33 0.46 Table 7 shows the classification results.</S>
			<S sid ="178" ssid = "10">Although the direct learning approach can identify threads with unanswered questions well, SA based learning provides a little better results in identifying threads with issues (Q2) and unresolved issues (Q3).</S>
			<S sid ="179" ssid = "11">It seems that SA-based features may help performing more difficult tasks (e.g. assessment for ISSUEs in discussions) We need further investigation on different types of assessment tasks.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "6">
			<S sid ="180" ssid = "1">Rhetorical Structure Theory (Mann and Thomson, 1988) based discourse processing has attracted much attention with successful applications in sentence compression and summarization.</S>
			<S sid ="181" ssid = "2">Most of the current work on discourse processing focuses on sentence-level text organization (Soricut and Marcu, 2003) or the intermediate step (Sporleder and Lapata, 2005).</S>
			<S sid ="182" ssid = "3">Analyzing and utilizing discourse information at a higher level, e.g., at the paragraph level, still remains a challenge to the natural language community.</S>
			<S sid ="183" ssid = "4">In our work, we utilize the discourse information at a message level.</S>
			<S sid ="184" ssid = "5">There has been prior work on dialogue act analysis and associated surface cue words (Samuel 2000; Hirschberg and Litman 1993).</S>
			<S sid ="185" ssid = "6">There have also been Dialogue Acts modeling approaches for automatic tagging and recognition of conversational speech (Stolcke et al., 2000) and related work in corpus linguistics where machine learning techniques have been used to find conversational patterns in spoken transcripts of dialogue corpus (Shawar and Atwell, 2005).</S>
			<S sid ="186" ssid = "7">Although spoken dialogue is different from message-based conversation in online discussion boards, they are closely related to our thread analysis work, and we plan to investigate potential use of conversation patterns in spoken dialogue in threaded discussions.</S>
			<S sid ="187" ssid = "8">Carvalho and Cohen (2005) present a dependency-network based collective classification method to classify email speech acts.</S>
			<S sid ="188" ssid = "9">However, estimated speech act labeling between messages is not sufficient for assessing contributor roles or identifying help needed by the participants.</S>
			<S sid ="189" ssid = "10">We included other features like participant profiles.</S>
			<S sid ="190" ssid = "11">Also our corpus consists of less informal student discussions rather than messages among project participants, which tend to be more technically coherent.</S>
			<S sid ="191" ssid = "12">Requests and commitments of email exchange are analyzed in (Lampert et al., 2008).</S>
			<S sid ="192" ssid = "13">As in their analysis, we have a higher kappa value for questions than answers, and some sources of ambiguity in human annotations such as different forms of answers also appear in our data.</S>
			<S sid ="193" ssid = "14">However, student discussions tend to focus on problem solving rather than task request and commitment as in project management applications, and their data show different types of ambiguity due to different nature of participant interests.</S>
			<S sid ="194" ssid = "15">There also has been work on non-traditional, qualitative assessment of instructional discourse (Graesser et al., 2005; McLaren et al., 2007; Boyer et al., 2008).</S>
			<S sid ="195" ssid = "16">The assessment results can be used in finding features for student thinking skills or level of understanding.</S>
			<S sid ="196" ssid = "17">Although the existing work has not been fully used for discussion thread analysis, we are investigating opportunities for using such features to cover additional discourse analysis capabilities.</S>
			<S sid ="197" ssid = "18">Similar approaches for classifying speech acts were investigated (Kim and Ravi 2007).</S>
			<S sid ="198" ssid = "19">Our work captures more features that are relevant to analyzing noisy student discussion threads and support a full automatic analysis of student discussions instead of manual generation of thread analysis rules.</S>
	</SECTION>
	<SECTION title="Summary and Future Work. " number = "7">
			<S sid ="199" ssid = "1">We have presented an approach for automatically classifying student discussions to identify discussions that have unanswered questions and need instructor attention.</S>
			<S sid ="200" ssid = "2">We applied a multi-phase learning approach, where the first phase classifies individual messages with SAs and the second phase classifies discussion threads with SA-based features.</S>
			<S sid ="201" ssid = "3">We also created thread classifiers directly from features in discussion messages.</S>
			<S sid ="202" ssid = "4">The preliminary results indicate that SA-based features may help difficult classification tasks.</S>
			<S sid ="203" ssid = "5">We plan to perform more analysis on different types of thread classification tasks.</S>
			<S sid ="204" ssid = "6">We found that automatic classification of undergraduate student discussions is very challenging 90 due to incoherence and noise in the data.</S>
			<S sid ="205" ssid = "7">Especially messages that contain long sentences, informal statements with uncommon words, answers in form of question, are difficult to classify.</S>
			<S sid ="206" ssid = "8">In order to use other SA categories such as NegAck and analyze various types of student interactions, we plan to use more annotated discussion data.</S>
			<S sid ="207" ssid = "9">A deeper assessment of online discussions requires a combination with other information such as discussion topics (Feng et al., 2006).</S>
			<S sid ="208" ssid = "10">For example, classification of discussion topics can be used in identifying topics that participants have more confusion about.</S>
			<S sid ="209" ssid = "11">Furthermore, such information can also be used in profiling participants such as identifying mentors or help seekers on a particular topic as in (Kim and Shaw 2009).</S>
			<S sid ="210" ssid = "12">We are investigating several extensions in order to generate more useful instructional tools.</S>
	</SECTION>
	<SECTION title="Acknowledgments">
			<S sid ="211" ssid = "13">This work was supported by National Science Foundation, CCLI Phase II grant (#0618859).</S>
	</SECTION>
</PAPER>
