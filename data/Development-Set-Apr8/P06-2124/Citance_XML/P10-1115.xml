<PAPER>
	<ABSTRACT>
		<S sid ="1" ssid = "1">Probabilistic latent topic models have recently enjoyed much success in extracting and analyzing latent topics in text in an unsupervised way.</S>
		<S sid ="2" ssid = "2">One common deficiency of existing topic models, though, is that they would not work well for extracting cross-lingual latent topics simply because words in different languages generally do not co-occur with each other.</S>
		<S sid ="3" ssid = "3">In this paper, we propose a way to incorporate a bilingual dictionary into a probabilistic topic model so that we can apply topic models to extract shared latent topics in text data of different languages.</S>
		<S sid ="4" ssid = "4">Specifically, we propose a new topic model called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) which extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary.</S>
		<S sid ="5" ssid = "5">Both qualitative and quantitative experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data.</S>
	</ABSTRACT>
	<SECTION title="Introduction" number = "1">
			<S sid ="6" ssid = "6">As a robust unsupervised way to perform shallow latent semantic analysis of topics in text, probabilistic topic models (Hofmann, 1999a; Blei et al., 2003b) have recently attracted much attention.</S>
			<S sid ="7" ssid = "7">The common idea behind these models is the following.</S>
			<S sid ="8" ssid = "8">A topic is represented by a multinomial word distribution so that words characterizing a topic generally have higher probabilities than other words.</S>
			<S sid ="9" ssid = "9">We can then hypothesize the existence of multiple topics in text and define a generative model based on the hypothesized topics.</S>
			<S sid ="10" ssid = "10">By fitting the model to text data, we can obtain an estimate of all the word distributions corresponding to the latent topics as well as the topic distributions in text.</S>
			<S sid ="11" ssid = "11">Intuitively, the learned word distributions capture clusters of words that co-occur with each other probabilistically.</S>
			<S sid ="12" ssid = "12">Although many topic models have been proposed and shown to be useful (see Section 2 for more detailed discussion of related work), most of them share a common deficiency: they are designed to work only for monolingual text data and would not work well for extracting cross-lingual latent topics, i.e. topics shared in text data in two different natural languages.</S>
			<S sid ="13" ssid = "13">The deficiency comes from the fact that all these models rely on co-occurrences of words forming a topical cluster, but words in different language generally do not co-occur with each other.</S>
			<S sid ="14" ssid = "14">Thus with the existing models, we can only extract topics from text in each language, but cannot extract common topics shared in multiple languages.</S>
			<S sid ="15" ssid = "15">In this paper, we propose a novel topic model, called Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) model, which can be used to mine shared latent topics from unaligned text data in different languages.</S>
			<S sid ="16" ssid = "16">PCLSA extends the Probabilistic Latent Semantic Analysis (PLSA) model by regularizing its likelihood function with soft constraints defined based on a bilingual dictionary.</S>
			<S sid ="17" ssid = "17">The dictionary-based constraints are key to bridge the gap of different languages and would force the captured co-occurrences of words in each language by PCLSA to be “synchronized” so that related words in the two languages would have similar probabilities.</S>
			<S sid ="18" ssid = "18">PCLSA can be estimated efficiently using the General Expectation- Maximization (GEM) algorithm.</S>
			<S sid ="19" ssid = "19">As a topic extraction algorithm, PCLSA would take a pair of unaligned document sets in different languages and a bilingual dictionary as input, and output a set of aligned word distributions in both languages that can characterize the shared topics in the two languages.</S>
			<S sid ="20" ssid = "20">In addition, it also outputs a topic cov 1128 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1128–1137, Uppsala, Sweden, 1116 July 2010.</S>
			<S sid ="21" ssid = "21">Qc 2010 Association for Computational Linguistics erage distribution for each language to indicate the relative coverage of different shared topics in each language.</S>
			<S sid ="22" ssid = "22">To the best of our knowledge, no previous work has attempted to solve this topic extraction problem and generate the same output.</S>
			<S sid ="23" ssid = "23">The closest existing work to ours is the MuTo model proposed in (BoydGraber and Blei, 2009) and the JointLDA model published recently in (Jagaralamudi and Daume´ III, 2010).</S>
			<S sid ="24" ssid = "24">Both used a bilingual dictionary to bridge the language gap in a topic model.</S>
			<S sid ="25" ssid = "25">However, the goals of their work are different from ours in that their models mainly focus on mining cross-lingual topics of matching word pairs and discovering the correspondence at the vocabulary level.</S>
			<S sid ="26" ssid = "26">Therefore, the topics extracted using their model cannot indicate how a common topic is covered differently in the two languages, because the words in each word pair share the same probability in a common topic.</S>
			<S sid ="27" ssid = "27">Our work focuses on discovering correspondence at the topic level.</S>
			<S sid ="28" ssid = "28">In our model, since we only add a soft constraint on word pairs in the dictionary, their probabilities in common topics are generally different, naturally capturing which shows the different variations of a common topic in different languages.</S>
			<S sid ="29" ssid = "29">We use a cross-lingual news data set and a review data set to evaluate PCLSA.</S>
			<S sid ="30" ssid = "30">We also propose a “cross-collection” likelihood measure to quantitatively evaluate the quality of mined topics.</S>
			<S sid ="31" ssid = "31">Experimental results show that the PCLSA model can effectively extract cross-lingual latent topics from multilingual text data, and it outperforms a baseline approach using the standard PLSA on text data in each language.</S>
	</SECTION>
	<SECTION title="Related Work. " number = "2">
			<S sid ="32" ssid = "1">Many topic models have been proposed, and the two basic models are the Probabilistic Latent Semantic Analysis (PLSA) model (Hofmann, 1999a) and the Latent Dirichlet Allocation (LDA) model (Blei et al., 2003b).</S>
			<S sid ="33" ssid = "2">They and their extensions have been successfully applied to many problems, including hierarchical topic extraction (Hofmann, 1999b; Blei et al., 2003a; Li and McCallum, 2006), author-topic modeling (Steyvers et al., 2004), contextual topic analysis (Mei and Zhai, 2006), dynamic and correlated topic models (Blei and Lafferty, 2005; Blei and Lafferty, 2006), and opinion analysis (Mei et al., 2007; Branavan et al.,2008).</S>
			<S sid ="34" ssid = "3">Our work is an extension of PLSA by in corporating the knowledge of a bilingual dictionary as soft constraints.</S>
			<S sid ="35" ssid = "4">Such an extension is similar to the extension of PLSA for incorporating social network analysis (Mei et al., 2008a) but our constraint is different.</S>
			<S sid ="36" ssid = "5">Some previous work on multilingual topic models assume documents in multiple languages are aligned either at the document level, sentence level or by time stamps (Mimno et al., 2009; Zhao and Xing, 2006; Kim and Khudanpur, 2004; Ni et al., 2009; Wang et al., 2007).</S>
			<S sid ="37" ssid = "6">However, in many applications, we need to mine topics from unaligned text corpus.</S>
			<S sid ="38" ssid = "7">For example, mining topics from search results in different languages can facilitate summarization of multilingual search results.</S>
			<S sid ="39" ssid = "8">Besides all the multilingual topic modeling work discussed above, comparable corpora have also been studied extensively (e.g.</S>
			<S sid ="40" ssid = "9">(Fung, 1995; Franz et al., 1998; Masuichi et al., 2000; Sadat et al., 2003; Gliozzo and Strapparava, 2006)), but most previous work aims at acquiring word translation knowledge or cross-lingual text categorization from comparable corpora.</S>
			<S sid ="41" ssid = "10">Our work differs from this line of previous work in that our goal is to discover shared latent topics from multilingual text data that are weakly comparable (e.g. the data does not have to be aligned by time).</S>
	</SECTION>
	<SECTION title="Problem Formulation. " number = "3">
			<S sid ="42" ssid = "1">In general, the problem of cross-lingual topic extraction can be defined as to extract a set of common cross-lingual latent topics covered in text collections in different natural languages.</S>
			<S sid ="43" ssid = "2">A cross- lingual latent topic will be represented as a multinomial word distribution over the words in all the languages, i.e. a multilingual word distribution.</S>
			<S sid ="44" ssid = "3">For example, given two collections of news articles in English and Chinese, respectively, we would like to extract common topics simultaneously from the two collections.</S>
			<S sid ="45" ssid = "4">A discovered common topic, such as the terrorist attack on September 11, 2001, would be characterized by a word distribution that would assign relatively high probabilities to words related to this event in both English and Chinese (e.g. “terror”, “attack”, “afghanistan”, “taliban”, and their translations in Chinese).</S>
			<S sid ="46" ssid = "5">As a computational problem, our input is a multilingual text corpus, and output is a set of cross-lingual latent topics.</S>
			<S sid ="47" ssid = "6">We now define this problem more formally.</S>
			<S sid ="48" ssid = "7">Definition 1 (MultiLingual Corpus) A multilingual corpus C is a set of text collections</S>
	</SECTION>
	<SECTION title="Probabilistic Cross-Lingual Latent. " number = "4">
			<S sid ="49" ssid = "1">Semantic Analysis {C1, C2 , . . .</S>
			<S sid ="50" ssid = "2">, Cs }, where Ci = {di , di , . . .</S>
			<S sid ="51" ssid = "3">, di } 1 2 Mi is a collection of documents in language Li withIn this section, we present our probabilistic cross vocabulary Vi = {wi , wi , . . .</S>
			<S sid ="52" ssid = "4">, wi }.</S>
			<S sid ="53" ssid = "5">Here, Mi is lingual latent semantic analysis (PCLSA) model 1 2 Nithe total number of documents in Ci , Ni is the to tal number of words in Vi , and di is a document in collection Ci . Following the common assumption of bag-of- words representation, we represent document diand discuss how it can be used to extract cross lingual topics from multilingual text data.</S>
			<S sid ="54" ssid = "6">The main reason why existing topic models can’t be used for cross-lingual topic extraction is because they cannot cross the language barrier.</S>
			<S sid ="55" ssid = "7">Intuitively, in order to cross the language barrier with a bag of words {wi , wi , . . .</S>
			<S sid ="56" ssid = "8">, wi }, and use and extract a common topic shared in articles in j1 j2 jd c(wi , di ) to denote the count of word wi in docu k j k ment di . Definition 2 (Cross-Lingual Topic): A cross- lingual topic θ is a semantically coherent multinomial distribution over all the words in the vo cabularies of languages L1, ..., Ls.</S>
			<S sid ="57" ssid = "9">That is, p(w|θ) would give the probability of a word w which can be in any of the s languages under consideration.</S>
			<S sid ="58" ssid = "10">θ is semantically coherent if it assigns high probabilities to words that are semantically related either in the same language or across different languages.</S>
			<S sid ="59" ssid = "11">different languages, we must rely on some kind of linguistic knowledge.</S>
			<S sid ="60" ssid = "12">Our PCLSA model assumes the availability of bilingual dictionaries for at least some language pairs, which are generally available for major language pairs.</S>
			<S sid ="61" ssid = "13">Specifically, for text data in languages L1, ..., Ls , if we represent each language as a node in a graph and connect those language pairs for which we have a bilingual dictionary, the minimum requirement is that the whole graph is connected.</S>
			<S sid ="62" ssid = "14">Thus, as a minimum, we will need s − 1 distinct bilingual dictio Clearly, we have ∑s ∈ cross-lingual topic θ.</S>
			<S sid ="63" ssid = "15">p(w|θ) = 1 for any naries.</S>
			<S sid ="64" ssid = "16">This is so that we can potentially cross all the language barriers.</S>
			<S sid ="65" ssid = "17">Definition 3 (Cross-Lingual Topic Extraction) Given a multilingual corpus C, the task of cross-lingual topic extraction is to model and extract k major cross-lingual topics {θ1, θ2, . . .</S>
			<S sid ="66" ssid = "18">, θk } from C, where θi is a cross-lingual topic, and k is a user specified parameter.</S>
			<S sid ="67" ssid = "19">The extracted cross-lingual topics can be directly used as a summary of the common content of the multilingual data set.</S>
			<S sid ="68" ssid = "20">Note that once a cross-lingual topic is extracted, we can easily obtain its representation in each language Li by “splitting” the cross-lingual topic into multiple word distributions in different languages.</S>
			<S sid ="69" ssid = "21">Formally, the word distribution of a cross-lingual topic θ in language Li is given by pi (wi |θ) = p(wi |θ) ∑ w∈Vi p(w|θ)These aligned language-specific word distribu tions can directly review the variations of topics in different languages.</S>
			<S sid ="70" ssid = "22">They can also be used to analyze the difference of the coverage of the same topic in different languages.</S>
			<S sid ="71" ssid = "23">Moreover, they are also useful for retrieving relevant articles or passages in each language and aligning them to the same common topic, thus essentially also allowing us to integrate and align articles in multiple languages.</S>
			<S sid ="72" ssid = "24">Our key idea is to “synchronize” the extraction of monolingual “component topics” of a cross- lingual topic from individual languages by forcing a cross-lingual topic word distribution to assign similar probabilities to words that are potential translations according to a LiLj bilingual dictionary.</S>
			<S sid ="73" ssid = "25">We achieve this by adding such preferences formally to the likelihood function of a probabilistic topic model as “soft constraints” so that when we estimate the model, we would try to not only fit the text data well (which is necessary to extract coherent component topics from each language), but also satisfy our specified preferences (which would ensure the extracted component topics in different languages are semantically related).</S>
			<S sid ="74" ssid = "26">Below we present how we implement this idea in more detail.</S>
			<S sid ="75" ssid = "27">A bilingual dictionary for languages Li and Lj generally would give us a many-to-many mapping between the vocabularies of the two languages.</S>
			<S sid ="76" ssid = "28">With such a mapping, we can construct a bipartite graph Gij = (Vij , Eij ) between the two languages where if one word can be potentially translated into another word, the two words would be connected with an edge.</S>
			<S sid ="77" ssid = "29">An edge can be weighted based on the probability of the corresponding translation.</S>
			<S sid ="78" ssid = "30">An example graph for ChineseEnglish dictionary is shown in Figure 1.</S>
			<S sid ="79" ssid = "31">Figure 1: A Dictionary based Word Graph With multiple bilingual dictionaries, we can merge the graphs to generate a multipartite graph G = (V, E).</S>
			<S sid ="80" ssid = "32">Based on this graph, the PCLSA model extends the standard PLSA by adding a constraint to the likelihood function to “smooth” the word distributions of topics in PLSA on the multipartite graph so that we would encourage the words that are connected in the graph (i.e. possible translations of each other) to be given similar probabilities by every cross-lingual topic.</S>
			<S sid ="81" ssid = "33">Thus when a cross-lingual topic picks up words that co- occur in monolingual text, it would prefer picking up word pairs whose translations in other languages also co-occur with each other, giving us a coherent multilingual word distribution that characterizes well the content of text in different languages.</S>
			<S sid ="82" ssid = "34">Specifically, let Θ = {θj } (j = 1, ..., k) be a set of k cross-lingual topic models to be discovered from a multilingual text data set with s languages such that p(w|θi ) is the probability of word w ac cording to the topic model θi . If we are to use the regular PLSA to model our data, we would have the following log-likelihood and we usually use a maximum likelihood estimator to estimate parameters and discover topics.</S>
			<S sid ="83" ssid = "35">is the degree of word u, i.e. the sum of the weights of all the edges ending with u. Intuitively, R(C) measures the difference between p(wu|θj ) and p(wv |θj ) for each pair (u, v) in a bilingual dictionary; the more they differ, the larger R(C) would be.</S>
			<S sid ="84" ssid = "36">So it can be regarded as a “loss function” to help us assess how well the “component word distributions” in multiple languages are correlated semantically.</S>
			<S sid ="85" ssid = "37">Clearly, we would like the extracted topics to have a smallR(C).</S>
			<S sid ="86" ssid = "38">We choose this specific form of loss func tion because it would make it convenient to solve the optimization problem of maximizing the corresponding regularized maximum likelihood (Mei et al., 2008b).</S>
			<S sid ="87" ssid = "39">The normalization with Deg(u) and Deg(v) can be regarded as a way to compensate for the potential ambiguity of u and v in their translations.</S>
			<S sid ="88" ssid = "40">Putting L(C) and R(C) together, we would like to maximize the following objective function which is a regularized log-likelihood: O(C, G) = (1 − λ)L(C) − λR(C) (1) where λ ∈ (0, 1) is a parameter to balance the likelihood and the regularizer.</S>
			<S sid ="89" ssid = "41">When λ = 0, we recover the standard PLSA.</S>
			<S sid ="90" ssid = "42">Specifically, we will search for a set of values for all our parameters that can maximize the objective function defined above.</S>
			<S sid ="91" ssid = "43">Our parameters include all the cross-lingual topics and the coverage distributions of the topics in all documents, which we denote by Ψ = {p(w|θj ), p(θj |d)}d,w,jwhere j = 1, ..., k, w varies over the entire vo cabularies of all the languages , d varies over all the documents in our collection.</S>
			<S sid ="92" ssid = "44">This optimization problem can be solved using a Generalized Expectation-Maximization (GEM) algorithm as described in (Mei et al., 2008a).</S>
			<S sid ="93" ssid = "45">s k L(C) = ∑ ∑ ∑ c(w, d) log ∑ p(θj |d)p(w|θj ) Specifically, in the E-step of the algorithm, the i=1 d∈Ci w j=1 distribution of hidden variables is computed using Eq. 2.Our main extension is to add to L(C) a cross lingual constraint term R(C) to incorporate theknowledge of bilingual dictionaries.</S>
			<S sid ="94" ssid = "46">R(C) is de fined as k z(w, d, j) = p(θj |d)p(w|θj ) j′ p(θj′ |d)p(w|θj′ ) (2) R( ) = 1 2 ∑ w(u, v) ∑( p(wu |θj ) Deg(u ) p(wv |θj ) )2 Deg(v) Then in the M step, we need to maximize the ⟨u,v⟩∈E j=1 complete data likelihood Q(Ψ; Ψn): where w(u, v) is the weight on the edge between u and v in the multipartite graph G = (V, E), which in our experiments is set to 1, and Deg(u) Q(Ψ; Ψn ) = (1 − λ)L′ (C) − λR(C) where L′ (C) = ∑ ∑ c(w, d) ∑ z(w, d, j) log p(θj |d)p(w|θj ), (3) d w j a simple segmenter1 to split the data into Chinese phrases.</S>
			<S sid ="95" ssid = "47">Both Chinese and English stopwords are removed from our data.</S>
			<S sid ="96" ssid = "48">The dictionary file we used for our PCLSA 2 with the constraints that ∑j p(θj |d) = 1 and ∑w p(w|θj ) = 1.</S>
			<S sid ="97" ssid = "49">There is a closed form solution if we only want to maximize the L′ (C) part:model is from mandarintools.com . For each Chi nese phrase, if it has several English meanings, we add an edge between it and each of its English translation.</S>
			<S sid ="98" ssid = "50">If one English translation is an English phrase, we add an edge between the Chinese phrase and each English word in the phrase.</S>
			<S sid ="99" ssid = "51">∑ c(w, d)z(w, d, j) p(n+1) (θj |d) = w ∑w ∑j′ c(w, d)z(w, d, j′ ) 5.2 Baseline.</S>
			<S sid ="100" ssid = "52">Method ∑ c(w, d)z(w, d, j) As a baseline method, we can apply the standard p(n+1) (w|θj ) = d (4) w c(w′ , d)z(w′ , d, j) PLSA (Hofmann, 1999a) directly to the multilingual corpus.</S>
			<S sid ="101" ssid = "53">Since PLSA takes advantage of However, there is no closed form solution in the M-step for the whole objective function.</S>
			<S sid ="102" ssid = "54">Fortunately, according to GEM we do not need to find the local maximum of Q(Ψ; Ψn ) in every M-step, and we only need to find a new value Ψn+1 to improve the complete data likelihood, i.e. to make sure Q(Ψn+1 ; Ψn ) ≥ Q(Ψn ; Ψn ).</S>
			<S sid ="103" ssid = "55">So our method is to first maximize the L′ (C) part using Eq. 4 and then use Eq. 5 to gradually increase the R(C) part.</S>
			<S sid ="104" ssid = "56">p(t+1) (wu |θj ) = (1 − α)p(t)(wu|θj ) (5) the word co-occurrences in the document level to find semantic topics, directly using it for a multilingual corpus will result in finding topics mainly reflecting a single language (because words in different languages would not co-occur in the same document in general).</S>
			<S sid ="105" ssid = "57">That is, the discovered topics are mostly monolingual.</S>
			<S sid ="106" ssid = "58">These monolingual topics can then be aligned based on a bilingual dictionary to suggest a possible cross-lingual topic.</S>
			<S sid ="107" ssid = "59">6 Experimental Results.</S>
			<S sid ="108" ssid = "60">6.1 Qualitative Comparison.</S>
			<S sid ="109" ssid = "61">+ α ∑ ⟨u,v⟩∈E w(u, v) Deg(v) p (t) (wv |θj ) To qualitatively compare PCLSA with the baseline method, we compare the word distributions of topics extracted by them.</S>
			<S sid ="110" ssid = "62">The data set we used in thisHere, parameter α is the length of each smooth ing step.</S>
			<S sid ="111" ssid = "63">Obviously, after each smoothing step, the sum of the probabilities of all the words in one topic is still equal to 1.</S>
			<S sid ="112" ssid = "64">We smooth the parameters until we cannot get a better parameter set Ψn+1 . Then, we continue to the next E-step.</S>
			<S sid ="113" ssid = "65">If there is no Ψn+1 s.t. Q(Ψn+1 ; Ψn) ≥ Q(Ψn; Ψn), then we consider Ψn to be the local maximum point of the objective function Eq. 1.</S>
	</SECTION>
	<SECTION title="Experiment Design. " number = "5">
			<S sid ="114" ssid = "1">5.1 Data Set.</S>
			<S sid ="115" ssid = "2">The data set we used in our experiment is collected from news articles of Xinhua English and Chinese newswires.</S>
			<S sid ="116" ssid = "3">The whole data set is quite big, containing around 40,000 articles in Chinese and 35,000 articles in English.</S>
			<S sid ="117" ssid = "4">For different purpose of our experiments, we randomly selected different number of documents from the whole corpus, and we will describe the concrete statistics in each experiment.</S>
			<S sid ="118" ssid = "5">To process the Chinese corpus, we use experiment is selected from the Xinhua News data during the period from Jun. 8th, 2001 to Jun. 15th, 2001.</S>
			<S sid ="119" ssid = "6">There are totally 1799 English articles and 1485 Chinese articles in the data set.</S>
			<S sid ="120" ssid = "7">The num-.</S>
			<S sid ="121" ssid = "8">ber of topics to be extracted is set to 10 for both methods.</S>
			<S sid ="122" ssid = "9">Table 1 shows the experimental results.</S>
			<S sid ="123" ssid = "10">To make it easier to understand, we add an English translation to each Chinese phrase in our results.</S>
			<S sid ="124" ssid = "11">The first ten rows show sample topics of the modeling results of traditional PLSA model.</S>
			<S sid ="125" ssid = "12">We can see that it only contains mono-language topics, i.e. the topics are either in Chinese or in English.</S>
			<S sid ="126" ssid = "13">The next ten rows are the results from our PCLSA model.</S>
			<S sid ="127" ssid = "14">Compared with the baseline method, PCLSA can not only find coherent topics from the cross-lingual corpus, but it can also show the content about one topic from both two language corpora.</S>
			<S sid ="128" ssid = "15">For example, in ’Topic 2’ 1 http://www.mandarintools.com/segmenter.html 2 http://www.mandarintools.com/cedict.html Table 2: Synthetic Data Set from Xinhua News En glis h S h r i n e 9 0 O l y m p i c 1 0 1 Ch am pio nsh ip 7 0 Chi nes e CP C An niv ers ary 9 5 Af gha n Wa r 2 0 6 Ch am pio nsh ip 7 2 which is about ’Israel’ and ’Palestinian’, the Chinese corpus mentions a lot about ’Arafat’ who is the leader of ’Palestinian’, while the English corpus discusses more on topics such as ’cease fire’ 6.3 Quantitative Evaluation.</S>
			<S sid ="129" ssid = "16">We also quantitatively evaluate how well our PCLSA model can discover common topics among corpus in different languages.</S>
			<S sid ="130" ssid = "17">We propose a “cross-collection” likelihood measure for this purpose.</S>
			<S sid ="131" ssid = "18">The basic idea is: suppose we got k cross-lingual topics from the whole corpus, then for each topic, we split the topic into two separate set of topics, English topics and Chinese topics, using the splitting formula described before, and ’women’.</S>
			<S sid ="132" ssid = "19">Similarly, in ’Topic 9’, the topic i.e. pi (wi |θ) = p(w |θ) . Then, we use the.</S>
			<S sid ="133" ssid = "20">is related to Philippine, the Chinese corpus mentions some environmental situation in Philippine, while the English corpus mentions a lot about ’Abu Sayyaf’.</S>
			<SUBSECTION>6.2 Discovering Common Topics.</SUBSECTION>
			<S sid ="134" ssid = "21">To demonstrate the ability of PCLSA for finding common topics in cross-lingual corpus, we use some event names, e.g. ’Shrine’ and ’Olympic’, as queries and randomly select a certain number of documents from the whole corpus, which are related to the queries.</S>
			<S sid ="135" ssid = "22">The number of documents for each query in the synthetic data set is shown in Table 2.</S>
			<S sid ="136" ssid = "23">In either the English corpus or the Chinese corpus, we select a smaller number of documents about topic ’Championship’ combined with the other two topics in the same corpus.</S>
			<S sid ="137" ssid = "24">In this way, when we want to extract two topics from either English or Chinese corpus, the ’Championship’ topic may not be easy to extract, because the other two topics have more documents in the corpus.</S>
			<S sid ="138" ssid = "25">However, when we use PCLSA to extract four topics from the two corpora together, we expect that the topic ’Championship’ will be found, because now the sum of English and Chinese documents related to ’Championship’ is larger than other topics.</S>
			<S sid ="139" ssid = "26">The experimental result is shown in Table 3.</S>
			<S sid ="140" ssid = "27">The first two columns are the two topics extracted from Engish corpus, the third and the forth columns are two topics from Chinese corpus, and the other four columns are the results from cross-lingual corpus.</S>
			<S sid ="141" ssid = "28">We can see that in either the Chinese sub- collection or the English sub-collection, the topic ’Championship’ is not extracted as a significant topic.</S>
			<S sid ="142" ssid = "29">But, as expected, the topic ’Championship’ is extracted from the cross-lingual corpus, while the topic ’Olympic’ and topic ’Shrine’ are merged together.</S>
			<S sid ="143" ssid = "30">This demonstrate that PCLSA is capable of extracting common topics from a cross-lingual corpus.</S>
			<S sid ="144" ssid = "31">w∈Vi p(w|θ) word distribution of the Chinese topics (translating the words into English) to fit the English Corpus and use the word distribution of the English topics (translating the words into Chinese) to fit the Chinese Corpus.</S>
			<S sid ="145" ssid = "32">If the topics mined are common topics in the whole corpus, then such a “cross- collection” likelihood should be larger than those topics which are not commonly shared by the English and the Chinese corpus.</S>
			<S sid ="146" ssid = "33">To calculate the likelihood of fitness, we use the folding-in method proposed in (Hofmann, 2001).</S>
			<S sid ="147" ssid = "34">To translate topics from one language to another, e.g. Chinese to English, we look up the bilingual dictionary and do word-to-word translation.</S>
			<S sid ="148" ssid = "35">If one Chinese word has several English translations, we simply distribute its probability mass equally to each English translation.</S>
			<S sid ="149" ssid = "36">For comparison, we use the standard PLSA model as the baseline.</S>
			<S sid ="150" ssid = "37">Basically, suppose PLSA mined k semantic topics in the Chinese corpus and k semantic topics in the English corpus.</S>
			<S sid ="151" ssid = "38">Then, we also use the “cross-collection” likelihood measure to see how well those k semantic Chinese topics fit the English corpus and those k semantic English topics fit the Chinese corpus.</S>
			<S sid ="152" ssid = "39">We totally collect three data sets to compare the performance.</S>
			<S sid ="153" ssid = "40">For the first data set, (English 1, Chinese 1), both the Chinese and English corpus are chosen from the Xinhua News Data during the period from 2001.06.08 to 2001.06.15, which has 1799 English articles and 1485 Chinese articles.</S>
			<S sid ="154" ssid = "41">For the second data set, (English 2, Chinese 2), the Chinese corpus Chinese 2 is the same as Chinese 1, but the English corpus is chosen from 2001.06.14 to 2001.06.19 which has 1547 documents.</S>
			<S sid ="155" ssid = "42">For the third data set, (English 3, Chinese 3), the Chinese corpus is the same as in data set one, but the English corpus is chosen from 2001.10.02 to 2001.10.07 which contains 1530 documents.</S>
			<S sid ="156" ssid = "43">In other words, in the first data set, Table 1: Qualitative Evaluation T o p i c 0 T o p i c 1 T o p i c 2 T o p i c 3 T o pi c 4 T o p i c 5 Top ic 6 T o p i c 7 Topi c 8 To pic 9 ( p a r t y ) (c o m m un ist ) $ \ W ( r e v o l u t i o n ) (p art y me m be r) ; ! ; ( c e n t r a l ) ( i s m ) T t r ( c a d r e ) =E �f(ch airma n mao) (chinese commu nist) f f i @ ( l e a d e r ) � ( c r i m e ) � (a gr ic ul tu re ) J J W ( t r a v e l ) �( hea the ndo m) 0$.:( public securi ty) ( n a m e ) � ( c a s e ) (law enforce ment) r n ( c i t y ) ; £ t f r J ( p e n a l i z e ) � : f .</S>
			<S sid ="157" ssid = "44">( a t h l e t e ) J a ( c h a m p i o n ) t�(ch ampion ship) ( b a s e ) B=E (bad mint on) l f ( s p o r t s ) j \ : � ( f i n a l ) ( w o m e n ) � J t ( c h e s s ) � : 5 t ( f i t n e s s ) ( p a l e s t i n e ) l w:\:(pal estine) � e J &apos;( is ra el ) 1f( cea se fire ) ( U N ) � f( mi d ea st) (leb ano n) (mac edon) $ * ( c o n fl i c t) l k ( t a l k ) f(colla boration ) _t.�( shang hai) :K � (re lat io n) (bilat eral) W &amp; ( t r a d e ) �(pr eside nt) ( c o u n t r y ) 0 (fr ien dl y) f t ( m e e t )�� w(rus sia) �l f(e duc atio n) ( b a l l ) � ( l e a g u e ) ( s o c c e r ) :: 5 $ ( m i n u t e ) (team member ) � fl J( te a c h e r) (sc hoo l) ( t e a m ) E f ( g r a d e A ) i s r a e l p al es ti ni a n e u p o l i c e r e p o r t s e c u r e k i l l e u r o p e e g y p t t r e a t y b t b e a t f i n a l c h a m p i o n s h i p p l a y c h a m p i o n w i n o l y m p i c g a m e c u p d o l l a r p e r c e n t m il li o n i n d e x s t o c k p o i n t s h a r e c l o s e 0 b i l l i o n c h i n a c o o p e r a t e s h a n g h a i d e v e l o p b e i j e p a r t i c u l a t e m a t t e r s c o i n v e s t p r o j e c t ( b i l a t e r a l ) f (c ol la b or at io n) l k ( t a l k ) 0 ( f r i e n d l y ) ( p a l e s t i n e ) c o u n t r y ( U N ) f f i @ ( l e a d e r ) b i l a t e r a l s t a t e � ( l e a g u e ) ( n a m e ) ( b a l l ) ( s h e n h u a ) ( h o s t ) A b a l l � ( j i n d e ) � * ( s e a s o n ) ( p l a y e r ) i s r a e l � e J &apos; ( i s r a e l ) b t p a l e s t i n i a n c e a s e f i r e ii � (a ra fa t) w o m e n j e r u s a l e m m i d e a s t l e b a n o n c o o p e r a t e s c o d e v e l o p c o u n t r y p r e s i d e n t a p e c s h a n g h a i a f r i c a m e e t � �(zemi n jiang) � :f .( at h le te ) p a r t i c u l a t e J a a t h l e t e c h a m p i o n i i � J t ( c h e s s ) c o m p e t i t i o n c o n t e s t a n t 1(gy mnast ics) p a r t y ( p a r t y ) c o m m u n i s t r e v o l u t i o n( is m ) J L S (a nt i w ar ) f P � (c o m ra de ) $\ W(re volu tion) (p ar ty ) i d e o l o g y e u k h a t a m i i r e l a n d (ireland ) el ec t vo te pr esi de nti al cp c ira n ref er en du m i n v e s t (in ve st m en t) J t ( b i l l i o n ) � l f ( e d u c a ti o n ) (enviro n. protect.)</S>
			<S sid ="158" ssid = "45">� ( m o n e y ) ( s c h o o l ) m a r k e t � f l J ( t e a c h e r ) b u s i n e s s 0 d o ll a r p e r c e n t i n d e x m il li o n s t o c k b il li o n p o i n t i- (billion) s h a r e IJ, A( abs orb ) l (abu) l (pa rtic le) phi lip pin e abu ( b a s e ) I I I t f o ( o b j e c t ) Table 3: Effectiveness of Extracting Common Topics Engli sh 1 En glis h 2 C h i n e s e 1 C hi ne se 2 C r o s s 1 C r o s s 2 C r o s s 3 C r o s s 4 japa n shri ne visit koiz umi yas uku ni war aug ust asia cri min al ii o l y m p i c i o c b e i j e g a m e j u l y b i d s w i m v o t e cha mpi onsh ip com mitt ee ( C P C ) ( c h a m p i o n s h i p ) i t !</S>
			<S sid ="159" ssid = "46">( w o r l d ) &apos; i § � ( t h o u g h t ) ( t h e o r y ) 5 &apos; i § ( m a r x ) W J c ( s w i m ) t� (cha mpio nship ) ( p a r t y ) } !</S>
			<S sid ="160" ssid = "47">( f o u n d p a r t y ) &apos;i&apos;tf (afgh an) ( t a l i b a n ) ;f Jj} (ta lib an ) (mi litar y) 1( atta ck) � (US army ) f t ( l a d e n ) t r ( a r m y ) � �( bo mb) $ (ka bul) k o i z u m i y a s u k u n i i o c j a p a n o l y m p i c b e i j e s h r i n e v i s i t (ol y m pi c) ;\%\/l 5(ol ympi c) ;fJ j}(t ali ban ) (mil itary ) c i t y r e f u g e e s i d e � (US army ) � � (b o m b) $ (kab ul) (at ta ck ) 1&lt; �(r efu gee) s w i m ( c h a m p i o n s h i p ) § E i 3 J c ( f r e e s t y l e ) l f ; J &lt; ( d i v i n g ) t� (cha mpio nship ) � j \ : � ( s e m i fi n a l) c o m p e t i t i o n W J c ( s w i m ) � ( r e c o r d ) � � �( xu eju an luo ) I ( w o r k e r ) p a r t y � 1 &apos; ( t h r e e ) 5 &apos; i § ( m a r x ) c o m m u n i s t m a r x t h e o r y }!</S>
			<S sid ="161" ssid = "48">(foun d party ) ( C P C ) r e v o l u t i o n the English corpus and Chinese corpus are comparable with each other, because they cover similar events during the same period.</S>
			<S sid ="162" ssid = "49">In the second data set, the English and Chinese corpora share some common topics during the overlap period.</S>
			<S sid ="163" ssid = "50">The third data is the most tough one since the two corpora are from different periods.</S>
			<S sid ="164" ssid = "51">The purpose of using these three different data sets for evaluation is to test how well PCLSA can mine common topics from either a data set where the English corpus and the Chinese corpus are comparable or a data set where the English corpus and the Chinese corpus rarely share common topics.</S>
			<S sid ="165" ssid = "52">The experimental results are shown in Table 4.</S>
			<S sid ="166" ssid = "53">Each row shows the “cross-collection” likelihood of using the “cross-collection” topics to fit the data set named in the first column.</S>
			<S sid ="167" ssid = "54">For example, in the first row, the values are the “cross-collection” likelihood of using Chinese topics found by different methods from the first data set to fit English 1.</S>
			<S sid ="168" ssid = "55">The last collum shows how much improvement we got from PCLSA compared with PLSA.</S>
			<S sid ="169" ssid = "56">From the results, we can see that in all the data sets, our PCLSA has higher “cross-collection” likelihood value, which means it can find better common topics compared to the baseline method.</S>
			<S sid ="170" ssid = "57">Notice that the Chinese corpora are the same in all three data sets.</S>
			<S sid ="171" ssid = "58">The results show that both PCLSA and PLSA get lower “cross-collection” likelihood for fitting the Chinese corpora when the data set becomes “tougher”, i.e. less topic overlapping, but the im Table 4: Quantitative Evaluation of Common Topic Finding (“cross-collection” log-likelihood) P C L S A P L S A Rel.</S>
			<S sid ="172" ssid = "59">Imp rv.</S>
			<S sid ="173" ssid = "60">En glis h 1 2.8 629 4E +06 3.0 317 6E +06 5 . 6 % Chi nes e 1 4.6 998 9E +06 4.8 536 9E +06 3 . 2 % En glis h 2 2.4 817 4E +06 2.6 080 5E +06 4 . 8 % Chi nes e 2 4.7 321 8E +06 4.8 890 6E +06 3 . 2 % En glis h 3 2.4 471 4E +06 2.6 054 0E +06 6 . 1 % Chi nes e 3 4.7 963 9E +06 4.9 427 3E +06 3 . 0 % provement of PCLSA over PLSA does not drop much.</S>
			<S sid ="174" ssid = "61">On the other hand, the improvement of PCLSA over PLSA on the three English corpora does not show any correlation with the difficulty of the data set.</S>
			<SUBSECTION>6.4 Extracting from Multi-Language Corpus.</SUBSECTION>
			<S sid ="175" ssid = "62">In the previous experiments, we have shown the capability and effectiveness of the PCLSA model in latent topic extraction from two language corpora.</S>
			<S sid ="176" ssid = "63">In fact, the proposed model is general and capable of extracting latent topics from multi- language corpus.</S>
			<S sid ="177" ssid = "64">For example, if we have dictionaries among multiple languages, we can construct a multipartite graph based on the correspondence between those vocabularies, and then smooth the PCLSA model with this graph.</S>
			<S sid ="178" ssid = "65">To show the effectiveness of PCLSA in mining multiple language corpus, we first construct a simulated data set based on 1115 reviews of three brands of laptops, namely IBM (303), Apple(468) and DELL(344).</S>
			<S sid ="179" ssid = "66">To simulate a three language cor Table 5: Effectiveness of Latent Topic Extraction from Multi-Language Corpus To pic 0 T o pi c 1 To pic 2 T o pi c 3 T o p i c 4 To pi c 5 To pi c 6 To pic 7 cd(ap ple) port( apple ) drive (appl e) airpo rt(ap ple) firew ire(a pple) dvd( apple ) usb(a pple) rw(a pple) card( apple ) mous e(app le) b at te ry (d el l) d r i v e ( d e l l ) 82 00 (d ell ) in sp ir on (d ell ) sy st e m (d ell ) ho ur (d ell ) so un d( de ll) de ll( de ll) se rv ic e( de ll) lif e( de ll) mous e(dell ) butto n(dell ) touch pad(d ell) pad(d ell) keybo ard(d ell) point( dell) stick( dell) rest(d ell) touch (dell) erase( dell) prin t(ap ple) reso luti on( dell ) burn (app le) nor mal (del l) ima ge(d ell) digi tal(a pple ) orga nize (app le) cds( appl e) latc h(ap ple) adv ertis e(de ll) po rt( ib m) ca rd (ib m) m od e m( ib m) di sp la y(i b m) bu ilt (ib m) sw ap (ib m) ea sy (ib m) co nn ec tor (ib m) fe at ur e(i b m) cd (ib m) lapt op(i bm) t20( ibm ) thin kpa d(ib m) batt ery( ibm ) note boo k(ib m) ibm (ib m) 3 ( i b m ) f e e l ( i b m ) h o u r ( i b m ) h i g h ( i b m ) o s ( a p p l e ) r u n ( a p p l e ) 1(a ppl e) ra m( app le) ma c(a ppl e) batt ery (ap ple ) hou r(a ppl e) 12( app le) ope rate (ap ple) wor d(a ppl e) p or t( d el l) 2 ( d e l l ) u s b ( d e ll ) 1 ( d e l l ) 0(del l) slot(d ell) firewi re(de ll) displ ay(de ll) stand ard(d ell) fast(d ell) osx(a pple) memo ry(del l) specia l(dell) crucia l(dell) memo ry(ap ple) memo ry(ib m) netsca pe(ap ple) resell er(app le) 1 0 ( d e l l ) speci al(ap ple) apple work( apple) file(ap ple) bounc e(appl e) quit(a pple) word( apple) file(ib m) file(de ll) micr osoft (appl e) ms(a pple) excel (appl e) port(d ell) port(a pple) port(i bm) firewi re(app le) imac( apple) firewi re(del l) firewi re(ib m) jack(a pple) playb ack(d ell) jack(d ell) bat ter y( del l) bat ter y(i b m) bat ter y( ap ple ) ge for ce 4( del l) 100 mhz (app le) 4 4 0 ( d e l l ) b u s ( a p p l e ) 8 2 0 0 ( d e l l ) 8 1 0 0 ( d e l l ) c hi ps et (d el l) l i g h t e s t ( i b m ) q u a l i t y ( d e l l ) y e a r ( i b m ) h a s s l e ( i b m ) b a n i a ( d e l l ) 800m hz(ap ple) trackp ad(ap ple) cover( ibm) work mans hip(de ll) sectio n(appl e) uxga( dell) ultras harp( dell) displa y(dell ) organi ze(ap ple) learn( apple) logo(a pple) postsc ript(a pple) ll(app le) sxga( dell) warm (apple ) light (ibm ) ultra bay(i bm) conn ector (ibm ) dvd( ibm) nice( ibm) mod em(i bm) conn ector (dell ) light (appl e) light (dell ) flopp y(ib m) batter y(appl e) point( dell) touch pad(d ell) button (dell) hour( apple) batter y(ibm ) batter y(dell ) fan(de ll) erase( dell) point( apple) 2 0 0 0( ib m ) wind ow(i bm) 20 00( app le) 2000( dell) wind ow(a pple) wind ow(d ell) porte ge(ib m) optio n(ib m) hassl e(ibm ) devic e(ibm ) ra m (a p pl e) ra m (i b m ) ra m (d el l) sc re en (a p pl e) 1 ( a p p l e ) s c r e e n ( i b m ) s c r e e n ( d e l l ) 1 ( i b m ) 1 ( d e l l ) m ac o( a p pl e) po rt( de ll) po rt( ap pl e) po rt( ib m ) 2 ( d e l l ) 2 ( a p p l e ) 2(ib m) spea k(de ll) tosh iba( dell ) spea k(ib m) tosh iba( ibm ) itune( apple) apple work( apple) imovi e(appl e) impor t(appl e) batter y(appl e) iphoto (apple ) batter y(ibm ) batter y(dell ) hour( apple) hour(i bm) ux ga (d ell ) sc re en (d ell ) sc re en (ib m) sc re en (a pp le) ult ra sh ar p( de ll) 160 0x1 200 (del l) dis pla y(d ell) dis pla y(a ppl e) dis pla y(ib m) vie w(d ell) port (app le) port (ib m) port (del l) usb( appl e) plug (app le) cord (app le) usb( ibm ) usb( dell ) fire wire (app le) plug (ib m) pentiu m(del l) proce ssor(d ell) p4(del l) power (dell) pentiu m(app le) pentiu m(ib m) keybo ard(de ll) proce ssor(i bm) proce ssor(a pple) power (apple ) driv e(ib m) driv e(d ell) driv e(a ppl e) har d(i bm ) osx (ap ple) har d(d ell) har d(a ppl e) car d(i bm ) dvd (ib m) car d(d ell) pus, we use an ’IBM’ word, an ’Apple’ word, and a ’Dell’ word to replace an English word in their corpus.</S>
			<S sid ="180" ssid = "67">For example, we use ’IBM10’, ’Apple10’, ’Dell10’ to replace the word ’CD’ whenever it appears in an IBM’s, Apple’s, or Dell’s review.</S>
			<S sid ="181" ssid = "68">After the replacement, the reviews about IBM, Apple, and Dell will not share vocabularies with each other.</S>
			<S sid ="182" ssid = "69">On the other hand, for any three created words which represent the same English word, we add three edges among them, and therefore we get a simulated dictionary graph for our PCLSA model.</S>
			<S sid ="183" ssid = "70">The experimental result is shown in Table 5, in which we try to extract 8 topics from the cross- lingual corpus.</S>
			<S sid ="184" ssid = "71">The first ten rows show the result of our PCLSA model, in which we set a very small value to the weight parameter λ for the regularizer part.</S>
			<S sid ="185" ssid = "72">This can be used as an approximation of the result from the traditional PLSA model on this three language corpus.</S>
			<S sid ="186" ssid = "73">We can see that the extracted topics are mainly written in mono- language.</S>
			<S sid ="187" ssid = "74">As we set the value of parameter λ larger, the extracted topics become multilingual, which is shown in the next ten rows.</S>
			<S sid ="188" ssid = "75">From this result, we can see the difference between the reviews of different brands about the similar topic.</S>
			<S sid ="189" ssid = "76">In addition, if we set the λ even larger, we will get topics that are mostly made of the same words from the three different brands, which means the extracted topics are very smooth on the dictionary graph now.</S>
			<S sid ="190" ssid = "77">7 Conclusion.</S>
			<S sid ="191" ssid = "78">In this paper, we study the problem of cross- lingual latent topic extraction where the task is to extract a set of common latent topics from multilingual text data.</S>
			<S sid ="192" ssid = "79">We propose a novel probabilistic topic model (i.e. the Probabilistic Cross-Lingual Latent Semantic Analysis (PCLSA) model) that can incorporate translation knowledge in bilingual dictionaries as a regularizer to constrain the parameter estimation so that the learned topic models would be synchronized in multiple languages.</S>
			<S sid ="193" ssid = "80">We evaluated the model using several data sets.</S>
			<S sid ="194" ssid = "81">The experimental results show that PCLSA is effective in extracting common latent topics from multilingual text data, and it outperforms the baseline method which uses the standard PLSA to fit each monolingual text data set.</S>
			<S sid ="195" ssid = "82">Our work opens up some interesting future research directions to further explore.</S>
			<S sid ="196" ssid = "83">First, in this paper, we have only experimented with uniform weighting of edge in the bilingual graph.</S>
			<S sid ="197" ssid = "84">It should be very interesting to explore how to assign weights to the edges and study whether weighted graphs can further improve performance.</S>
			<S sid ="198" ssid = "85">Second, it would also be interesting to further extend PCLSA to accommodate discovering topics in each language that aren’t well-aligned with other languages.</S>
			<S sid ="199" ssid = "86">8 Acknowledgments.</S>
			<S sid ="200" ssid = "87">We sincerely thank the anonymous reviewers for their comprehensive and constructive comments.</S>
			<S sid ="201" ssid = "88">The work was supported in part by NASA grant NNX08AC35A, by the National Science Foundation under Grant Numbers IIS0713581, IIS 0713571, and CNS0834709, and by a Sloan Research Fellowship.</S>
	</SECTION>
</PAPER>
