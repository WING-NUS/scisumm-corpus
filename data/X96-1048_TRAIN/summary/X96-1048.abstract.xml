	<ABSTRACT>
	<S sid="0">OVERVIEW OF RESULTS OF THE MUC-6 EVALUATION</S>
			<S sid ="2" ssid = "2">The latest in a series of natural language processing system evaluations was concluded in October 1995 and was the topic of the Sixth Message Understanding Conference (MUC6) in November.</S>
			<S sid ="3" ssid = "3">Participants were invited to enter their systems in as many as four different task-oriented evaluations.</S>
			<S sid ="4" ssid = "4">The Named Entity and Coreference tasks entailed Standard Generalized Markup Language (SGML) annotation of texts and were being conducted for the first time.</S>
			<S sid ="5" ssid = "5">The other two tasks, Template Element and Scenario Template, were information extraction tasks that followed on from the MUC evaluations conducted in previous years.</S>
			<S sid ="6" ssid = "6">The evolution and design of the MUC6 evaluation are discussed in the paper by Grishman and Sundheim in this volume.</S>
			<S sid ="7" ssid = "7">All except the Scenario Template task are defined independently of any particular domain.</S>
			<S sid ="8" ssid = "8">This paper surveys the results of the evaluation on each task and, to a more limited extent, across tasks.</S>
			<S sid ="9" ssid = "9">Discussion of the results for each task is organized generally under the following topics: • Results on task as whole; • Results on some aspects of task; • Performance on &quot;walkthrough article.&quot;</S>
			<S sid ="10" ssid = "10">The walkthrough article is an article selected from the test set.</S>
			<S sid ="11" ssid = "11">Participants were asked to analyze their system&apos;s performance on that article and comment on it in their presentations and papers.</S>
				</ABSTRACT>
