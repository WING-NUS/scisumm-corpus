Finite-State Registered  Automata
for Non-Concatenative Morphology





Yael Cohen-Sygal∗
University of Haifa


Shuly Wintner†
University of Haifa



Abstract

We introduce finite-state registered automata (FSRAs), a new computational  device within the 
framework of finite-state  technology, specifically tailored for implementing  non-concatenative 
morphological processes.  This model extends  and augments existing finite-state  techniques, 
which are presently not optimized for describing this kind of phenomena. We first define the 
model and discuss its mathematical and computational properties. Then, we provide an extended 
regular language whose expressions denote FSRAs. Finally, we exemplify the utility of the model 
by providing several examples of complex morphological  and phonological phenomena, which are 
elegantly implemented with FSRAs.

1. Introduction

Finite-state (FS) technology has been  considered adequate for describing the morpho- 
logical processes of the world’s languages since the pioneering works  of Koskenniemi 
(1983) and  Kaplan  and  Kay (1994). Several toolboxes  provide extended regular expres- 
sion  description languages and  compilers of the  expressions to finite-state automata 
(FSAs) and  transducers (FSTs) (Karttunen et al. 1996; Mohri  1996; van Noord and 
Gerdemann 2001a). While FS approaches to most natural languages have generally been 
very successful, it is widely recognized that they are less suitable for non-concatenative 
phenomena; in particular, FS techniques are assumed not to be able to efficiently account 
for  the  non-concatenative word formation processes that  Semitic  languages  exhibit 
(Lavie et al. 1988).
    While  much  of the  inflectional morphology  of Semitic  languages can  be  rather 
straightforwardly described using  concatenation as the  primary operation, the  main 
word formation process  in such  languages is inherently non-concatenative. The stan- 
dard account describes words in Semitic languages as combinations of two morphemes: 
a root and  a pattern.1 The root consists  of consonants only, by default three  (although 
longer  roots  are  known). The pattern is a combination of vowels  and,  possibly, con- 
sonants too,  with  “slots”  into  which  the  root  consonants can  be inserted. Words  are 
created by interdigitating roots into patterns: The first consonant of the root is inserted 
into the first consonantal slot of the pattern, the second  root consonant fills the second 
slot,  and  the  third  fills the  last  slot.  After  the  root  combines with  the  pattern, some



∗ Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: yaelc@cs.haifa.ac.il.
†  Department of Computer Science, University of Haifa, 31905 Haifa, Israel. E-mail: shuly@cs.haifa.ac.il.
1 An additional morpheme, vocalization, is used  to abstract the pattern further; for the present purposes,
this distinction is irrelevant.

Submission received:  17 August 2004; revised submission received:  15 June 2005; accepted for publication: 26
September 2005.



© 2006 Association for Computational Linguistics



















Figure 1
Na¨ıve FSA with duplicated paths.



morpho-phonological alternations take place, which  may be non-trivial but are mostly 
concatenative.
    The major problem that we tackle in this work  is medium-distance dependencies, 
whereby some elements that are related to each other in some deep-level representation 
(e.g., the consonants of the root) are separated on the surface.  While these  phenomena 
do not lie outside the descriptive power of FS systems, na¨ıvely  implementing them  in 
existing  finite-state calculi is either  impossible or, at best, results in large networks that 
are inefficient  to process,  as the following examples demonstrate.

Example 1
We begin with a simplified problem, namely accounting for circumfixes.  Consider three 
Hebrew patterns: haDDaDa, hitDaDaDut, and  miDDaD, where the empty boxes indi- 
cate the slots in the patterns into which the consonants of the roots are inserted. Hebrew 
orthography2 dictates that these patterns be written hDDDa,  htDDDut, and mDDD, re- 
spectively, i.e., the consonants are inserted into the ‘D’ slots as one unit (i.e., the patterns 
can be viewed as circumfixes). An automaton that accepts all the possible  combinations 
of three-consonant stems and these three circumfixes is illustrated in Figure  1.3 Given r 
stems  and  p circumfixes,  the number of its states  is (2r + 2)p + 2, i.e., increases linearly 
with  the  number of stems  and  circumfixes.  The number of arcs  in this  automaton is
3rp + 2p, i.e, also O(rp). Evidently, the three  basic different paths  that  result  from  the 
three  circumfixes have  the same  body,  which  encodes the stems.  An attempt to avoid 
the duplication of paths  is represented by the automaton of Figure  2, which  accepts the 
language denoted by the regular expression (ht + h + m)(root)(ut + a + E). The number 
of states  here  is 2r + 4, i.e., is independent of the number of circumfixes.  The number 
of arcs is (3r + 2p), that  is, O(r + p), and  thus,  the complexity of the number of arcs is 
also reduced. Obviously, however, such an automaton over-generates by accepting also 
invalid words such as mDDDut. In other words, it ignores  the dependencies which hold 
between prefixes  and  suffixes of the same  circumfix.  Since finite-state devices  have  no



2 Many of the vowels  are not explicitly  depicted in the Hebrew script.
3 This is an over-simplified example;  in practice,  the process  of combining roots with patterns is highly 
idiosyncratic, like other  derivational morphological processes.


50










Figure 2
Over-generating FSA.


memory, save  for the states,  there  is no simple  and  space-efficient way  to account for 
such dependencies.

Example 2
Consider now a representation of Hebrew where all vowels  are explicit, e.g., the pattern 
hitDaDeD. Consider also the roots r.g.z, b.$.l, and  g.b.r. The consonants of a given root 
are inserted into the ‘D’ slots to obtain bases such as hitragez, hitba$el, and hitgaber. The 
finite state automaton of Figure  3 is the minimized automaton accepting the language; 
it has  fifteen  states.  If the number of three  letter  roots  is r, then  a general automaton 
accepting the combinations of the roots with this pattern will have 4r + 3 states and 5r +
1 arcs. Notice  the duplicated arcs which  stem from copying the pattern in the different 
paths.

Example 3
Another non-concatenative process  is reduplication: The process  in which a morpheme 
or part  of it is duplicated. Full reduplication is used  as a pluralization process  in Malay 
and  Indonesian; partial reduplication is found in Chamorro to indicate intensivity. It 
can also be found in Hebrew as a diminutive formation of nouns and adjectives:

kel
eb
kl
ab
la
b
$a
pa
n
$p
an
pa
n
z
a
q
a
n
zq
an
qa
n
$
a
x
o
r
$x
ar
xa
r
dog
pu
pp
y
ra
bb
it
bu
nn
y
b
e
a
r
d
go
at
ee
bl
a
c
k
da
rk
qa
ta
n 
litt
le
q
ta
n
ta
n 
ti
n
y







Let  Σ be  a  finite  alphabet. The  language  L = {ww | w ∈ Σ∗}  is  known to  be
trans-regular, therefore no  finite-state automaton  accepts  it. However, the  language
Ln = {ww | w ∈ Σ∗, |w| = n} for some  constant n is regular. Recognizing Ln  is a finite
approximation of the  general problem of recognizing L. The length  of the  words in 
natural languages can  in most  cases  be bounded by  some  n ∈ N, hence  the  amount
of reduplication in natural languages is practically limited. Therefore, the descriptive 
power of Ln  is sufficient  for  the  amount of reduplication in  natural languages (by








Figure 3
FSA for the pattern hitDaDeD.


51





constructing Ln for a small  number of different ns). An automaton that  accepts  Ln can 
be constructed by listing  a path  for each accepted string  (since Σ and  n are finite, the 
number of words in  Ln  is finite).  The  main  drawback of such  an  automaton is the
growth in its size as |Σ| and n increase:  The number of strings  in Ln is |Σ n . Thus, finite-
state  techniques can account for limited reduplication, but  the resulting networks are
space-inefficient.
    As a final, non-linguistic, motivating example, consider the problem of n-bit incre- 
mentation, introduced by Kornai (1996).

Example 4
The goal of this example is to construct a transducer over  Σ = {0, 1} whose  input is a
32 bit  binary number and  whose  output is  the  result  of  adding 1 to  the  input.  A
transducer that performs addition by 1 on binary numbers has only 5 states and 12 arcs,4 
but this transducer is neither sequential nor sequentiable. The problem is that since the 
input is scanned left to right  but the carry moves  right  to left, the output of the first bit 
has to be delayed, possibly even  until  the last input bit is scanned. Thus,  for an n-bit 
binary incrementor, 2n disjunctions have  to be considered, and  therefore a minimized 
transducer has  to assign  a separate state  to each  combination of bits,  resulting in 2n 
states and a similar  number of transitions.

    In  this  work  we  propose a  novel  FS model  which  facilitates  the  expression  of 
medium-distance dependencies such as interdigitation and reduplication in an efficient 
way.  Our  main  motivation is theoretical, i.e., reducing the  complexity of the  number 
of states  and  arcs in the networks; we show  that  these  theoretical contributions result 
in practical improvements. In Section  3 we define  the model  formally, show  that  it is 
equivalent to FSAs and  define  many  closure  properties directly.5 We then  (Section  4) 
define a regular expression language for denoting FSRAs. In Section 5 we provide dedi- 
cated  regular expression operators for some non-concatenative phenomena and  exem- 
plify the usefulness of the model  by efficiently accounting for the motivating examples. 
In Section 6 we extend  FSRAs to transducers. The model  is evaluated through an actual 
implementation in Section 7. We conclude with suggestions for future research.


2. Related Work

In spite of the common view that FS technology is in general inadequate for describing 
non-concatenative processes, several  works  address the above-mentioned problems in 
various ways. We summarize existing  approaches in this section.
    Several works  examine the applicability of traditional two-level systems for imple- 
menting non-concatenative morphology. Two-Level  Morphology was  used  by Kataja 
and Koskenniemi (1988) to create a rule system  for phonological and morphophonolog- 
ical alternations in Akkadian, accounting for word inflection  and regular verbal deriva- 
tion. As this solution effectively  defines  lexical representations of word-forms, its main 
disadvantage is that  the final network is the na¨ıve  one, suffering from  the space  com- 
plexity  problems discussed above. Lavie et al. (1988) examine the applicability of Two-



4 A complete explanation of the construction can be found in http://www.xrce.xerox.com/competencies/
content-analysis/fsCompiler/fsexamples.html#Add1.
5 Many of the formal  proofs  and constructions, especially the ones that are similar  to the case of standard
FSAs, are suppressed; see Cohen-Sygal (2004) for the complete proofs  and constructions.


52





Level Morphology to the description of Hebrew Morphology, and  in particular to verb 
inflection.  Their lexicon consists of three parts: verb primary bases (the past tense, third 
person, singular, masculine), verb prefixes,  and  verb suffixes. They attempt to describe 
Hebrew verb inflection  as a concatenation of prefix+base+suffix, implementable by the 
Two-Level model. However, they conclude that “The Two-Level rules are not the natural 
way to describe ... verb inflection  process.  The only alternative choice ... is to keep all 
bases ... it seems wasteful to save all the secondary bases of verbs of the same pattern.” 
Other  works  deal with non-concatenative morphology by extending ordinary FSAs 
without extending their  expressivity. The traditional two-level model  of Koskenniemi 
(1983) is expanded into n-tape  automata by Kiraz (2000), following the insight of Kay 
(1987) and  Kataja and  Koskenniemi (1988). The idea  is to use more  than  two  levels of 
expression: The surface  level employs one representation, but the lexical form employs 
multiple representations (e.g., root, pattern) and therefore can be divided into different 
levels, one for each representation. Elements that are separated on the surface  (such as 
the root’s consonants) are adjacent on a particular lexical level. For example, to describe
circumfixation using  this model,  a 4-tape  automaton of the form  (surface,  PR pattern, 
circumfix, stem⊕ is constructed, so that each word is represented by 4 levels. The surface
level  represents the  final  form  of the  word. The  PR pattern is the  pattern in which
the  stem  and  the  circumfix  are  combined (P represents the  circumfix’s  position and 
R the root  letter ’s position), e.g., PRRRP. The circumfix  and  stem  levels represent the 
circumfix  and the stem respectively.
    For example, combining the Hebrew stem  pqd  with  the circumfix  ht-ut  will have 
the 4-level representation shown in Figure  4. Notice  that  the symbols  representing the 
circumfix  in the PR pattern level (i.e., the occurrences of the symbol  ‘P’), the circumfix 
symbols  in the circumfix level, and the circumfix symbols in the surface level are located 
in correlating places  in the  different levels.  The same  holds  for the  stem  symbols. In 
this way,  it is clear which  symbols  of the surface  word belong  to the circumfix,  which 
belong  to the stem, and how they combine together to create the final form of the word. 
The 4-tape automaton of Figure  5 accepts  all the combinations created by circumfixing 
roots with the three circumfixes of Example  1. Each arc is attributed with a quadruplet, 
consisting of four correlating symbols  in the four levels. Notice that as in FSAs, the paths 
encoding the roots are duplicated for each circumfix, so that this automaton is as space- 
inefficient  as ordinary FSAs. Kiraz (2000) does not discuss  the space complexity of this 
model,  but  the number of states  still seems  to increase  with  the number of roots  and 
patterns. Moreover, the  n-tape  model  requires specification of dependencies between 
symbols  in different levels, which  may be non-trivial.
   Walther (2000a) suggests a solution for describing natural language reduplication 
using  finite-state methods. The idea  is to enrich  finite-state automata with  three  new 
operations: repeat,  skip, and  self loops.  Repeat arcs  allow  moving backwards within a 
string  and  thus  repeat a part  of it (to model  reduplication). Skip arcs  allow  moving 
forwards in a string  while  suppressing the spell out of some  of its letters;  self loop arcs 
model  infixation. In Walther (2000b), the  above  technique is used  to describe Temiar







Figure 4
4-tape representation for the Hebrew word htpqdut.


53




















Figure 5
4-tape automaton for circumfixation example.



reduplication, but  no complexity analysis of the  model  is given.  Moreover, this  tech- 
nique  does not seem to be able to describe  interdigitation.
Beesley  and   Karttunen  (2000)  describe   a  technique,  called   compile-replace,  for
constructing FSTs, which  involves reapplying the  regular-expression compiler to  its 
own  output. The compile-replace algorithm facilitates  a compact definition of non- 
concatenative morphological processes, but since such expressions compile  to the na¨ıve 
networks, no space is saved. Furthermore, this is a compile-time mechanism rather than 
a theoretical and mathematically founded solution.
    Other works extend the FS model by enabling some sort of context-sensitivity. Blank 
(1985, 1989) presents a model,  called  Register  Vector  Grammar, introducing context- 
sensitivity by representing the states and transitions of finite-state automata as ternary- 
valued vectors, which need not be fully specified. No formal properties of this model are 
discussed. In a similar  vein, Kornai  (1996) introduces vectorized finite-state automata, 
where both  the  states  and  the  transitions are  represented by  vectors  of elements of 
a partially ordered set. The vectors  are  manipulated by operations of unification and 
overwriting. The  vectors  need  not  be fully  determined, as some  of the  elements can 
be unknown (free). In this way  information can be moved through the transitions by 
the overwriting operation and  traversing these  transitions can be sanctioned through 
the  unification operation. As  one  of the  examples of the  advantages of this  model, 
Kornai  (1996) shows  it can efficiently  solve  the  problem of 32-bit binary incrementor 
(Example  4). Using vectorized finite-state automata, a 32-bit incrementor is constructed 
where first,  using  overwriting, the  input is scanned and  stored in  the  vectors,  and 
then,  using  unification, the result  is calculated where the carry  can be computed from 
right  to left. We return to this  example in example 6, where we  show  how  our  own 
model   can  solve  it  efficiently.  The  formalism presented  by  Kornai  (1996) allows  a 
significant reduction in  the  network size,  but  its  main  disadvantage lies  in  the  fact 
that  it significantly deviates from the standard methodology of developing finite-state 
devices, and integration of vectorized automata with standard ones remains a challenge. 
Moreover, it is unclear how, for a given problem, the corresponding network should be 
constructed: Programming with  vectorized automata seems  to be unnatural, and  no 
regular expression language is provided for them.
A more  general approach to the  design of finite-state machines is introduced by
Mohri,  Pereira,  and Riley (2000). They introduce an object-oriented library  for manipu-


54





lating finite-state devices that is based on the algebraic  concepts of rational power series 
and  semirings. This approach facilitates  a high  degree of generality as the algorithms 
are defined for the general algebraic notions, which  can then  be specialized according 
to the needs of the user. They exemplify the usefulness of this library by showing how to 
specialize it for the manipulation of weighted automata and transducers. Our work  can 
be seen as another specialization of this general approach, tailored for ideally  dealing 
with our motivating examples.
    Several  works  introduce the notion  of registers, whether for solving  similar  prob- 
lems  or motivated by  different considerations. Krauwer and  des  Tombe  (1981) refer 
to  transducers with  a  finite  number of  registers when   comparing transducers and 
context  free  grammars with  respect  to their  capabilities to describe languages. They 
sketch  a proof  showing that  such  transducers are  equivalent to ordinary finite-state 
transducers. However, they  never  formally define  the  model  and  do  not  discuss its 
ability to efficiently implement non-concatenative natural languages phenomena. More- 
over,  they  do  not  show  how  the  closure  properties can  be implemented directly on 
these  registered transducers, and  do not provide any  regular language denoting such 
transducers.
   Motivated by different considerations, Kaminski and Francez (1994) present a com- 
putational model  which  extends finite state  automata to the case of infinite  alphabets. 
This  model  is limited to  recognizing only  regular languages over  infinite  alphabets 
while  maintaining closure  under Kleene star  and  boolean operations, with  the excep- 
tion  of closure  under complementation. The  familiar  automaton is augmented with 
registers, used  to  store  alphabet symbols, whose  number is fixed  for  each  automa- 
ton  and  can  vary  from  one  automaton to  another. The  model   is  designed to  deal 
with  infinite  alphabets, and  therefore it cannot  distinguish between different symbols; 
it  can  identify different patterns  but  cannot   distinguish  between different symbols 
in  the  pattern as  is often  needed in  natural languages. Our  solution is reminiscent 
of Kaminski and  Francez  (1994) in  the  sense  that  it augments finite-state automata 
with  finite memory (registers) in a restricted way,  but  we avoid  the above-mentioned 
problem. In  addition, our  model  supports a  register alphabet that  differs  from  the 
language alphabet, allowing the information stored in the registers to be more  mean- 
ingful.  Moreover, our  transition relation is a more  simplified extension of the  stan- 
dard one  in  FSAs, rendering our  model  a conservative extension of standard  FSAs 
and  allowing simple  integration of existing  networks with  networks based  on  our 
model.
    Finally,  Beesley (1998) directly addresses medium-distance dependencies between 
separated morphemes in words. He proposes a method, called flag diacritics, which adds 
features to symbols  in regular expressions to enforce  dependencies between separated 
parts  of a string.  The dependencies are forced  by different kinds  of unification actions. 
In this  way,  a small  amount of finite  memory is added, keeping the  total  size of the 
network relatively small.  Unfortunately, this  method is not  formally defined, nor  are 
its mathematical and computational properties proved. Furthermore, flag diacritics are 
manipulated at the level of the extended regular expressions, although it is clear that 
they  are compiled into additional memory and  operators in the networks themselves. 
The presentations of Beesley (1998) and  Beesley and  Karttunen (2003) do not explicate 
the  implementation of such  operators and  do  not  provide an  analysis of their  com- 
plexity.  Our approach is similar  in spirit,  but we provide a complete mathematical and 
computational analysis of such  extended networks, including a proof  that  the  model 
is indeed regular and  constructions of the  main  closure  properties. We also  provide 
dedicated regular expression operations for  non-concatenative  processes and  show


55





how they are compiled into extended networks, thereby accounting for the motivating 
examples.


3. Finite-state Registered  Automata

We define  a new  model,  finite-state  registered  automata (FSRA), aimed  at facilitating 
the expression of various non-concatenative morphological phenomena in an efficient 
way.  The  model  augments finite-state automata with  finite  memory (registers) in  a 
restricted way  that  saves  space  but does  not add  expressivity. The number of registers 
is finite,  usually small,  and  eliminates the  need  to duplicate paths as it enables  the 
automaton to “remember ” a finite number of symbols. In addition to being  associated 
with  an  alphabet symbol,  each  arc is also  associated with  an  action  on the  registers. 
There  are  two  kinds  of actions,  read and  write.  The  read  action,  denoted R, allows 
traversing an  arc  only  if a designated register contains a specific  symbol.  The write 
action,  denoted W, allows  traversing an  arc  while  writing a  specific  symbol  into  a 
designated register. In this section  we define FSRAs and  show  that they are equivalent 
to standard FSAs (Section 3.1). We then  directly define  several  closure  operations over 
FSRAs (Section  3.2) and  provide some  optimizations in Section  3.3. We conclude this 
section with a discussion of minimization (Section 3.4).

3.1 Definitions and Examples

Definition
A finite-state registered  automaton (FSRA) is a tuple  A = (Q, q0 , Σ, Γ, n, δ, F⊕, where:
•	Q is a finite set of states.
•	q0  ∈ Q is the initial state.
•	Σ is a finite alphabet (the language alphabet).
•	n ∈ N (indicating the number of registers).
•	Γ is a finite alphabet including the symbol  ‘#’ (the registers alphabet).
We use meta-variables ui , vi to range  over Γ and u, v to range  over Γn .
•	The initial content of the registers is #n , meaning that the initial value
of all the registers is ‘empty’.
•	δ ⊆ Q × Σ ∪ {E}× {R, W}× {0, 1, 2, ... , n − 1}× Γ × Q is the transition 
relation. The intuitive meaning of δ is as follows:
–	(s, σ, R, i, γ, t) ∈ δ where i > 0 implies  that if A is in state s, the input 
symbol  is σ, and the content of the i-th register is γ, then A may 
enter state t.
–	(s, σ, W, i, γ, t) ∈ δ where i > 0 implies  that if A is in state s and the
input symbol  is σ, then the content of the i-th register is changed
into γ (overwriting whatever was there before) and A may enter 
state t.
–	(s, σ, R, 0, #, t) implies  that if A is in state s and the input symbol  is σ, 
then A may enter state t. Notice that the content of register number 0
is always #. We use the shorthand notation (s, σ, t) for such transitions.
•	F ⊆ Q is the set of final states.


56





Definition
A configuration of A is a pair  (q, u), where q ∈ Q and  u ∈ Γn  (q is the  current state
and  u represents the registers content). The set of all configurations of A is denoted by
Q c . The pair qc  = (q0 , #n ) is called the initial configuration, and configurations with the 
first component in F are called  final configurations. The set of final configurations is 
denoted by Fc .

Definition
Let u = u0 u1 ... un−1  and  v = v0 v1 ... vn−1 . Given  a symbol  α ∈ Σ ∪ {E} and  an FSRA
A, we say that  a configuration (s, u) produces  a configuration (t, v), denoted (s, u) f-α,A
(t, v), iff either  one of the following holds:

•	There exists i, 0 ≤ i ≤ n − 1, and  there  exists γ ∈ Γ, such that  (s, α, R, i, γ, t) ∈
δ and u = v and ui = vi = γ; or
•	There exists i, 0 ≤ i ≤ n − 1, and  there  exists γ ∈ Γ, such that  (s, α, W, i, γ, t) ∈
δ and for all k, k ∈ {0, 1, ..., n − 1}, such that k •= i, uk = vk and vi = γ.

   Informally, a configuration c1  produces a configuration c2  iff the  automaton can 
move from c1 to c2 when scanning the input α (or without any input, when α = E) in one 
step. If the register operation is R, then the contents of the registers in the two configura- 
tions must  be equal,  and in particular the contents of the designated register in the two 
configurations should be the expected symbol (γ). If the register operation is W, then the 
contents of the registers in the two configurations is equal except for the designated reg- 
ister, whose  contents in the produced configuration should be the expected symbol  (γ).

Definition
A run of A on w is a sequence of configurations c0 , ..., cr  such  that  c0  = qc , cr  ∈ Fc , and 
for every  k, 1 ≤ k ≤ r, ck−1  f-αk ,A  ck  and  w = α1 ...αr . An FSRA A accepts a word w if 
there  exists a run of A on w. Notice that |w| may be less than  r since some of the αi may
be E. The language recognized by an FSRA A, denoted by L(A), is the set of words over
Σ∗ accepted by A.

Example 5
Consider again  example 1. We construct an efficient  FSRA accepting all and  only  the 
possible  combinations of stems  and  circumfixes.  If the number of stems  is r, we define
an FSRA A = (Q, q0 , Σ, Γ, 2, δ, {qf }⊕ where:
•	Q = {q0 , q1 , ... , q2r+2 , qf }
•	Σ = {a, b, c, ... , z, ht, ut}
•	Γ = {htDDDut, hDDDa, mDDD, #}
•	δ = {(q0 , ht, W, 1, htDDDut, q1 ), (q0 , h, W, 1, hDDDa, q1 )}
∪
{(q0 , m, W, 1, mDDD, q1 ), (q2r+2 , ut, R, 1, htDDDut, qf )}
∪
{(q2r+2 , a, R, 1, hDDDa, qf ), (q2r+2 , E, R, 1, mDDD, qf )}
∪
{(q1 , α1 , qi ), (qi , α2 , qi+1 ), (qi+1 , α3 , q2r+2 ) | 2 ≤ i ≤ 2r and
α1 α2 α3 is the i-th stem}.


57




This automaton is shown in Figure  6. The number of its states  is 2r + 4 (like the FSA
of Figure  2), that  is, O(r), and  in particular independent of the number of circumfixes. 
The  number of arcs  is also  reduced from  O(r × p), where p indicates the  number of
circumfixes,  to O(r + p).

Example 6
Consider again  example 2. The FSRA of Figure  7 also accepts  the same language. This 
automaton has  seven  states  and  will  have  seven  states  for any  number of roots.  The 
number of arcs is also reduced to 3r + 3.
    Next,  we  show  that  finite-state registered automata and  standard finite  state  au- 
tomata recognize the  same  class  of languages. Trivially,  every  finite-state automaton 
has an equivalent FSRA: Every FSA is also an FSRA since every transition (s, σ, t) in an 
FSRA is a shorthand notation for (s, σ, R, 0, #, t). The other  direction is also simple.


Theorem 1
Every FSRA has an equivalent finite-state automaton.

We prove  this by constructing an equivalent FSA to a given FSRA. The construction is 
based  on the fact that  in FSRAs the number of registers is finite, as are the sets Γ and 
Q, the register alphabet and  states, respectively. Hence the number of configurations is 
finite. The FSA’s states  are the configurations of the FSRA, and  the transition function 
simulates the ‘produces’ relation. Notice that this relation holds between configurations 
depending on Σ only,  similarly to the transition function in an FSA. The constructed 
FSA is non-deterministic, with possible  E-moves. The formal  proof is suppressed.
   The number of configurations in A is |Q|× |Γ n , hence the growth in the number of 
states  when  constructing A∗ from A might  be in the worst  case exponential in the num-
ber of registers. In other  words, the move from FSAs to FSRAs can yield an exponential 
reduction in the size of the network. As we show  below,  the reduction in the number of 
states can be even more dramatic.
    The FSRA model  defined above  allows  only  one register operation on each  tran- 
sition.  We extend  it to allow  up  to k register operations on  each  transition, where k 
is determined for each automaton separately. The register operations are defined as a 
sequence (rather than  a set), in order  to allow  more  than  one  operation on the  same

















Figure 6
FSRA for circumfixation.


58











Figure 7
FSRA for the pattern hitDaDeD.


register over one transition. This extension allows further reduction of the network size 
for some automata as well as other  advantages that will be discussed presently.

Definition
An  order-k finite-state  registered  automaton  (FSRA-k) is a tuple  A = (Q, q0 , Σ, Γ, n,
k, δ, F⊕, where:

•	Q, q0 , Σ, Γ, n, F and the initial content of the registers are as before.
•	k ∈ N (indicating the maximum number of register operations allowed 
on each arc).
•	Let ActionsΓ = {R, W}× {0, 1, 2, ... , n − 1}× Γ. Then



 k
δ ⊆ Q × Σ ∪ {E}×     {(a1 , ..., aj ⊕| for all i, 1 ≤ i ≤ j, ai  ∈ ActionsΓ



 × Q


j=1

is the transition relation. δ is extended to allow each transition to be 
associated with a series of up to k operations on the registers. Each 
operation has the same meaning as before.


    The register operations are executed in the order  in which  they are specified.  Thus, 
(s, σ, (a1 , ..., ai ⊕, t) ∈ δ where i ≤ k implies  that if A is in state s, the input symbol  is σ and
all the register operations a1 , ..., ai  are executed successfully, then A may enter state t.

Definition


Given a ∈ ActionsΓ we define a relation over Γn , denoted u f-


v for u, v ∈ Γn . We define



u f-a


n
v 
where 
u = u0



... 
un−1



and v 
= v0



... 
vn−1


a
iff the 
follow
ing 
holds:



•	if a = (R, i, γ) for some i,0 ≤ i ≤ n − 1 and for some γ ∈ Γ, then u = v
and ui = vi = γ.
•	if a = (W, i, γ) for some i,0 ≤ i ≤ n − 1 and for some γ ∈ Γ, then for all
k ∈ {0, 1, ... , n − 1} such that k •= i, uk = vk and vi = γ.

This relation is extended to series over ActionsΓ . Given a series (a , ..., a  ⊕∈ (ActionsΓ )p
n 	1 	p	n


where p ∈ N, we  define  a  relation over  Γn   denoted u f- 	v


for  u, v ∈ Γn . We


define u f- a1 ,...,ap ) v


iff the following 
holds:





•	if p = 1, then u f-a1   v.
•	if p > 1, then there exists w ∈ Γn such that u f-a




w and w f- a2 ,...,ap ) v.




59





Definition
Let u, v ∈ Γn . Given a symbol  α ∈ Σ ∪ {E} and an FSRA-k A, we say that a configuration
(s, u) produces a configuration (t, v), denoted (s, u) f-α,A  (t, v), iff there exist (a1 , ... , ap ⊕∈ 
(ActionsΓ )p for some p ∈ N such that  (s, α, (a , ... , a ⊕, t) ∈ δ and u f- 	v.


n 	1 	p


a1 ,...,ap )



Definition
A run of A on w is a sequence of configurations c0 , ..., cr such that c0  = qc , cr  ∈ Fc , and for 
every  l, 1 ≤ l ≤ r, cl−1  f-αl ,A  cl  and  w = α1 ...αr . An FSRA-k A accepts a word w if there
exists a run  of A on w. The language recognized by an FSRA-k A, denoted by L(A), is 
the set of words over Σ∗ accepted by A.


Example 7
Consider the Arabic nouns qamar (moon),  kitaab  (book), $ams (sun), and daftar (note- 
book).  The definite  article  in Arabic  is the prefix  al, which  is realized as al  when  pre- 
ceding  most consonants; however, the ‘l’ of the prefix assimilates to the first consonant 
of the noun  when  the latter  is ‘d’, ‘$’, etc. Furthermore, Arabic  distinguishes between 
definite  and  indefinite case markers. For example, nominative case is realized as the 
suffix u on definite  nouns, un  on indefinite nouns. Examples of the different forms  of 
Arabic nouns are:



wo
rd
no
mi
na
tiv
e 
de
fin
ite
no
mi
na
tiv
e 
in
de
fin
ite
qa
m
ar 
kit
aa
b
$a
m
s 
da
ft
ar
’
a
l
q
a
m
a
r
u
’
a
l
k
i
t
a
a
b
u
’
a
$
$
a
m
s
u
’
a
d
d
a
f
t
a
r
u
q
a
m
a
r
u
n
 
k
i
t
a
a
b
u
n
$
a
m
s
u
n
 
d
a
f
t
a
r
u
n


    The FSRA-2 of Figure  8 accepts  all the nominative definite  and  indefinite forms  of 
the above  nouns. In order  to account for the assimilation, register 2 stores  information 
about  the actual  form of the definite  article. Furthermore, to ensure that definite  nouns 
occur  with  the  correct  case ending, register 1 stores  information of whether or not  a 
definite  article was seen.















Figure 8
FSRA-2 for Arabic nominative definite  and indefinite nouns.


60





    FSRA-k and FSRAs recognize the same class of languages. Trivially, every FSRA has 
an equivalent FSRA-k: Every  FSRA is an FSRA-k for k = 1. The other  direction is also 
simple.


Theorem 2
Every FSRA-k has an equivalent FSRA.

We show how to construct an equivalent FSRA (or FSRA-1) A∗ given an FSRA-k A. Each 
transition in A is replaced by a series  of transitions in A’, each of which  performs one 
operation on the  registers. The first transition in the  series  deals  with  the  new  input 
symbol  and  the  rest  are  E-transitions. This  construction requires additional states  to 
enable  the  addition of transitions. Each  transition in A that  is replaced requires the 
addition of as many  states  as the number of register operations performed on this 
transition minus one. The formal  construction is suppressed.
    In what  follows,  the term  FSRA will be used  to denote FSRA-k. Simple FRSA will 
be referred to as FSRA-1. For the sake of emphasis, however, the term  FSRA-k will still 
be used  in some cases.
    FSRA is a very  space-efficient finite-state device.  The  next  theorem shows  how 
ordinary finite-state automata can be encoded efficiently  by the FSRA-2 model.  Given
a finite-state automaton A, an equivalent FSRA-2 A∗ is constructed. A∗ has three  states
and  two  registers (in fact, only  one  register is used  since  register number 0 is never 
addressed). One  state  functions as a representative for the  final  states  in A, another 
one  functions as  a representative for  the  non-final states  in  A, and  the  third  as  an 
initial  state.  The register alphabet consists  of the states  of A and  the symbol  ‘#’. Each
arc  in  A has  an  equivalent arc  in  A∗  with  two  register operations. The  first  reads
the  current state  of A from  the  register and  the  second  writes  the  new  state  into  the 
register. If the source  state  of a transition in A is a final state,  then  the source  state  of
the corresponding transition in A∗  will be the final states  representative; if the source
state of a transition in A is a non-final state, then  the source  state of the corresponding 
transition in A∗ will be the non-final states  representative. The same  holds  also for the

target  states.  The purpose of the  initial  state  is to write  the  start  state  of A into  the 
register. In this way A∗ simulates the behavior of A. Notice that the number of arcs in A∗
equals  the number of arcs in A plus  one, i.e., while  FSRAs can dramatically reduce the 
number of states,  compared to standard FSAs, a reduction in the number of arcs is not 
guaranteed.


Theorem 3
Every  finite-state automaton  has  an  equivalent FSRA-2  with  three  states  and  two 
registers.


Proof 1
Let A = (Q, q0 , Σ, δ, F⊕ be an FSA and  let f : Q → fqf, qnfI, be a total  function defined
by


  qf	q ∈ F


f (q) =


qnf


q ∈/ F




61





Construct an FSRA-2 A∗ = (Q∗, q∗ , Σ∗, Γ∗, 2, 2, δ∗, F∗⊕, where:
•	Q∗ = {q∗ , qnf, qf}. q∗  is the initial state, qf is the final states representative,
0 	0
and qnf is the non-final states representative
•	Σ∗ = Σ 
•	Γ = Q ∪ {#}
•	F∗ = {qf }
•	δ∗ = {(f (s), σ, ((R, 1, s), (W, 1, t)⊕, f (t)) | (s, σ, t) ∈ δ}
∪
{(q∗ , E, ((W, 1, q0 )⊕, f (q0 ))}
The formal  proof that L(A) = L(A∗ ) is suppressed. •


3.2 Closure Properties

The equivalence shown in the previous section between the classes of languages recog- 
nized  by finite-state automata and finite-state registered automata immediately implies 
that  finite-state registered automata maintain the  closure  properties of regular lan- 
guages. Applying the regular operations to finite-state registered automata can be easily 
done  by converting them  first  into  finite-state automata. However, as shown above, 
such  a conversion may  result  in an exponential increase  in the size of the automaton, 
invalidating the advantages of this model.  Therefore, we show  how  some of these 
operations can be defined directly for FSRAs. The constructions are mostly  based  on 
the standard constructions for FSAs with some essential modifications. In what follows,
let A1  = (Q1 , q1 , Σ1 , Γ1 , n1 , k1 , δ1 , F1 ⊕ and  A2  = (Q2 , q2 , Σ2 , Γ2 , n2 , k2 , δ2 , F2 ⊕ be finite-state
0 	0
registered automata.

3.2.1 Union. Two FSRAs, A1 , A2 , are unioned into an FSRA A in the same way as in FSAs: 
by adding a new initial state and connecting it with E-arcs to each of the (former)  initial 
states of A1 , A2 . The number of registers and the maximal number of register operations 
per  arc  in  A is the  maximum of the  corresponding values  in  A1 , A2 . Notice  that  in 
any specific run  of A, the computation goes through just one of the original automata; 
therefore the same set of registers can be used  for strings of L(A1 ) or L(A2 ) as needed.

3.2.2 Concatenation. We show  two  different constructions of an  FSRA A = (Q, q0 , Σ,
Γ, n, k, δ, F⊕ to recognize L(A1 ) · L(A2 ). Concatenation in finite-state automata is achieved
by leaving  only  the  accepting states  of the second  automaton as accepting states  and
adding an E-arc from every  accepting state of the first automaton to the initial  state of 
the second  automaton. Doing  just this in FSRA is insufficient because  using  the same 
registers might  cause undesired effects: The result  might  be affected  by the content left 
in the registers after dealing with  a substring from L(A1 ). Thus, this basic construction 
is used  with  care. The first alternative is to employ more  registers in the FSRA. In this 
way when  dealing with a substring from L(A1 ) the first n1 registers are used,  and when 
moving to deal with  a substring from L(A2 ) the next n2 registers are used.  The second 
alternative is to use additional register operations that clear the content of the registers 
before  handling the next substring from  L(A2 ). This solution may  be less intuitive but 
will be instrumental for Kleene closure  below.


62





3.2.3 Kleene  Closure.  The  construction is based  on  the  concatenation construction. 
Notice  that  it cannot  be based  on the first alternative (adding registers) due  to the fact 
that  the number of iterations in Kleene star is not limited, and  therefore the number of 
registers needed cannot  be bounded. Thus, the second  alternative is used:  Register  op- 
erations are added to delete the content of registers. The construction is done by turning 
the initial state into a final one (if it is not already final) and connecting each of the final 
states  to the initial  state  with  an E-arc that  is associated with  a register operation that 
deletes  the contents of the registers, leaving them  ready to handle the next substring.

3.2.4 Intersection.  For the intersection construction, assume that  A1  and  A2  are E-free 
(we show an algorithm for removing E-arcs in Section 3.3.1). The following construction 
simulates the runs  of A1 and A2 simultaneously. It is based  on the basic construction for 
intersection of finite-state automata, augmented by a simulation of the  registers and 
their  behavior. Each transition is associated with  two  sequences of operations on the 
registers, one for each automaton. The number of the registers is the sum of the number 
of registers in the  two  automata. In the  intersection automaton the  first  n1  registers 
are designated to simulate the behavior of the registers of A1  and  the next n2  registers 
simulate the behavior of A2 . In this way a word can be accepted by the intersection au- 
tomaton iff it can be accepted by each one of the automata separately. Notice that register 
operations from δ1  and  δ2  cannot  be associated with  the same register. This guarantees 
that no information is lost during the simulation of the two intersected automata.

3.2.5 Complementation. Ordinary FSAs are  trivially closed  under complementation. 
However, given  an FSA A whose  language is L(A), the  minimal FSA recognizing the 
complement of L(A) can be exponentially large.  More  precisely, for any  integer n > 2, 
there  exists a non-deterministic finite-state automaton (NFA) with  n states  A, such that
any  NFA  that  accepts  the  complement of L(A) needs  at least  2n−2  states  (Holzer and
Kutrib  2002). We have  no  reason  to believe  that  FSRAs will  demonstrate a different 
behavior; therefore, we  maintain that  in the  worst  case,  the  best  approach for  com- 
plementing an FSRA would be to convert  it into  FSA and  complement the  latter.  We 
therefore do not provide a dedicated construction for this operator.

3.3 Optimizations
3.3.1 E-removal. An E-arc in an FSRA is an arc of the form  (s, E, ( a⊕, t) where  a is used


as a meta-variable over  (ActionsΓ


+ (i.e.,  a represents a vector  of 
register operations).


n  
Notice  that  this kind  of arc might  occur  in an FSRA by its definition. Given  an FSRA
that  might  contain  E-arcs, an equivalent FSRA without E-arcs can be constructed. The 
construction is based  on the algorithm for E-removal  in finite-state automata, but  the 
register operations that  are  associated with  the  E-arc have  to be dealt  with,  and  this 
requires some care. The resulting FSRA has one more state than  the original,  and some 
additional arcs may be added, too.
    The main  problem is E-loops; while  these can be easily removed in standard FSAs, 
here such loops can be associated with register operations which must be accounted for. 
The number of possible  sequences of register operations along an E-loop is unbounded, 
but  it  is  easy  to  prove   that  there  are  only  finitely  many   equivalence  classes of  such 
sequences: Two  sequences are in the  same  equivalence class if and  only  if they  have 
the same  effect on the state  of the machine; since each machine has a finite number of 
configurations (see theorem 1), there are only finitely many  such equivalence classes.
Therefore, the  basic  idea  behind the  construction is as follows:  If there  exists  an
E-path from q1 to q2 with the register operations  a over its arcs, and an arc (q2 , σ,   b⊕, q3 )


63




















Figure 9
E removal paradigm.



where σ •= E, and  an E-path  from  q3  to q4  with  the  register operations c over  its arcs, 
then  the  equivalent E-free network will include the arcs  (q2 , σ, (b⊕, q3 ), (q1 , σ, (a, b⊕, q3 ), 
(q2 , σ, (b, c ⊕, q4 ), and  (q1 , σ, (a, b, c ⊕, q3 ), with  all the  E-arcs removed. This  is  illustrated
in Figure  9. Notice  that  if q1  and  q2  are  the  same  state,  then  states  q2  and  q3  will  be 
connected by two parallel arcs differing in their associated register operations; the same
holds  for states q2 and q4 . Similarly,  when  q3 and q4 are the same state.
In addition to the above  changes, special  care is needed for the case in which  the
empty word is accepted by the original automaton. The formal  construction is similar 
in spirit to the E-removal  paradigm in weighted automata (Mohri 2000), where weights 
along  an E-path  need  to be gathered. Therefore, we suppress the formal  construction 
and the proof of its correctness.

3.3.2  Optimizing  Register   Operations.  In  FSRAs,  traversing  an  arc  depends  not 
only  on  the  input symbol   but  also  on  satisfying the  series  of  register operations. 
Sometimes, a  given   series  of  register operations  can  never   be  satisfied,   and   thus 
the  arc  to  which  it is attached cannot  be  traversed. For  example, the  series  of reg-
ister  operations ((W, 1, a), (R, 1, b)⊕ can  never  be  satisfied,   hence  an  arc  of  the  form
(q1 , σ, ((W, 1, a), (R, 1, b)⊕, q2 ) is redundant. In addition, the constructions of Sections  3.2
and  3.3.1 might  result  in redundant states  and  arcs that  can never  be reached or can
never  lead  to a final state.  Moreover, in many  cases a series  of register operations can 
be  minimized into  a shorter series  with  the  same  effect.  For  example, the  series  of
register operations ((W, 1, a), (R, 1, a), (W, 1, b)⊕ is equal in its effect to the series ((W, 1, b)⊕.
Therefore, we show an algorithm for optimizing a given FSRA by minimizing the series
of register operations over its arcs and removing redundant arcs and states.
For a given  FSRA A = (Q, q0 , Σ, Γ, n, δ, F⊕, we construct an equivalent FSRA A∗ =
(Q, q0 , Σ, Γ, n, δ∗, F⊕ = Opt(A), such  that  δ∗  is created from  δ by  removing redundant
arcs  and  by  optimizing all  the  series  of  register operations. We  begin  by  defining


(ActionsΓ


+   as  the  
subset  of 
(ActionsΓ
|i


+
that  
consists  
only  of 
operatio
ns over  
the
+


i-th register. Define a total function sati   : (ActionsΓ


|i   −→ {true,  false} by:






sati (a) =


( true	if there exist u, v 
∈ Γn   such that   u f- a  v
false	otherwise




64




sati (a) = true iff  the  series  of  register operations a  is  satisfiable, i.e.,  there  exists  a 
configuration of  register contents for  which  all  the  operations in  the  series  can  be 
executed successfully. Determining whether  sati (a) = true by  exhaustively checking 
all the vectors  in Γn  may  be inefficient.  Therefore, we show  a necessary and  sufficient
+


condition for determining whether sati (a) = true for some a ∈ (ActionsΓ


, which  can
|i


be checked  efficiently.  In addition, this condition will be useful  in optimizing the series
of register operations as will be shown later. A series of register operations over the i-th 
register is not satisfiable if either  one of the following holds:

•	A write operation is followed by a read  operation expecting a different 
value.
•	A read  operation is immediately followed by a read  operation expecting a 
different value.





Theorem 4
For  all  a = ((op1 , i, γ1 ), (op2 , i, γ2 ), ... , (ops , i, γs )⊕∈ (ActionsΓ



,  sat (a) = false  if  and
|i


only if either  one of the following holds:


1.	There exists k,1 ≤ k < s, such that opk = W and there exists m, k < m ≤ s, 
such that opm = R, γk  •= γm and for all j, k < j < m, opj  = R.
2.	There exists k,1 ≤ k < s, such that opk = opk+1  = R and γk  •= γk+1 .


    Notice  that  if i = 0, then  by the definition of FSRAs, all the register operations in 
the series  are the same  operation, which  is (R, 0, #); and  this  operation can never  fail. 
In addition, if all the  operations in the series  are write  operations, then  again,  by the 
definition of FSRAs, these operations can never  fail. If none of the two conditions of the 
theorem holds,  then the series of register operations is satisfiable.
    We now  show  how  to optimize a series  of operations over  a given  register. An 
optimized series is defined only over satisfiable  series of register operations in the 
following way:

•	If all the operations are write operations, then leave only the last one (since 
it will overwrite all its predecessors).
•	If all the operations are read  operations, then by theorem 4, they are all the 
same operation, and in this case just leave one of them.
•	If there are both read  and write operations, then distinguish between two 
cases:

–	If the first operation is a write operation, leave only the last write 
operation in the series.
–	If the first operation is a read  operation, leave the first operation 
(which is read) and the last write operation in the series. If the last 
write operation writes  into the register the same symbol  that the 
read  operation required, then the write is redundant; leave only the 
read  operation.


65







Definition
Define a function mini  : (ActionsΓ


+	(ActionsΓ
|i



|i . Let a = ((op1 , i, γ1 ), ... , (ops , i,


γs )⊕. If sati (a) = true then:
•	If for all k,1 ≤ k ≤ s, opk = W, define mini (a) = ((W, i, γs )⊕.
•	If for all k,1 ≤ k ≤ s, opk = R then define mini (a) = ((R, i, γs )⊕.
•	If there exists m,1 ≤ m ≤ s such that opm = W and if there exists t,
1 ≤ t ≤ s, such that opt = R then:



 ((W, i, γj )⊕	if op1 = W and
 	for all k, j < k ≤




s,  opk = R


 ((R, i, γ1 ), (W, i, γj )⊕	if op1 = R and


mini (a) = 



f
o
r
 
a
l
l
 
k
,
 
j
 
<
 
k
 
≤
 
s
,
  
o
p
k
 
=
 
R
 
a
n
d
 
γ
1
 
•
=
 
γ
j
(R, i, γ1 )⊕	if op1 = R and if there exists j, 1 ≤ j ≤ s,


(
 	such that for all k, j < k	s,



 	opk


= R and γ1


≤
= γj



    The formal proof that mini (a) is the minimal equivalent series of register operations 
of a is suppressed.
We now  show  how  to optimize a series  of register operations. Define  a function


min : (ActionsΓ   +	+


+ define  min(a) = b


where b is obtained from a by:

•	Each subseries ai  of a, consisting of all the register operations on the i-th 
register, is checked  for satisfaction. If sati (ai ) = false then the arc cannot  be 
traversed and min(a) = b = null. If sati (ai ) = true then ai  is replaced in a by 
min(ai ). Notice that the order  of the minimized subseries in the complete 
series is unimportant as they operate on different registers.
•	If there exists i •= 0, such that ai  is not empty, then the subseries a0
consisting only of operations of the form (R, 0, #) is deleted from a.

Finally,  given  an  FSRA A = (Q, q0 , Σ, Γ, n, δ, F⊕,  construct an  equivalent FSRA A∗ =
(Q, q0 , Σ, Γ, n, δ∗, F⊕ = Opt(A) where
δ∗ = {(q1 , σ, (min(a)⊕, q2 	|  (q1 , σ, (a⊕, q2     ∈ δ and min(a) •= null

Opt(A) is optimized with respect  to register operations.
    Like FSAs, FSRAs may have states  that can never  be reached or can never  lead to a 
final state. These states (and their connected arcs) can be removed in the same way they 
are removed in FSAs. In sum, FSRA optimization is done  in two stages:

1.	Minimizing the series of register operations over the FSRA transitions.

2.	Removing redundant states and arcs.

    Notice  that  stage  1 must  be performed before  stage  2 as it can result  in further re- 
duction in the size of the network when  performing the second  stage. For a given FSRA 
A, define  OPT(A) as the  FSRA obtained from  Opt(A) by removing all the  redundant


66




states  and  transitions. An FSRA A is optimized if OPT(A) = A (notice  that  OPT(A) is 
unique, i.e., if B = OPT(A) and C = OPT(A), then B = C).


3.4 FSRA Minimization

FSRAs can be minimized along  three  different axes: states,  arcs, and  registers. Reduc- 
tion  in the  number of registers can always be achieved by converting an FSRA to an 
FSA (Section 3.1), eliminating registers altogether. Since FSRAs are inherently non- 
deterministic (see the discussion of linearization below),  their  minimization is related 
to the  problem of non-deterministic finite-state automata (NFA) minimization, which 
is known to be NP-hard.6  However, while  FSRA arc minimization is NP-hard, FSRA 
state  minimization is different. Recall that  in theorem 3 we have  shown that  any  FSA 
has an equivalent FSRA-2 with  3 states  and  2 registers. It thus  follows  that  any  FSRA 
has an equivalent FSRA-2 with  3 states  (simply  convert  the FSRA to an FSA and  then 
convert  it to an FSRA-2 with 3 states). Notice that minimizing an FSRA in terms of states 
or registers can significantly increase  the number of arcs. As many  implementations of 
finite-state devices use space that is a function of the number of arcs, the benefit that lies 
in such minimization is limited. Therefore, a different minimization function, involving 
all the  three  axes,  is called  for. We do  not  address this  problem in this  work.  As for 
arc minimization, we  cite the  following theorem. As its proof  is most  similar  to the 
corresponding proof on NFA, we suppress it.

Theorem 5
FSRA arc minimization is NP-hard.

The  main  advantage of finite-state devices  is their  linear  recognition time.  In finite- 
state  automata, this  is  achieved by  determinizing  the  network, ensuring  that  the 
transition  relation is  a  function.  In  FSRAs,  in  contrast, a  functional transition  re- 
lation   does   not  guarantee  linear   recognition  time,   since  multiple  possible   transi- 
tions  can  exist  for  a  given  state  and  a  given  input symbol.  For  example, given  an
FSRA A = (Q, q0 , Σ, Γ, n, k, δ, F⊕,  and  some  q, q1 , q2  ∈ Q and  σ ∈ Σ, two  arcs  such  as
(q, σ, ((W, 1, a)⊕, q1 ), (q, σ, ((W, 1, b)⊕, q2 ) ∈ δ do not hamper the functionality of the FSRA
transition relation. However, they  do imply  that  for the state  q and  for the same  input
symbol  (σ), more than one possible  arc can be traversed. We use deterministic to denote 
FSRAs in which  the transition relation is a function, and a new term, linearized, is used 
to denote FSRAs for which  linear  recognition time is guaranteed.
   Generally, a FSRA is linearized if it is optimized, E-free, and  given  a current state 
and  a new  input symbol,  and  at  most  one  transition can  be  traversed. Thus,  if the
transition relation includes two  arcs  of the  form  (q, σ, (a⊕, q1 ), (q, σ, (b⊕, q2 ), then  a and
b must  be a contradicting series of register operations. Two series of register operations
are contradicting if at most one of them  is satisfiable. Since the FSRA is optimized, each 
series of register operations is a concatenation of subseries, each operating on a differ- 
ent  register;  and  the  subseries operating on the  i-th  register must  be either  empty or
((W, i, γ)⊕ or ((R, i, γ)⊕ or ((R, i, γ1 ), (W, i, γ2 )⊕. ((W, i, γ)⊕ contradicts neither ((R, i, γ)⊕ nor
((R, i, γ1 ), (W, i, γ2 )⊕. ((R, i, γ)⊕ and ((R, i, γ1 ), (W, i, γ2 )⊕ are contradicting only if γ •= γ1 
.



6 While this theorem is a part of folklore, we were unable to find a formal  proof. We explicitly  prove  this 
theorem in Cohen-Sygal (2004).


67





Definition
An  FSRA  A = (Q, q0 , Σ, Γ, n, k, δ, F⊕,  is  linearized if  it  is  optimized, E-free,  and   for
all (q, σ, (a⊕, q1 ), (q, σ, (b⊕, q2 ) ∈ δ such  that  (a⊕ •= (b⊕,  where (a⊕ = ((op1 , i1 , γ1 ), ... , (op1 ,



i1 	1



2    2 	2



2     2 
	
2


1    1 
	
1 
	
k


k , γk )⊕ and  (b⊕ = ((op1 , i1 , γ1 ), ... , (opm , im , γm )⊕ , there  exists  j1 , 1 ≤ j1  ≤ k and  there
exists j2 ,1 ≤ j2  ≤ m, such that op1 = op2 = R, i1   = i2  and γ1  •= γ2 .


j1	j2


j1	j2


j1	j2


A na¨ıve  algorithm for converting a given  FSRA into  an equivalent linearized one
is to convert  it to an  FSA and  then  determinize it. In the  worst  case, this  results in 
an  exponential increase  in the  network size.  As the  following theorem shows,  FSRA 
linearization is NP-complete.

Theorem 6
FSRA linearization is NP-complete.

Proof 2
Evidently, given  an FSRA A, it can be verified  in polynomial time that  A is linearized. 
Therefore, FSRA linearization is in NP.
    Let φ be a CNF formula with  m clauses  and n variables. Construct an FSRA A such 
that L(A) = {E} if φ is satisfiable, otherwise L(A) = ∅.
Let x1 , ... , xn be the variables of φ. Define A = (Q, q0 , Σ, Γ, n, 1, δ, F⊕, such that:
•	Q = {q0 , q1 , ... , qn+m }
•	F = {qn+m }
•	Σ is irrelevant (choose any Σ).
•	Γ = {T, F}.
•	δ = {(qi−1 , E, (W, i, T), qi ) | 1 ≤ i ≤ n}∪ {(qi−1 , E, (W, i, F), qi ) | 1 ≤ i ≤ n}
∪
{(qn+i−1 , E, (R, j, T), qn+i ) | 1 ≤ i ≤ m and xj occurs in the i-th clause}
∪
{(qn+i−1 , E, (R, j, F), qn+i ) | 1 ≤ i ≤ m and xj occurs in the i-th clause}

Notice that each path  in A is of length  m + n. The first n arcs in the path 
write an assignment into the registers, then it is possible  to traverse the 
remaining m arcs in the path  only if the assignment stored into the 
registers satisfies φ.

For example, for the CNF formula (x1 ∨ x2 ∨ x5 ) ∧ (x1 ∨ x2 ) ∧ (x3 ∨ x4 ∨ x5 ), the FSRA of
Figure  10 is constructed. Observe that  the  number of states  and  arcs  in this  FSRA is 
O(mn). Now,  linearize A into an FSRA A∗ and  assume this can be done  in polynomial 
time.  By the definition of linearized FSRA, A∗  does  not  contain  E-arcs. Therefore, E ∈ 
L(A∗ ) iff the initial state of A∗ is also a final one. Hence, φ is satisfiable  iff the initial state
of A∗ is also a final one. •


4. A Regular Expression Language for FSRAs

Regular  expressions are a formal way for defining regular languages. Regular  language 
operations construct regular expressions in a convenient way.  Several  toolboxes  (soft- 
ware packages) provide extended regular expression description languages and compil-


68















Figure 10
FSRA for a given CNF formula.


ers of the expressions to finite-state devices,  automata, and  transducers (see Section 1). 
We  provide a regular expression language for  constructing FSRAs, the  denotations 
of whose  expressions are  FSRAs. In the  following discussion we  assume the  regular 
expression syntax  of XFST (Beesley and Karttunen 2003) for basic expressions.7

Definition
Let ActionsΓ = {R, W}× {0, 1, 2, ... , n − 1}× Γ, where n is the number of registers and


Γ is the register alphabet. If R is a regular expression and  a ∈ (ActionsΓ


+ is a series of


register operations, then  the following are also regular expressions: a 1 R, a 1 1R, a <1 R,
and a <1<1 R.

We now  define  the denotation of each of the above  expressions. Let R be a regular


expression whose  denotation is the  FSRA A, and  let a ∈ (ActionsΓ


+ . The denotation


of a <1 R is an FSRA A∗ obtained from  A by adding a new  node,  q, which  becomes  the
initial  node  of A∗, and  an arc from  q to the  initial  node  of A; this  arc is labeled  by E
and  associated with  a. Notice  that  in the regular expression a <1 R, R and  a can contain 
operations on joint registers. In some cases, one would like to distinguish between the 
registers used  in a and  in R. Usually, it is up  to the  user  to correctly  manipulate the 
usage of registers, but in some cases automatic distinction seems desirable. For example, 
if R includes a circumfix  operator (see below),  its corresponding FSRA will  contain 
register operations created automatically by the operator. Instead of remembering that 
circumfixation always uses register 1, one can simply  distinguish between the registers 
of a and  R via  the  a <1<1 R operator. This  operator has  the  same  general effect as  
the previous one, but the transition relation in its FSRA uses fresh registers that  are 
added to the machine.
In a similar  way,  the operators a 1 R and  a 1 1R are translated into  networks. The
difference between these  operators and  the previous ones is that  here, the register 
operations in a are  executed after traversing all the  arcs  in the  FSRA denoted by  R. 
Using these additional operators, it is easy to show that every FSRA has a corresponding 
regular expression denoting it, by a trivial modification of the construction presented by 
Kleene (1956).

Example 8
Consider the  case  of vowel  harmony in  Warlpiri (Sproat  1992), where the  vowel  of 
suffixes  agrees  in certain  aspects  with  the  vowel  of the  stem  to which  it is attached.


7 In particular, concatenation is denoted by juxtaposition and E is denoted by 0.


69





A simplified account of the phenomenon is that suffixes come in two varieties, one with
‘i’ vowels  and  one with  ‘u’ vowels.  Stems  whose  last vowel  is ‘i’ take  suffixes  of the 
first variety,  whereas stems  whose  last  vowel  is ‘u’ or ‘a’ take  the  other  variety.  The 
following examples are from Sproat  (1992) (citing Nash  (1980)):

1.	maliki+ki.li+.li+lki+ji+li
(dog+PROP+ERG+then+me+they)

2.	kud. u+ku.lu+.lu+lku+ju+lu
(child+PROP+ERG+then+me+they)

3.	minija+ku.lu+.lu+lku+ju+lu
(cat+PROP+ERG+then+me+they)

An  FSRA that  accepts  the  above  three  words is denoted by  the  following complex 
regular expression:

define LexI  [m a l i k i];   %   words ending  in ‘i’ 
define LexU [k u d u];          %   words ending  in ‘u’ 
define LexA [m i n i j a];     %   words ending  in ‘a’
! Join  all the  lexicons and write to  register 1 ‘u’ or  ‘i’
! according to  the  stem‘s  last  vowel.
define Stem [<(W,1,i)> <1    LexI] | [<(W,1,u)>   <1    [LexU | LexA]];
! Traverse  the  arc  only  if the  scanned symbol is the  content of
! register 1.
define V  [<(R,1,i)> 1 i] | [<(R,1,u)> 1 u]; 
define PROP  [+  k V  l V];        %  PROP    suffix 
define ERG     [+  l V];              %  ERG   suffix
define Then [+  l k V];	%   suffix indicating ‘then’ 
define Me	[+  j V];	%   suffix  indicating ‘me’ 
define They [+  l V];	%   suffix indicating ‘they’
! define the  whole network
define  WarlpiriExample Stem PROP  ERG  Then Me  They;

Register  1 stores  the  last  vowel  of the  stem,  eliminating the  need  to duplicate paths 
for  each  of  the  different cases.  The  lexicon  is  divided into  three  separate  lexicons 
(LexI, LexU, LexA), one for each word ending (‘i’, ‘u’, or ‘a’ respectively). The separate 
lexicons  are  joined  into  one  (the  variable Stem)  and  when  reading the  last  letter  of 
the  base  word, its  type  is written into  register 1. Then,  when  suffixing  the  lexicon 
base  words, the  variable V uses  the  the  content of register 1 to determine which  of 
the symbols ‘i’, ‘u’ should be scanned and  allows  traversing the arc only if the correct 
symbol  is scanned. Note that this solution is applicable independently of the size of the 
lexicon, and can handle other suffixes in the same way.

Example 9
Consider again  Example  7. The FSRA constructed for Arabic  nominative definite  and 
indefinite nouns can be denoted by the following regular expression:

! Read the  definite article (if present).
! Store  in register 1 whether  the  noun is definite or  indefinite.
! Store  in register 2 the  actual form  of  the  definite article.


70





define Prefix  [<(W,1,indef)> <1    0]  | [<(W,1,def),(W,2,l)> <1    ’al] | 
[<(W,1,def),(W,2,$)> <1    ’a$] | [<(W,1,def),(W,2,d)> <1    ’ad];
! Normal base - definite and indefinite
define Base [ [<(R,2,l)> <1    0]  | [<(R,1,indef)> <1    0]  ] 
[ [k  i t a a b]  | [q  a m   a r] ];
! Bases beginning with  $ - definite and indefinite
define $Base [ [<(R,2,$)> <1    0]  | [<(R,1,indef)> <1    0]  ] [$  a m   s];
! Bases beginning with  d - definite and indefinite
define dBase [ [<(R,2,d)> <1    0]  | [<(R,1,indef)> <1    0]  ] [d  a f t a r];
! Read definite and indefinite suffixes.
define Suffix  [<(R,1,def)> 1 u]  | [<(R,1,indef)> 1 un];
! The complete  network.
define ArabicExample  Prefix [Base  | $Base | dBase] Suffix;

The  variable Prefix  denotes the  arcs  connecting the  first  two  states   of  the  FSRA, 
in which  the definite  article (if present) is scanned and  information indicating whether 
the word is definite  or not is saved  into  register 1. In addition, if the word is definite 
then  register 2 stores  the  actual  form  of the  definite  article.  The  lexicon  is divided 
into  several  parts:  The Base variable denotes nouns that  do  not  trigger assimilation. 
Other  variables ($Base, dBase) denote nouns that  trigger assimilation, where for each 
assimilation case, a different lexicon is constructed. Each part  of the lexicon deals  with 
both its definite  and indefinite nouns by allowing traversing the arcs only if the register 
content is appropriate. The  variable Suffix denotes the  correct  suffix,  depending on 
whether the noun  is definite  or indefinite. This is possible  using  the information that 
was stored in register 1 by the variable Prefix.


5. Linguistic  Applications

We demonstrated in examples 5 and  6 that  FSRAs can model  some  non-concatenative 
phenomena more  efficiently  than  standard finite-state devices.  We now  introduce new 
regular expression operators, accounting for our motivating linguistic phenomena, and 
show  how expressions using  these operators are compiled into the appropriate FSRA.


5.1 Circumfixes

We introduce a dedicated regular expression operator for circumfixation and show how 
expressions using  this operator are compiled into the appropriate FSRA. The operator 
accepts  a regular expression, denoting a set  of bases,  and  a set  of circumfixes,  each 
of which  is a pair  of regular expressions (prefix,  suffix). It yields  as a result  an FSRA 
obtained by applying each  circumfix  to each  of the  bases.  The main  purpose of this 
operator is to deal  with  cases  in which  the  circumfixes are  pairs  of strings,  but  it is 
defined such that the circumfixes can be arbitrary regular expressions.


Definition
Let Σ be a finite  set  such  that  D, {, }, (, ⊕, ⊗ ∈/ Σ. We define  the  ⊗ operation to be of
the form

R ⊗ {(β1 Dγ1 ⊕(β2 Dγ2 ⊕ ... (βm Dγm ⊕}


71




where:  m ∈ N is the number of circumfixes;  R is a regular expression over  Σ denoting 
the  set of bases;  and  βi , γi for 1 ≤ i ≤ m are regular expressions over  Σ denoting the
prefix and suffix of the i-th circumfix, respectively.

    Notice  that  R, βi , γi may  denote infinite  sets. To define  the  denotation of this  op- 
erator,  let Aβ , Aγ  be the FSRAs denoted by βi , γi , respectively. The operator yields  an
i	i
FSRA constructed by concatenating three FSRAs. The first is the FSRA constructed from 
the  union of the  FSRAs A∗β , ... , A∗β , where each  A∗β  is an  FSRA obtained from  Aβ
1 	m	i	i
by adding a new  node,  q, which  becomes  the  initial  node  of A∗β , and  an  arc from  q
to the  initial  node  of Aβ ; this  arc is labeled  by E and  associated with  ((W, 1, βi Dγi )⊕
(register 1 is used  to store  the  circumfix).  In addition, the  register operations of the
FSRA Aβ  are  shifted  by  one  register in  order  not  to cause  undesired effects  by  the 
use  of register 1. The second  FSRA is the  FSRA denoted by the  regular expression R 
(again,  with  one  register shift)  and  the  third  is constructed in  the  same  way  as the 
first  one,  the  only  difference being  that  the  FSRAs are  those  denoted by  γ1 , ... , γm
and  the  associated register operation is ((R, 1, βi Dγi )⊕.  Notice  that  the  concatenation
operation, defined in Section  3.2.2, adjusts the  register operations in the FSRAs to be
concatenated, to avoid  undesired effects  caused by using  joint  registers. We use  this 
operation to concatenate the three  FSRAs, leaving  register 1 unaffected (to handle the 
circumfix).


Example 10
Consider the  participle-forming combinations in German, e.g., the  circumfix  ge-t. A  
simplified account of the phenomenon is that German verbs  in their present form take 
an n suffix but in participle form they take the circumfix  ge-t. The following examples 
are from Sproat  (1992):

sa¨useln     ‘rustle’    gesa¨uselt     ‘rustled’
bru¨ sten   ‘brag’     gebru¨ stet   ‘bragged’

The  FSRA of  Figure   11, which   accepts  the  four  forms,  is  denoted by  the  regular 
expression

[s a¨ usel |  br u¨  st e] ⊗ {(EDn⊕(g eDt⊕}


This regular expression can be easily  extended to accept  more  German verbs  in other 
forms.  More  circumfixation phenomena  in  other  languages such  as  Indonesian and 
Arabic can be modeled in the same way using  this operator.










Figure 11
Participle-forming combinations in German.


72





Example 11
Consider again  Example  5. The FSRA accepting all the possible  combinations of stems 
and  the Hebrew circumfixes h-a, ht-ut,  m-E can be denoted by the regular expression
R ⊗ {(hDa⊕(htDut⊕(mDE⊕} where R denotes an FSA accepting the roots.


5.2 Interdigitation

Next, we define a dedicated operator for interdigitation. It accepts  a set of regular 
expressions, representing a set of roots, and  a list of patterns, each of which  containing 
exactly  n slots. It yields  as a result  an FSRA denoting the set containing all the strings 
created by splicing  the roots into the slots in the patterns. For example, consider the He- 
brew roots r.$.m, p.&.l, p.q.d  and the Hebrew patterns hitDaDeD, miDDaD, haDDaDa. 
The  roots  are  all trilateral, and  the  patterns have  three  slots  each.  Given  these  two
inputs, the new operator yields an FSRA denoting the set {hitra$em, hitpa&el,  hitpaqed, 
mir$am, mip&al,  mipqad, har$ama, hap&ala, hapqada }.

Definition
Let Σ be a finite set such that  D, {, }, (, ⊕, ⊕ ∈/ Σ. We define  the splice  operation to be of
the form

{(α11 , α12 , ..., α1n ⊕, (α21 , α22 , ..., α2n ⊕, ..., (αm1 , αm2 , ..., αmn ⊕}

⊕

{(β11 Dβ12 D...β1n Dβ1 n+1 ⊕, (β21 Dβ22 D...β2n Dβ2 n+1 ⊕, ..., (βk1 Dβk2 D...βkn Dβk n+1 ⊕}

where:

•	n ∈ N is the number of slots (represented by ‘D’) in the patterns into which 
the roots letters should be inserted.
•	m ∈ N is the number of roots to be inserted.
•	k ∈ N is the number of patterns.
•	αij, βij are regular expressions (including regular expressions denoting
FSRAs).

    The left set is a set of roots  to be inserted into the slots in the right  set of patterns. 
For the sake of brevity, βi and αi are used as shorthand notations for βi1 Dβi2 D...Dβi(n+1) 
and αi1 αi2 ...αin , respectively.
   Consider first the  case where αij ∈ Σ ∪ {E} for 1 ≤ i ≤ m and  1 ≤ j ≤ n and  βij ∈ 
Σ ∪ {E} for 1 ≤ i ≤ k and 1 ≤ j ≤ n + 1. In this case the splice operation yields as a result 
an  FSRA-1 A = (Q, q0 , Σ, Γ, 3, δ, F⊕,  such  that  L(A) = {βj1 αi1 βj2 αi2 ...βjn αin βj(n+1)  | 1 ≤
i ≤ m , 1 ≤ j ≤ k}, where:

•	Q = {q0 , q1 , ..., q2n+1 }
•	F = {q2n+1 }
•	Σ = ({αij| 1 ≤ i ≤ m , 1 ≤ j ≤ n} ∪ {βij | 1 ≤ i ≤ k , 1 ≤ j ≤ n + 1} \ {E}


73


























Figure 12
Interdigitation FSRA – general.

•	Γ = {βi | 1 ≤ i ≤ k} ∪ {αi| 1 ≤ i ≤ m} ∪ {#}.
•	δ = {(q0 , βi1 , W, 1, βi , q1 )| 1 ≤ i ≤ k}
∪
{(q1 , αi1 , W, 2, αi , q2 )| 1 ≤ i ≤ m}
∪
{(q2j−2 , βij , R, 1, βi , q2j−1 )| 1 ≤ i ≤ k , 2 ≤ j ≤ n + 1}
∪
{(q2j−1 , αij , R, 2, αi , q2j )| 1 ≤ i ≤ m , 2 ≤ j ≤ n}


This  FSRA is shown in Figure  12. It has  3 registers, where register 1 remembers the 
pattern and  register 2 remembers the root.  Notice  that  the FSRA will have  3 registers
and  2n + 2 states  for any number of roots  and  patterns. The number of arcs is k × (n +
1) + m × n. In the (default) case of trilateral roots, for m roots and k patterns the resulting
machine has a constant number of states and O(k + m) arcs.
    In  the  general case,  where αij  and  βij can  be  arbitrary regular expressions, the 
construction of the FSRA denoted by this operation is done  in the same  way  as in the 
case of circumfixes with  two  main  adjustments. The first is that  in this  case the  final 
FSRA is constructed by concatenating 2n + 1 intermediate FSRAs (n FSRAs for the  n 
parts  of the roots and n + 1 FSRAs for the n + 1 parts  of the patterns). The second  is that 
here,  2 registers are used  to remember both  the root and  the pattern. We suppress the 
detailed description of the construction.


Example 12
Consider again the Hebrew roots r.$.m, p.&.l, p.q.d  and the Hebrew patterns hitDaDeD,
miDDaD, and haDDaDa. The splice operation

{(r, $, m⊕(p, &, l⊕(p, q, d⊕} ⊕ {(hitDaDeD⊕(miDDaD⊕(haDDaDa⊕}


74





yields  the  FSRA of Figure  13. The  E-arc was  added only  for the  convenience of the 
drawing.
    It should be noted that  like other  processes of derivational morphology, Hebrew 
word formation is highly  idiosyncratic: Not  all roots  combine with  all patterns, and 
there  is  no  systematic way  to  determine when  such  combinations will  be  realized 
in  the  language. Yet, this  does  not  render our  proposed operators useless:  One  can 
naturally characterize classes  of roots  and  classes  of patterns for which  all the  com- 
binations exist. Furthermore, even when  such a characterization is difficult  to come by, 
the  splice  operator can be used,  in combination with  other  extended regular expres- 
sion  operators, to define  complex  expressions for  generating the  required language. 
This is compatible with  the general approach for using  finite-state techniques, imple- 
menting each phenomenon independently and combining them  together using  closure 
properties.



5.3 Reduplication


We now return to the reduplication problem as was presented in example 3. We extend 
the  finite-state  registered  model  to  efficiently  accept  Ln  = {ww | w ∈ Σ∗,  |w| = n}, a  
finite instance of the general problem, which  is arguably sufficient  for describing 
reduplication in natural languages. Using  FSRAs as defined above  does  not  improve 
space  efficiency,  because  a separate path  for each reduplication is still needed. Notice 
that  the  different symbols  in Ln  have  no  significance except  the  pattern they  create. 
Therefore, FSRAs are extended in order  to be able to identify a pattern without actually 
distinguishing between different symbols  in it. The extended model,  FSRA*, is obtained 
from the FSRA-1 model  by adding a new  symbol,  ‘*’, assumed not to belong  to Σ, and 
by forcing  Γ to be equal  to Σ. The ‘*’ indicates equality between the input symbol  and 
the  designated register content, eliminating the  need  to duplicate paths for different 
symbols.























Figure 13
Interdigitation example.


75





Definition
Let ∗ ∈/ Σ. An FSRA* is an FSRA-1 where Σ = Γ (and  thus  includes ’#’) and  the tran- 
sition  function is  extended to  be  δ ⊆ Q × Σ ∪ {E, ∗} × {R, W}× {0, 1, 2, ... , n − 1}× 
Σ ∪ {∗} × Q. The extended meaning of δ is as follows:

•	(s, σ, R, i, γ, t) ∈ δ, (s, σ, W, i, γ, t) ∈ δ where σ, γ •= ∗ imply  the same 
as before.
•	(s, σ, R, i, ∗, t) ∈ δ and  (s, ∗, R, i, σ, t) ∈ δ for σ •= E imply  that if the 
automaton is in state s, the input symbol  is σ and the content of the i-th 
register is the same σ, then the automaton may enter state t.
•	(s, σ, W, i, ∗, t) ∈ δ and  (s, ∗, W, i, σ, t) ∈ δ for σ •= E imply  that if the 
automaton is in state s and the input symbol  is σ, then the content of the 
i-th register is changed to σ, and the automaton may enter state t.

•	(s, ∗, R, i, ∗, t) ∈ δ implies  that if the automaton is in state s, the input 
symbol  is some σ ∈ Σ and the content of the i-th register is the same σ,
then the automaton may enter state t.

•	(s, ∗, W, i, ∗, t) ∈ δ implies  that if the automaton is in state s and the input 
symbol  is some σ ∈ Σ, then the content of the i-th register is changed to the
same σ, and the automaton may enter state t.


    With  this  extended model  we can construct an efficient  registered automaton for 
Ln : The number of registers is n+1. Registers  1, ..., n remember the first n symbols  to be 
duplicated. Figure  14 depicts an extended registered automaton that accepts Ln for n =
4. Notice that the number of states depends only on n and not on the size of Σ. Figure 15 
schematically depicts an extended registered automaton that accepts Ln for some n ∈ N. 
The language {ww | |w|≤ n} for some  n ∈ N can be generated by a union  of FSRA*, 
each  one  generating Ln  for some  i ≤ n. Since n is usually small  in natural language
reduplication, the  resulting automaton is manageable, and  in any  case, considerably 
smaller  than the na¨ıve automaton.


5.4 Assimilation

In  example 7, FSRAs are  used  to  model  assimilation in  Arabic  nominative definite 
nouns. Using  the  FSRA* model  defined above,  further reduction in the  network size 
can be achieved. The FSRA* of Figure 16 accepts all the nominative definite forms of the 
Arabic  nouns kitaab,  qamar, and  daftar (more  nouns can be added in a similar  way). 
Register  1 stores information about  the actual  form of the definite  article, to ensure that 
assimilation occurs when  needed and only then. Notice that in this FSRA, in contrast to








Figure 14
Reduplication for n = 4.


76











Figure 15
Reduplication – general case.




the FSRA of Figure  8, the definite  Arabic article al is not scanned as one symbol  but as 
two separate symbols.



6. Finite-state Registered  Transducers

We  extend  the  FSRA model  to  finite-state  registered  transducers  (FSRT), denoting 
relations over two finite alphabets. The extension is done by adding to each transition an 
output symbol. This facilitates an elegant solution to the problem of binary incrementors 
which  was introduced in Example  4.


Example 13
Consider again  the  32-bit incrementor example introduced in Example  4. Recall that 
a sequential transducer for an n-bit binary incrementor would require 2n states  and  a 
similar  number of transitions. Using  the FSRT model,  a more  efficient n-bit transducer 
can  be  constructed. A 4-bit  FSRT incrementor is shown in  Figure  17. The  first  four 
transitions copy  the  input string  into  the  registers, then  the  input is scanned (using 
the  registers) from  right  to  left (as  the  carry  moves),  calculating the  result,  and  the 
last  four  transitions output the  result  (in case the  input is 1n , an  extra  1 is added in 
the  beginning). Notice  that  this  transducer guarantees linear  recognition time,  since 
from  each  state  only  one  arc  can  be  traversed in  each  step,  even  when   there  are
E-arcs.  In the  same  way,  an  n-bit  transducer can  be  constructed for  all  n ∈ N. Such
a transducer will  have  n registers, 3n + 1 states  and  6n arcs.  The FSRT model  solves
the incrementor problem in much  the same  way  it is solved  by vectorized finite-state















Figure 16
FSRA* for Arabic nominative definite  nouns.


77






























Figure 17
4-bit incrementor using  FSRT.




automata, but  the FSRT solution is more  intuitive and  is based  on existing  finite-state 
techniques.
    It is easy to show  that FSRTs, just like FSRAs, are equivalent to their non-registered 
counterparts. It  immediately implies  that  FSRTs maintain the  closure  properties of 
regular relations. As in FSRAs, implementing the closure  properties directly on FSRTs 
is essential for benefiting from  their  space  efficiency.  The common operators such  as 
union, concatenation, etc., are  implemented in the  same  ways  as in FSRAs. A direct 
implementation of FSRT composition is a na¨ıve  extension of ordinary transducer com- 
position, based  on  the  intersection construction of FSRAs. We explicitly  define  these 
operations in Cohen-Sygal (2004).


7. Implementation and Evaluation

In order  to practically compare the space and time performance of FSRAs and FSAs, we 
have  implemented the special  operators introduced in Sections  4 and  5 for circumfix- 
ation  and  interdigitation, as well as direct  construction of FSRAs. We have  compared 
FSRAs with  ordinary FSAs by building corresponding networks for circumfixation, 
interdigitation, and  n-bit incrementation. For circumfixation, we constructed networks 
for the circumfixation of 1,043 Hebrew roots  and  4 circumfixes.  For interdigitation we 
constructed a network accepting the splicing  of 1,043 roots  into  20 patterns. For n-bit 
incrementation we  constructed networks for 10-bit, 50-bit, and  100-bit incrementors. 
Table 1 displays the size of each of the networks in terms  of states,  arcs, and  actual  file 
size.


78






Table 1
Space comparison between FSAs and FSRAs.

Operation	Network type 	States 	Arcs 	Registers 	File size

Circ
umf
ixat
ion
FS
A
8
1
1
3
,
8
2
4
–
4
7
k
B
(4 
circ
umf
ixes
, 
1,04
3 
root
s)
FS
RA
3
5
6
3
6
0
1
1
6
k
B
Inte
rdig
itati
on
FS
A
12
,5
27
31
,0
77
–
4
5
1
k
B
(20 
patt
erns
, 
1,04
3 
root
s)
FS
RA
5
8
3
,
2
5
9
2
6
7
k
B
10-
bit 
incr
eme
ntor
Se
qu
ent
ial 
FS
T
2
6
8
3
2
2
–
7
k
B

FS
RT
3
1
6
0
1
0
2
k
B
50-
bit 
incr
eme
ntor
Se
qu
ent
ial 
FS
T
23
,3
28
24
,6
02
–
6
0
0
k
B

FS
RT
1
5
1
3
0
0
5
0
8
k
B
100-bit incrementor 	Sequential FST	176,653	181,702	–	4.73Mb

FS
RT
3
0
1
6
0
0
1
0
0
1
7
k
B

Table 2
Time comparison between FSAs and FSRAs.


20
0 
wo
rds
1,0
00 
wo
rds
5,0
00 
wo
rds
Circ
umf
ixat
ion
FS
A
0
.
0
1
s
0
.
0
2
s
0
.
0
8
s
(4 
circ
umf
ixes
, 
1,04
3 
root
s)
FS
RA
0
.
0
1
s
0
.
0
2
s
0
.
0
9
s
Inte
rdig
itati
on
FS
A
0
.
0
1
s
0
.
0
2
s
1
s
(20 
patt
erns
, 
1,04
3 
root
s)
FS
RA
0
.
3
5
s
1
.
4
2
s
1
0
.
1
1
s
10-
bit 
incr
eme
ntor
Se
qu
ent
ial 
FS
T
0
.
0
1
s
0
.
0
5
s
0
.
1
7
s

FS
RT
0
.
0
1
s
0
.
0
6
s
0
.
2
3
s
50-
bit 
incr
eme
ntor
Se
qu
ent
ial 
FS
T
0
.
1
3
s
0
.
2
s
0
.
5
9
s

FS
RT
0
.
0
8
s
0
.
4
s
1
.
6
s


    Clearly, FSRAs provide a significant reduction in the network size. In particular, we 
could  not construct an n-bit incrementor FSA for any  n greater than  100 as a result  of 
memory problems, whereas using  FSRAs we  had  no problem constructing networks 
even for n = 50, 000.
    In addition, we compared the recognition times of the two models. For that purpose, 
we used  the circumfixation, interdigitation, 10-bit incrementation, and 50-bit incremen- 
tation  networks to analyze 200, 1,000, and  5,000 words. As can be seen in Table 2, time 
performance is comparable for the two models, except  for interdigitation, where FSAs 
outperform FSRAs by a constant factor. The reason  is that  in this network the usage  of 
registers is massive and  thereby, there  is a higher cost to the reduction of the network 
size, in terms of analysis time. This is an instance of the common tradeoff of time versus 
space: FSRAs improve the network size at the cost of slower analysis time in some cases. 
When  using  finite-state devices  for natural language processing, often  the  generated 
networks become too large to be practical. In such cases, using FSRAs can make network 
size  manageable. Using  the  closure  constructions one  can  build  desired networks of 
reasonable size, and  at the  end  decide  whether to convert  them  to ordinary FSAs, if 
time performance is an issue.

8. Conclusions

In this work  we introduce finite-state registered networks (automata and  transducers), 
an extension of finite-state networks which  adds  a limited amount of memory, in the


79





form  of registers,  to each  transition. We show  how  FSRAs can  be used  to efficiently 
model  several  non-concatenative morphological phenomena, including circumfixation, 
root  and  pattern word formation in Semitic  languages, vowel  harmony, and  limited 
reduplication.
    The main  advantage of finite-state registered networks is their space efficiency. We 
show  that  every  FSA can be simulated by an equivalent FSRA with  three  states  and 
two  registers. For the  motivating linguistic examples, we show  a significant decrease 
in the number of states  and the number of transitions. For example, to account for all
the possible  combinations of r roots  and  p patterns, an ordinary FSA requires O(r × p)
arcs whereas an FSRA requires only  O(r + p). As a non-linguistic example, we  show
a transducer that computes n-bit increments of binary numbers. While an ordinary 
(sequential) FST requires O(2n ) states and arcs, an FSRT which  guarantees linear  recog- 
nition  time requires only O(n) states and arcs.
    In spite  of their  efficiency, finite-state registered networks are equivalent, in terms 
of their expressive power, to ordinary finite state networks. We provide an algorithm for 
converting FSRAs to FSAs and  prove  the equivalence of the models. Furthermore, we 
provide direct constructions of the main closure properties of FSAs for FSRAs, including 
concatenation, union, intersection, and composition.
    In order  for finite-state networks to be useful  for linguistic processing, we provide 
a  regular expression language denoting  FSRAs.  In  particular, we  provide a  set  of 
extended regular expression operators that  denote FSRAs and  FSRTs. We demonstrate 
the utility  of the operators by accounting for a variety of complex  morphological and 
phonological phenomena, including circumfixation (Hebrew and  German), root-and- 
pattern (Hebrew), vowel  harmony (Warlpiri), assimilation (Arabic),  and  limited redu- 
plication. These  dedicated operators can  be used  in conjunction with  standard finite 
state calculi, thereby providing a complete set of tools for the computational treatment 
of non-concatenative morphology.
    This work  opens  a variety of directions for future research. An immediate question 
is the conversion of FSAs to FSRAs. While it is always possible  to convert  a given  FSA 
to an FSRA (simply add  one register which  is never  used),  we believe that it is possible 
to automatically convert  space inefficient FSAs to more compact FSRAs. A pre-requisite 
is a clear understanding of the parameters for minimization: These include the number 
of states, arcs, and registers, and the size of the register alphabet. For a given FSRA, the 
number of states  can always be reduced to a constant (theorem 3) and  registers can be 
done  away  with  entirely (by converting the FSRA to an FSA, Section 3.1). In contrast, 
minimizing the number of arcs in an FSRA is NP-hard (Section 3.4). A useful conversion 
of FSAs to FSRAs must  minimize some  combination of these  parameters, and  while  it 
may  be intractable in general, it can be practical in many  special  cases. In particular, 
the  case of finite  languages (acyclic FSAs) is both  of practical importance and  — we 
conjecture — can result  in good compaction.
    More work is also needed in order  to establish more properties of FSRTs. In particu- 
lar, we did  not  address issues  such  as sequentiality or sequentiability for this  model.
Similarly,  FSRA∗ can  benefit  from  further research. All the  closure  constructions for
FSRA∗s can be done in a similar way to FSRAs, with the exception of intersection. For in-
tersection, we believe that the use of predicates (van Noord and Gerdemann 2001b) can 
be beneficial. Furthermore, the use of predicates can be beneficial for describing natural 
language reduplication where the reduplication is not as bounded as the example we
deal with in this work.  In addition, the FSRA∗ model  can be extended into transducers.
    Finally,  in Section  7 we  discuss  an implementation of FSRAs. Although we  have 
used  this  system  to construct networks for several  phenomena, we  are  interested in


80





constructing a network for describing the complete morphology of a natural language 
containing many  non-concatenative phenomena, e.g., Hebrew. A morphological ana- 
lyzer for Hebrew, based  on finite-state calculi, already exists (Yona and  Wintner 2005), 
but  is very  space-inefficient and,  therefore, hard  to maintain. It would be beneficial  to 
compact such a network using  FSRTs, and  to inspect  the time versus space tradeoff on 
such a comprehensive network.



Acknowledgments
We are grateful to Dale Gerdemann for his 
help and inspiration. We thank Victor Harnik 
and Nissim  Francez  for their comments on
an earlier  version of this paper. We are also 
thankful to the anonymous reviewers, whose 
comments helped substantially to improve 
this article. This research was supported by 
The Israel Science Foundation (grant
no. 136/01).


References
Beesley, Kenneth R. 1998. Constraining 
separated morphotactic dependencies in 
finite-state grammars. In Proceedings of 
FSMNLP-98, pages  118–127, Bilkent, 
Turkey.
Beesley, Kenneth R. and Lauri Karttunen.
2000. Finite-state non-concatenative 
morphotactics. In Proceedings of the
Fifth Workshop of the ACL Special Interest 
Group in Computational Phonology, 
SIGPHON-2000, pages  1–12, 
Luxembourg.
Beesley, Kenneth R. and Lauri Karttunen.
2003. Finite-State Morphology. CSLI 
Publications.
Blank, Glenn D. 1985. A new kind of finite-
state automaton: Register  vector grammar. 
In Proceedings of the International Joint 
Conference on Artificial Intelligence, pages  
749–755, UCLA.
Blank, Glenn D. 1989. A finite and real-time 
processor for natural language. 
Communications  of the ACM,
32(10):1174–1189.
Cohen-Sygal, Yael. 2004. Computational 
implementation of non-concatenative 
morphology. Master ’s thesis, Department 
of Computer Science, University of Haifa, 
Israel.
Holzer,  Markus and Martin  Kutrib.  2002. 
State complexity of basic operations on 
nondeterministic finite automata. In 
Jean-Marc  Champarnaud and Denis 
Maurel,  editors, Implementation and 
Application of Automata, 7th International 
Conference, CIAA 2002, volume 2608 of 
Lecture Notes in Computer Science, 
Springer, pages  148–157.


Kaminski, Michael and Nissim  Francez.
1994. Finite memory automata. Theoretical
Computer  Science, 134(2):329–364.
Kaplan,  Ronald  M. and Martin  Kay. 1994. 
Regular  models of phonological rule 
systems. Computational Linguistics,
20(3):331–378.
Karttunen, Lauri, Jean-Pierre Chanod, 
Gregory Grefenstette, and Anne Schiller.
1996. Regular  expressions for language 
engineering. Natural Language Engineering,
2(4):305–328.
Kataja, Laura  and Kimmo Koskenniemi.
1988. Finite-state description of Semitic 
morphology: A case study of ancient 
Akkadian. In Proceedings of COLING 88, 
International Conference on Computational 
Linguistics, pages  313–315, Budapest.
Kay, Martin.  1987. Nonconcatenative
finite-state morphology. In Proceedings of the 
Third Conference of the European Chapter of 
the Association for Computational 
Linguistics, pages  2–10, Copenhagen, 
Denmark.
Kiraz, George Anton.  2000. Multitiered 
nonlinear morphology using  multitape 
finite automata: A case study on Syriac 
and Arabic. Computational Linguistics,
26(1):77–105.
Kleene, S. C. 1956. Representation of events 
in nerve  nets and finite automata. In C. E. 
Shannon and J. McCarthy, editors, 
Automata Studies. Princeton University 
Press, pages  3–42.
Kornai, Andra´ s. 1996. Vectorized finite-state 
automata. In Proceedings of the Workshop on 
Extended Finite-State  Models of Languages in 
the 12th European Conference on Artificial 
Intelligence, pages  36–41, Budapest.
Koskenniemi, Kimmo. 1983. Two-Level 
Morphology: A General Computational Model 
for Word-Form Recognition and Production. 
The Department of General  Linguistics, 
University of Helsinki.
Krauwer, Steven and Louis des Tombe. 1981. 
Transducers and grammars as theories of 
language. Theoretical Linguistics, 8:173–202.
Lavie, Alon, Alon Itai, Uzzi Ornan, and Mori
Rimon. 1988. On the applicability of
two-level morphology to the inflection  of
Hebrew verbs. Technical  Report  513,


81







Department of Computer Science, 
Technion,  32000 Haifa, Israel.
Mohri, Mehryar. 1996. On some applications 
of finite-state automata theory to natural 
language processing. Natural Language 
Engineering, 2(1):61–80.
Mohri, Mehryar. 2000. Generic
epsilon-removal algorithm for weighted 
automata. In Sheng Yu and Andrei Paun, 
editors, 5th International Conference, CIAA
2000, volume 2088, Springer-Verlag, 
pages  230–242.
Mohri, Mehryar, Fernando Pereira,  and 
Michael Riley. 2000. The design principles 
of a weighted finite-state transducer 
library.  Theoretical Computer Science,
231(1):17–32.
Nash,  David.  1980. Topics in Warlpiri 
Grammar. Ph.D. thesis, Massachusetts 
Institute of Technology.
Sproat,  Richard  W. 1992. Morphology and
  Computation. MIT Press, Cambridge, MA. 
van Noord, Gertjan and Dale Gerdemann.
2001a. An extendible regular expression 
compiler for finite-state approaches in 
natural language processing. In O. Boldt 
and H. Ju¨ rgensen, editors, Automata


Implementation, 4th International 
Workshop on Implementing Automata, 
WIA’99, Potsdam, Germany, Revised 
Papers,
number 2214 in Lecture Notes in Computer
Science. Springer.
van Noord, Gertjan and Dale Gerdemann.
2001b. Finite state transducers 
with predicates and identity. 
Grammars,
4(3):263–286.
Walther, Markus. 2000a. Finite-state 
reduplication in one-level  
prosodic morphology. In 
Proceedings of
the First Conference of the North 
American Chapter of the 
Association for Computational 
Linguistics, pages 296–302, 
Seattle.
Walther, Markus. 2000b. Temiar 
reduplication in one-level  prosodic 
morphology. In Proceedings of 
SIGPHON,  Workshop on Finite-State 
Phonology, pages  13–21, 
Luxembourg.
Yona, Shlomo and Shuly Wintner.
2005. A finite-state morphological 
grammar of Hebrew. In Proceedings 
of
the ACL-2005 Workshop on Computational
Approaches to Semitic 
Languages, Ann Arbor.





































82


This article has been cited by:

1. Hugo C.C. Carneiro, Felipe M.G. França, Priscila M.V. Lima. 2015. Multilingual part-of-speech 
tagging with weightless neural networks. Neural Networks 66, 11-21. [CrossRef]
2. Olamma Iheanetu, Michael AdeyeyeFinite state representation of reduplication processes in Igbo
1-6. [CrossRef]
3. Jie Fu, H. G. TannerOptimal planning on register automata 4540-4545. [CrossRef]
4. Erwin Chan,  Charles Yang.  2008. Kenneth  R.  Beesley &  Lauri  Karttunen,  Finite  State 
Morphology  . Stanford, CA: CSLI Publications (distributed by the  University  of Chicago 
Press), 2003. xviii + 505pp. and CD-ROM.  ISBN hardbound 1-57586-433-9, paperbound
1-57586-434-7. Word Structure 1:2, 246-254. [CrossRef]
5. SHULY WINTNER. 2008. Strengths and weaknesses of finite-state technology: a case study in 
morphological grammar development. Natural Language Engineering 14:04. . [CrossRef]


































