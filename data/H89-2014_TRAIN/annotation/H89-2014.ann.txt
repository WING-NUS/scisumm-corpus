Citance Number: 1 | Reference Article:  H89-2014.txt | Citing Article:  W93-0111.txt |  Citation Marker Offset:  29544-29556 | Citation Marker:  Kupiec, 1989 | Citation Offset:  29438-29556 | Citation Marker:  This approach is similar in spirit to the iterative computational approaches of the Hidden Markov Models (Kupiec, 1989 ... ) | Reference Offset:  ['4016-4079'] | Reference Text:  The work described here also makes use of a hidden Markov model | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 2 | Reference Article:  H89-2014.txt | Citing Article:  A92-1018.txt | Citation Marker Offset:  6271-6284 | Citation Marker:  Kupiec, 1989a | Citation Offset:  6267-6426 | Citation Text:  In [Kupiec, 1989a], networks are used to selectively augment the context in a basic first-order model, rather than using uniformly second-order dependencies | Reference Offset:  ['17414-17662'] | Reference Text:  A model containing all of the refinements described, was tested using a magazine article containing 146 sentences (3,822 words). A 30,000 word dictionary was used, supplemented by inflectional analysis for words not found directly in the dictionary | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 3 | Reference Article:  H89-2014.txt | Citing Article:  A92-1018.txt | Citation Marker Offset:  19300-19313 | Citation Marker:  Kupiec, 1989a | Citation Offset:  19201-19314 | Citation Text:  adequate training requires processing from tens of thousands to hundreds of thousands of tokens [Kupiec, 1989a] | Reference Offset:  ['12949-13268'] | Reference Text:  An alternative to uniformly increasing the order of the conditioning is to extend it selectively. Mixed higher-order context can be modeled by introducing explicit state sequences. In the arrangement the basic first-order network remains, permitting all possible category sequences, and modeling first-order dependency | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 4 | Reference Article:  H89-2014.txt | Citing Article:  J93-2006.txt | Citation Marker Offset:  6334-6345 | Citation Marker:  Kupiec 1989 | Citation Offset:  6260-6308 | Citation Text:  The effectiveness of such models is well known ( ... Kupiec 1989 ... ) | Reference Offset:  ['634-776'] | Reference Text:  The paper describes refinements that are currently being investigated in a model for part-of-speech assignment to words in unrestricted text | Discourse Facet:  Aim_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 5 | Reference Article:  H89-2014.txt | Citing Article:  H91-1046.txt | Citation Marker Offset:  9600-9612 | Citation Marker:  Kupiec, 1989 | Citation Offset:  9520-9613 | Citation Text:  The vocabulary entry may be a word or an equivalence class based on categories (Kupiec, 1989) | Reference Offset:  ['4210-4226', '4418-4435', '4458-4600'] | Reference Text:  word equivalence ... classes were used ... it is assumed that the distribution of the use of a word depends on the set of categories it can assume, and words are partitioned accordingly | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 6 | Reference Article:  H89-2014.txt | Citing Article:  H91-1046.txt | Citation Marker Offset:  2604-2608 | Citation Marker:  1989 | Citation Offset:  2596-2694 | Citation Text:  Kupiec (1989) has experimented with the inclusion of networks to model mixed-order dependencies |  Reference Offset:  ['13047-13129', '13270-13390'] | Reference Text:  Mixed higher-order context can be modeled by introducing explicit state sequences ... The basic network is then augmented with the extra state sequences which model certain category sequences in more detail | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 7 | Reference Article:  H89-2014.txt | Citing Article:  C00-1081.txt | Citation Marker Offset:  12766-12778 | Citation Marker:  Kupiec, 1989 | Citation Offset:  12743-12829 | Citation Text:  In a practical tagger (Kupiec, 1989), only the most frequent 100 words are lexicalized | Reference Offset:  ['10004-10349'] | Reference Text:  In a ranked list of words in the corpus the most frequent 100 words account for approximately 50% of the total tokens in the corpus, and thus data is available to estimate them reliably. The most frequent 100 words of the corpus were assigned individually in the model, thereby enabling them to have different distributions over their categories | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 8 | Reference Article:  H89-2014.txt | Citing Article:  H92-1022.txt | Citation Marker Offset: 3309-3311 | Citation Marker: 11 | Citation Offset:  3216-3318 | Citation Text:  The parameters of the model can be estimated from  ... untagged [ ...  11] text. | Reference Offset:  ['778-855'] | Reference Text:  The model has the advantage that a pre-tagged training corpus is not required | Discourse Facet:  Implication_Citation | Annotator:  Kokil Jaidka, NTU |

Citance Number: 9 | Reference Article: H89-2014.txt | Citation Offset:  2163-2342 | Citation Marker Offset: 2360-2362 | Citation Marker: 11 | Citation Offset: 2163-2367 | Citation Text:  One area in which the statistical approach has done particularly well is automatic part of speech tagging, assigning each word in an input sentence its proper part of speech [ ... 11 ... ] | Reference Offset:  ['20371-20478'] | Reference Text:  A stochastic method for assigning part-of-speech categories to unrestricted English text has been described | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 10 | Reference Article:  H89-2014.txt | Citing Article:  C92-1060.txt | Citation Marker Offset:  24558-24570 | Citation Marker:  Kupiec, 1989 | Citation Offset:  24423-24682 | Citation Text:  only common words are represented individually; the rest of the words in the dictionary are partitioned into word equivalence classes (Kupiec, 1989) such that all words that can function as a particular set of part-of-speech categories are given the same label | Reference Offset:  ['4210-4226', '4418-4435', '4458-4600'] | Reference Text:  word equivalence ... classes were used ... it is assumed that the distribution of the use of a word depends on the set of categories it can assume, and words are partitioned accordingly | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


Citance Number: 11 | Reference Article:  H89-2014.txt | Citing Article:  J93-1001.txt | Citation Marker Offset:  24510-24522 | Citation Marker:  1989 | Citation Offset:  24284-24321 | Citation Text:  contemporary part-of-speech programs: ... Kupiec (1989 ... ) | Reference Offset:  ['634-776', '17543-18116'] | Reference Text:  The paper describes refinements that are currently being investigated in a model for part-of-speech assignment to words in unrestricted text ... A 30,000 word dictionary was used, supplemented by inflectional analysis for words not found directly in the dictionary. In the document, 142 words were tagged as unknown (their possible categories were not known). A total of 1,526 words had ambiguous categories (i.e. 40% of the document). Critical examination of the tagging provided by the augmented model showed 168 word tagging errors, whereas the basic model gave 215 erroneous word tags. The former represents 95.6% correct word tagging on the text as a whole (ignoring unknown words), and 89% on the ambiguous words | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka, NTU |


