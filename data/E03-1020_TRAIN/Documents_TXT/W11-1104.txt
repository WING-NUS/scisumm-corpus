Word Sense Induction by Community Detection
Proceedings of the TextGraphs-6 Workshop, pages 24–28,Portland, Oregon, USA, 19-24 June 2011. c©2011 Association for Computational Linguistics
Word Sense Induction by Community Detection
David Jurgens1,21HRL Laboratories, LLC 2Department of Computer Science
Malibu, California, USA University of California, Los Angelesjurgens@cs.ucla.edu
Abstract
Word Sense Induction (WSI) is an unsu-pervised approach for learning the multiplesenses of a word. Graph-based approaches toWSI frequently represent word co-occurrenceas a graph and use the statistical propertiesof the graph to identify the senses. We rein-terpret graph-based WSI as community detec-tion, a well studied problem in network sci-ence. The relations in the co-occurrence graphgive rise to word communities, which distin-guish senses. Our results show competitiveperformance on the SemEval-2010 WSI Task.
1 IntroductionMany words have several distinct meanings. For ex-ample, “law” may refer to legislation, a rule, or po-lice depending on the context. Word Sense Induc-tion (WSI) discovers the different senses of a word,such as “law,” by examining its contextual uses. Byderiving the senses of a word directly from a corpus,WSI is able to identify specialized, topical meaningsin domains such as medicine or law, which prede-fined sense inventories may not include.
aWe consider graph-based approaches to WSI,which typically construct a graph from word occur-rences or collocations. The core problem is how toidentify sense-specific information within the graphin order to perform sense induction. Current ap-proaches have used clustering (Dorow and Wid-dows, 2003; Klapaftis and Manandhar, 2008) orstatistical graph models (Klapaftis and Manandhar,2010) to identify sense-specific subgraphs.
We reinterpret the challenge of identifying sense-specific information in a co-occurrence graph as oneof community detection, where a community is de-
fined as a group of connected nodes that are moreconnected to each other than to the rest of the graph(Fortunato, 2010). Within the co-occurrence graph,we hypothesize that communities identify sense-specific contexts for each of the terms. Communitydetection identifies groups of contextual cues thatconstrain each of the words in a community to a sin-gle sense.
To test our hypothesis, we require a communitydetection algorithm with two key properties: (1) aword may belong to multiple, overlapping commu-nities, which is necessary for discovering multiplesenses, and (2) the community detection may be hi-erarchically tuned, which corresponds to sense gran-ularity. Therefore, we adapt a recent, state of the artapproach, Link Clustering (Ahn et al., 2010). Ourinitial study suggests that community detection of-fers competitive performance and sense quality.2 Word Sense InductionA co-occurrence graph is fundamental to our ap-proach; terms are represented as nodes and anedge between two nodes indicates the terms’ co-occurrence, with a weight proportional to frequency.While prior work has focused on clustering thenodes to induce senses, using Link Clustering (Ahnet al., 2010), we cluster the edges, which is equiv-alent to grouping the word collocations to iden-tify sense-specific contexts. We summarize our ap-proach as four steps: (1) selecting the contextualcues, (2) building a co-occurrence graph, (3) per-forming community detection on the graph, and (4)sense labeling new contexts using the discoveredcommunities.Context Refinement Representing the co-occurrence graph for all terms in a context is
24
prohibitively expensive. Moreover, often only asubset of the terms in a context constrain the senseof an ambiguous word. Therefore, we refine aword’s context to include only a subset of the termspresent. Following previous work (Ve´ronis, 2004),we select only nouns in the context.
Early experiments indicated that including infre-quent terms in the co-occurrence graph yielded poorperformance, which we attribute to having too fewconnecting edges to identify meaningful communitystructure. Therefore, we include only those nounsoccurring in the most frequent 5000 tokens, whichare likely to be representative the largest communi-ties in which a term takes part. Last, we include allthe nouns and verbs used in the SemEval 2010 WSITask (Manandhar et al., 2010), which are used inour evaluation. The selected context terms are thenstemmed using the Porter stemmer.
Building the Co-occurrence Graph The graph isiteratively constructed by adding edges between theterms from a context. For each pair-wise combi-nation of terms, an edge is added and its weightis increased by 1. This step effectively embeds aclique if it did not exist before, connecting all ofthe context’s words within the graph. Once all con-texts have been seen, the graph is then pruned to re-move all edges with weight below a threshold t =25. This step removes edges form infrequent collo-cations, which may not contribute sufficient graphstructure for community detection, and as a practi-cal consideration, greatly speeds up the communitydetection process. However, we note that parameterwas largely unoptimized and future work may see abenefit from accounting for edge weight.
Community Detection Within the co-occurrencegraph, communities may have partial overlap. Forexample, Figure 1 illustrates a part of the local graphfor “mouse.” Two clear senses emerge from theneighbors: one for the input device and another forthe animal. However, the terms that correspondto one sense also co-occur with terms correspond-ing to the other sense, e.g., “information,” whichhinders finding communities directly from discon-nected components in the local neighborhood. Find-ing sense-specific communities requires recognizingthat the co-occurring terms may be shared by mul-tiple communities. Therefore, to identify communi-
mouse
access
data
information
people
software
computer
line
cell
lines
rolefunction
movement
control
research
analysis
screen
point
development
study
blood
expression
protein
proteins
stem
gene
windows
text full
webdisplay
application
differentiation
growth
studies
science
results
button
user
type
types
devicesize
surface
culture
shapewindow
medline
skin
factor
adult
genes
tissue
bone
tissues
Figure 1: A portion of the local co-occurrence graphfor “mouse” from the SemEval-2010 Task 14 corpus
ties we selected the approach of Ahn et al. (2010),summarized next, which performs well for overlap-ping community structure.
First, the edges are clustered using an unweightedsimilarity function based on the neighbors of twoedges, ei,j and ei,k: sim(ei,j , ei,k) = njnnknj?nk , whereni denotes the node i and its neighbors. This simi-larity reflects the percentage of terms that co-occurin common with the term for nodes j and k, inde-pendent of the terms that co-occur with the sharedterm for i. For example, in Figure 1, the similarityfor the edges connecting “mouse” with “user” and“software,” 25 , measures the overlap in the neighborsof “user” and “software” independent of the neigh-bors for “mouse,” such as “cell” and “size.”
Using this similarity function, the edges are ag-glomeratively clustered into a dendrogram. We usethe single-link criteria which iteratively merges thetwo clusters connected by the edge pair with thehighest similarity. The dendrogram may then be cutat different levels to reveal different cluster granu-larities; cuts near the bottom of the dendrogram cre-ate a larger number of small groups of collocations,whereas cuts near the top create fewer, larger groupsof collocations. To select the specific partitioningof the dendrogram into clusters, we select the solu-tion that maximizes the partition density, which Ahnet al. (2010) define as D = 2M
?cmc
mc-(nc-1)(nc-2)(nc-1)
,
where M is the number of edges in the graph, c de-
25
notes a specific cluster, and nc and mc are the num-ber of nodes and edges in cluster c, respectively.
The final set of communities is derived from thesepartitions: a node is a member of each community inwhich one of its edges occurs. Last, we remove allcommunities of size 3 and below, which we interpretas having too few semantic constraints to reliablydisambiguate each of its terms.
Sense Induction from Communities Each termin a community is treated as having a specific sense,with one sense per community. To label a contextualusage, we identify the community that best maps tothe context. For a given context, made of the set ofwords W , we score each community i, consisting ofwords C , using the Jaccard index weighted by com-munity size: score(Ci,W ) = |Ci| · |CinW ||Ci?W | . Thissimilarity function favors mapping contexts to largercommunities, which we interpret as having more se-mantic constraints. The final sense labeling consistsof the scores for all overlapping communities.
3 EvaluationWe use the SemEval-2 Task 14 evaluation (Manand-har et al., 2010) to measure the quality of inducedsenses. We summarize the evaluation as follows.Systems are provided with an unlabeled training cor-pus consisting of 879,807 multi-sentence contextsfor 100 polysemous words, comprised of 50 nounsand 50 verbs. Systems induce sense representationsfor target words from the training corpus and thenuse those representations to label the senses of thetarget words in unseen contexts from a test corpus.We use the entire multi-sentence context for build-ing the co-occurrence graph.
The induced sense labeling is scored using twounsupervised and one supervised methods. The un-supervised scores consists of two contrasting mea-sures: the paired FScore (Artiles et al., 2009) andthe V-Measure (Rosenberg and Hirschberg, 2007).Briefly, the V-Measure rates the homogeneity andcompleteness of a clustering solution. Solutions thathave word clusters formed from one gold-standardsense are homogeneous; completeness measures thedegree to which a gold-standard sense’s instancesare assigned to a single cluster. The paired FScorereflects the overlap of the solution and the gold stan-dard in cluster assignments for all pair-wise combi-
FScore V-Meas. S80/20 S60/40SPD 61.1 (3) 3.6 (18) 57.64 (18) 57.64 (16)SV 56.16 (9) 8.7 (6) 57.90 (18) 57.36 (17)SF 63.4 (1) 0 (26) 56.18 (21) 56.20 (21)BestF 63.3 (1) 0 (26) 58.69 (14) 58.24 (13)BestV 26.7 (25) 16.2 (1) 58.34 (16) 57.27 (17)BestS 49.8 (15) 15.7 (2) 62.44 (1) 61.96 (1)MFS 63.4 0 58.67 58.95
Table 1: Performance results on the SemEval-2010WSI Task, with rank shown in parentheses. Refer-ence scores of the best submitted systems are shownin the bottom.
 0 30 60 90
 120
 0 75 150 225 300 375
Mem
bers
hips
Com
mun
ity S
ize
Avg. MembershipsAvg. Size
0.00
0.20
0.40
0.60
0.80
1.00
50K100K
150K200K
250K300K
350K400K
0.000.010.020.030.040.050.060.070.080.09
F-Sc
ore
V-M
easu
re
Merge Steps Prior to Cutting the Dendrogram (in thousands)
F-ScoreV-Measure
Figure 2: V-Measure and paired FScore resultsfor different partitionings of the dendrogram. Thedashed vertical line indicates SPD
nation of instances. The supervised evaluation trans-forms the induced sense clusters of a portion of thecorpus into a word sense classifier, which is thentested on the remaining corpus. An 80/20 train-testsplit, S80/20, and 60/40 split, S60/40, are both used.
Results As a first measure of the quality of the in-duced senses, we evaluated both the solution thatmaximized the partition density, referred to as SPD,and an additional 5,000 solutions, evenly distributedamong the possible dendrogram partitionings. Fig-ure 2 shows the score distribution for V-Measure andpaired FScore. Table 1 lists the scores and rank forSPD and the solutions that optimize the V-Measure,SV , and FScore, SF , among the 26 participatingTask-14 systems. For comparison, we include thehighest performing systems on each measure and theMost Frequent Sense (MFS) baseline.
26
Discussion Optimizing the partition density re-sults in high performance only for the FScore; how-ever, optimizing for the V-Measure yields competi-tive performance on both measures. The behavior isencouraging as most approaches submitted to Task14 favor only one measure.
Figure 2 indicates a relationship between the V-Measure and community memberships. Therefore,using SV , we calculated the Pearson correlation be-tween a term’s scores and the number of communitymemberships within a single solution. The corre-lation with the paired FScore, r = -0.167, was notstatistically significant at p < .05, while correlationwith the V-Measure, r = 0.417 is significant withp < 1.6e-5. This suggests that at a specific com-munity granularity, additional communities enablethe WSI mapping process to make better sense dis-tinctions between contexts. However, we note thatV-Measure begins to drop as the average commu-nity membership increases in solutions after SV , asshown in Figure 2. We suspect that as the agglomer-ative merge process continues, communities repre-senting different senses become merged, leading toa loss of purity.
The lower performance of SPD and the impact ofcommunity memberships raises the important ques-tion of how to best select the communities. Whileco-occurrence graphs have been shown to exhibitsmall-world network patterns (Ve´ronis, 2004), op-timizing for the general criterion of partition densitythat has performed well on such networks does notresult in communities that map well to sense-specificcontexts. We believe that this behavior is due toimpact of the sense inventory; selecting a commu-nity solution purely based on the graph’s structuremay not capture the correct sense distinctions, ei-ther having communities with too few members todistinguish between senses or too many members,which conflates senses. However, a promising fu-ture direction is to examine whether the there existfeatures of the graph structure that would allow forrecognizing the specific community solutions thatcorrespond directly to different sense granularitieswithout the need for an external evaluation metric.
4 Related WorkWe highlight those related works with connectionsto community detection. Ve´ronis (2004) demon-
strated that word co-occurrence graphs follow asmall-world network pattern. In his scheme, wordsenses are discovered by iteratively deleting themore connected portions of the subgraph to revealthe different senses’ network structure. Our workcapitalizes on this intuition of discovering sense-related subgraphs, but leverages formalized methodsfor community detection to identify them.
Dorow and Widdows (2003) identify sense-related subgraphs in a similar method to commu-nity detection for local region of the co-occurrencegraph. They use a random walk approach to identifyregions of the graph that are sense-specific. Thoughnot identical, we note that the random walk modelhas been successfully applied to community detec-tion (Rosvall et al., 2009). Furthermore, Dorow andWiddows (2003) performs graph clustering on a per-word basis; in contrast, the proposed approach iden-tifies communities for the entire graph, effectivelyperforming an all-word WSI.
Klapaftis and Manandhar (2010) capture hierar-chical relations between collocations using a Hi-erarchical Random Graph model where nodes arecollocations and edges indicate their co-occurrence,which improved performance over non-hierarchicalmodels. Our community detection approach alsocaptures the hierarchical structure of the collocationgraph, but uses a much simpler graphical representa-tion that for n terms requires O(n) nodes and O(n2)edges, compared to O(n2) nodes and O(n3) edgesfor the above approach, which allows it to build thecollocation graph from a larger set of terms.
5 ConclusionWe have proposed a new graph-based method forWSI based on finding sense-specific word commu-nities within a co-occurrence graph, which are thenidentify distinguish senses in new contexts. Aninitial analysis using the SemEval-2010 WSI taskdemonstrates competitive performance. Future re-search will address two potential avenues: (1) theimpact of word frequency on community size andmemberships and (2) identifying both graph proper-ties and semantic relations within hierarchical com-munities that distinguish between sense granulari-ties. Software for the WSI model and for Link Clus-tering is available as a part of the S-Space Package(Jurgens and Stevens, 2010).
27
ReferencesYong-Yeol Ahn, James P. Bagrow, and Sune Lehmann.
2010. Link communities reveal multiscale complexityin networks. Nature, (466):761–764, August.
Javier Artiles, Enrique Amigo´, and Julio Gonzalo. 2009.The role of named entities in web people search. InProceedings of EMNLP, pages 534–542. ACL.
Beate Dorow and Dominic Widdows. 2003. Discover-ing corpus-specific word senses. In Proceedings of the10th EACL, pages 79–82.
Santo Fortunato. 2010. Community detection in graphs.Physics Reports, 486(3-5):75–174.
David Jurgens and Keith Stevens. 2010. The S-SpacePackage: An Open Source Package for Word SpaceModels. In Proceedings of the ACL 2010 SystemDemonstrations.
Ioannis P. Klapaftis and Suresh Manandhar. 2008. Wordsense induction using graphs of collocations. In Pro-ceeding of ECAI 2008, pages 298–302.
Ioannis P. Klapaftis and Suresh Manandhar. 2010. Wordsense induction & disambiguation using hierarchicalrandom graphs. In Proceedings of EMNLP, pages745–755. ACL.
Suresh Manandhar, Ioannis P. Klapaftis, Dmitriy Dli-gach, and Sameer S. Pradhan. 2010. SemEval-2010 task 14: Word sense induction & disambigua-tion. In Proceedings of the 5th International Workshopon Semantic Evaluation, pages 63–68. Association forComputational Linguistics.
Andrew Rosenberg and Julia Hirschberg. 2007. V-measure: A conditional entropy-based external clusterevaluation measure. In Proceedings of the Joint Con-ference of EMNLP-CoNLL. ACL, June.
M. Rosvall, D. Axelsson, and C.T. Bergstrom. 2009.The map equation. The European Physical Journal-Special Topics, 178(1):13–23.
J. Ve´ronis. 2004. HyperLex: lexical cartography for in-formation retrieval. Computer Speech & Language,18(3):223–252.
28
