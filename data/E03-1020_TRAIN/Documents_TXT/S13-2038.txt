UKP-WSI: UKP Lab Semeval-2013 Task 11 System Description
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 212–216, Atlanta, Georgia, June 14-15, 2013. c©2013 Association for Computational Linguistics
UKP-WSI: UKP Lab Semeval-2013 Task 11 System Description
Hans-Peter Zorn† and Iryna Gurevych†‡
†Ubiquitous Knowledge Processing Lab (UKP-TUDA)Department of Computer Science, Technische Universita¨t Darmstadt
‡Ubiquitous Knowledge Processing Lab (UKP-DIPF)German Institute for Educational Research and Educational Information
www.ukp.tu-darmstadt.de
Abstract
In this paper, we describe the UKP Lab sys-tem participating in the Semeval-2013 task“Word Sense Induction and Disambiguationwithin an End-User Application”. Our ap-proach uses preprocessing, co-occurrence ex-traction, graph clustering, and a state-of-the-art word sense disambiguation system. Wedeveloped a configurable pipeline which canbe used to integrate and evaluate other com-ponents for the various steps of the complextask.
1 Introduction
The task “Evaluating Word Sense Induction andWord Sense Disambiguation in an End-User Ap-plication” of SemEval-2013 (Navigli and Vannella,2013) aims at an extrinsic evaluation scheme forWSI to overcome the difficulties inherent to WSIevaluation. The task requires building a WSI sys-tem and combining it with a WSD step to assign theinduced sentences to example instances.
Word sense disambiguation (WSD) is the taskof determining the correct meaning for an ambigu-ous word from its context. WSD algorithms usu-ally choose one sense out of a given set of possiblesenses for each word. A resource that enumeratespossible senses for each word is called a sense in-ventory. Manually created inventories come usuallyin form of lexical semantic resources, such as Word-Net or more specifically created inventories such asOntoNotes (Hovy et al., 2006).
Word sense induction (WSI) on the other handaims to create such an inventory from a corpus in
an unsupervised manner. For each word that shouldbe disambiguated, a WSI algorithm creates a set ofcontext clusters that will be used to define and de-scribe the senses.
We build our system upon the open-source DKProframework 1 and a corresponding WSD component(upcoming).
Input for the task comes as two files. One containsthe search queries, also referred as topics. Sense in-duction will be performed for each of those topics.The second file contains 6400 entries from the re-sult pages of a search engine. Each entry consists ofthe title, a snippet and the URL of the correspondingweb page.
2 Related Work
One of the early approaches to WSI (Schu¨tze, 1998)maps words into a vector space and representsword contexts as vector-sums and use cosine vec-tor similarity, clustering is performed by expectationmaximization (EM) clustering. Dorow and Wid-dows (2003) use the BNC to build a co-occurrencegraph for nouns, based on a co-occurrence fre-quency threshold. They perform Markov cluster-ing on this graph. Pantel and Lin (2002) proposesa clustering approach called clustering by commit-tee (CBC). This algorithm first selects the wordswith the highest similarity based on mutual infor-mation and then builds groups of highly connectedwords called committees. It then iteratively assignsthe remaining words to one of the committee clus-ters by comparing them to the averaged the com-
1http://code.google.com/p/dkpro-core-asl/
212
mittee feature vectors. This exploits the assumptionthat two or more words together disambiguate eachother, Bordag (2006) extends on this idea by usingword triples to form non-ambiguous seed-clusters.Many approaches use a variety of graph clusteringalgorithms for WSI: Others (Klapaftis and Manand-har, 2010) use hierarchical agglomerative clusteringon hierarchical random graphs created from wordco-occurrences. Di Marco and Navigli (2013) useword sense induction for web search result cluster-ing. They introduce a maximum spanning tree al-gorithm that operates on co-occurrence graphs builtfrom large corpora, such as ukWaC (Baroni et al.,2009). The system by Pedersen (2010) employsclustering first- and second-order co-occurrences aswell as singular value decomposition on the co-occurrence matrix, which is clustered using repeatedbisections. Jurgens (2011) employ a graph-basedcommunity detection algorithm on a co-occurrencegraph. Distributional approaches for WSI includeLSA Apidianaki and Van de Cruys (2011) or LDA(Brody and Lapata, 2009).
3 Our Approach
Our system consists of two independent parts. Thefirst is a batch process that creates database con-taining co-occurrence statistics derived from a back-ground corpus. The second is the actual WSI andWSD pipeline doing the result clustering. Both partsinclude identical preprocessing steps for segmenta-tion and lemmatization.
The pipeline (Figure 1) first performs Word SenseInduction, resulting in an induced sense inventory.A WSD algorithm then uses this inventory to dis-ambiguate all instances of the search query within aweb-page. A majority voting finally assigns a senseto each result-snippet.
The sense induction algorithm is based on graphclustering on a co-occurrence graph, similar to theapproach by Di Marco and Navigli (2013). Our ap-proach differs from previous work in the way weperform a greedy search for additional context andhow it combines WSI with an advanced WSD stepusing lexical expansions. Moreover, we considerour generic UIMA-based WSD and WSI system asa useful basis for experimentation and evaluation ofWSI systems.
# words # co-occurrencesWikipedia 3,011,397 96,979,920ukWaC 8,687,711 441,005,478
Table 1: Size of co-occurrence databases
3.1 Preprocessing
The pipeline first reads topics and snippets. If theweb-page can be downloaded at the URL that cor-responds to the result, it is cleaned by an HTMLparser and the plain text is appended to the snippet.As further steps we segment and lemmatize the in-put. We apply the same preprocessing to snippets,queries and the corpora.
3.2 Co-occurrence Extraction
We calculate the log-likelihood ratio (LLR) (Dun-ning, 1993) and point-wise mutual information(PMI) (Church and Hanks, 1990) of a word pair co-occurring at sentence level using a modified versionof the collocation statistics implemented in ApacheMahout 2. Even when sorting the co-occurrences byPMI, we employ a minimum support cut-off basedon the LLR, which is based on significance. Allpairs with a log-likelihood ratio < 1 are discarded.This value is lower than the significance level of 3˜.8we found in the literature, but because in the ex-pand step (see algorithm 2) we require more thantwo words to co-occur with the target word, we useda lower value. We use the English Wikipedia 3 andukWaC (Baroni et al., 2009) as background corpus.Table 1 gives an overview about the obtained co-occurrence pairs.
3.3 Clustering Algorithm
The algorithm is a two-step approach that first cre-ates an initial clustering of a graph G = (V,E)and then improves this clustering in a second step.The initial step (Algorithm 1) starts by retrieving thetop n = 150 most similar terms for the target wordby querying the co-occurrence database we createdin section 3.2. These represent vertices in a graph.We then construct 4 a minimum spanning tree (mst)
2http://mahout.apache.org3Dump from April 20114For all of our graph operations, we employ the igraph li-
brary for R, http://igraph.sf.net
213
Figure 1: WSI and WSD Pipeline
by inserting edges {vi, vj} from the co-occurrencedatabase. The weight w({vi, vj}) of each edge isset to the inverse of the used similarity measuredist (LLR or PMI) between those terms. The min-imum spanning tree then is cut into subtrees be it-eratively removing the edge with the highest edge-betweenness (Freeman, 1977) (betweeness) untilthe size of the largest component of G falls belowa threshold Sinitial.
Algorithm 1 initialClustersV (G0)? top n most similar words to target wordw(vi, vj)? dist(termi, termj)G? mst(G0)V (G)? V (G) \ vtargetwhilemax(|C(G)|) > Sintitial doE(G)? E(G) \ argmaxe(betweeness(e))
end while
The resulting partitioning of the graph is the start-ing point for the second phase of the algorithm,which we call expand/join step (Algorithm 2). Dur-ing this step, the algorithm looks iteratively at allclusters Csmall of size s smaller than Smax = 9 (de-termined empirically), starting with the largest ones.From each of these clusters, it constructs a queryto the co-occurrence database, retrieving all termsthat significantly co-occur together with all terms inthe respective cluster (querys) and with the targetword (E). This list of terms is then compared toall clusters Clarge with |C| > s . If the normalizedintersection between one of those Clarge is above athreshold t = 0.3 (determined empirically), we as-sume that the Csmall represents the same sense asthe Clarge and merge those clusters. If this is not thecase for any of the larger clusters, we assume thatCsmall represents a sense of its own extend the clus-
ter by adding edges between vertices representingthe expansion terms and Csmall.
Algorithm 2 expandJoinRequire: G is a minimum spanning forestfor s = Smax ? 1 dofor all Csmall(G), |Csmall| = s doE ? querys(v1, .., vi)for all Clarge ? G, |Clarge| > s doif |Clarge n E|/|Clarge| > t thenClarge ? Clarge ? Csmall
elseCsmall ? Csmall ? E
end ifend for
end forend for
3.4 Word Sense Disambiguation
We use the DKPro WSD framework, which imple-ments various WSD algorithms, with the same sys-tem configuration as reported by Miller et al. (2012).It uses a variant of the Simplified Lesk Algorithm(Kilgarriff et al., 2000). This algorithm measuresthe overlap between a words context and the tex-tual descriptions of senses within a machine read-able dictionary, such as WordNet. The senses thathave been induced in the previous step are providedto the framework as a sense inventory. Instead ofusing sense descriptions, we now compute the over-lap between the sense clusters and the context ofthe target word. The WSD system expands boththe word context and the sense clusters with syn-onyms from a distributional thesaurus (DT), similarto Lin (1998). The DT has been created from 10Mdependency-parsed sentences of English newswire
214
Run F1 ARI RI JI # clusters avg cl. sizewacky-llr 0.5826 0.0253 0.5002 0.3394 3.6400 32.3434wp-llr 0.5864 0.0377 0.5109 0.3177 4.1700 21.8702wp-pmi 0.6048 0.0364 0.5050 0.2932 5.8600 30.3098
Table 2: Results for the submitted runs
from the Leipzig Corpora Collection (Biemann etal., 2007) for word similarity5. Besides knowledge-based WSD, the DT also has been successfully usedfor improving the performance of semantic text sim-ilarity (Ba¨r et al., 2012). The WSD component dis-ambiguates each instance of the search query withinthe snippet and web page individually.
4 Results
The clustering was evaluated using four differentmetrics as described by Di Marco and Navigli(2013). The Rand index and its chance-adjustedvariant ARI are common cluster evaluation metrics.The adjusted rand index gives special weight to lessfrequent senses. The Jaccard index (JI) disregardsthe cases where two results are assigned to differ-ent clusters in the gold standard, therefore it is lesssensitive to the granularity of the clustering. TheF1-Measure gives more attention to the individualclusters and how they cover the topics in the goldstandard.
We submitted several runs for different config-urations of the co-occurrence extraction (Table 2).Between runs, we did not modify the configurationof the sense induction or disambiguation step. Thefirst run used collocations extracted from ukWaCscored by LLR metric (wacky-llr), and two othersused Wikipedia as background corpus. One of theWP-based runs used PMI as association metric (wp-pmi), the other one used LLR (wp-llr). The run onthe larger ukWaC corpus scored best with regard tothe Jaccard measure, but worst in the adjusted Randindex measure. We attribute low scores for ARI tothe fact that our system did not induce certain lessfrequent senses, resulting in small average numberof clusters. The coarse grained clusters however,have been assigned quite well by our WSD system,as shown by relatively high Jaccard Index. For the
5The software used to create the DT is available fromhttp://www.jobimtext.org
WP-based runs, the clustering based on PMI pro-duced more clusters and therefore scored higher onthe F1 measure than the LLR-based run. From anexploratory analysis of the created clusters, we as-sume that the WP-based runs have a higher chanceto find more rare senses in this specific task, sincethe gold standard was also based on Wikipedia dis-ambiguation pages.
5 Conclusion
We presented our word sense induction and dis-ambiguation pipeline for search result clustering.Our contribution is a sense induction algorithm thatincrementally retrieves more context from a co-occurrence database and the integration of WSI andWSD into a UIMA-based pipeline for easy experi-mentation. The system scored best with regard toJaccard similarity of clusters, while performing lowespecially with the adjusted rand index. We assumethat our sense granularity was too low for this taskand failed to create clusters for rare senses. Thiscould be improved by making the merge phase ofthe induction algorithm less eager. Furthermore,increasing the size of the background corpus, e.g.by combining the both corpora that have been usedcould increase the size of the context clusters espe-cially for rare senses, which should further improvethe performance in these cases. We attribute thegood results with regard to the F1 and Jaccard mea-sures also to our state-of-the-art word sense disam-biguation step and the use of the distributional the-saurus.
6 AcknowledgementsWe thank Tristan Miller for helping us with theDKPro WSD framework and Chris Biemann forproviding the distributional thesaurus. This workhas been supported by the Volkswagen Foundationas part of the Lichtenberg-Professorship Programunder grant No. I/82806.
215
ReferencesMarianna Apidianaki and Tim Van de Cruys. 2011. La-
tent Semantic Word Sense Induction and Disambigua-tion. In ACL HLT 2011, pages 1476–1485, June.
Daniel Ba¨r, Chris Biemann, Iryna Gurevych, and TorstenZesch. 2012. UKP: Computing Semantic TextualSimilarity by Combining Multiple Content SimilarityMeasures. In Proceedings of First Joint Conference onLexical and Computational Semantics (*SEM), pages435–440.
Marco Baroni, Silvia Bernardini, Adriano Ferraresi, andEros Zanchetta. 2009. The WaCky wide web: acollection of very large linguistically processed web-crawled corpora. Language Resources and Evalua-tion, 43(3):209–226, February.
Chris Biemann, Gerhard Heyer, Uwe Quasthoff, andMatthias Richter. 2007. The Leipzig Corpora Collec-tion - Monolingual corpora of standard size. In Pro-ceedings of Corpus Linguistic 2007, Birmingham, UK.
Stefan Bordag. 2006. Word Sense Induction: Triplet-Based Clustering and Automatic Evaluation. In Pro-ceedings of the 11th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, pages 137–144, Trento, Italy.
Samuel Brody and Mirella Lapata. 2009. Bayesian wordsense induction. In Proceedings of the 12th Con-ference of the European Chapter of the Associationfor Computational Linguistics, EACL ’09, pages 103–111, Stroudsburg, PA, USA. Association for Compu-tational Linguistics.
Kenneth Ward Church and Patrick Hanks. 1990. Wordassociation norms, mutual information, and lexicogra-phy. Computational Linguistics, 16(1):22–29, March.
Antonio Di Marco and Roberto Navigli. 2013. Cluster-ing and Diversifying Web Search Results with Graph-Based Word Sense Induction. Computational Linguis-tics, 39(4):1–46, November.
Beate Dorow and Dominic Widdows. 2003. Discover-ing corpus-specific word senses. In Proceedings of theTenth Conference on European Chapter of the Associ-ation for Computational Linguistics - EACL ’03, vol-ume 2, page 79, Morristown, NJ, USA, April. Associ-ation for Computational Linguistics.
Ted Dunning. 1993. Accurate Methods for the Statisticsof Surprise and Coincidence. Computational Linguis-tics, 19(1):61 – 74.
Linton C Freeman. 1977. A set of measures of centralitybased on betweenness. Sociometry, 40(1):35–41.
Eduard Hovy, Mitchell Marcus, Martha Palmer, LanceRamshaw, and Ralph Weischedel. 2006. OntoNotes:the 90% solution. In Proceedings of the Human Lan-guage Technology Conference of the NAACL, Com-panion Volume: Short Papers, NAACL-Short ’06,
pages 57–60, Stroudsburg, PA, USA. Association forComputational Linguistics.
David Jurgens. 2011. Word Sense Induction by Commu-nity Detection. In HLT ’11: Proceedings of the 49thAnnual Meeting of the Association for ComputationalLinguistics Human Language Technologies, pages 24–28, Portland, Oregon.
Adam Kilgarriff, Brighton England, and Joseph Rosen-zweig. 2000. English Senseval: Report and Results.In Proceedings of the 2nd International Conference onLanguage Resources and Evaluation, Athens, Greece.
Ioannis P. Klapaftis and Suresh Manandhar. 2010. Wordsense induction & disambiguation using hierarchicalrandom graphs. In Proceedings of the 2010 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 745–755, Cambridge, Massachusetts,October. Association for Computational Linguistics.
Dekang Lin. 1998. Automatic retrieval and clusteringof similar words. In Proceedings of the 36th annualmeeting on Association for Computational Linguistics,pages 768–774, Morristown, NJ, USA, August. Asso-ciation for Computational Linguistics.
Tristan Miller, Chris Biemann, Torsten Zesch, and IrynaGurevych. 2012. Using Distributional Similarity forLexical Expansion in Knowledge-based Word SenseDisambiguation. In Proceedings of the 24th In-ternational Conference on Computational Linguistics(COLING 2012).
Roberto Navigli and Daniele Vannella. 2013. SemEval-2013 Task 11: Evaluating Word Sense Induction &Disambiguation within An End-User Application. InProceedings of the 7th International Workshop on Se-mantic Evaluation (SemEval 2013), in conjunctionwith the Second Joint Conference on Lexical and Com-putational Semantcis (*SEM 2013), Atlanta, USA.
Patrick Pantel and Dekang Lin. 2002. Discovering wordsenses from text. In Proceedings of the eighth ACMSIGKDD international conference on Knowledge dis-covery and data mining - KDD ’02, page 613, NewYork, New York, USA, July. ACM Press.
Ted Pedersen. 2010. Duluth-WSI: SenseClusters appliedto the sense induction task of SemEval-2. In Proceed-ings of the 5th International Workshop on SemanticEvaluation, pages 363–366, Stroudsburg, PA, USA,July. Association for Computational Linguistics.
Hinrich Schu¨tze. 1998. Automatic word sense discrim-ination. Computational Linguistics, 24(1):97–123,March.
216
