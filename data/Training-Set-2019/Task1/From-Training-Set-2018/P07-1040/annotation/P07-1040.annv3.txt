Citance Number: 1 | Reference Article: P07-1040 | Citing Article: C08-1014 | Citation Marker Offset: ['17'] | Citation Marker: Rosti et al.,2007b | Citation Offset: ['16','17'] | Citation Text: <S sid ="16" ssid = "16">In this two-pass method, translation performance hinges on the N-best hypotheses that are generated in the first pass (since rescoring occurs on these), so adding the translation candidates generated by other MT systems to these hypotheses could potentially improve the performance.</S><S sid ="17" ssid = "17">This technique is called system combination (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b).</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation | 
Citance Number: 2 | Reference Article: P07-1040 | Citing Article: C08-1014 | Citation Marker Offset: ['32'] | Citation Marker: Rosti et al.,2007b | Citation Offset: ['32'] | Citation Text: <S sid ="32" ssid = "7">Confusion network and re-decoding have been well studied in the combination of different MT systems (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b).</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation | 
Citance Number: 3 | Reference Article: P07-1040 | Citing Article: C08-1014 | Citation Marker Offset: ['92'] | Citation Marker: Rosti et al.,2007b | Citation Offset: ['88','89','90','91','92'] | Citation Text: <S sid ="88" ssid = "35">Bangalore et al.</S><S sid ="89" ssid = "36">(2001), Sim et al.</S><S sid ="90" ssid = "37">(2007), Rosti et al.</S><S sid ="91" ssid = "38">(2007a), and Rosti et al.</S><S sid ="92" ssid = "39">(2007b) chose the hypothesis that best agrees with other hypotheses on average as the skeleton.</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation | 
Citance Number: 4 | Reference Article: P07-1040 | Citing Article: C08-1014 | Citation Marker Offset: ['97'] | Citation Marker: Rosti et al.,2007b | Citation Offset: ['93','94','95','96','97'] | Citation Text: <S sid ="93" ssid = "40">Bangalore et al.</S><S sid ="94" ssid = "41">(2001) used a WER based alignment and Sim et al.</S> <S sid ="95" ssid = "42">(2007), Rosti et al.</S><S sid ="96" ssid = "43">(2007a), and Rosti et al.</S><S sid ="97" ssid = "44">(2007b) used minimum Translation Error Rate (TER) based alignment to build the confusion network.</S> | Reference Offset: ['89'] | Reference Text: <S sid ="89" ssid = "10">The hypothesis resulting in the lowest average TER score when aligned against all other hypotheses is chosen as the skeleton as follows (4) where is the number of systems.</S> | Discourse Facet: Method_Citation | 
Citance Number: 5 | Reference Article: P07-1040 | Citing Article: D09-1115 | Citation Marker Offset: ['7'] | Citation Marker: Rosti et al.,2007a | Citation Offset: ['7'] | Citation Text: <S sid ="7" ssid = "7">In recent several years, the system combination methods based on confusion networks developed rapidly (Bangalore et al., 2001; Matusov et al., 2006; Sim et al., 2007; Rosti et al., 2007a; Rosti et al., 2007b; Rosti et al., 2008; He et al., 2008), which show state-of-the-art performance in benchmarks.</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation | 
Citance Number: 6 | Reference Article: P07-1040 | Citing Article: D09-1115 | Citation Marker Offset: ['133', '134'] | Citation Marker: Rosti et al.,2007a | Citation Offset: ['133','134'] | Citation Text: <S sid ="133" ssid = "3">While in lattice decoding, a translation path may skip some nodes as some hypothesis arcs may cross more than one backbone arc. Similar to the features in Rosti et al.</S><S sid ="134" ssid = "4">(2007a), the features adopted by lattice-based model are arc posterior probability, language model probability, the number of null arcs, the number of hypothesis arcs possessing more than one non-null word and the number of all non-null words.</S> | Reference Offset: ['124', '125', '126'] | Reference Text: <S sid ="124" ssid = "3">All confusion networks are connected to a single start node with NULL arcs which contain the prior probability from the system used as the skeleton for that network.</S> <S sid ="125" ssid = "4">All confusion network are connected to a common end node with NULL arcs.</S><S sid ="126" ssid = "5">The final arcs have a probability of one.</S> | Discourse Facet: Method_Citation | 
Citance Number: 7 | Reference Article: P07-1040 | Citing Article: D09-1115 | Citation Marker Offset: ['148'] | Citation Marker: Rosti et al.,2007a | Citation Offset: ['147','148'] | Citation Text: <S sid ="147" ssid = "17">Each arc has different confidences concerned with different systems, and the confidence of system s is denoted by ps(arc).</S><S sid ="148" ssid = "18">ps(arc) is increased by 1/(k + 1) if the hypothesis ranking k in the system s contains the arc (Rosti et al., 2007a; He et al., 2008).</S> | Reference Offset: ['80', '81', '82'] | Reference Text: <S sid ="80" ssid = "1">Confusion network decoding in MT has to pick one hypothesis as the skeleton which determines the word order of the combination.</S><S sid ="81" ssid = "2">The other hypotheses are aligned against the skeleton.</S><S sid ="82" ssid = "3">Either votes or some form of confidences are assigned to each word in the network.</S> | Discourse Facet: Method_Citation | 
Citance Number: 8 | Reference Article: P07-1040 | Citing Article: N09-2003 | Citation Marker Offset: ['24', '25'] | Citation Marker: 2007.0 | Citation Offset: ['24','25'] | Citation Text: <S sid ="24" ssid = "24">Qc 2009 Association for Computational Linguistics System Combination: In a typical system combination task, e.g. Rosti et al.</S><S sid ="25" ssid = "25">(2007), each component system produces a set of translations, which are then grafted to form a confusion network.</S> | Reference Offset: ['119', '120', '121'] | Reference Text: <S sid ="119" ssid = "15">On a test set, the first set of weights is used to generate an -best list from the bi-gram expanded lattice.</S><S sid ="120" ssid = "16">This -best list is then re-scored with the higher order -gram.</S><S sid ="121" ssid = "17">The second set of weights is used to find the final -best from the re-scored -best list.</S> | Discourse Facet: Method_Citation | 
Citance Number: 9 | Reference Article: P07-1040 | Citing Article: P08-2021 | Citation Marker Offset: ['2', '3'] | Citation Marker: 2007.0 | Citation Offset: ['2','3'] | Citation Text: <S sid ="2" ssid = "2">We build our confusion networks using the method of Rosti et al.</S><S sid ="3" ssid = "3">(2007), but, instead of forming alignments using the tercom script (Snover et al., 2006), we create alignments that minimize invWER (Leusch et al., 2003), a form of edit distance that permits properly nested block movements of substrings.</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation | 
Citance Number: 10 | Reference Article: P07-1040 | Citing Article: P08-2021 | Citation Marker Offset: ['23', '24'] | Citation Marker: 2007.0 | Citation Offset: ['23','24'] | Citation Text: <S sid ="23" ssid = "23">The procedure described by Rosti et al.</S> <S sid ="24" ssid = "24">(2007) has been shown to yield significant improvements in translation quality, and uses an estimate of Translation Error Rate (TER) to guide the alignment.</S> | Reference Offset: ['196','197'] | Reference Text: <S sid ="196" ssid = "4">Also, confusion networks generated by using the -best hypothesis from all systems as the skeleton were used with prior probabilities derived from the average TER scores.</S><S sid ="197" ssid = "5">This guarantees that the best path will not be found from a network generated for a system with zero weight.</S> | Discourse Facet: Method_Citation | 
Citance Number: 11 | Reference Article: P07-1040 | Citing Article: P08-2021 | Citation Marker Offset: ['29', '30'] | Citation Marker: 2007.0 | Citation Offset: ['28','29','30'] | Citation Text: <S sid ="28" ssid = "28">In fact, it only requires a procedure for creating pairwise alignments of translations that allow appropriate re-orderings.</S><S sid ="29" ssid = "29">For this, Rosti et al.</S><S sid ="30" ssid = "30">(2007) use the tercom script (Snover et al., 2006), which uses a number of heuristics (as well as dynamic programming) for finding a sequence of edits (insertions, deletions, substitutions and block shifts) that convert an input string to another.</S> | Reference Offset: ['64','70'] | Reference Text: <S sid ="64" ssid = "15">Translation edit rate (TER) (Snover et al., 2006)has been proposed as more intuitive evaluation met 1.</S><S sid ="70" ssid = "21">ric since it is based on the rate of edits required to transform the hypothesis into the reference.</S> | Discourse Facet: Method_Citation | 
Citance Number: 12 | Reference Article: P07-1040 | Citing Article: P08-2021 | Citation Marker Offset: ['69', '70'] | Citation Marker: 2007.0 | Citation Offset: ['69','70'] | Citation Text: <S sid ="69" ssid = "1">ITG-based alignments and tercom-based alignments were also compared in oracle experiments involving confusion networks created through the algorithm of Rosti et al.</S><S sid ="70" ssid = "2">(2007).</S> | Reference Offset: ['6','144','145','146'] | Reference Text: <S sid ="6" ssid = "6">A generic weight tuning algorithm may be used to optimize various automatic evaluation metrics including TER, BLEU and METEOR.</S><S sid ="144" ssid = "6">The algorithm explores better weights iteratively starting from a set of initial weights.</S><S sid ="145" ssid = "7">First, each dimension is optimized using a grid-based line minimization algorithm.</S><S sid ="146" ssid = "8">Then, a new direction based on the changes in the objective function is estimated to speed up the search.</S> | Discourse Facet: Method_Citation | 
Citance Number: 13 | Reference Article: P07-1040 | Citing Article: P08-2021 | Citation Marker Offset: ['78', '79'] | Citation Marker: 2007.0 | Citation Offset: ['78','79'] | Citation Text: <S sid ="78" ssid = "10">Note that the algorithm of Rosti et al.</S><S sid ="79" ssid = "11">(2007) used N -best lists in the combination.</S> | Reference Offset: ['93'] | Reference Text: <S sid ="93" ssid = "14">When using -best lists from each system, the words may be assigned a different score based on the rank of the hypothesis.</S> | Discourse Facet: Method_Citation | 
Citance Number: 14 | Reference Article: P07-1040 | Citing Article: P11-1125 | Citation Marker Offset: ['47', '48'] | Citation Marker: 2007b | Citation Offset: ['46','47','48'] | Citation Text: <S sid ="46" ssid = "16">This large grammatical difference may produce a longer sentence with spuriously inserted words, as in I saw the blue trees was found in Figure 1(c).</S><S sid ="47" ssid = "17">Rosti et al.</S><S sid ="48" ssid = "18">(2007b) partially resolved the problem by constructing a large network in which each hypothesis was treated as a skeleton and the multiple networks were merged into a single network.</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation | 
Citance Number: 15 | Reference Article: P07-1040 | Citing Article: P11-1125 | Citation Marker Offset: ['127'] | Citation Marker: 2007b | Citation Offset: ['127'] | Citation Text: <S sid ="127" ssid = "18">Our baseline confusion network system has an additional penalty feature, hp (m), which is the total edits required to construct a confusion network using the mth system hypothesis as a skeleton, normalized by the number of nodes in the network (Rosti et al., 2007b).</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation | 
Citance Number: 16 | Reference Article: P07-1040 | Citing Article: P39_p07 | Citation Marker Offset: ['24', '25'] | Citation Marker: 2007.0 | Citation Offset: ['24','25'] | Citation Text: <S sid ="24" ssid = "24">@2009 Association for Computational Linguistics System Combination: In a typical system combi nation task, e.g. Rosti et al.</S><S sid ="25" ssid = "25">(2007), each compo nent system produces a set of translations, which are then grafted to form a confusion network.</S> | Reference Offset: ['119','120','121'] | Reference Text: <S sid ="119" ssid = "15">On a test set, the first set of weights is used to generate an -best list from the bi-gram expanded lattice.</S><S sid ="120" ssid = "16">This -best list is then re-scored with the higher order -gram.</S><S sid ="121" ssid = "17">The second set of weights is used to find the final -best from the re-scored -best list.</S> | Discourse Facet: Method_Citation | 
Citance Number: 17 | Reference Article: P07-1040 | Citing Article: P101121_p07 | Citation Marker Offset: ['20', '21'] | Citation Marker: 2007.0 | Citation Offset: ['19','20','21'] | Citation Text: <S sid ="19" ssid = "19">If measures with this property are used to tune a typical statistical MT system, it can sometimes be observed that the MT system learns to play against this, and might even learn to produce translations which show the good features without actually being good translations.</S> <S sid ="20" ssid = "20">For example, Rosti et al.</S><S sid ="21" ssid = "21">(2007) report such an effect.</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation |
Citance Number: 18 | Reference Article: P07-1040 | Citing Article: Pling_p07 | Citation Marker Offset: ['13'] | Citation Marker: 2007.0 | Citation Offset: ['12','13'] | Citation Text: <S sid ="12" ssid = "12">In this paper, a system combination based on confusion network (CN) is described.</S><S sid ="13" ssid = "13">This approach is not new, and numerous publications are available on that subject, see for example, (Rosti et al., 2007); (Shen et al., 2008); (Karakos et al., 2008) and (Leusch et al., 2009).</S> | Reference Offset: ['36'] | Reference Text: <S sid ="36" ssid = "36">In this work, confusion networks are generated by using the -best output from each system as the skeleton, and prior probabilities for each network are estimated from the average TER scores between the skeleton and other hypotheses.</S> | Discourse Facet: Method_Citation | 
Citance Number: 19 | Reference Article: P07-1040 | Citing Article: Pling_p07 | Citation Marker Offset: ['41'] | Citation Marker: 2007.0 | Citation Offset: ['41'] | Citation Text: <S sid ="41" ssid = "13">This diers from the result of (Rosti et al., 2007) where the nearest hypothesis is computed at each step, which is supposed to be better.</S> | Reference Offset: ['199','200','201','202','203'] | Reference Text: <S sid ="199" ssid = "7">The new method was evaluated on the Arabic to English and Chinese to English NIST MT05 tasks.</S><S sid ="200" ssid = "8">Compared to the baseline from (Rosti et al., 2007), the new method improves the BLEU scores significantly.</S> <S sid ="201" ssid = "9">The combination weights were tuned to optimize three automatic evaluation metrics: TER, BLEU and METEOR.</S><S sid ="202" ssid = "10">The TER tuning seems to yield very good results on Arabic - the BLEU tuning seems to be better on Chinese.</S><S sid ="203" ssid = "11">It also seems like METEOR should not be used in tuning due to high insertion rate and low precision.</S> | Discourse Facet: Method_Citation | 
Citance Number: 20 | Reference Article: P07-1040 | Citing Article: Psem_p07 | Citation Marker Offset: ['13'] | Citation Marker: Rosti et al. 2007 | Citation Offset: ['13'] | Citation Text: <S sid ="13" ssid = "13">The handicap of using a single reference can be addressed by constructing a lattice of reference translationsthis technique has been used to combine the output of multiple translation systems (Rosti et al. 2007).</S> | Reference Offset: ['140'] | Reference Text: <S sid ="140" ssid = "2">A confusion network may be represented by a word lattice and standard tools may be used to generate -best hypothesis lists including word confidence scores, language model scores and other features.</S> | Discourse Facet: Method_Citation | 
Citance Number: 21 | Reference Article: P07-1040 | Citing Article: Psem_p07 | Citation Marker Offset: ['116'] | Citation Marker: Rosti et al. 2007 | Citation Offset: ['116'] | Citation Text: <S sid ="116" ssid = "8">In addition, it may also be used as a general-purpose string alignment toolTER has been used for aligning multiple system outputs to each other for MT system combination (Rosti et al. 2007), a task for which TERp may be even better suited.</S> | Reference Offset: ['64','70'] | Reference Text: <S sid ="64" ssid = "15">Translation edit rate (TER) (Snover et al., 2006)has been proposed as more intuitive evaluation met 1.</S><S sid ="70" ssid = "21">ric since it is based on the rate of edits required to transform the hypothesis into the reference.</S> | Discourse Facet: Method_Citation | 
Citance Number: 22 | Reference Article: P07-1040 | Citing Article: W08-0329 | Citation Marker Offset: ['7'] | Citation Marker: Rosti et al. 2007 | Citation Offset: ['7'] | Citation Text: <S sid ="7" ssid = "7">The recent approaches used pairwise alignment algorithms based on symmetric alignments from a HMM alignment model (Matusov et al., 2006) or edit distance alignments allowing shifts (Rosti et al., 2007).</S> | Reference Offset: ['86'] | Reference Text: <S sid ="86" ssid = "7">The modified Levenshtein alignment as used in TER is more natural than simple edit distance such as word error rate since machine translation hypotheses may have different word orders while having the same meaning.</S> | Discourse Facet: Method_Citation | 
Citance Number: 23 | Reference Article: P07-1040 | Citing Article: W08-0329 | Citation Marker Offset: ['17'] | Citation Marker: Rosti et al. 2007 | Citation Offset: ['17'] | Citation Text: <S sid ="17" ssid = "17">As in (Rosti et al., 2007), confusion networks built around all skeletons are joined into a lattice which is expanded and re- scored with language models.</S> | Reference Offset: ['123','124','125'] | Reference Text: <S sid ="123" ssid = "2">To prevent the -best from a system with a low or zero weight being selected as the skeleton, confusion networks are generated for each system and the average TER score in Equation 4 is used to estimate a prior probability for the corresponding network.</S><S sid ="124" ssid = "3">All confusion networks are connected to a single start node with NULL arcs which contain the prior probability from the system used as the skeleton for that network.</S> <S sid ="125" ssid = "4">All confusion network are connected to a common end node with NULL arcs.</S> | Discourse Facet: Method_Citation | 
Citance Number: 24 | Reference Article: P07-1040 | Citing Article: W08-0329 | Citation Marker Offset: ['39'] | Citation Marker: Rosti et al. 2007 | Citation Offset: ['39'] | Citation Text: <S sid ="39" ssid = "17">Other scores for the word arc are set as in (Rosti et al., 2007).</S> | Reference Offset: ['40'] | Reference Text: <S sid ="40" ssid = "40">In this work, log-posterior probabilities are estimated for each confusion network arc instead of using votes or simple word confidences.</S> | Discourse Facet: Method_Citation | 
Citance Number: 25 | Reference Article: P07-1040 | Citing Article: W08-0329 | Citation Marker Offset: ['88'] | Citation Marker: Rosti et al. 2007 | Citation Offset: ['87','88'] | Citation Text: <S sid ="87" ssid = "21">The first, syscomb pw, corresponds BLEU System deen fren worst 11.84 16.31 best 28.30 33.13 syscomb 29.05 33.63 Table 3: NIST BLEU scores on the GermanEnglish (deen) and French-English (fren) Europarl test2008 set.</S><S sid ="88" ssid = "22">to the pairwise TER alignment described in (Rosti et al., 2007).</S> | Reference Offset: ['95', '96'] | Reference Text: <S sid ="95" ssid = "16">Due to the computational burden of the TER alignment, only -best hypotheses were considered as possible skeletons, and hypotheses per system were aligned.</S><S sid ="96" ssid = "17">Similar approach to estimate word posteriors is adopted in this work.</S> | Discourse Facet: Method_Citation | 
Citance Number: 26 | Reference Article: P07-1040 | Citing Article: W09-0441 | Citation Marker Offset: ['36'] | Citation Marker: Rosti et al.,2007 | Citation Offset: ['35','36'] | Citation Text: <S sid ="35" ssid = "9">The handicap of using a single reference can be addressed by the construction of a lattice of reference translations.</S><S sid ="36" ssid = "10">Such a technique has been used with TER to combine the output of multiple translation systems (Rosti et al., 2007).</S> | Reference Offset: ['140'] | Reference Text: <S sid ="140" ssid = "2">A confusion network may be represented by a word lattice and standard tools may be used to generate -best hypothesis lists including word confidence scores, language model scores and other features.</S> | Discourse Facet: Method_Citation | 