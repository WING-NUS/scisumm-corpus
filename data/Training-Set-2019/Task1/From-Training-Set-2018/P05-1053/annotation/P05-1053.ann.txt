Citance Number: 2 | Reference Article:  P05-1053.xml | Citing Article:  C08-1088.xml | Citation Marker Offset:  ['15'] | Citation Marker:  2005 | Citation Offset:  ['15'] | Citation Text:  <S sid ="15" ssid = "15">However, detailed research (Zhou et al., 2005) shows that itâ€™s difficult to extract new effective features to further improve the extraction accuracy.</S> | Reference Offset:  ['193'] | Reference Text:  <S sid ="193" ssid = "75">Instead of exploring the full parse tree information directly as previous related work, we incorporate the base phrase chunking information performance improvement from syntactic aspect while further incorporation of the parse tree and dependence tree information only slightly improves the performance.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 3 | Reference Article:  P05-1053.xml | Citing Article:  C08-1088.xml | Citation Marker Offset:  ['180'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['180'] | Citation Text:  <S sid ="180" ssid = "28">Furthermore, when the UPST (FPT) kernel is com bined with a linear state-of-the-state feature- based kernel (Zhou et al., 2005) into a composite one via polynomial interpolation in a setting similar to Zhou et al.</S> | Reference Offset:  ['51','52'] | Reference Text:  <S sid ="51" ssid = "7">Moreover, we only apply the simple linear kernel, although other kernels can peform better.</S><S sid ="52" ssid = "8">The reason why we choose SVMs for this purpose is that SVMs represent the state-of–the-art in the machine learning research community, and there are good implementations of the algorithm available.</S> | Discourse Facet:  Implication_Citation | Annotator:  Kokil Jaidka | 


Citance Number: 5 | Reference Article:  P05-1053.xml | Citing Article:  C10-1018.xml | Citation Marker Offset:  ['42'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['42'] | Citation Text:  <S sid ="42" ssid = "5">Most of the features used in our system are based on the work in (Zhou et al., 2005).</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 6 | Reference Article:  P05-1053.xml | Citing Article:  C10-1018.xml | Citation Marker Offset:  ['45'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['45'] | Citation Text:  <S sid ="45" ssid = "8">Due to space limitations, we only describe the collocation features and refer the reader to (Zhou et al., 2005) for the rest of the features.</S> | Reference Offset:  ['40'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 8 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['14'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['14'] | Citation Text:  <S sid ="14" ssid = "14">Among them, feature-based methods (Kambhatla 2004; Zhou et al., 2005) achieve certain success by employing a large amount of diverse linguistic features, varying from lexical knowledge, entity- related information to syntactic parse trees, dependency trees and semantic information</S> | Reference Offset:  ['17','20'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S><S sid ="20" ssid = "20">Evaluation shows that the incorporation of diverse features enables our system achieve best reported performance.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 9 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['14'] | Citation Marker:  Zhou et al 2005 | Citation Offset:  ['14'] | Citation Text:  <S sid ="14" ssid = "14">How ever, it is difficult for them to effectively capture struc tured parse tree information (Zhou et al 2005), which is critical for further performance improvement in relation extraction.</S> | Reference Offset:  ['196','197'] | Reference Text:  <S sid ="196" ssid = "78">Second, it is well known that full parsing is always prone to long-distance parsing errors although the Collins’ parser used in our system achieves the state-of-the-art performance.</S><S sid ="197" ssid = "79">Therefore, the state-of-art full parsing still needs to be further enhanced to provide accurate enough information, especially PP (Preposition Phrase) attachment.</S> | Discourse Facet:  Implication_Citation | Annotator:  Kokil Jaidka |


Citance Number: 10 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['161'] | Citation Marker:  Zhou et al 2005 | Citation Offset:  ['161'] | Citation Text:  <S sid ="161" ssid = "24">Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al (2006), is applied to integrate the proposed c ontextsensitive convolution tree kernel with a state -of the-art linear kernel (Zhou et al 2005)</S> | Reference Offset:  ['51','52'] | Reference Text:  <S sid ="51" ssid = "7">Moreover, we only apply the simple linear kernel, although other kernels can peform better.</S><S sid ="52" ssid = "8">The reason why we choose SVMs for this purpose is that SVMs represent the state-of–the-art in the machine learning research community, and there are good implementations of the algorithm available.</S> | Discourse Facet:  Implication_Citation | Annotator:  Kokil Jaidka | 


Citance Number: 11 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['167'] | Citation Marker:  20 05 | Citation Offset:  ['166','167'] | Citation Text:  <S sid ="166" ssid = "29">7 Here, we use the same set of flat features (i.e. word,.</S><S sid ="167" ssid = "30">entity type, mention level, overlap, base phrase chunk- ing, dependency tree, parse tree and semantic information) as Zhou et al (20 05).</S> | Reference Offset:  ['34'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 12 | Reference Article:  P05-1053.xml | Citing Article:  D07-1076.xml | Citation Marker Offset:  ['177'] | Citation Marker:  2005 | Citation Offset:  ['176','177'] | Citation Text:  <S sid ="176" ssid = "39"> dependency kernel Zhou et al.</S><S sid ="177" ssid = "40">(2005)</S> | Reference Offset:  ['33'] | Reference Text:  <S sid ="33" ssid = "4">Culotta et al (2004) extended this work to estimate kernel functions between augmented dependency trees and achieved 63.2 F-measure in relation detection and 45.8 F-measure in relation detection and classification on the 5 ACE relation types.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 14 | Reference Article:  P05-1053.xml | Citing Article:  D09-1149.xml | Citation Marker Offset:  ['53'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['53'] | Citation Text:  <S sid ="53" ssid = "5">For each pair of entity mentions, we extract and compute various lexical and syntactic features, as employed in a state-of-the-art relation extraction system (Zhou et al., 2005).</S> | Reference Offset:  ['60','17'] | Reference Text:  <S sid ="60" ssid = "3">For each pair of mentions3, we compute various lexical, syntactic and semantic features.</S><S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 15 | Reference Article:  P05-1053.xml | Citing Article:  D09-1149.xml | Citation Marker Offset:  ['81'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['81'] | Citation Text:  <S sid ="81" ssid = "19">It is well known that the number of the instances for each relation type in the ACE RDC corpora is greatly unbalanced (Zhou et al., 2005) as shown in Table 1 for the ACE RDC 2004 corpus.</S> | Reference Offset:  ['121','122'] | Reference Text:  <S sid ="121" ssid = "3">ACE corpus suffers from a small amount of annotated data for a few subtypes such as the subtype “Founder” under the type “ROLE”.</S><S sid ="122" ssid = "4">It also shows that the ACE RDC task defines some difficult sub- types such as the subtypes “Based-In”, “Located” and “Residence” under the type “AT”, which are difficult even for human experts to differentiate.</S> | Discourse Facet:  Implication_Citation | Annotator:  Kokil Jaidka |


Citance Number: 16 | Reference Article:  P05-1053.xml | Citing Article:  D12-1074.xml | Citation Marker Offset:  ['100'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['100'] | Citation Text:  <S sid ="100" ssid = "36">This is a lightweight model and generally does not attempt to exhaustively leverage all possible proven sources of useful features (Zhou et al., 2005) towards a higher absolute score, but rather to serve as a point of comparison to the models which rely on syntactic information.</S> | Reference Offset:  ['40'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 17 | Reference Article:  P05-1053.xml | Citing Article:  E06-2012.xml | Citation Marker Offset:  ['59'] | Citation Marker:  Zelenko et al, 2003, Zhou et al, 2005 | Citation Offset:  ['59'] | Citation Text:  <S sid ="59" ssid = "29">Recent work has begun to address relation and event extraction through trainable means, chiefly SVM classification (Zelenko et al, 2003, Zhou et al, 2005).</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 18 | Reference Article:  P05-1053.xml | Citing Article:  E12-1020.xml | Citation Marker Offset:  ['54'] | Citation Marker:  2005 | Citation Offset:  ['54','55'] | Citation Text:  <S sid ="54" ssid = "34">For the choice of features, we use the full set of features from Zhou et al.</S><S sid ="55" ssid = "35">(2005) since it is reported to have a state-of-the-art performance (Sun et al., 2011).</S> | Reference Offset:  ['17','20'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S><S sid ="20" ssid = "20">Evaluation shows that the incorporation of diverse features enables our system achieve best reported performance.</S> | Discourse Facet:  ['Method_Citation','Results_Citation'] | Annotator:  Kokil Jaidka |


Citance Number: 19 | Reference Article:  P05-1053.xml | Citing Article:  E12-1020.xml | Citation Marker Offset:  ['109'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['109'] | Citation Text:  <S sid ="109" ssid = "34">We use a state-of-the-art feature space (Zhou et al., 2005) to represent examples (including all correct examples, erroneous ones and untagged examples) and use MaxEnt as the weight learning model since it shows competitive performance in relation extraction (Jiang and Zhai, 2007) and outputs probabilities associated with each prediction.</S> | Reference Offset:  ['37','40'] | Reference Text:  <S sid ="37" ssid = "8">Tree kernel-based approaches proposed by Zelenko et al (2003) and Culotta et al (2004) are able to explore the implicit feature space without much feature engineering.</S><S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 20 | Reference Article:  P05-1053.xml | Citing Article:  E12-1020.xml | Citation Marker Offset:  ['225'] | Citation Marker:  2005 | Citation Offset:  ['224','225'] | Citation Text:  <S sid ="224" ssid = "3">We use SVM as our learning algorithm with the full feature set from Zhou et al.</S><S sid ="225" ssid = "4">(2005).</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 21 | Reference Article:  P05-1053.xml | Citing Article:  I08-1004.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Zhou et al 2005 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">Indeed, such feature-based methods have been widely applied in parsing (Collins 1999; Charniak 2001), semantic role labeling (Pradhan et al 2005), semantic relation extraction (Zhou et al 2005) and co-reference resolution (Lapin and Leass 1994; Aone and Bennett 1995; Mitkov 1998; Yang et al 2004; Luo and Zitouni 2005; Bergsma and Lin 2006).</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 22 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['9'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">However it is reported (Zhou et al., 2005; Kambhatla, 2004) that hierarchical structured syntactic features contributes less to performance improvement.</S> | Reference Offset:  ['193'] | Reference Text:  <S sid ="193" ssid = "75">Instead of exploring the full parse tree information directly as previous related work, we incorporate the base phrase chunking information performance improvement from syntactic aspect while further incorporation of the parse tree and dependence tree information only slightly improves the performance.</S> | Discourse Facet:  Implication_Citation | Annotator:  Kokil Jaidka |


Citance Number: 23 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['32'] | Citation Marker:  2005 | Citation Offset:  ['31','32'] | Citation Text:  <S sid ="31" ssid = "7">Zhou et al.</S><S sid ="32" ssid = "8">(2005) explore various features in relation extraction using SVM.</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 24 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['36'] | Citation Marker:  2005 | Citation Offset:  ['35','36'] | Citation Text:  <S sid ="35" ssid = "11">The features used in Kambhatla (2004) and Zhou et al.</S><S sid ="36" ssid = "12">(2005) have to be selected and carefully calibrated manually.</S> | Reference Offset:  ['34','40'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 25 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['39'] | Citation Marker:  2005 | Citation Offset:  ['38','39'] | Citation Text:  <S sid ="38" ssid = "14">Besides, Zhou et al.</S><S sid ="39" ssid = "15">(2005) introduce additional chunking features to enhance the parse tree features.</S> | Reference Offset:  ['193'] | Reference Text:  <S sid ="193" ssid = "75">Instead of exploring the full parse tree information directly as previous related work, we incorporate the base phrase chunking information performance improvement from syntactic aspect while further incorporation of the parse tree and dependence tree information only slightly improves the performance.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 26 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['136'] | Citation Marker:  2005 | Citation Offset:  ['135','136'] | Citation Text:  <S sid ="135" ssid = "6">we call the features used in Zhou et al.</S><S sid ="136" ssid = "7">(2005) and Kambhatla (2004) flat feature set.</S> | Reference Offset:  ['34','40'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S><S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 27 | Reference Article:  P05-1053.xml | Citing Article:  N06-1037.xml | Citation Marker Offset:  ['137'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['137'] | Citation Text:  <S sid ="137" ssid = "8">(Zhou et al., 2005), our experiments are carried out on explicit relations due to the poor inter-annotator agreement in annotation of implicit relations and their limited numbers.</S> | Reference Offset:  ['110'] | Reference Text:  <S sid ="110" ssid = "3">In this paper, we only model explicit relations because of poor inter-annotator agreement in the annotation of implicit relations and their limited number.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 28 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['12'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['12'] | Citation Text:  <S sid ="12" ssid = "12">The first utilizes a set of carefully selected features obtained from different levels of text analysis, from part-of-speech (POS) tagging to full parsing and dependency parsing (Kambhatla, 2004; Zhao and Grishman, 2005; Zhou et al., 2005)1.</S> | Reference Offset:  ['34'] | Reference Text:  <S sid ="34" ssid = "5">Kambhatla (2004) employed Maximum Entropy models for relation extraction with features derived from word, entity type, mention level, overlap, dependency tree and parse tree.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 29 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['34'] | Citation Marker:  2005 | Citation Offset:  ['33','34'] | Citation Text:  <S sid ="33" ssid = "1">Zhao and Grishman (2005) and Zhou et al.</S><S sid ="34" ssid = "2">(2005) explored a large set of features that are potentially useful for relation extraction.</S> | Reference Offset:  ['40'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 31 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['124'] | Citation Marker:  2005 | Citation Offset:  ['122','123','124'] | Citation Text:  <S sid ="122" ssid = "69">Bag-of-Words: These features have also been explore by Zhao and Grishman (2005) and Zhou et.</S><S sid ="123" ssid = "70">al.</S><S sid ="124" ssid = "71">(2005).</S> | Reference Offset:  ['67','68'] | Reference Text:  <S sid ="67" ssid = "10">This is done by replacing the pronominal mention with the most recent non-pronominal antecedent when determining the word features, which include: • WM1: bag-of-words in M1 • HM1: head word of M1 3 In ACE, each mention has a head annotation and an.</S><S sid ="68" ssid = "11">extent annotation.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 32 | Reference Article:  P05-1053.xml | Citing Article:  N07-1015.xml | Citation Marker Offset:  ['132'] | Citation Marker:  2005 | Citation Offset:  ['130','131','132'] | Citation Text:  <S sid ="130" ssid = "77">Dependency Relations and Dependency Paths: These features have been explored by Bunescu and Mooney (2005a), Zhao and Grishman (2005), and Zhou et.</S><S sid ="131" ssid = "78">al.</S><S sid ="132" ssid = "79">(2005).</S> | Reference Offset:  ['93'] | Reference Text:  <S sid ="93" ssid = "36">This category of features includes information about the words, part-of-speeches and phrase labels of the words on which the mentions are dependent in the dependency tree derived from the syntactic full parse tree.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 33 | Reference Article:  P05-1053.xml | Citing Article:  N09-3012.xml | Citation Marker Offset:  ['7'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['7'] | Citation Text:  <S sid ="7" ssid = "7">Although in order to achieve the best performance, it is necessary to use a proper combination of these features (Zhou et al., 2005), in this paper, we will concentrate on how to better capture the syntactic features for relation extraction.</S> | Reference Offset:  ['20'] | Reference Text:  <S sid ="20" ssid = "20">Evaluation shows that the incorporation of diverse features enables our system achieve best reported performance.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 34 | Reference Article:  P05-1053.xml | Citing Article:  N13-1093.xml | Citation Marker Offset:  ['108'] | Citation Marker:  2005 | Citation Offset:  ['107','108'] | Citation Text:  <S sid ="107" ssid = "11">These experiments are done using Zhou et al.</S><S sid ="108" ssid = "12">(2005), TPWF kernel, SL kernel, different versions of proposed KH F kernel and KH ybrid kernel.</S> | Reference Offset:  ['51'] | Reference Text:  <S sid ="51" ssid = "7">Moreover, we only apply the simple linear kernel, although other kernels can peform better.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 35 | Reference Article:  P05-1053.xml | Citing Article:  N13-1093.xml | Citation Marker Offset:  ['113'] | Citation Marker:  2005 | Citation Offset:  ['112','113'] | Citation Text:  <S sid ="112" ssid = "16">We also performed (5-fold cross validation) experiments by combining the Stage 1 classifier with each of the Zhou et al.</S><S sid ="113" ssid = "17">(2005)</S> | Reference Offset:  ['53'] | Reference Text:  <S sid ="53" ssid = "9">In this paper, we use the binary-class SVMLight2 deleveloped by Joachims (1998).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 36 | Reference Article:  P05-1053.xml | Citing Article:  P06-1016.xml | Citation Marker Offset:  ['13'] | Citation Marker:  Zhou et al 2005 | Citation Offset:  ['13'] | Citation Text:  <S sid ="13" ssid = "13">One major challenge in relation extraction is due to the data sparseness problem (Zhou et al 2005).</S> | Reference Offset:  ['121'] | Reference Text:  <S sid ="121" ssid = "3">ACE corpus suffers from a small amount of annotated data for a few subtypes such as the subtype “Founder” under the type “ROLE”.</S> | Discourse Facet:  Implication_Citation | Annotator:  Kokil Jaidka |


Citance Number: 37 | Reference Article:  P05-1053.xml | Citing Article:  P06-1016.xml | Citation Marker Offset:  ['18'] | Citation Marker:  Zhou et al 2005 | Citation Offset:  ['18'] | Citation Text:  <S sid ="18" ssid = "18">While various machine learning approaches, such as generative modeling (Miller et al 2000), maximum entropy (Kambhatla 2004) and support vector machines (Zhao and Grisman 2005; Zhou et al 2005), have been applied in the relation extraction task, no explicit learning strategy is proposed to deal with the inherent data sparseness problem caused by the much uneven distribution among different relations.</S> | Reference Offset:  ['53','121'] | Reference Text:  <S sid ="53" ssid = "9">In this paper, we use the binary-class SVMLight2 deleveloped by Joachims (1998).</S><S sid ="121" ssid = "3">ACE corpus suffers from a small amount of annotated data for a few subtypes such as the subtype “Founder” under the type “ROLE”.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 39 | Reference Article:  P05-1053.xml | Citing Article:  P06-1016.xml | Citation Marker Offset:  ['45'] | Citation Marker:  | Citation Offset:  ['45'] | Citation Text:   <S sid ="45" ssid = "18">Zhou et al (2005) further systematically explored diverse lexical, syntactic and semantic features through support vector machines and achieved F- measure of 68.1 and 55.5 on the 5 relation types and the 24 relation subtypes in the ACE RDC 2003 corpus respectively.</S> | Reference Offset:  ['130'] | Reference Text:  <S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 40 | Reference Article:  P05-1053.xml | Citing Article:  P06-1016.xml | Citation Marker Offset:  ['128'] | Citation Marker:  2005 | Citation Offset:  ['128'] | Citation Text:  <S sid ="128" ssid = "60">Same as Zhou et al (2005), we only model explicit relations and explicitly model the argument order of the two mentions involved.</S> | Reference Offset:  ['110','58','59'] | Reference Text:  <S sid ="110" ssid = "3">In this paper, we only model explicit relations because of poor inter-annotator agreement in the annotation of implicit relations and their limited number.</S><S sid ="58" ssid = "1">The semantic relation is determined between two mentions.</S><S sid ="59" ssid = "2">In addition, we distinguish the argument order of the two mentions (M1 for the first mention and M2 for the second mention), e.g. M1-Parent- Of-M2 vs. M2-Parent-Of-M1.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 43 | Reference Article:  P05-1053.xml | Citing Article:  P06-1017.xml | Citation Marker Offset:  ['207'] | Citation Marker:  2005 | Citation Offset:  ['206','207'] | Citation Text:  <S sid ="206" ssid = "17">In the future, we would like to use more effective feature sets Zhou et al.</S><S sid ="207" ssid = "18">(2005)</S> | Reference Offset:  ['40'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 45 | Reference Article:  P05-1053.xml | Citing Article:  P06-1104.xml | Citation Marker Offset:  ['39'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "5">Feature-based methods (Kambhatla, 2004; Zhou et al., 2005; Zhao and Grishman, 20052 ) for this task employ a large amount of diverse linguistic features, such as lexical, syntactic and semantic features.</S> | Reference Offset:  ['40'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 47 | Reference Article:  P05-1053.xml | Citing Article:  P08-2023.xml | Citation Marker Offset:  ['29'] | Citation Marker:  2005 | Citation Offset:  ['29','30'] | Citation Text:  <S sid ="29" ssid = "9">Based on his work, Zhou et al (2005)</S><S sid ="30" ssid = "10">further incorporated the base phrase chunking information and semi-automatically collected country name list and personal relative trigger word list.</S> | Reference Offset:  ['18','155'] | Reference Text:  <S sid ="18" ssid = "18">Our study illustrates that the base phrase chunking information contributes to most of the performance inprovement from syntactic aspect while additional full parsing information does not contribute much, largely due to the fact that most of relations defined in ACE corpus are within a very short distance.</S><S sid ="155" ssid = "37">This is largely due to incorporation of two semantic resources, i.e. the country name list and the personal relative trigger word list.</S> | Discourse Facet:  ['Results_Citation','Implication_Citation'] | Annotator:  Kokil Jaidka |


Citance Number: 48 | Reference Article:  P05-1053.xml | Citing Article:  P09-1113.xml | Citation Marker Offset:  ['39'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "39">While syntactic features are known to improve the performance of supervised IE, at least using clean hand-labeled ACE data (Zhou et al., 2007; Zhou et al., 2005), we do not know whether syntactic features can improve the performance of unsupervised or distantly supervised IE.</S> | Reference Offset:  ['18'] | Reference Text:  <S sid ="18" ssid = "18">Our study illustrates that the base phrase chunking information contributes to most of the performance inprovement from syntactic aspect while additional full parsing information does not contribute much, largely due to the fact that most of relations defined in ACE corpus are within a very short distance.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 49 | Reference Article:  P05-1053.xml | Citing Article:  P09-1113.xml | Citation Marker Offset:  ['52'] | Citation Marker:  2005 | Citation Offset:  ['50','51','52','53'] | Citation Text:  <S sid ="50" ssid = "10">More recent approaches have used deeper syntactic information derived from parses of the input sentences, including work exploiting syntactic dependencies by Lin and Pantel (2001) and Snow et al.</S><S sid ="51" ssid = "11">(2005), and work in the ACE paradigm such as Zhou et al.</S><S sid ="52" ssid = "12">(2005) and Zhou et al.</S><S sid ="53" ssid = "13">(2007).</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 50 | Reference Article:  P05-1053.xml | Citing Article:  P09-1114.xml | Citation Marker Offset:  ['25'] | Citation Marker:  2005 | Citation Offset:  ['23','24','25'] | Citation Text:  <S sid ="23" ssid = "1">Recent work on relation extraction has been dominated by feature-based and kernel-based supervised learning methods.</S><S sid ="24" ssid = "2">Zhou et al.</S><S sid ="25" ssid = "3">(2005) and Zhao and Grishman (2005) studied various features and feature combinations for relation extraction.</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet: Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 51 | Reference Article:  P05-1053.xml | Citing Article:  P09-1114.xml | Citation Marker Offset:  ['7'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['7'] | Citation Text:  <S sid ="7" ssid = "7">Recent work on relation extraction has shown that supervised machine learning coupled with intelligent feature engineering or kernel design provides state-of-the-art solutions to the problem (Culotta and Sorensen, 2004; Zhou et al., 2005; Bunescu and Mooney, 2005; Qian et al., 2008).</S> | Reference Offset:  ['17','20'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S><S sid ="20" ssid = "20">Evaluation shows that the incorporation of diverse features enables our system achieve best reported performance.</S> | Discourse Facet:  ['Method_Citation','Results_Citation'] | Annotator:  Kokil Jaidka |


Citance Number: 52 | Reference Article:  P05-1053.xml | Citing Article:  P11-1053.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">Then the feature based method explicitly extracts a variety of lexical, syntactic and semantic features for statistical learning, either generative or discriminative (Miller et al., 2000; Kambhatla, 2004; Boschee et al., 2005; Grishman et al., 2005; Zhou et al., 2005; Jiang and Zhai, 2007).</S> | Reference Offset:  ['40'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 53 | Reference Article:  P05-1053.xml | Citing Article:  P11-1053.xml | Citation Marker Offset:  ['81'] | Citation Marker:  2005 | Citation Offset:  ['80','81'] | Citation Text:  <S sid ="80" ssid = "44">We first adopted the full feature set from Zhou et al.</S><S sid ="81" ssid = "45">(2005), a state-of-the-art feature based relation extraction system.</S> | Reference Offset:  ['40','52'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S><S sid ="52" ssid = "8">The reason why we choose SVMs for this purpose is that SVMs represent the state-of–the-art in the machine learning research community, and there are good implementations of the algorithm available.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 54 | Reference Article:  P05-1053.xml | Citing Article:  P11-1053.xml | Citation Marker Offset:  ['193'] | Citation Marker:  2005 | Citation Offset:  ['193','194'] | Citation Text:  <S sid ="193" ssid = "157">Zhou et al.</S><S sid ="194" ssid = "158">(2005) tested their system on the ACE 2003 data;.</S> | Reference Offset:  ['108'] | Reference Text:  <S sid ="108" ssid = "1">This paper uses the ACE corpus provided by LDC to train and evaluate our feature-based relation extraction system.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 55 | Reference Article:  P05-1053.xml | Citing Article:  P11-1056.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['11'] | Citation Text:  <S sid ="11" ssid = "11">However, most approaches to RE have assumed that the relationsâ€™ arguments are given as input (Chan and Roth, 2010; Jiang and Zhai, 2007; Jiang, 2009; Zhou et al., 2005), and therefore offer only a partial solution to the problem.</S> | Reference Offset:  ['59'] | Reference Text:  <S sid ="59" ssid = "2">In addition, we distinguish the argument order of the two mentions (M1 for the first mention and M2 for the second mention), e.g. M1-Parent- Of-M2 vs. M2-Parent-Of-M1.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 56 | Reference Article:  P05-1053.xml | Citing Article:  P11-1056.xml | Citation Marker Offset:  ['58'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['58'] | Citation Text:  <S sid ="58" ssid = "19">Most prior RE evaluation on ACE data assumed that mentions are already pre-annotated and given as input (Chan and Roth, 2010; Jiang and Zhai, 2007; Zhou et al., 2005).</S> | Reference Offset:  ['128'] | Reference Text:  <S sid ="128" ssid = "10">In this paper, we only measure the performance of relation extraction on “true” mentions with “true” chaining of coreference (i.e. as annotated by the corpus annotators) in the ACE corpus.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 57 | Reference Article:  P05-1053.xml | Citing Article:  P11-3012.xml | Citation Marker Offset:  ['34'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['34'] | Citation Text:  <S sid ="34" ssid = "7">We used Zhou et al.â€™s lexical features (Zhou et al., 2005) as the basis for the features of our system similar to what other researchers have done (Chan and Roth, 2010).</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 58 | Reference Article:  P05-1053.xml | Citing Article:  P11-3012.xml | Citation Marker Offset:  ['47'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['47'] | Citation Text:  <S sid ="47" ssid = "4">Although a bit lower than Zhou et al.â€™s result of 55.5 (Zhou et al., 2005), we attribute the difference to our use of a different tokenizer, different parser, and having not used the semantic information features.</S> | Reference Offset:  ['130'] | Reference Text:  <S sid ="130" ssid = "12">It shows that our system achieves best performance of 63.1%/49.5%/ 55.5 in precision/recall/F-measure when combining diverse lexical, syntactic and semantic features.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 59 | Reference Article:  P05-1053.xml | Citing Article:  P13-1147.xml | Citation Marker Offset:  ['167'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['167'] | Citation Text:  <S sid ="167" ssid = "10">This is slightly behind that of Zhang (2006); the reason might be threefold: i) different data partitioning; ii) different pre-processing; iii) they incorporate features from additional sources, i.e. a phrase chunker, dependency parser and semantic resources (Zhou et al., 2005) (we have on average 9 features/instance, they use 40).</S> | Reference Offset:  ['17','126'] | Reference Text:  <S sid ="17" ssid = "17">This paper focuses on the ACE RDC task and employs diverse lexical, syntactic and semantic knowledge in feature-based relation extraction using Support Vector Machines (SVMs).</S><S sid ="126" ssid = "8">In this way, we model relation extraction as a multi-class classification problem with 43 classes, two for each relation subtype (except the above 6 symmetric subtypes) and a “NONE” class for the case where the two mentions are not related.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 60 | Reference Article:  P05-1053.xml | Citing Article:  W06-1634.xml | Citation Marker Offset:  ['9'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">Techniques based on machine learning (Zhou et al., 2005; Hao et al., 2005; Bunescu and Mooney, 2006) are expected to alleviate this problem in manually crafted IE.</S> | Reference Offset:  ['53'] | Reference Text:  <S sid ="53" ssid = "9">In this paper, we use the binary-class SVMLight2 deleveloped by Joachims (1998).</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 61 | Reference Article:  P05-1053.xml | Citing Article:  W06-1634.xml | Citation Marker Offset:  ['17'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['17'] | Citation Text:  <S sid ="17" ssid = "2">A technique that many previous approaches have used is shallow parsing (Koike et al., 2003; Yao et al., 2004; Zhou et al., 2005).</S> | Reference Offset:  ['4'] | Reference Text:  <S sid ="4" ssid = "4">This suggests that most of useful information in full parse trees for relation extraction is shallow and can be captured by chunking.</S> | Discourse Facet:  Implication_Citation | Annotator:  Kokil Jaidka |


Citance Number: 63 | Reference Article:  P05-1053.xml | Citing Article:  W06-1667.xml | Citation Marker Offset:  ['174'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['174'] | Citation Text:  <S sid ="174" ssid = "110">Especially, although we did not concern the dependency tree and full parse tree information as other supervised methods (Miller et al., 2000; Culotta and Soresen, 2004; Kambhatla, 2004; Zhou et al., 2005), the incorporation of simple features, such as words and chunking information, still can provide complement information for capturing the characteristics of entity pairs.</S> | Reference Offset:  ['193'] | Reference Text:  <S sid ="193" ssid = "75">Instead of exploring the full parse tree information directly as previous related work, we incorporate the base phrase chunking information performance improvement from syntactic aspect while further incorporation of the parse tree and dependence tree information only slightly improves the performance.</S> | Discourse Facet:  Results_Citation | Annotator:  Kokil Jaidka |


Citance Number: 64 | Reference Article:  P05-1053.xml | Citing Article:  W08-0602.xml | Citation Marker Offset:  ['39'] | Citation Marker:  2005 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "39">This follows on from the success of these methods in general NLP (see for example Zhou et al (2005)).</S> | Reference Offset:  ['30'] | Reference Text:  <S sid ="30" ssid = "1">The relation extraction task was formulated at the 7th Message Understanding Conference (MUC7 1998) and is starting to be addressed more and more within the natural language processing and machine learning communities.</S> | Discourse Facet:  Aim_Citation | Annotator:  Kokil Jaidka |


Citance Number: 65 | Reference Article:  P05-1053.xml | Citing Article:  W08-0602.xml | Citation Marker Offset:  ['136'] | Citation Marker:  2005 | Citation Offset:  ['136'] | Citation Text:  <S sid ="136" ssid = "51">We use features developed in part from those described in Zhou et al (2005) and Wang et al (2006).</S> | Reference Offset:  ['40'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 66 | Reference Article:  P05-1053.xml | Citing Article:  W11-1101.xml | Citation Marker Offset:  ['203'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['203'] | Citation Text:  <S sid ="203" ssid = "11">A variety of features have been explored for ERD in previous research (Zhou et al., 2005; Zhou et al., 2008; Jiang and Zhai, 2007; Miller et al., 2000).</S> | Reference Offset:  ['40'] | Reference Text:  <S sid ="40" ssid = "11">This paper will further explore the feature-based approach with a systematic study on the extensive incorporation of diverse lexical, syntactic and semantic information.</S> | Discourse Facet:  Method_Citation | Annotator:  Kokil Jaidka |


Citance Number: 68 | Reference Article:  P05-1053.xml | Citing Article:  W11-1815.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Zhou et al., 2005 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">BB task example Ureaplasma parvum is a mycoplasma and a pathogenic biology challenges (Kim et al., 2010) and geographical locations (Zhou et al., 2005).</S> | Reference Offset:  ['12'] | Reference Text:  <S sid ="12" ssid = "12">Entities can be of five types: persons, organizations, locations, facilities and geopolitical entities (GPE: geographically defined regions that indicate a political boundary, e.g. countries, states, cities, etc.).</S> | Discourse Facet:  Hypothesis_Citation | Annotator:  Kokil Jaidka |


