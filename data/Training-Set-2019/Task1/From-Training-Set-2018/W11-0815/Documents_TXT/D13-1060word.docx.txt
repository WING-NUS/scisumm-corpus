Identifying Phrasal Verbs Using Many Bilingual Corpora




Karl Pichotta∗
Department of Computer Science 
University of Texas at Austin 
pichotta@cs.utexas.edu


John DeNero Google, Inc. 
denero@google.com







Abstract

We address the problem of identifying mul- 
tiword  expressions  in  a   language, focus- 
ing on English phrasal  verbs.   Our poly- 
glot ranking approach  integrates  frequency 
statistics from translated corpora  in 50 dif- 
ferent languages.  Our experimental  eval- 
uation demonstrates that combining statisti- 
cal evidence from many parallel corpora us- 
ing a  novel ranking-oriented  boosting algo- 
rithm  produces a comprehensive set of English 
phrasal verbs, achieving performance compa- 
rable to a human-curated  set.


1   Introduction

A multiword expression (MWE), or noncomposi- 
tional compound,  is a  sequence  of words whose 
meaning  cannot be composed  directly from the 
meanings of its constituent words. These idiosyn- 
cratic phrases are prevalent in the lexicon of a lan- 
guage; Jackendoff (1993) estimates that their num- 
ber is on the same order of magnitude as that of sin- 
gle words,  and Sag et al. (2002)  suggest that they 
are much more common, though quantifying  them 
is challenging (Church, 2011). The task of identify- 
ing MWEs is relevant not only to lexical semantics 
applications, but also machine translation (Koehn et 
al., 2003; Ren et al., 2009; Pal et al., 2010), informa- 
tion retrieval (Xu et al., 2010; Acosta et al., 2011), 
and syntactic parsing (Sag et al., 2002). Awareness 
of MWEs has empirically  proven useful in a num- 
ber of domains: Finlayson and Kulkarni (2011), for 
example,  use MWEs to attain a significant  perfor-
  

We focus on a particular subset of MWEs, English 
phrasal verbs. A phrasal verb consists of a head 
verb followed by one or more particles,  such that 
the meaning of the phrase cannot be determined by 
combining the simplex meanings of its constituent 
words (Baldwin and Villavicencio, 2002; Dixon,
1982; Bannard et al., 2003).1 Examples of phrasal
verbs include count on [rely], look after [tend], or 
take off [remove], the meanings of which do not in- 
volve counting, looking, or taking. In contrast, there 
are verbs followed by particles that are not phrasal 
verbs, because their meaning is compositional, such 
as walk towards, sit behind, or paint on.
  We  identify phrasal  verbs by using frequency 
statistics calculated from parallel corpora, consist- 
ing of bilingual pairs of documents such that one 
is a translation  of the other, with one document in 
English. We leverage the observation that a verb 
will translate in an atypical way when occurring  as 
the head of a phrasal  verb. For example, the word 
look in the context of look after will tend to trans- 
late differently from how look translates generally. 
In order to characterize this difference, we calculate 
a frequency  distribution over translations of look, 
then compare it to the distribution of translations of 
look when followed by the word after. We expect 
that idiomatic phrasal verbs will tend to have unex- 
pected translation of their head verbs, measured by 
the Kullback-Leibler  divergence between those dis- 
tributions.
  Our polyglot ranking approach is motivated by the 
hypothesis that using many parallel corpora of dif- 
ferent languages will help determine the degree of 
semantic idiomaticity  of a phrase.  In order to com-


mance improvement in word sense disambiguation;	 	


Venkatapathy  and Joshi (2006) use features associ- 
ated with MWEs to improve word alignment.
∗Research conducted during an internship at Google.
  

1 Nomenclature varies: the term verb-particle construction 
is also used to denote what we call phrasal verbs; further, the 
term phrasal verb is sometimes used to denote a broader class 
of constructions.


bine evidence from multiple  languages, we develop 
a novel boosting algorithm tailored to the task of 
ranking multiword expressions by their degree of id- 
iomaticity.  We train and evaluate on disjoint subsets 
of the phrasal verbs in English Wiktionary2. In our
3	1
experiments,  the set of phrasal verbs identified  au-


tomatically by our method achieves held-out recall 
that nears the performance of the phrasal verbs in 
WordNet 3.0, a human-curated  set.  Our approach 
strongly outperforms  a monolingual   system,  and 
continues  to improve when incrementally  adding 
translation statistics for 50 different languages.

2   Identifying Phrasal Verbs

The task of identifying phrasal verbs using corpus 
information raises several issues of experimental de- 
sign. We consider four central issues below in moti- 
vating our approach.

Types vs. Tokens.    When a phrase is used in con- 
text, it takes a particular  meaning  among its pos- 
sible senses.   Many phrasal verbs admit composi- 
tional senses in addition to idiomatic ones—contrast 
idiomatic “look down on him for his politics” with 
compositional “look down on him from the balcony.” 
In this paper, we focus on the task of determining 
whether a phrase type is a phrasal verb, meaning that 
it frequently expresses an idiomatic meaning across 
its many token usages in a corpus. We do not at- 
tempt to distinguish which individual phrase tokens 
in the corpus have idiomatic  senses.

Ranking vs.  Classification.     Identifying phrasal 
verbs involves relative, rather than categorical, judg- 
ments: some phrasal verbs are more compositional 
than others, but retain a degree of noncomposition- 
ality (McCarthy et al., 2003). Moreover,   a poly- 
semous phrasal verb may express an idiosyncratic 
sense more or less often than a compositional  sense 
in a particular corpus. Therefore, we should expect 
a corpus-driven   system  not to classify phrases  as 
strictly idiomatic or compositional, but instead as- 
sign a ranking or relative scoring to a set of candi- 
dates.

Candidate Phrases.   We distinguish  between the 
task of identifying  candidate multiword  expressions

2 http://en.wiktionary.org


Table 1: Features used by the polyglot ranking system.


and the task of ranking those candidates by their se- 
mantic idiosyncracy. With English phrasal verbs, it 
is straightforward  to enumerate all desired verbs fol- 
lowed by one or more particles, and rank the entire 
set.

Using Parallel Corpora.  There have been a num- 
ber of approaches proposed for the use of multilin- 
gual resources for MWE identification  (Melamed,
1997; Villada Moiro´ n and Tiedemann, 2006; Caseli 
et al., 2010; Tsvetkov and Wintner, 2012; Salehi 
and Cook, 2013). Our approach differs from pre- 
vious work in that we identify MWEs using transla- 
tion distributions of verbs, as opposed to 1–1, 1–m, 
or m–n word alignments, most-likely  translations, 
bilingual dictionaries, or distributional entropy. To 
the best of our knowledge, ours is the first approach 
to use translational distributions  to leverage the ob- 
servation that a verb typically translates differently 
when it heads a phrasal verb.

3   The Polyglot Ranking Approach

Our approach uses bilingual  and monolingual  statis- 
tics as features,  computed  over unlabeled corpora. 
Each statistic  characterizes the degree of idiosyn- 
crasy of a candidate  phrasal  verb, using a  single 
monolingual or bilingual corpus. We combine fea- 
tures for many language pairs using a boosting algo- 
rithm that optimizes a ranking objective using a su- 
pervised training set of English phrasal verbs. Each 
of these aspects of our approach is described in de- 
tail below; for reference, Table 1 provides  a list of 
the features used.

3.1   Bilingual Statistics

One of the intuitive properties of an MWE is that 
its individual words likely do not translate literally 
when the whole expression is translated into another 
language (Melamed, 1997). We capture this effect


by measuring the divergence between how a verb 
translates generally and how it translates when head- 
ing a candidate phrasal verb.
  A parallel corpus is a  collection of document 
pairs (DE , DF ), where DE  is in English, DF  is in
another language, one document is a translation  of 
the other, and all documents DF   are in the same 
language.  A phrase-aligned parallel corpus aligns 
those documents  at a sentence,  phrase,  and word 
level. A phrase e aligns to another phrase f if some 
word in e aligns to some word in f and no word in 
e or f aligns outside of f or e, respectively.   As a 
result of this definition, the words within an aligned 
phrase pair are themselves connected by word-level 
alignments.


to its subphrase most commonly  aligned to the verb 
in e.  It expresses how this verb is translated in the 
context of a phrasal verb construction.3  Equation (1) 
defines a distribution  over all phrases x of a foreign 
language.
  We also assign statistics  to verbs as they are trans- 
lated outside of the context of a phrase. Let v(e) 
be the verb of a phrasal  verb candidate  e, which 
is always its first word.  For a single-word   verb 
phrase v(e), we can compute the constituent transla- 
tion probability Pv(e)(x), again using Equation (1). 
The difference between Pe(x) and Pv(e)(x)  is that 
the latter sums over all translations of the verb v(e), 
regardless of whether it appears in the context of e:
)


  Given an English phrase e, define F (e) to be the 
set of all foreign  phrases observed aligned to e in a


Pv(e)(x) =



f ∈F (v(e))


P (f |v(e)) · δ (π1(v(e), f ), x)


parallel corpus. For any f ∈ F (e), let P (f |e) be the
conditional probability of the phrase e translating  to
the phrase f .  This probability is estimated  as the 
relative frequency of observing f and e as an aligned 
phrase pair, conditioned on observing  e aligned to 
any phrase in the corpus:

N (e, f )



For a one-word phrase such as v(e),  π1(v(e), f ) 
is the subphrase of f that most commonly directly 
word-aligns to the one word of v(e).
  Finally, for a phrase e and its verb v(e), we calcu- 
late the Kullback-Leibler  (KL) divergence between 
the translation distribution of v(e) and e:


P (f |e) = I:


f ! N (e, f !)



DK L


(Pv(e) Pe)


= ) Pv(e)(x) ln
x


Pv(e)(x)
Pe(x)



(2)


with N (e, f ) the number of times e and f are ob-
served occurring  as an aligned phrase pair.
  Next, we assign  statistics  to individual verbs 
within phrases. The first word of a candidate phrasal 
verb e is a verb. For a candidate phrasal verb e and 
a foreign  phrase f , let π1(e, f ) be the subphrase of 
f that is most commonly word-aligned to the first 
word of e. As an example, consider the phrase pair 
e = talk down to and f = hablar con menosprecio. 
Suppose that when e is aligned to f , the word talk is 
most frequently aligned to hablar. Then π1(e, f ) = 
hablar.
  For a phrase e and its set F (e) of aligned trans- 
lations, we define the constituent translation proba- 
bility of a foreign  subphrase x as:



where the sum ranges over all x such that Pv(e)(x) >
0. This quantifies the difference between the trans-
lations of e’s verb when it occurs in e, and when it 
occurs in general. Figure 1 illustrates this computa- 
tion on a toy corpus.

Smoothing. Equation (2) is defined only if, for ev- 
ery x such that Pv(e)(x)  > 0, it is also the case 
that Pe(x)  > 0.  In order to ensure that this con- 
dition holds, we smooth the translation distributions 
toward uniform. Let D be the set of phrases with 
non-zero probability under either distribution:
D = {x : Pv(e)(x) > 0 or Pe(x) > 0}

Then, let UD be the uniform distribution over D:


Pe(x) =  )
f ∈F (e)


P (f |e) · δ (π1(e, f ), x) 	(1)


U  (x) = 
f 1/|D|   
if x ∈ D
D 	0	if x ∈/ D


where δ is the Kronecker delta function, taking value
1 if its arguments are equal and 0 otherwise.  Intu- 
itively, Pe assigns the probability  mass for every f



     3 To extend this statistic to other types of multiword expres- 
sions, one could compute a similar distribution for other content 
words in the phrase.


0 	5    10   15   20   25   30   35   40   45   50

Number of languages (k)






Aligned Phrase Pair 	N (e, f ) 	⇡1 (e, f )


tion distributions for any inflected form 
ei  ∈ E:



looking forward to



1 	deseando



1
ϕL(e) =


)	    !	! \
v(ei ) 	ei


deseando

looking forward to 
mirando adelante a

looking 
mirando

looking 
buscando  a





3 	mirando



5 	mirando



3 	buscando


|
E
| 
ei 
∈
E

3
.
2
   
M
o
n
o
l
i
n
g
u
a
l
 
S
t
a
t
i
s
t
i
c
s
W
e 
al
so 
co
lle
ct  
a 
nu
m
be
r 
of 
m
o
n
oli
n
g
u
al 
st
ati
sti
cs 
fo
r 
ea
ch 
ph
ra
sa
l 
v
er
b 
ca
nd
id
at
e, 
m
oti
va
te
d  
b
y 
th
e 
co
ns
id
er
ab
le 
b
o
d
y 
of 
pr
ev
io
us 
w
or
k 
o
n 
th
e 
to
pi
c 
(C
hu
rc
h 
an
d 
H
an
ks
, 
19
90
; 
Li
n, 
1
9
9
9; 
M
c
C
ar
th
y 
et 
al
., 
2
0
0
3)
. 
T
he 
m
on
oli
ng
ua
l  
st
ati
sti
cs 
ar
e 
de
si
gn
ed 
to 
id
e
nti
fy 
fr
e
q
u
e
nt 
co
llo
ca
tio
ns 
in 
a 
la
ng
ua
ge
.  
T
hi
s 
se
t 
of 
m
on
oli
ng
ua
l  
fe
at
ur
es 
is 
no
t 
co
m
pr
eh
en
si
ve
, 
as 
w
e 
fo
cu
s 
o
ur 
at
te
nti
o
n 
pr
i
m
ar
ily 
o
n 
bi
li
n
g
u
al 
fe
a-


mirando	deseando 	buscando

Pv(e) (x) 	5   = 0.6 25	0	3   = 0.37 5


tures in this pap\ebre.gin{tabular}{rrrr}
&\textit{mirando} 	&\textit{deseando} &\te
As above, de$fiP_n{ev(Ee)}to(x)b$e &th$\efrsaect 
{o5f}{m8}o=r0p.h6o25lo$g- &$0$ 	&$\f


8	8
ically inflected\hvlairniean\t\s [o-f1eax]candidate  e,  and let
P 0	$P'_{v(e)}(x)$&$0.610	$ 	&$0.02$	&$0.


v(e) (x) 	0.6 10	0.02	0.37 3


V be the set o\f hilniflnec\te\d[v-1aerxia]nts of the 
head verb
v(e) of e. We 
d$ePfi_en(ex)th$re&e$\sftraatcis{t3i}c{s4c}a=l0c.u7l5at$ed 
&f$ro\fmrac{1}{4}=0.25  $


Pe (x) 	3   = 0.7 5


4   = 0.25	0


the phrase 
coun\thslionfea\m\ o[n-
1oelixn]gual English 
corpus.
$P'_e(x
)$&$0.
729	$ 	&$0.254	$ 	&$0.


Pe (x) 	0.7 29	0.254	0.02


First, we define\µhl1i(nee) \to\ b[e-1tehxe]relative 
frequency of
the candidate e\,egndiv{etnabeul’sarh}ead verb, 
summed over


0
v(ei )


kP 0   ) =   
0.109 +  
0.045 + 1.159 
= 1.005


morphologi
cal 
variants:

µ
 
D
(
_
e
{
)
K
L
=
}
  
l
(
n
P
'
P
_
{
(
v
E
(
e
V
_
i
)
)
}
  
\
|
 
P
'
_
{
e
_
i
}
)
 
=
  
-
0
.
1
0
9
 
+
  
-
0
.
0
4
5
  
+


Figure 1: The computation of DK L (P  


P   ) using a	1	|
I
:


toy corpus, for e = looking forward to. Note that the sec-
ond aligned phrase pair contains the third, so the second’s 
count of 3 must be included in the third’s count of 5.


= ln


ei ∈E N (ei)
vi ∈V N (vi)




When computing divergence in Equation (2), we use 
the smoothed distributions P ! and P !     :
e	v(e)

Pe(x) = αPe(x) + (1 − α)UD (x)
Pv(e)(x) = αPv(e)(x) + (1 − α)UD (x).

We use α = 0.95, which distributes 5% of the total 
probability mass evenly among all events in D.

Morphology. We calculate statistics for morpho- 
logical variants of an English  phrase.  For a candi- 
date English phrasal verb e (for example, look up),


where N (x) is the number of times phrase x was
observed in the 
monolingual  corpus.
  Second, define µ2(e) to be the 
pointwise  mutual information (PMI) 
between V (the event that one of the 
inflections of the verb in e is 
observed) and R, the event of 
observing the rest of the phrase:

µ2(e)
= PMI(V, R)
= lg P (V, R) − lg (P (V )P (R))
= lg P (E) − lg (P (V )P (R))
= lg ) N (ei)−lg ) N (vi)−lg N (r)+lg N


let E denote the set of inflections of that phrasal verb


ei ∈E


vi ∈V


(for look up, this will be [look|looks|looked|looking]
up). We extract the variants in E from the verb en-
tries in English Wiktionary. The final score com- 
puted from a phrase-aligned parallel corpus translat- 
ing English  sentences into a language L is the aver- 
age KL divergence of smoothed constituent transla-


where N is the total number of 
tokens in the corpus, and logarithms  
are base-2.  This statistic character- 
izes the degree of association  
between  a verb and its phrasal 
extension. We only calculate µ2 for 
two- word  phrases, as it did not 
prove helpful for longer phrases.


  Finally, define µ3(e) to be the relative frequency 
of the phrasal verb e augmented  by an accusative 
pronoun, conditioned on the verb.  Let A be the 
set of phrases in E with an accusative pronoun (it, 
them, him, her, me, you) optionally  inserted either at 
the end of the phrase or directly after the verb. For
e = look up, A = {look up, look X up, look up X, 
looks up, looks X up, looks up X, . . . }, with X  an
accusative pronoun. The µ3 statistic is similar to µ1, 
but allows for an intervening  or following pronoun:

µ3(e) = ln P (A|V )
I:


Algorithm 1 Recall-Oriented Ranking AdaBoost
1: for i = 1 : |X | do
2:	w[i] ← 1/|X |
3: end for
4: for t = 1 : T do
5:	for all h ∈ H do
6:	Eh  ← 0
7:	for i = 1 : |X | do
8:	if xi  /∈ h then
9:	Eh  ← Eh + w[i]
10:	end if
11:	end for



= ln


ei ∈A N (ei)


12:	end for


I:vi ∈V N (vi)


13:	ht


← argmax


h∈H


|EB


− Eh|



This statistic is designed to exploit the intuition that 
phrasal verbs frequently  have accusative pronouns 
either inserted into the middle (e.g. look it up) or at


14:	αt ← ln(EB /Eht )
15:	for i = 1 : |X | do
16:	if xi  ∈ ht then
17:	w[i] ←  1 w[i] exp (−αt)


the end (e.g. look down on him).

3.3   Ranking Phrasal Verb Candidates

Our goal is to assign a single  real-valued  score to 
each candidate e, by which we can rank candidates 
according to semantic idiosyncrasy.   For each lan- 
guage L for which we have a parallel  corpus,  we 
defined, in section 3.1, a function  ϕL(e) assigning 
real values to candidate phrasal verbs e, which we 
hypothesize is higher on average for more idiomatic 
compounds. Further, in section 3.2, we defined real- 
valued monolingual  functions µ1, µ2, and µ3  for 
which we hypothesize the same trend holds. Be- 
cause each score individually ranks all candidates, 
it is natural to view each ϕL and µi  as a weak rank- 
ing function that we can combine with a supervised 
boosting objective.   We use a modified  version of 
AdaBoost (Freund and Schapire, 1995) that opti- 
mizes for recall.
  For each ϕL and µi,  we compute  a ranked  list 
of candidate phrasal verbs, ordered from highest to 
lowest value. To simplify learning, we consider only 
the top 5000 candidate phrasal verbs according to
µ1, µ2, and µ3.  This pruning procedure excludes 
candidates that do not appear in our monolingual 
corpus.
  We optimize the ranker using an unranked, in- 
complete training set of phrasal verbs. We can eval- 
uate the quality of the ranker by outputting the top 
N ranked candidates and measuring recall relative


18:              else
19:                     w[i] ←  1 w[i] exp (αt)
20:              end if
21:        end for
22: end for



to this gold-standard training set.  We choose this 
recall-at-N metric so as to not directly penalize pre- 
cision errors, as our training  set is incomplete.
Define H to be the set of N -element sets contain-
ing the top proposals for each weak ranker (we use
N = 2000). That is, each element of H is a set con-
taining the 2000 highest values for some ϕL or µi. 
We define the baseline error EB  to be 1 − E[R], with
R the recall-at-N  of a ranker ordering the candidate 
phrases in the set ∪H at random. The value E[R] is
estimated by averaging the recall-at-N  of 1000 ran- 
dom orderings of ∪H.
  Algorithm 1 gives the formulation of the Ada- 
Boost training algorithm that we use  to combine 
weak rankers. The algorithm  maintains  a weight 
vector w (summing to 1) which  contains a positive 
real number for each gold standard phrasal verb in 
the training  set X .  Initially, w is uniformly set to
1/|X |. At each iteration of the algorithm, w is mod-
ified to take higher values for recently misclassi-
fied examples. We repeatedly choose weak rankers
ht ∈ H (and corresponding real-valued coefficients
αt) that correctly rank examples with high w values.






  Lines 5–12 of Algorithm 1 calculate the weighted 
error values Eh  for every weak ranker set h ∈ H.
The error Eh will be 1 if h contains none of X and 0
if h contains all of X , as w always sums to 1. Line
13 picks the ranker ht ∈ H whose weighted error is
as far as possible from  the random  baseline error EB .
Line 14 calculates a coefficient αt for ht, which will 
be positive if Eht    < EB  and negative if Eht    > EB . 
Intuitively, αt encodes the importance of ht—it will 
be high if ht performs well, and low if it performs 
poorly. The Z in lines 17 and 19 is the normalizing 
constant ensuring the vector w sums to 1.
  After  termination of  Algorithm  1,  we  have 
weights α1, . . . , αT  and lists h1, . . . , hT . Define ft 
as the function  that generated the list ht (each ft will 
be some ϕL or µi). Now, we define a final combined 
function ϕ, taking  a phrase e and returning  a real 
number:
T
ϕ(e) = ) αtft(e).
t=1
We   standardize  the scores of  individual weak 
rankers to have mean 0 and variance 1, so that their 
scores are comparable.
  The final learned ranker outputs a real value, in- 
stead of the class labels frequently  found in Ada- 
Boost. This follows previous work using boosting 
for learning to rank (Freund et al., 2003; Xu and Li,
2007). Our algorithm differs from previous methods 
because we are seeking to optimize for Recall-at-N , 
rather than a ranking loss.

4   Experimental Evaluation

4.1   Training  and Test Set
In order to train and evaluate our system, we con- 
struct a  gold-standard   list of phrasal  verbs from 
the freely available English Wiktionary. We gather 
phrasal verbs from three sources within Wiktionary:

1. Entries labeled as English  phrasal  verbs4,

2. Entries labeled as English  idioms5, and

3. The derived terms6 of English verb entries.

  4 http://en.wiktionary.org/wiki/Category: 
English_phrasal_verbs
5 http://en.wiktionary.org/wiki/Category:
English_idioms
6 For  example,    see  http://en.wiktionary.org/
wiki/take#Derived_terms











Table 2:  Particles and prepositions allowed in phrasal 
verbs gathered from Wiktionary.


  Many of the idioms and derived  terms are not 
phrasal verbs (e.g. kick the bucket, make-or-break). 
We filter out any phrases not of the form V P +, with 
V a verb, and P + denoting one or more occurrences 
of particles and prepositions from the list in Table 2. 
We omit prepositions that do not productively form 
English  phrasal verbs, such as amid and as.  This 
process also omits some compounds that are some- 
times called phrasal verbs, such as light verb con- 
structions, e.g. have a go (Butt, 2003), and noncom- 
positional  verb-adverb collocations,  e.g. look for- 
ward.
  There  are a number  of extant phrasal verb cor- 
pora. For example, McCarthy et al. (2003) present 
graded human compositionality  judgments for 116 
phrasal verbs, and Baldwin (2008)  presents a large 
set of candidates produced by an automated system, 
with false positives manually  removed.  We use Wik- 
tionary instead, in an attempt to construct  a maxi- 
mally comprehensive  data set that is free from any 
possible biases introduced  by automatic extraction 
processes.

4.2   Filtering and Data Partition

The merged list of phrasal verbs extracted from Wik- 
tionary included some common  collocations  that 
have compositional  semantics (e.g. know about), as 
well as some  very rare constructions (e.g. cheese 
down). We removed these spurious results system- 
atically by filtering  out very frequent and very infre- 
quent entries. First, we calculated the log probability 
of each phrase, according to a language model built 
from a large monolingual  corpus of news documents 
and web documents,  smoothed with stupid back- 
off (Brants et al., 2007). We sorted all Wiktionary 
phrasal verbs according to this value. Then, we se- 
lected the contiguous 75% of the sorted phrases that 
minimize the variance of this statistic. This method




Recall-at-1220

Dev
Test
Frequent Candidates
17.0
19.3
WordNet 3.0 Frequent
41.6
43.7
WordNet 3.0 Filtered
49.4
48.8
Monolingual Only
30.1
30.2
Bilingual Only
47.1
43.9
Monolingual+Bilingual
50.8
47.9

Table 3:  Our boosted  ranker combining monolingual 
and bilingual features (bottom) compared to three base- 
lines (top) gives comparable performance to the human- 
curated upper bound.



removed  a few very frequent  phrases and a large 
number of rare phrases. The remaining  phrases were 
split randomly into a development  set of 694 items 
and a held-out  test set of 695 items.


4.3   Corpora

Our monolingual English corpus consists of news ar- 
ticles and documents collected from the web. Our 
parallel corpora from English to each  of 50 lan- 
guages  also consist of documents collected  from 
the web via distributed data mining of parallel doc- 
uments  based on the text content  of web pages 
(Uszkoreit et al., 2010).
  The parallel corpora were segmented into aligned 
sentence pairs and word-aligned using two iterations 
of IBM Model 1 (Brown et al., 1993) and two iter- 
ations of the HMM-based  alignment model (Vogel 
et al., 1996) with posterior symmetrization (Liang et 
al., 2006). This training recipe is common in large- 
scale machine translation systems.


4.4   Generating Candidates

To generate the set of candidate phrasal verbs con- 
sidered during evaluation, we exhaustively enumer- 
ated the Cartesian product of all verbs present in the
previously  described Wiktionary set (V), all parti-
cles in Table 2 (P) and a small  set of second parti-
cles T = {with, to, on, E}, with E the empty string.
The set of candidate phrasal verbs we consider dur- 
ing evaluation is the product V × P × T , which con-
tains 96,880 items.



4.5   Results

We optimize a ranker using the boosting algorithm 
described in section 3.3, using the features from Ta- 
ble 1, optimizing performance on the Wiktionary de- 
velopment set described in section 4.2. Monolingual 
and bilingual  statistics are calculated using the cor- 
pora described in section 4.3, with candidate phrasal 
verbs being drawn from the set described in section
4.4.
  We  evaluate our method of identifying phrasal 
verbs by computing recall-at-N . This statistic is the 
fraction of the Wiktionary test set that appears in the 
top N proposed phrasal verbs by the method, where 
N is an arbitrary  number of top-ranked candidates 
held constant when comparing different approaches 
(we use N = 1220). We do not compute precision, 
because the test set to which we compare is not an 
exhaustive list of phrasal verbs, due to the develop- 
ment/test split, frequency filtering, and omissions in 
the original lexical resource. Proposing  a phrasal 
verb not in the test set is not necessarily an error, but 
identifying many phrasal verbs from the test set is an 
indication of an effective method. Recall-at-N  is a 
natural way to evaluate a ranking  system where the 
gold-standard data is an incomplete,  unranked set.
  Table 3 compares our approach to three baselines 
using the Recall-at-1220 metric evaluated on both 
the development and test sets. As a lower bound, we 
evaluated the 1220 most frequent candidates in our 
Monolingual  corpus (Frequent Candidates).
  As a competitive  baseline, we evaluated the set of 
phrasal verbs in WordNet 3.0 (Fellbaum, 1998). We 
selected the most frequent 1220 out of 1781 verb- 
particle constructions in WordNet (WordNet 3.0 Fre- 
quent). A stronger baseline resulted from apply- 
ing the same filtering procedure to WordNet that 
we did to Wiktionary: sorting all verb-particle en- 
tries by their language model score and retaining the
1220 consecutive entries that minimized  language 
model variance (WordNet 3.0 Filtered).  WordNet 
is a human-curated resource, and yet its recall-at-N 
compared to our Wiktionary  test set is only 48.8%, 
indicating  substantial divergence between the two 
resources.   Such divergence  is typical: lexical re- 
sources often disagree about what multiword expres- 
sions to include (Lin, 1999).
The three final lines in Table 3 evaluate  our



50%


40%


30%


20%







Combined 
with 
AdaBoost
Individual 
Bilingual 
Statistics




10%




0%
0	5	10   15   20   25   30   35   40   45   50

Number of languages (k)


Figure 2: The solid line shows recall-at-1220 when com- 
bining the k best-performing bilingual statistics and three 
monolingual statistics. The dotted line shows the indi- 
vidual performance of the kth best-performing bilingual 
statistic, when applied in isolation to rank candidates.


boosted  ranker.  Automatically detecting  phrasal 
verbs using monolingual features alone strongly out- 
performed the frequency-based lower bound, but un- 
derperformed the WordNet baseline. Bilingual fea- 
tures, using features from 50 languages, proved sub- 
stantially more effective.  The combination of both 
types of features yielded the best performance, out- 
performing the human-curated WordNet baseline on 
the development set (on which our ranker was opti- 
mized) and approaching its performance on the held- 
out test set.

4.6   Feature Analysis

The solid line in Figure 2 shows the recall-at-1220 
for a boosted ranker using all monolingual statistics 
and k bilingual statistics, for increasing k.  Bilin- 
gual statistics are added according to their individual 
recall, from best-performing to worst. That is, the 
point at k = 0 uses only µ1, µ2, and µ3, the point at 
k = 1 adds the best individually-performing bilin- 
gual statistic  (Spanish)  as a weak  ranker,  the next 
point adds the second-best bilingual statistic (Ger- 
man), etc. Boosting maximizes performance on the 
development set, and evaluation is performed on the 
test set. We use T = 53 (equal to the total number 
of weak rankers).


Table 4: An ablation of monolingual statistics shows that 
they are useful in addition to the 50 bilingual statistics 
combined, and no single statistic provides maximal per- 
formance.


  The dotted line in Figure 2 shows that individual 
bilingual statistics have recall-at-1220 ranging from
34.4% to 5.0%. This difference reflects the differ- 
ent sizes of parallel corpora and usefulness of dif- 
ferent languages in identifying  English semantic id- 
iosyncrasy.  Combining  together the signal of mul- 
tiple languages is clearly beneficial,  and including 
many low-performing  languages still offers overall 
improvements.
  Table 4 shows the effect of adding different sub- 
sets of the monolingual  statistics to the set of all
50 bilingual statistics. Monolingual  statistics give 
a performance  improvement   of up to 5.5% recall 
on the test set, but the comparative behavior of the 
various combinations of the µi  is somewhat unpre- 
dictable when training on the development  set and 
evaluating on the test set. The pointwise mutual in- 
formation of a verb and its particles (µ2) appears to 
be the most useful feature.  In fact, the test set per- 
formance of using µ2 alone outperforms the combi- 
nation of all three. The best combination  even out- 
performs the WordNet 3.0 baseline on the test set, 
though optimizing on the development set would  not 
select this model.

4.7   Error Analysis
Table 5 shows the 100 highest ranked phrasal verb 
candidates by our system that do not appear in either 
the development or test sets.  Most of these candi- 
dates are in fact English phrasal verbs that happened 
to be missing from Wiktionary; some are present 
in Wiktionary  but were removed from the reference



pick up
pat on
tap into
fit for
charge with
suit against
catch up
burst into
muck up
haul up
give up
get off
get through
get up
get in
tack on
buzz about
do like
plump for
haul in
keep up with
strap on
catch up with
suck into
get round
chop off
slap on
pitch into
get into
inquire into
drop behind
get on
catch up on
pass on
cue from
carry around
get around
get over
shoot at
pick over
shoot by
shoot in
make up to
get past
cast down
set up with
rule off
hand round
piss on
hit by
break down
move for
lead off
pluck off
flip through
edge over
strike off
plug into
keep up
go past
set off
pull round
see about
stay on
put up
sidle up to
buzz around
take off
set up
slap in
head towards
shoot past
inquire for
tuck up
lie with
well before
go on with
reel from
drive along
snap off
barge into
whip on
put down
instance through
bar from
cut down on
let in
tune in to
move off
suit in
lean against
well beyond
get down to
go across
sail into
lie over
hit with
chow down on
look after
catch at


Table 5: The highest ranked phrasal verb candidates from our full system that do not appear in either Wiktionary set. 
Candidates are presented in decreasing rank; “pat on” is the second highest ranked candidate.




sets during filtering, and the remainder  are in fact 
not phrasal verbs (true precision errors).
  These errors fall  largely into two categories. 
Some candidates are compositional,  but contain pol- 
ysemous verbs, such as hit by, drive along, and head 
towards.  In these cases, prepositions disambiguate 
the verb, which naturally affects translation distri- 
butions.  Other candidates are not phrasal verbs, but 
instead phrases that tend to have a different  syntac- 
tic role, such  as suit against, instance through,  fit 
for, and lie over (conjugated  as lay over). A care- 
ful treatment of part-of-speech tags when computing 
corpus statistics might address this issue.

5   Related Work

The idea of using word-aligned  parallel corpora 
to identify idiomatic expressions   has  been pur- 
sued  in a  number  of different ways.   Melamed 
(1997)  tests candidate MWEs by collapsing them 
into single tokens, training a new translation model 
with these tokens,  and using the performance of 
the new model to judge candidates’ noncomposi- 
tionality.  Villada Moiro´ n and Tiedemann (2006) 
use word-aligned  parallel corpora to identify Dutch 
MWEs, testing the assumption that the distributions 
of alignments of MWEs will generally have higher 
entropies than those of fully  compositional com- 
pounds. Caseli et al. (2010) generate candidate mul-


tiword expressions by picking out sufficiently com- 
mon phrases that align to single target-side tokens. 
Tsvetkov and Wintner (2012) generate candidate 
MWEs by finding one-to-one alignments in paral- 
lel corpora which are not in a bilingual dictionary, 
and ranking  them based on monolingual statistics. 
The system of Salehi and Cook (2013) is perhaps 
the closest to the current work, judging noncompo- 
sitionality  using string edit distance between a can- 
didate phrase’s automatic  translation  and its com- 
ponents’ individual translations. Unlike the current 
work, their method does not use distributions  over 
translations or combine individual bilingual values 
with boosting; however, they find, as we do, that in- 
corporating  many languages is beneficial to MWE 
identification.
  A large body of work  has investigated  the identifi- 
cation of noncompositional compounds from mono- 
lingual sources (Lin, 1999; Schone and Jurafsky,
2001; Fazly and Stevenson,  2006; McCarthy et 
al., 2003; Baldwin et al., 2003; Villavicencio,
2003). Many of these monolingual  statistics could 
be viewed  as weak rankers and fruitfully incorpo- 
rated into our framework.
  There has also been a substantial amount of work 
addressing the problem of differentiating  between 
literal and idiomatic instances of phrases in con- 
text (Katz and Giesbrecht, 2006; Li et al., 2010;


Sporleder and Li, 2009; Birke  and Sarkar,  2006; 
Diab and Bhutada, 2009). We do not attempt this 
task; however,  techniques for token identification 
could be used to improve type identification (Bald- 
win, 2005).

6   Conclusion

We have presented the polyglot ranking  approach 
to phrasal verb identification, using parallel corpora 
from many languages to identify phrasal verbs. We 
proposed an evaluation metric that acknowledges the 
inherent incompleteness of reference  sets, but dis- 
tinguishes among competing systems in a manner 
aligned to the goals of the task. We developed  a 
recall-oriented learning method that integrates mul- 
tiple weak ranking signals, and demonstrated exper- 
imentally that combining statistical evidence from a 
large number of bilingual corpora,  as well as from 
monolingual  corpora, produces the most effective 
system overall.  We look forward to generalizing 
our approach to other types of noncompositional 
phrases.

Acknowledgments

Special  thanks to Ivan Sag, who argued  for the 
importance of handling multi-word expressions in 
natural language processing applications,  and who 
taught the authors about natural language syntax 
once upon a time. We would also like to thank the 
anonymous reviewers for their helpful suggestions.


References

Otavio Acosta, Aline Villavicencio, and Viviane Moreira.
2011. Identification  and treatment of multiword ex- 
pressions applied to information retrieval. In Proceed- 
ings of the ACL Workshop on Multiword  Expressions.
Timothy Baldwin and Aline Villavicencio.  2002. Ex- 
tracting the unextractable: A  case  study on verb- 
particles. In Proceedings of the Sixth Conference on 
Natural Language Learning.
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and 
Dominic Widdows.  2003.  An empirical model of 
multiword expression decomposability.    In Proceed- 
ings of the ACL Workshop on Multiword  Expressions.
Timothy Baldwin.  2005.  Deep lexical acquisition of 
verb-particle constructions. Computer Speech & Lan- 
guage, Special Issue on Multiword Expressions.


Timothy Baldwin. 2008. A resource for evaluating the 
deep lexical acquisition of english verb-particle con- 
structions. In Proceedings of the LREC Workshop To- 
wards a Shared Task for Multiword Expressions.
Colin Bannard, Timothy Baldwin,  and Alex Lascarides.
2003. A statistical approach to the semantics of verb- 
particles. In Proceedings of the ACL Workshop on 
Multiword Expressions.
Julia Birke and Anoop Sarkar. 2006. A clustering ap- 
proach for the nearly unsupervised recognition of non- 
literal language. In Proceedings of European Chapter 
of the Association for Computational Linguistics.
Thorsten Brants, Ashok C. Popat,  Peng Xu, Franz  J.
Och, and Jeffrey Dean. 2007. Large language mod- 
els in machine translation. In Proceedings of the Joint 
Conference  on Empirical Methods in Natural Lan- 
guage Processing  and Computational Natural Lan- 
guage Learning.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della 
Pietra, and Robert L. Mercer. 1993. The mathematics 
of statistical machine translation:  Parameter estima- 
tion. Computational Linguistics.
Miriam Butt. 2003. The light verb jungle. In Proceed- 
ings of the Workshop on Multi-Verb  Constructions. 
Helena de Medeiros Caseli, Carlos Ramisch, Maria das
Grac¸as Volpe Nunes, and Aline Villavicencio. 2010.
Alignment-based extraction of multiword expressions.
Language Resources and Evaluation.
Kenneth Ward Church and Patrick Hanks. 1990. Word 
association norms, mutual information,  and lexicogra- 
phy. Computational Linguistics, 16(1).
Kenneth Church. 2011. How many multiword expres- 
sions do people know?  In Proceedings of the ACL 
Workshop on Multiword  Expressions.
Mona T. Diab and Pravin Bhutada. 2009. Verb noun 
construction MWE token supervised classification.  In 
Proceedings of the ACL Workshop on Multiword Ex- 
pressions.
Robert Dixon.  1982. The grammar of english phrasal 
verbs. Australian Journal of Linguistics.
Afsaneh Fazly and Suzanne Stevenson. 2006.  Automat- 
ically constructing  a lexicon  of verb phrase idiomatic 
combinations. In Proceedings of the European Chap- 
ter of the Association for Computational Linguistics.
Christiane Fellbaum. 1998.  WordNet: An Electronic
Lexical Database. The MIT Press.
Mark Finlayson  and Nidhi Kulkarni.  2011. Detecting 
multiword expressions improves  word sense disam- 
biguation. In Proceedings of the ACL Workshop on 
Multiword Expressions.
Yoav Freund and Robert E. Schapire. 1995. A decision- 
theoretic generalization of on-line learning and an ap- 
plication to boosting. In Proceedings of the Confer- 
ence on Computational  Learning Theory.


Yoav Freund, Raj Iyer, Robert E Schapire, and Yoram 
Singer.  2003.  An efficient boosting algorithm for 
combining preferences.  The Journal of Machine 
Learning Research.
Ray Jackendoff. 1993. The Architecture of the Language
Faculty. MIT Press.
Graham Katz and Eugenie Giesbrecht. 2006.  Auto- 
matic identification of non-compositional multi-word 
expressions using latent semantic analysis. In Pro- 
ceedings of the ACL Workshop on Multiword Expres- 
sions.
Philipp Koehn, Franz Josef  Och, and Daniel Marcu.
2003. Statistical phrase-based translation.  In Proceed- 
ings of the North American Chapter of the Association 
for Computational Linguistics.
Linlin Li, Benjamin Roth, and Caroline Sporleder. 2010.
Topic models for  word sense disambiguation   and 
token-based idiom detection. In Proceedings of the 
Association for Computational Linguistics.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align- 
ment by agreement. In Proceedings  of the North 
American Chapter of the Association for Computa- 
tional Linguistics.
Dekang Lin.  1999. Automatic identification of non- 
compositional phrases. In Proceedings of the Asso- 
ciation for Computational Linguistics.
Diana McCarthy, Bill  Keller, and John Carroll.  2003.
Detecting a continuum  of compositionality in phrasal 
verbs. In Proceedings of the ACL Workshop on Multi- 
word Expressions.
I. Dan Melamed. 1997. Automatic discovery of non- 
compositional  compounds in parallel data.  In Pro- 
ceedings of the Conference on Empirical Methods in 
Natural Language Processing.
Santanu Pal, Sudip Kumar  Naskar, Pavel Pecina, Sivaji 
Bandyopadhyay,  and Andy Way.  2010.  Handling 
named entities and compound  verbs in phrase-based 
statistical machine translation.  In Proceedings of the 
COLING 2010 Workshop on Multiword  Expressions.
Zhixiang Ren, Yajuan Lu, Jie Cao, Qun Liu, and Yun 
Huang. 2009. Improving  statistical machine transla- 
tion using domain bilingual multiword expressions. In 
Proceedings of the ACL Workshop on Multiword Ex- 
pressions.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann A.
Copestake, and Dan Flickinger. 2002. Multiword ex- 
pressions: A pain in the neck for NLP. In Proceedings 
of the CICLING Conference on Intelligent Text Pro- 
cessing and Computational  Linguistics.
Bahar Salehi and Paul Cook. 2013. Predicting the com- 
positionality of multiword expressions using transla- 
tions in multiple languages.  In Second Joint Confer- 
ence on Lexical and Computational  Semantics.


Patrick  Schone and Daniel Jurafsky.     2001.     Is 
knowledge-free induction of multiword unit dictionary 
headwords   a solved problem?    In Proceedings of 
the Conference on Empirical  Methods in Natural Lan- 
guage Processing.
Caroline Sporleder and Linlin Li.  2009. Unsupervised 
recognition of literal and non-literal  use of idiomatic 
expressions. In Proceedings of the European Chapter 
of the Association for Computational Linguistics.
Yulia Tsvetkov and Shuly Wintner.  2012.  Extraction 
of multi-word expressions from small parallel corpora. 
In Natural Language Engineering.
Jakob Uszkoreit,  Jay Ponte, Ashok Popat, and Moshe Du- 
biner. 2010. Large scale parallel document mining for 
machine translation. In Proceedings of the Conference 
on Computational Linguistics.
Sriram Venkatapathy and Aravind K Joshi. 2006. Us- 
ing information about multi-word expressions for the 
word-alignment  task.   In Proceedings  of the ACL 
Workshop on Multiword  Expressions.
Begon˜ a  Villada Moiro´ n and Jo¨ rg Tiedemann.	2006.
Identifying idiomatic expressions  using automatic 
word-alignment.  In Proceedings of the EACL Work- 
shop on Multiword Expressions in a Multilingual Con- 
text.
Aline Villavicencio.   2003. Verb-particle constructions 
and lexical resources. In Proceedings of the ACL 
workshop on Multiword  expressions.
Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996. HMM-based word alignment in statistical trans- 
lation. In Proceedings of the Conference on Computa- 
tional linguistics.
Jun Xu and Hang Li.  2007. AdaRank: a boosting  al- 
gorithm for information retrieval. In Proceedings of 
the SIGIR Conference on Research and Development 
in Information Retrieval.
Ying Xu, Randy Goebel, Christoph  Ringlstetter,  and 
Grzegorz Kondrak. 2010. Application of the tightness 
continuum  measure to chinese information  retrieval. 
In Proceedings of the COLING Workshop on Multi- 
word Expressions.


