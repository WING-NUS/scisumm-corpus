Citance Number: 1 | Reference Article:  W95-0104.txt | Citing Article:  A00-2019.txt | Citation Marker Offset:  ['23'] | Citation Marker:  1995 | Citation Offset:  ['23'] | Citation Text:  <S sid ="23" ssid = "23">Golding (1995) showed how methods used for WSD (decision lists and Bayesian classifiers) could be adapted to detect errors resulting from common spelling confusions among sets such as there, their, and they&apos;re.</S> | Reference Offset:  ['32','25'] | Reference Text:  <S sid ="32" ssid = "4">\Ve treat context-sensitive spelling correction as a task of word disambiguation.</S><S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  ['Aim_Citation','Method_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 2 | Reference Article:  W95-0104.txt | Citing Article:  A97-1025.txt | Citation Marker Offset:  ['29'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['29'] | Citation Text:  <S sid ="29" ssid = "7">A number of feature-based methods have been tried, including Bayesian classifiers (Gale, Church, and Yarowsky, 1992; Golding, 1995), decision lists (Yarowsky, 1994), and knowledge-based approaches (McRoy, 1992).</S> |  Reference Offset:  ['25'] | Reference Text:  <S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 3 | Reference Article:  W95-0104.txt | Citing Article:  A97-1025.txt | Citation Marker Offset:  ['125'] | Citation Marker:  1995 | Citation Offset:  ['125'] | Citation Text:  <S sid ="125" ssid = "1">The results described in this section are based on the 18 confusion sets selected by Golding (1995; 1996).</S> | Reference Offset:  ['63'] | Reference Text:  <S sid ="63" ssid = "12">Table 1 shows the performance of the baseline method for 18 confusion sets.</S> | Discourse Facet:  Results_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 4 | Reference Article:  W95-0104.txt | Citing Article:  C04-1131.txt | Citation Marker Offset:  ['46'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['46'] | Citation Text:  <S sid ="46" ssid = "34">We have also selected a decision list classifier (DL) which is similar to the classifier used by (Yarowsky, 1994) for words having two senses, and extended for more senses by (Golding, 1995).</S> | Reference Offset:  ['17','25'] | Reference Text:  <S sid ="17" ssid = "17">This paper takes Yarowsky&apos;s method as a starting point, and hypothesizes that further improvements can be obtained by taking into account not only the single strongest piece of evidence, but all the available evidence.</S><S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  ['Hypothesis_Citation','Method_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 5 | Reference Article:  W95-0104.txt | Citing Article:  D07-1012.txt | Citation Marker Offset:  ['71'] | Citation Marker:  1995 | Citation Offset:  ['71'] | Citation Text:  <S sid ="71" ssid = "36">Golding (1995) builds a classifier based on a rich set of context features.</S> | Reference Offset:  ['18','24'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S><S sid ="24" ssid = "24">\Ve then apply each of the two component methods mentioned aboveÂ­ context words and collocations.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 6 | Reference Article:  W95-0104.txt | Citing Article:  D11-1119.txt | Citation Marker Offset:  ['40'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['40'] | Citation Text:  <S sid ="40" ssid = "11">A variety of machine-learning methods have been proposed in spelling correction and preposition and article error correction fields, such as Bayesian classifiers (Golding, 1995; Golding and Roth, 1996), Winnow-based learning (Golding and Roth, 1999), decision lists (Golding, 1995)</S> | Reference Offset:  ['25'] | Reference Text:  <S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 7 | Reference Article:  W95-0104.txt | Citing Article:  E06-1030.txt | Citation Marker Offset:  ['164'] | Citation Marker:  1995 | Citation Offset:  ['164'] | Citation Text:  <S sid ="164" ssid = "24">The memory-based learner was tested using the 18 confusion word sets from Golding (1995) on the WSJ section of the Penn Treebank and the Brown Corpus.</S> | Reference Offset:  ['58','59','63'] | Reference Text: <S sid ="58" ssid = "7">The performance figures given below are based on training each method on the 1-million-word Brown corpus [Kucera.</S><S sid ="59" ssid = "8">and Francis, 1967] and testing it on a 3/4-million-word corpus of Wall Street Journal text [Marcus et al., 1993].</S><S sid ="63" ssid = "12">Table 1 shows the performance of the baseline method for 18 confusion sets.</S> | Discourse Facet:  Results_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 8 | Reference Article:  W95-0104.txt | Citing Article:  E99-1024.txt | Citation Marker Offset:  ['34'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['33','34'] | Citation Text:  <S sid ="33" ssid = "33">Take the case of context-sensitive spelling error detection 3, which is equivalent to the homophone problem.</S><S sid ="34" ssid = "34">For that problem, some statistical methods have been applied and succeeded(Golding, 1995; GoldÂ­ ing and Schabes, 1996).</S> | Reference Offset:  ['18','19'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S><S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S> | Discourse Facet:  ['Method_Citation','Aim_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 9 | Reference Article:  W95-0104.txt | Citing Article:  H01-1052.txt | Citation Marker Offset:  ['20'] | Citation Marker:  3 | Citation Offset:  ['20','21','22'] | Citation Text:  <S sid ="20" ssid = "3">The more recent set of techniques includes multiplicative weight-update algorithms [4], latent semantic analysis [7], transformation-based learning [8], differential grammars [10], decision lists [12], and a variety of Bayesian classifiers [2,3,5].</S><S sid ="21" ssid = "4">In all of these papers, the problem is formulated as follows: Given a specific confusion set (e.g. {to, two, too}), all occurrences of confusion set members in the test set are replaced by some marker.</S><S sid ="22" ssid = "5">Then everywhere the system sees this marker, it must decide which member of the confusion set to choose.</S> | Reference Offset:  ['18','33','34','35'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S><S sid ="33" ssid = "5">The ambiguity among words is modelled by confusion sets.</S><S sid ="34" ssid = "6">A confusion set C = { w 1, ...,wn} means that each word Wi in the set is ambiguous with each other word in the set.</S><S sid ="35" ssid = "7">Thus if C = {deserÂ·t, desserÂ·t}, then when the spelling-correction program sees an occurrence of either desert or dessert in the target document, it takes it to be ambiguous between desert and dessert, and tries to infer from the context which of the two it should be.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 10 | Reference Article:  W95-0104.txt | Citing Article:  J98-1006.txt | Citation Marker Offset:  ['108'] | Citation Marker:  1995 | Citation Offset:  ['108','109'] | Citation Text:  <S sid ="108" ssid = "80">For each si, the probability is computed with Bayes&apos; rule: As Golding (1995) points out, the term p(c_kf ..</S><S sid ="109" ssid = "81">.,Ck I si) is difficult to estimate because of the sparse data problem, but if we assume, as is often done, that the occurrence of each cue is independent of the others, then</S> | Reference Offset:  ['85','86','87','88'] | Reference Text:  <S sid ="85" ssid = "34">The probability for each Wi is calculated using Bayes&apos; rule: As it stands, the likelihood term, p( c_k.</S><S sid ="86" ssid = "35">, c_ 1, c1, ...</S><S sid ="87" ssid = "36">, cklwi), is difficult to estimate from training data - we would have to count situations in which the entire context was previously observed around word Wi, which raises a. severe sparse-data problem.</S><S sid ="88" ssid = "37">Instead, therefore, we assume that the presence of one word in the context is independent of the presence of any other word.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 11 | Reference Article:  W95-0104.txt | Citing Article:  N03-2035.txt | Citation Marker Offset:  ['23'] | Citation Marker:  3 | Citation Offset:  ['23','24'] | Citation Text:  <S sid ="23" ssid = "23">Golding [3] proposed a Bayesian hybrid method to take into account all available evidence, instead of only the strongest one.</S><S sid ="24" ssid = "24">The method was applied to the task of context-sentitive spelling correction and was reported to be superior to decision lists.</S> | Reference Offset:  ['17','19','333','334'] | Reference Text:  <S sid ="17" ssid = "17">This paper takes Yarowsky&apos;s method as a starting point, and hypothesizes that further improvements can be obtained by taking into account not only the single strongest piece of evidence, but all the available evidence.</S><S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S><S sid ="333" ssid = "4">A method for doing this, based on Bayesian classifiers, was presented.</S><S sid ="334" ssid = "5">It was applied to the task of context-sensitive spelling correction, and was found to outperform the component methods as well as decision lists.</S> | Discourse Facet:  ['Method_Citation','Results_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 12 | Reference Article:  W95-0104.txt | Citing Article:  N03-2035.txt | Citation Marker Offset:  ['56'] | Citation Marker:  3 | Citation Offset:  ['56'] | Citation Text:  <S sid ="56" ssid = "23">Hybrid approach [3, 12] combines the strengths of other techniques such as Bayesian classifier, n-gram, and decision list.</S> | Reference Offset:  ['25'] | Reference Text:  <S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 13 | Reference Article:  W95-0104.txt | Citing Article:  N03-2035.txt | Citation Marker Offset:  ['89'] | Citation Marker:  3 | Citation Offset:  ['89'] | Citation Text:  <S sid ="89" ssid = "56">In the experiment, we classify the data into three group depending on types of text ambiguity according to section 2: CDSA, CISA and Homograph, and compare the results from different approaches; Winnow, Bayseian hybrid [3] and POS trigram.</S> | Reference Offset:  ['18'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 14 | Reference Article:  W95-0104.txt | Citing Article:  N04-1016.txt | Citation Marker Offset:  ['98'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['98','99'] | Citation Text:  <S sid ="98" ssid = "8">These include a variety of Bayesian classifi ers (Golding, 1995; Golding and Schabes, 1996), decision lists (Golding, 1995) transformation-based learning (Mangu and Brill, 1997), Latent Semantic Analysis (LSA) (Jones and Martin, 1997), multiplicative weight update algorithms (Golding and Roth, 1999), and augmented mixture models (Cucerzan and Yarowsky, 2002).</S><S sid ="99" ssid = "9">Despite their differences, most approaches use two types of features: context words and collocations.</S> | Reference Offset:  ['18', '24'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S><S sid ="24" ssid = "24">\Ve then apply each of the two component methods mentioned aboveÂ­ context words and collocations.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 15 | Reference Article:  W95-0104.txt | Citing Article:  N04-1016.txt | Citation Marker Offset:  ['102'] | Citation Marker:  1995 | Citation Offset:  ['102'] | Citation Text:  <S sid ="102" ssid = "12">All methods use either the full set or a subset of 18 confusion sets originally gathered by Golding (1995).</S> | Reference Offset:  ['63'] | Reference Text:  <S sid ="63" ssid = "12">Table 1 shows the performance of the baseline method for 18 confusion sets.</S> | Discourse Facet:  Results_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 16 | Reference Article:  W95-0104.txt | Citing Article:  N04-1016.txt | Citation Marker Offset:  ['103'] | Citation Marker:  1995 | Citation Offset:  ['103'] | Citation Text:  <S sid ="103" ssid = "13">Most methods are trained and tested on Model Alta BNC Model Alta BNC f (t ) 72.98 70.00 f (w1 , t , w2 )/ f (t ) 87.77 76.33 f (w1 , t ) 84.40 83.02 f (w1 , w2 , t )/ f (t ) 86.27 74.47 f (t , w1 ) 84.89 82.74 f (t , w2 , w2 )/ f (t ) 84.94 74.23 f (w1 , t , w2 ) 89.24#*77.13 f (w1 , t , w2 )/ f (w1 , t ) 80.70 73.69 f (t , w1 , w2 ) 84.68 75.08 f (w1 , w2 , t )/ f (w2 , t ) 72.11 69.28 f (w1 , t )/ f (t ) 82.81 77.84 f (t , w1 , w2 )/ f (t , w1 ) 75.65 72.57 f (t , w1 )/ f (t ) 77.49 80.71# Table 5: Performance of Altavista counts and BNC counts for context sensitive spelling correction (data from Cucerzan and Yarowsky 2002) Model Accuracy Baseline BNC 70.00 Baseline Altavista 72.98 Best BNC 80.71â€ â€¡ Golding (1995) 81.40 Jones and Martin (1997) 84.26 Best Altavista 89.24â€ â€¡ Golding and Schabes (1996) 89.82 Mangu and Brill (1997) 92.79 Cucerzan and Yarowsky (2002) 92.20 Golding and Roth (1999) 94.23 Table 6: Performance comparison with the literature for context sensitive spelling correction the Brown corpus, using 80% for training and 20% for testing.3 We devised a simple, unsupervised method for performing spelling correction using web counts.</S> | Reference Offset:  ['19','58'] | Reference Text: <S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S><S sid ="58" ssid = "7">The performance figures given below are based on training each method on the 1-million-word Brown corpus [Kucera.</S> | Discourse Facet:  ['Aim_Citation','Results_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 17 | Reference Article:  W95-0104.txt | Citing Article:  N04-1016.txt | Citation Marker Offset:  ['114'] | Citation Marker:  1995 | Citation Offset:  ['114'] | Citation Text:  <S sid ="114" ssid = "24">Table 6 shows 3 An exception is Golding (1995), who uses the entire Brown corpus for training (1M words) and 3/4 of the Wall Street Journal corpus (Marcus et al., 1993) for testing.</S> | Reference Offset:  ['58','59'] | Reference Text:  <S sid ="58" ssid = "7">The performance figures given below are based on training each method on the 1-million-word Brown corpus [Kucera.</S><S sid ="59" ssid = "8">and Francis, 1967] and testing it on a 3/4-million-word corpus of Wall Street Journal text [Marcus et al., 1993].</S> | Discourse Facet:  Results_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 18 | Reference Article:  W95-0104.txt | Citing Article:  N04-1016.txt | Citation Marker Offset:  ['116'] | Citation Marker:  1995 | Citation Offset:  ['116'] | Citation Text:  <S sid ="116" ssid = "26">A comparison with the literature shows that the best Altavista model outperforms Golding (1995), Jones and Martin (1997) highest accuracy on the task is achieved by the class of multiplicative weight-update algorithms such as Winnow (Golding and Roth, 1999).</S> |  Reference Offset:  ['18'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 19 | Reference Article:  W95-0104.txt | Citing Article:  N10-1019.txt | Citation Marker Offset:  ['11'] | Citation Marker:  1995 | Citation Offset:  ['11'] | Citation Text:  <S sid ="11" ssid = "11">The majority of the data-driven methods use a classification technique to determine whether a word is used appropriately in its context, continuing the tradition established for contextual spelling correction by Golding (1995) and Golding and Roth (1996).</S> | Reference Offset:  ['35'] | Reference Text:  <S sid ="35" ssid = "7">Thus if C = {deserÂ·t, desserÂ·t}, then when the spelling-correction program sees an occurrence of either desert or dessert in the target document, it takes it to be ambiguous between desert and dessert, and tries to infer from the context which of the two it should be.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 20 | Reference Article:  W95-0104.txt | Citing Article:  P01-1005.txt | Citation Marker Offset:  ['19'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['19','20'] | Citation Text:  <S sid ="19" ssid = "4">The more recent set of techniques includes mult iplicative weight- update algorithms (Golding and Roth, 1998), latent semantic analysis (Jones and Martin, 1997), transformation- based learning (Mangu and Brill, 1997), differential grammars (Powers, 1997), decision lists (Yarowsky, 1994), and a variety of Bayesian classifiers (Gale et al., 1993, Golding, 1995, Golding and Schabes, 1996).</S><S sid ="20" ssid = "5">In all of these approaches, the problem is formulated as follows: Given a specific confusion set (e.g. {to,two,too}), all occurrences of confusion set members in the test set are replaced by a marker; everywhere the system sees this marker, it must decide which member of the confusion set to choose.</S> | Reference Offset:  ['18','162','163'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S><S sid ="162" ssid = "111">The idea is to discriminate among the words Wi in the confusion set by identifying the collocations that tend to occur around each w;.</S><S sid ="163" ssid = "112">An ambiguous target word is then classified by finding all collocations that match its context.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 21 | Reference Article:  W95-0104.txt | Citing Article:  P96-1010.txt | Citation Marker Offset:  ['25'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['25'] | Citation Text:  <S sid ="25" ssid = "25">Feature-based approaches, such as Bayesian clasÂ­ sifiers (Gale, Church, and Yarowsky, 1993), deciÂ­ sion lists (Yarowsky, 1994), and Bayesian hybrids (Golding, 1995), have had varying degrees of sucÂ­ cess for the problem of context-sensitive spelling correction.</S> | Reference Offset:  ['333','334'] | Reference Text:  <S sid ="333" ssid = "4">A method for doing this, based on Bayesian classifiers, was presented.</S><S sid ="334" ssid = "5">It was applied to the task of context-sensitive spelling correction, and was found to outperform the component methods as well as decision lists.</S> | Discourse Facet:  ['Method_Citation','Results_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 22 | Reference Article:  W95-0104.txt | Citing Article:  P96-1010.txt | Citation Marker Offset:  ['38'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['38'] | Citation Text:  <S sid ="38" ssid = "38">We consider an alternative method, Bayes, a Bayesian hybrid method (Golding, 1995), for the case where the words have the same part of speech.</S> | Reference Offset:  ['322', '325'] | Reference Text:  <S sid ="322" ssid = "38">Trigrams are at their worst when the words in the confusion set have the same part of speech.</S><S sid ="325" ssid = "41">In such cases, the Bayesian hybrid method is clearly better.</S> | Discourse Facet:  Results_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 23 | Reference Article:  W95-0104.txt | Citing Article:  P96-1010.txt | Citation Marker Offset:  ['78'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['78'] | Citation Text:  <S sid ="78" ssid = "3">A number of feature-based methods have been proposed, including Bayesian classifiers (Gale, Church, and Yarowsky, 1993), decision lists (Yarowsky, 1994), Bayesian hybrids (Golding, 1995), and, more recently, a method based on the Winnow multiplicative weight-updating algorithm (Golding and Roth, 1996).</S> | Reference Offset:  ['25'] | Reference Text:  <S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 24 | Reference Article:  W95-0104.txt | Citing Article:  P96-1010.txt | Citation Marker Offset:  ['80'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['79','80'] | Citation Text:  <S sid ="79" ssid = "4">We adopt the Bayesian hybrid method</S><S sid ="80" ssid = "5">This method has been described elsewhere (Golding, 1995)</S> | Reference Offset:  ['18'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 25 | Reference Article:  W95-0104.txt | Citing Article:  P98-2138.txt | Citation Marker Offset:  ['95'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['95'] | Citation Text:  <S sid ="95" ssid = "13">For English, a number of methods have been proposed to cope with real-word errors in spelling correction (Golding, 1995; Golding and Roth, 1996; Golding and Schabes, 1993; Tong and Evans, 1996).</S> | Reference Offset:  ['19'] | Reference Text: <S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S> | Discourse Facet:  Aim_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 26 | Reference Article:  W95-0104.txt | Citing Article:  P98-2138.txt | Citation Marker Offset: ['143'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['143'] | Citation Text:  <S sid ="143" ssid = "61">Following previous works (Golding, 1995; Meknavin et al., 1997), we have tried two types of features: context words and collocations.</S> | Reference Offset:  ['24'] | Reference Text:  <S sid ="24" ssid = "24">\Ve then apply each of the two component methods mentioned aboveÂ­ context words and collocations.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 27 | Reference Article:  W95-0104.txt | Citing Article:  W00-0701.txt | Citation Marker Offset:  ['23'] | Citation Marker:  Gol95 | Citation Offset:  ['23'] | Citation Text:  <S sid ="23" ssid = "6">This general scheme has been used to deÂ­ rive classifiers for a variety of natural lanÂ­ guage applications including speech applicaÂ­ tions (Rab89), pos tagging (Kup92; Sch95), word-sense ambiguation (GCY93) and contextÂ­ sensitive spelling correction (Gol95).</S> | Reference Offset:  ['18','19'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S><S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S> | Discourse Facet:  ['Method_Citation','Aim_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 28 | Reference Article:  W95-0104.txt | Citing Article:  W00-0701.txt | Citation Marker Offset:  ['113'] | Citation Marker:  Gol95 | Citation Offset:  ['113'] | Citation Text:  <S sid ="113" ssid = "18">MBL, by using long and very specialized conjunctions (DBZ99) and decision lists, due to their functional form - a linear function with exponentially decreasing weights - at the cost of predicting with a single feature, rather than a combination (Gol95).</S> | Reference Offset:  ['17'] | Reference Text:  <S sid ="17" ssid = "17">This paper takes Yarowsky&apos;s method as a starting point, and hypothesizes that further improvements can be obtained by taking into account not only the single strongest piece of evidence, but all the available evidence.</S> | Discourse Facet:  Hypothesis_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 29 | Reference Article:  W95-0104.txt | Citing Article:  W01-0502.txt | Citation Marker Offset:  ['10'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">A partial list consists of Bayesian classifiers (Gale et al., 1993), decision lists (Yarowsky, 1994), Bayesian hybrids (Golding, 1995)</S> | Reference Offset:  ['18'] | Reference Text:  <S sid ="18" ssid = "18">A method is presented for doing this, based on Bayesian classifiers.</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 30 | Reference Article:  W95-0104.txt | Citing Article:  W02-1005.txt | Citation Marker Offset:  ['9'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">Previous work has addressed the problem of CSSC from a machine learning perspective, including Bayesian and Decision List models (Golding, 1995)</S> | Reference Offset:  ['19','25'] | Reference Text:  <S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S><S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  ['Aim_Citation','Method_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 32 | Reference Article:  W95-0104.txt | Citing Article:  W02-1005.txt | Citation Marker Offset:  ['180'] | Citation Marker:  1995 | Citation Offset:  ['180'] | Citation Text:  <S sid ="180" ssid = "30">For CSSC, we tested our system on the identical data from the Brown corpus used by Golding (1995)</S> | Reference Offset:  ['19', '58'] | Reference Text:  <S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S><S sid ="58" ssid = "7">The performance figures given below are based on training each method on the 1-million-word Brown corpus [Kucera.</S> | Discourse Facet:  ['Aim_Citation','Results_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 33 | Reference Article:  W95-0104.txt | Citing Article:  W04-3238.txt | Citation Marker Offset:  ['13'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['13'] | Citation Text:  <S sid ="13" ssid = "13">A different body of work (e.g. Golding, 1995; Golding and Roth, 1996; Mangu and Brill, 1997) focused on resolving a limited number of cognitive substitution errors, in the framework of context sensitive spelling correction (CSSC).</S> | Reference Offset:  ['19'] | Reference Text:  <S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S> | Discourse Facet:  Aim_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 34 | Reference Article:  W95-0104.txt | Citing Article:  W06-1624.txt | Citation Marker Offset:  ['84'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['84'] | Citation Text:  <S sid ="84" ssid = "60">We use the metric described in (Yarowsky, 1994; Golding, 1995).</S> | Reference Offset:  ['216'] | Reference Text:  <S sid ="216" ssid = "165">Yarowsky [1994] used the following metric to calculate the strength of a feature f: reliability(!)</S> | Discourse Facet:  Method_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 35 | Reference Article:  W95-0104.txt | Citing Article:  W06-3604.txt | Citation Marker Offset:  ['146'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['146'] | Citation Text:  <S sid ="146" ssid = "9">More generally, as a precursor to the above- mentioned work, confusable disambiguation has been investigated in a string of papers discussing the application of various machine learning algorithms to the task (Yarowsky, 1994; Golding, 1995;</S> | Reference Offset:  ['32'] | Reference Text:  <S sid ="32" ssid = "4">\Ve treat context-sensitive spelling correction as a task of word disambiguation.</S> | Discourse Facet:  Aim_Citation | Annotator:  Aakansha Gehlot |


Citance Number: 37 | Reference Article:  W95-0104.txt | Citing Article:  W12-0304.txt | Citation Marker Offset:  ['33'] | Citation Marker:  Golding, 1995 | Citation Offset:  ['33'] | Citation Text:  <S sid ="33" ssid = "7">There are also other studies (Yarowsky, 1994; Golding, 1995 or Golding and Roth, 1996) that report the application of decision lists and Bayesian classifiers for spell checking; however, these models cannot be applied to grammar error detection.</S> | Reference Offset:  ['19','25'] | Reference Text:  <S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S><S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  ['Aim_Citation','Method_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 38 | Reference Article:  W95-0104.txt | Citing Article:  W96-0108.txt | Citation Marker Offset:  ['28'] | Citation Marker:  1995 | Citation Offset:  ['28'] | Citation Text:  <S sid ="28" ssid = "28">Golding [1995] has applied a hybrid Bayesian method for real-word error correction and Golding and Schabes [1996] have combined a POS trigram and Bayesian methods for the same purpose.</S> | Reference Offset:  ['19','25'] | Reference Text:  <S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S><S sid ="25" ssid = "25">\Ve try two ways of combining these components: decision lists, and Bayesian classifiers.</S> | Discourse Facet:  ['Aim_Citation','Method_Citation'] | Annotator:  Aakansha Gehlot |


Citance Number: 39 | Reference Article:  W95-0104.txt | Citing Article:  W98-1234.txt | Citation Marker Offset:  ['4'] | Citation Marker:  3 | Citation Offset:  ['4'] | Citation Text:  <S sid ="4" ssid = "4">Our module used for spelling correction was developed on the basis of works by Brill [1], Brill and Marcus [2), Golding [3), Golding and Schabes [4], and Powers [5).</S> | Reference Offset:  ['19'] | Reference Text:  <S sid ="19" ssid = "19">The work reported here was applied not to accent restoration, but to a related lexical disamÂ­ biguation task: context-sensitive spelling correction.</S> | Discourse Facet:  Aim_Citation | Annotator:  Aakansha Gehlot |


