Alignment By Agreement
We present an unsupervised approach to symmetric word alignment in which two simple asymmetric models are trained jointly to maximize a combination of data likelihood and agreement between the models.
Compared to the standard practice of intersecting predictions of independently-trained models, joint training provides a 32% reduction in AER.
Moreover, a simple and efficient pair of HMM aligners provides a 29% reduction in AER over symmetrized IBM model 4 predictions.
We use discriminative SMT on large training data, training 1.5 million features on 67,000 sentences.
