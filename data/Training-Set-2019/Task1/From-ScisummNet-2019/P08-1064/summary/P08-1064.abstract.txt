This paper presents a translation model that is based on tree sequence alignment, where a tree sequence refers to a single sequence of subtrees that covers a phrase. 
The model leverages on the strengths of both phrase-based and linguistically syntax-based method. 
It automatically learns aligned tree sequence pairs with mapping probabilities from word-aligned biparsed parallel texts. 
Compared with previous models, it not only captures non-syntactic phrases and discontinuous phrases with linguistically structured features, but also supports multi-level structure reordering of tree typology with larger span. 
This gives our model stronger expressive power than other reported models. 
Experimental results on the NIST MT-2005 Chinese-English translation task show that our method statistically significantly outperforms the baseline systems. 
