Bayesian Learning of a Tree Substitution Grammar
Tree substitution grammars (TSGs) offer many advantages over context-free grammars (CFGs), but are hard to learn.
Past approaches have resorted to heuristics.
In this paper, we learn a TSG using Gibbs sampling with a nonparametric prior to control subtree size.
The learned grammars perform significantly better than heuristically extracted ones on parsing accuracy.
