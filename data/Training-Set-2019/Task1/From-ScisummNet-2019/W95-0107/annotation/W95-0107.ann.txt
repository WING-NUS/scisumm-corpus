Citance Number: 1 | Reference Article:  W95-0107.txt | Citing Article:  P07-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following Ramshaw and Marcus (1995), the current dominant approach is formulating chunking as a classification task, in which each word is classified as the (B)eginning, (I)nside or (O) outside of a chunk.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For example, instead of referring to the word two to the left, a rule pattern could refer to the first word in the current chunk, or the last word of the previous chunk.</S><S sid = NA ssid = NA>Voutilainen (1993), in his impressive NPtool system, uses an approach that is in some ways similar to the one used here, in that he adds to his part-of-speech tags a new kind of tag that shows chunk structure; the chunk tag &quot;Â©>N&quot;, for example, is used for determiners and premodifiers, both of which group with the following noun head.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W95-0107.txt | Citing Article:  P07-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>NP chunks in the shared task data are BaseNPs, which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>At about the same time, Ejerhed (1988), working with Church, performed comparisons between finite state methods and Church's stochastic models for identifying both non-recursive clauses and non-recursive NPs in English text.</S><S sid = NA ssid = NA>We performed experiments using two different chunk structure targets, one that tried to bracket non-recursive &quot;baseNPs&quot; and one that partitioned sentences into non-overlapping N-type and V-type chunks, loosely following Abney's model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W95-0107.txt | Citing Article:  D12-1079.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Transformation-based learning (TBL) was originally introduced via the Brill part-of-speech tagger (Brill, 1992) and has since been applied to a wide variety of NLP tasks, including binary phrase structure bracketing (Brill, 1993), PP-attachment disambiguation (Brill and Resnik, 1994), base NP chunking (Ramshaw and Marcus, 1995), dialogue act tagging (Samuel et al1998), and named entity re cog nition (Black and Vasilakopoulos, 2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This technique has previously been used not only for part-of-speech tagging (Brill, 1994), but also for prepositional phrase attachment disambiguation (Brill and Resnik, 1994), and assigning unlabeled binary-branching tree structure to sentences (Brill, 1993a).</S><S sid = NA ssid = NA>The source texts were then run through Brill's part-of-speech tagger (Brill, 1993c), and, as a baseline heuristic, chunk structure tags were assigned to each word based on its part-of-speech tag.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W95-0107.txt | Citing Article:  P07-1031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Many approaches to identifying base noun phrases have been explored as part of chunking (Ramshawand Marcus, 1995), but determining sub-NP structure is rarely addressed.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Since chunking includes identifying the non-recursive portions of noun phrases, it can also be useful for other purposes including index term generation.</S><S sid = NA ssid = NA>This section discusses how text chunking can be encoded as a tagging problem that can be conveniently addressed using transformational learning.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W95-0107.txt | Citing Article:  P06-2013.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ramshaw and Marcus (Ramshaw and Marcus,1995) first represented base noun phrase recognition as a machine learning problem.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Applying transformational learning to text chunking requires that the system's current hypotheses about chunk structure be represented in a way that can be matched against the pattern parts of rules.</S><S sid = NA ssid = NA>By representing text chunking as a kind of tagging problem, it becomes possible to easily apply transformation-based learning.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W95-0107.txt | Citing Article:  P11-1139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Both the IOB representation (Ramshaw and Marcus, 1995) and the Start/End representation (Kudo and Matsumoto, 2001) are popular.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Encoding chunk structure with tags attached to words rather than non-recursive bracket markers inserted between words has the advantage that it limits the dependence between different elements of the encoded representation.</S><S sid = NA ssid = NA>In earlier work on transformational part-of-speech tagging (Ramshaw and Marcus, 1994), we noted that it is possible to greatly speed up the learning process by constructing a full, bidirectional index linking each candidate rule to those locations in the corpus at which it applies and each location in the corpus to those candidate rules that apply there.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W95-0107.txt | Citing Article:  I08-1050.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Meanwhile, it is common for NP chunking tasks to represent a chunk (e.g., NP) with two labels, the begin (e.g., B-NP) and inside (e.g., I-NP) of a chunk (Ramshaw and Marcus, 1995).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These putative errors, combined with the claimed high performance, suggest that NPtool's definition of NP chunk is also tuned for extracting terminological phrases, and thus excludes many kinds of NP premodifiers, again simplifying the chunking task.</S><S sid = NA ssid = NA>'Non-constituent NP conjunction, which Treebank labels NX, is another example that still causes problems.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W95-0107.txt | Citing Article:  H05-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>They mention that the resulting shallow parse tags are somewhat different than those used by Ramshaw and Marcus (1995), but that they found no significant accuracy differences in training on either set.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Since training set size has a significant effect on the results, values are shown for three different training set sizes.</S><S sid = NA ssid = NA>Training runs were halted after the first 500 rules; rules learned after that point affect relatively few locations in the training set and have only a very slight effect for good or ill on test set performance.)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W95-0107.txt | Citing Article:  D07-1084.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Training and testing were performed using the noun phrase chunking corpus described in Ramshaw & Marcus (1995) (Ramshaw and Marcus, 1995).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Text Chunking Using Transformation-Based Learning</S><S sid = NA ssid = NA>In earlier work on transformational part-of-speech tagging (Ramshaw and Marcus, 1994), we noted that it is possible to greatly speed up the learning process by constructing a full, bidirectional index linking each candidate rule to those locations in the corpus at which it applies and each location in the corpus to those candidate rules that apply there.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W95-0107.txt | Citing Article:  W06-0113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ramshaw and Marcus (1995) first introduced the machine learning techniques to chunking problem.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>By representing text chunking as a kind of tagging problem, it becomes possible to easily apply transformation-based learning.</S><S sid = NA ssid = NA>This section discusses how text chunking can be encoded as a tagging problem that can be conveniently addressed using transformational learning.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W95-0107.txt | Citing Article:  W06-0113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>After the work of Ramshaw and Marcus (1995), many machine learning techniques have been applied to the basic chunking task, such as Sup port Vector Machines (Kudo and Matsumoto, 2001), Hidden Markov Model (Molina and Pla 2002), Memory Based Learning (Sang, 2002), Conditional Random Fields (Sha and Pereira, 2003), and so on.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Text Chunking Using Transformation-Based Learning</S><S sid = NA ssid = NA>We also note some related adaptations in the procedure for learning rules that improve its performance, taking advantage of ways in which this task differs from the learning of part-of-speech tags.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W95-0107.txt | Citing Article:  W01-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The noun phrase extraction module uses Brill &apos; s POS tagger [Brill (1992)] and a base NPchunker [Ramshaw and Marcus (1995)].</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The source texts were then run through Brill's part-of-speech tagger (Brill, 1993c), and, as a baseline heuristic, chunk structure tags were assigned to each word based on its part-of-speech tag.</S><S sid = NA ssid = NA>This technique has previously been used not only for part-of-speech tagging (Brill, 1994), but also for prepositional phrase attachment disambiguation (Brill and Resnik, 1994), and assigning unlabeled binary-branching tree structure to sentences (Brill, 1993a).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W95-0107.txt | Citing Article:  W01-1011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Noun phrases were extracted using Ramshaw and Marcus &apos; s base NPchunker [Ramshaw and Marcus (1995)].</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Bourigault claims that the grammar can parse &quot;around 95% of the maximal length noun phrases&quot; in a test corpus into possible terminological phrases, which then require manual validation.</S><S sid = NA ssid = NA>The goal of the &quot;baseNP&quot; chunks was to identify essentially the initial portions of nonrecursive noun phrases up to the head, including determiners but not including postmodifying prepositional phrases or clauses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W95-0107.txt | Citing Article:  N03-1002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Five chunk tag sets, IOB1, IOB2, IOE1, IOE2 (Ramshaw and Marcus, 1995) and SE (Uchimoto et al, 2000), are commonly used.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this study, training and test sets marked with two different types of chunk structure were derived algorithmically from the parsed data in the Penn Treebank corpus of Wall Street Journal text (Marcus et al., 1994).</S><S sid = NA ssid = NA>Training and test materials with chunk tags encoding each of these kinds of structure were derived automatically from the parsed Wall Street Journal text in the Penn Treebank (Marcus et al., 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W95-0107.txt | Citing Article:  P12-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>text chunking model (Ramshaw and Marcus, 1995), which has been previously applied to Chinesesegmentation (Peng et al, 2004).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Training and test materials with chunk tags encoding each of these kinds of structure were derived automatically from the parsed Wall Street Journal text in the Penn Treebank (Marcus et al., 1994).</S><S sid = NA ssid = NA>In this study, training and test sets marked with two different types of chunk structure were derived algorithmically from the parsed data in the Penn Treebank corpus of Wall Street Journal text (Marcus et al., 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W95-0107.txt | Citing Article:  P02-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(IOB) encoding originating from (Ramshaw and Marcus, 1995).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Training and test materials with chunk tags encoding each of these kinds of structure were derived automatically from the parsed Wall Street Journal text in the Penn Treebank (Marcus et al., 1994).</S><S sid = NA ssid = NA>For this purpose, it is convenient to view chunking as a tagging problem by encoding the chunk structure in new tags attached to each word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W95-0107.txt | Citing Article:  P02-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ramshaw and Marcus (1995), Munoz et al (1999), Argamon et al (1998), Daelemans et al (1999a) find NP chunks, using Wall Street Journal training material of about 9000 sentences.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Training and test materials with chunk tags encoding each of these kinds of structure were derived automatically from the parsed Wall Street Journal text in the Penn Treebank (Marcus et al., 1994).</S><S sid = NA ssid = NA>In this study, training and test sets marked with two different types of chunk structure were derived algorithmically from the parsed data in the Penn Treebank corpus of Wall Street Journal text (Marcus et al., 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W95-0107.txt | Citing Article:  W09-1317.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Next, a rule-based text chunker (Ramshaw and Marcus, 1995) is applied on the tagged sentences to further identify phrasal units, such as base noun phrases NP and verbal units VB.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Rule 3 changes N to BN after a comma (which is tagged P), and in Rule 4, locations tagged BN are switched to BV if the following location is tagged V and has the part-of-speech tag VB.</S><S sid = NA ssid = NA>The goal of the &quot;baseNP&quot; chunks was to identify essentially the initial portions of nonrecursive noun phrases up to the head, including determiners but not including postmodifying prepositional phrases or clauses.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W95-0107.txt | Citing Article:  W07-1509.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Given a weight vector w, the scorew? f (x, y) ranks possible labelings of x, and we denote by Yk, w (x) the set of k top scoring labelings for x. We use the standard B, I, O encoding for named entities (Ramshaw and Marcus, 1995).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The search for the best-scoring rule can then be halted when a cell of the confusion matrix is reached whose maximum possible benefit is less than the net benefit of some rule already encountered.</S><S sid = NA ssid = NA>In this work, we have found it convenient to do so by encoding the chunking using an additional set of tags, so that each word carries both a part-of-speech tag and also a &quot;chunk tag&quot; from which the chunk structure can be derived.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W95-0107.txt | Citing Article:  P06-1087.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The NP chunks in the shared task data are base-NP chunks which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These putative errors, combined with the claimed high performance, suggest that NPtool's definition of NP chunk is also tuned for extracting terminological phrases, and thus excludes many kinds of NP premodifiers, again simplifying the chunking task.</S><S sid = NA ssid = NA>The same method can be applied at a higher level of textual interpretation for locating chunks in the tagged text, including non-recursive &quot;baseNP&quot; chunks.</S> | Discourse Facet:  NA | Annotator: Automatic


