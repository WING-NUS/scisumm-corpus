Citance Number: 1 | Reference Article:  W99-0501.txt | Citing Article:  P06-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >However, as various researchers have pointed out (Harabagiu et al, 1999), these networks lack information, in particular with regard to syntagmatic associations, which are generally unsystematic.</S> | Reference Offset:  ['2','3'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 3 ssid = >Machine Readable Dictionaries (MRDs) have long been recognized as N aluable resources in computational linguistics In their paper, Ide and Veroms (Ide and Veroms, 1993) projected a rather pessimistic outlook for the utility of MRDs as knowledge sources, a view that has impeded the enthusiasm of some researchers (Wilks et al 1996) make a strong argument in favor of using MRDs and shale then positive experience with using some dictionaries The MindNet project at Microsoft aims at fully automating the development of a very large lexical knowledge base using two MRDs the Longman Dictionary of Contemporary, English (LDOCE) and the American Heritage Third Edition (AHD3) Many technical aspects of this project are rooted in the works of Vanderwende (Vanderwende 1996) and Richardson (Richardson 1997)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W99-0501.txt | Citing Article:  W04-2116.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Work on the Extended WordNet project (Harabagiu et al, 1999) is achieving substantial progress in making the information in WordNet more explicit.</S> | Reference Offset:  ['2','4'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 4 ssid = >There are several differences between gloss disambiguation and text disambiguation A major difference is that in our project we know the meaning of each gloss, namely the synset to which a gloss applies Second, the glosses contain a definition, comments, and one or more examples We address the word sense disambiguation problem by using three complementary methods (a) heuristics, (b) conceptual density, and (c) statistics on large corpora The first two methods rely entirely on the information contained in WordNet, while the third one uses other corpora Specifically, the sources of knowledge available to us ate (1) lexical information that includes part of speech, position of words (i e head word), and lexical relations (2) collocations and syntactic patterns, (3) synset to which a gloss belongs, (4) hypernyms of sy nset and their glosses (5) synsets of poly semouns words and their glosses, (6) hypernyms of synsets of polysemous words, and their glosses, and so on Method 1 Classes of heuristics for word sense disambiguation A suitable technique for disambiguating dictionaries is to rely on heuristics able to cope with different sources of information Work in tins area was done by Ravin (Rat in 1990) in a similar project at IBM, (Klavans et al 1990), and others We present now some of the heuristics used by us A way of explaining a concept is to specialize a more general concept (i e a hypernym) It is likely that an explanation begins with a phrase whose head is one of its hypernyms, and the features are expressed either as attributes in the same phrase or as phrases attached to the first phrase Example The gloss of synset {intrusion} is (entrance by force or without permission or welcome) It is likely that the syntactic parallelism of two words translates into semantic parallelism and the words may have a common hypernym, or one is a hypernym of the other For adjectives, the hyperny my is replaced by the similarity relation Other heuristics in this class check whether or not two polysemous words belong to the same synset, or one is a hyperny m of the other, or if they belong to the same hierarchy Example The gloss of {interaction} is (a mutual or reciprocal action) In glosses, comments and examples are meant to provide supplemental information It is possible to find the specialization or typical relation linking the comment to the preceding head phrase in one of the synsets (or gloss) of the head phrase Example The gloss of the synset {scuff, scuffing} is (the act of scuffing (scraping or dragging the feet)) Examples in WordNet provide collocatronal information of the words in synsets The intrinsic semantic tag of the word from the synset which is used in the example can occur in the same lexical relation in some other gloss, carrying the semantic tag with it Example Synset {penetration} has the gloss (the act of forcing a way into something) Nouns representing actions are nominalizations of some verbs If a verbal collocation contains a noun, and is also a synonym of some morphologically related verb, then it is likely to be the nommalization source The verb from the gloss of a synonym describing an action, if not the source of the nominalization is likely to belong to the same hierarchy as the true nommalization source, since they must share some properties Example Let s = {escape, flight}, with the gloss (the act of escaping physically) A. lexical relation using a word w both in the gloss of a sy nsct s and in some other gloss signals a property of w associated NI lth S In other cases when two relations [w17w.,] and [zu,1 WA.] are found in two glosses of WordNet, and there are senses of w, and wk that have a common hypernym, it is likely that the correlation between w, and the common hypernym is projected in both collocations Example The gloss of the synset {Underground Railroad} is (abolitionists secret aid to escaping slaves) Method 2 Conceptual density method We have implemented a WSD system for free text that disambiguates multiple words simultaneously (NIrhalcea and NIoldovan, 1999) The method is based on measuring the number of common nouns shared by the verb and noun hierarchies, and thus gets around the lack of connections problem As an example, consider a verb - noun pair of words Denote with < vt,v2„ vh > and < ni, n2, ,711 > the senses of the verb and the noun in dNet For each possible pan v, — n„, the conceptual density is computed as follows 1 Extract all the glosses from the sub-hierarchy of th and determine the nouns from these glosses This constitutes the noun-context of verb v, Each such noun is stored together with a weight w that indicates the level in the sub-hierarchy of the verb concept in whose gloss the noun was found 2 Determine the glosses of the noun sub-hierarchy of nj and determine the nouns in them 3 Compute the conceptual density Cij of the common concepts between the nouns obtained at (1) and the nouns obtained at (2) using the metric EWk = loy(descendentsi) where 4 C,, ranks each pair v, — nj, for all z and j Vanants of this method work for other parts of speech pairs such as noun-noun, noun-verb, verb-verb, verb-noun, adjective-noun and verb-adverb This is a powerful method that works surprisingly well even for free text We haNe tested the method on SemCor, the part of the Brown corpus tagged with WordNet senses With this technique it is possible to rank the senses and to keep not only the first ranked sense, but the second or thud ranked senses especially when the ranking is sufficiently close and there is another way to check the validity of the disambiguation As a last resort, we can use a statistical approach to disambiguate those words that can not be done with any of the methods described so far Consider a collocating word-word pair w1 — w2 in which we consider that wi has been disambiguated already The disambiguation of w2 proceeds as follows { woul,&quot; OR w1w21(1)&quot; OR &quot;w1w;(21)&quot; We have searched the Internet using the AltaVista search engine The number of hits for each similarity list measures the relatedness of wi with each sense to; and thus provides a ranking of the senses The following procedure was used to disambiguate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words - that have only one sense in WordNet (in our experiment 6468 words were found) Step 2 Apply Method 1 - Heuristics - to the remaining 6294 polysemous words Method 1 provides correct disambiguation for 5475 words, thus an accuracy of 87% Out of the remaining 13% of the words, 3% were disambiguated erroneously and 10% could not be done with the heuristics used The collect sense for each word was determined manually by a team of three students We ha‘e found a few s3 nsets such as {commemorate, remember} that have no links to any other synsets, ie no h3 perny ms and no hypomy nis Step 3 Apply Method 2 - Conceptual Density - to the 6294 polysemous words, star ting fresh Step 4 Apply Method 3 - Statistics - to the 6294 words using AltaN ista on the Internet Step 5 The results obtained with Method 1 and Method 2 are combined, that is, take all the words that were disambiguated, and in the case of conflict give priority to Method 1 Step 6 The results from Step 5 are combined with the results given by Method 3 and in the case of conflict give priority to results obtained in Step 5 Table 1 indicates the accuracy obtained at each step An overall accuracy of 94% was achieved Our goal is to improve the technique to be able to disambiguate all words automatically These results must be seen against the background average rate of 59 39% correct sense assignment achieved when the first WordNet sense is assigned to each polysemous word This is considered the baseline performance level for word-sense disambiguation programs (Gale et al 1992) and is consistent with our own measurements</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W99-0501.txt | Citing Article:  P05-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, in eXtended WordNet (Harabagiu et al 1999), the rich glosses in WordNet are enriched by disambiguating the nouns, verbs, adverbs, and adjectives with synsets.</S> | Reference Offset:  ['2','8'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 8 ssid = >Since the organization of WordNet divides the English vocabulary into four separate domains-nouns, verbs, adjectives, and adverbs- closely related concepts are often entered in more than one of these domains Many (probably most) of these relations can be identified in terms of derivational morphology, e g, the noun execution is derived from the verb execute and so is an example of a deverbal noun WordNet already contains some of this kind of derivational morphology deadjectival nouns are linked to their root adjectives (length is derived twin long), deadjectival adverbs are linked to then root adjectnes (rapidly is derived from rapid), and some denominal adjectives are linked to then root nouns (cellular is derived from cell) In order to increase the connectivity of WordNet it would be desirable to include more such derivational morphology For example, derivational relations between nouns and verbs should be particularly useful (Hull and Gomez 1996) both deverbal nouns (avowal from avow) and denominal verbs (summarize from summary) Such connections would facilitate the recognition that the same idea can be expressed in different ways, e g , that &quot;He summarized the book&quot; and &quot;He gave a summary of the book&quot; are effectively equivalent in meaning Sometimes these morphological relations can be picked up from glosses, as when {disagreement} is defined as (the speech act of disagreeing or arguing or disputing), but these are generally regarded as uninformative definitions, and the reverse relation may not happen to occur Since many of the words are polysemous, morphological relations should not link words, but synsets that have related meanings For example, {execute} meaning (to put to death) should be linked to {execution} meaning (the act of putting a condemned person to death), and {execute} meaning (to carry out a task) should be linked to {execution} meaning (the act of doing something successfully), etc And in cases where the concepts of the noun and verb are different-e g, {womanize} from {woman}-no semantic link would need to be created</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W99-0501.txt | Citing Article:  W03-1404.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In the sections to follow we describe a mechanism for automating the extraction of these relationships (in the same vein as (Harabagiu et al 1999), and for using them to generative apt interpretations for metaphors involving WordNet entries.</S> | Reference Offset:  ['2','3'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 3 ssid = >Machine Readable Dictionaries (MRDs) have long been recognized as N aluable resources in computational linguistics In their paper, Ide and Veroms (Ide and Veroms, 1993) projected a rather pessimistic outlook for the utility of MRDs as knowledge sources, a view that has impeded the enthusiasm of some researchers (Wilks et al 1996) make a strong argument in favor of using MRDs and shale then positive experience with using some dictionaries The MindNet project at Microsoft aims at fully automating the development of a very large lexical knowledge base using two MRDs the Longman Dictionary of Contemporary, English (LDOCE) and the American Heritage Third Edition (AHD3) Many technical aspects of this project are rooted in the works of Vanderwende (Vanderwende 1996) and Richardson (Richardson 1997)</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W99-0501.txt | Citing Article:  W04-0815.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Harabagiu et al (1999) proposed a scheme for attaching sense tags to predicates within the framework of transforming WordNet glosses into a logical form.</S> | Reference Offset:  ['5','7'] | Reference Text:  <S sid = 5 ssid = >Our extension of WordNet intends to serve as a lexico-semantic resource for a variety of NLP applications, many of them requiring pragmatic and common-sense knowledge (Harabagm and Moldovan 1998) It is beneficial to transform the conceptual glosses in logical formulae Approach to implement Logical Form Transformations (LFTs) (1) Traditional lexicographic principles determine the discrimination of any conceptual definitions into a genus and the differentia Our LFTs implement the same distinction by always placing the genus predicate on the first position of the LFT, and the rest of the LFT viewed as the definition differentia In the case when the subject or the object are present in the gloss, they share the corresponding arguments with the action/state/event predicate For example, the LFT of (a person who backs a politician) the gloss of {supporter, protagonist, champion, admirer, booster, friend} is LFT = [person n#1(2,1) Sz back v#1(e1,114)) politician n#2(x2) (4) The role of complements within a phrase is replicated in the LFTs Predicates geneiated from modifiers share the same arguments with the predicates corresponding to the phrase heads Adjective piedicates share the same argument as the predicate corresponding to the noun they modify An exemplification is the LFT of the gloss of {art if act , artefact}, which maps (a man-made object) into [ object n#1(xi) Sc man-made a#1(x1)] Similarly, the argument of adverbial predicate is the argument marking the eventuality of the event/state/action they modify For example, the gloss of the verb synset {hare} is (run quickly), producing the LFT = [run(ei,a,i,x2) & quickly(e&quot;)] under the same syntactic role (e g subject, object or prepositional object) By convention, conjunctionpredicates have a variable number of arguments, since they cover a variable number of predicates The first argument represents the &quot;result&quot; of the logical operation induced by the conjunction (e g a logical and in the case of the and conjunction, or a logical or in the case of the or conjunction) The rest of the aiguments indicate the predicates covered by the conjunction, as they are aiguments of those predicates as well (6) We also geneiate 'medicates for every preposition encountered in the gloss The preposition predicates always have two arguments the first argument corresponding to the predicate of the head of the phi ase to which prepositional phi ase is attached, whereas the second argument corresponds to the prepositional object Sources of information.</S><S sid = 7 ssid = >Many NLP problems iely on the recognition of the typical lexico-semantic telationships between linguistic concepts The LFT codification met ely acknowledges the following syntax-based relationships (1) syntactic subjects, (2) syntactic objects (3) prepositional attachments (4) complex norninals and (5) adjectival/adverbial adjuncts Semantic interpretations of utterances, as %%ell as discoui se piocessing require knowledge about the semantic or thematic relationships between concepts The semantic form transformations provide with constraint-based mappings of the syntax-based relations covered in the LFTs into binary thematic relations or semantic relations (We distinguish between thematic telations such as agent, expenencer, etc, and semantic relations such as a-kind-of, part-of, etc) Approach to implement Semantic Form Transformations (SFTs) 1 The syntactic subject relations iecognized in the LFTs by the predicative formula subject(xi )&verb(e, 1, 3,2) can be mapped into a N anety of thematic relations The definition of the thematic relations is entirely based on infoimation Internal to the WordNet database, exptessed as constraints Foi example, all the subjects of verbs that are hyponyms of the verb cause or have this concept as the genus of then glosses are defined to represent the tole of agents (2) The syntactic object telations ate iecognized in the LFTs 1),. the predicative toimula verb(ei,xi,x)) & noun(z2) The definition of the thematic relations in which syntactic objects can be mapped is expressed in terms of verb synsets The constraining verb synsets tepresent the upper-most hypernyms of all verbs that (z) have syntactic objects in the WordNet glosses and (ii) belong to the same hierarchy or ate defined by gloss gent from the same hiei archy (3) The prepositional predicates ale tiansfoimed into thematic °I semantic relations When a WotdNet semantic relation holds between the arguments of a prepositional predicate, that specific relation becomes the semantic transformation of the predicate For example, the PP attachment [sacrament of penance} derived from the gloss of {confession} indicates a semantic kind-of relation due to the fact that in WordNet penance is a hyponym of sacrament (4) The transformation of complex nominal predicates into thematic or semantic constraints is done by first seeking a WordNet relation (or a combination of such relations) between the components of the predicate If such a (chain of) relation(s) is found, predicate nn is transformed into the dominant WordNet semantic relation Otherwise, the nn predicate is transformed into a thematic relation (5) The transformation of adjectival and adverbial adjuncts, represented in the LFTs as predicates sharing the same argument with the concepts they modify shall be connected to their modifiers through attribute relations</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W99-0501.txt | Citing Article:  P08-1060.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Endeavors such as that of Harabagiu et al (1999), in which each of the textual glosses in WordNet (Fellbaum, 1998) is linguistically analyzed to yield a sense-tagged logical form, is an example of the former approach.</S> | Reference Offset:  ['4','5'] | Reference Text:  <S sid = 4 ssid = >There are several differences between gloss disambiguation and text disambiguation A major difference is that in our project we know the meaning of each gloss, namely the synset to which a gloss applies Second, the glosses contain a definition, comments, and one or more examples We address the word sense disambiguation problem by using three complementary methods (a) heuristics, (b) conceptual density, and (c) statistics on large corpora The first two methods rely entirely on the information contained in WordNet, while the third one uses other corpora Specifically, the sources of knowledge available to us ate (1) lexical information that includes part of speech, position of words (i e head word), and lexical relations (2) collocations and syntactic patterns, (3) synset to which a gloss belongs, (4) hypernyms of sy nset and their glosses (5) synsets of poly semouns words and their glosses, (6) hypernyms of synsets of polysemous words, and their glosses, and so on Method 1 Classes of heuristics for word sense disambiguation A suitable technique for disambiguating dictionaries is to rely on heuristics able to cope with different sources of information Work in tins area was done by Ravin (Rat in 1990) in a similar project at IBM, (Klavans et al 1990), and others We present now some of the heuristics used by us A way of explaining a concept is to specialize a more general concept (i e a hypernym) It is likely that an explanation begins with a phrase whose head is one of its hypernyms, and the features are expressed either as attributes in the same phrase or as phrases attached to the first phrase Example The gloss of synset {intrusion} is (entrance by force or without permission or welcome) It is likely that the syntactic parallelism of two words translates into semantic parallelism and the words may have a common hypernym, or one is a hypernym of the other For adjectives, the hyperny my is replaced by the similarity relation Other heuristics in this class check whether or not two polysemous words belong to the same synset, or one is a hyperny m of the other, or if they belong to the same hierarchy Example The gloss of {interaction} is (a mutual or reciprocal action) In glosses, comments and examples are meant to provide supplemental information It is possible to find the specialization or typical relation linking the comment to the preceding head phrase in one of the synsets (or gloss) of the head phrase Example The gloss of the synset {scuff, scuffing} is (the act of scuffing (scraping or dragging the feet)) Examples in WordNet provide collocatronal information of the words in synsets The intrinsic semantic tag of the word from the synset which is used in the example can occur in the same lexical relation in some other gloss, carrying the semantic tag with it Example Synset {penetration} has the gloss (the act of forcing a way into something) Nouns representing actions are nominalizations of some verbs If a verbal collocation contains a noun, and is also a synonym of some morphologically related verb, then it is likely to be the nommalization source The verb from the gloss of a synonym describing an action, if not the source of the nominalization is likely to belong to the same hierarchy as the true nommalization source, since they must share some properties Example Let s = {escape, flight}, with the gloss (the act of escaping physically) A. lexical relation using a word w both in the gloss of a sy nsct s and in some other gloss signals a property of w associated NI lth S In other cases when two relations [w17w.,] and [zu,1 WA.] are found in two glosses of WordNet, and there are senses of w, and wk that have a common hypernym, it is likely that the correlation between w, and the common hypernym is projected in both collocations Example The gloss of the synset {Underground Railroad} is (abolitionists secret aid to escaping slaves) Method 2 Conceptual density method We have implemented a WSD system for free text that disambiguates multiple words simultaneously (NIrhalcea and NIoldovan, 1999) The method is based on measuring the number of common nouns shared by the verb and noun hierarchies, and thus gets around the lack of connections problem As an example, consider a verb - noun pair of words Denote with < vt,v2„ vh > and < ni, n2, ,711 > the senses of the verb and the noun in dNet For each possible pan v, — n„, the conceptual density is computed as follows 1 Extract all the glosses from the sub-hierarchy of th and determine the nouns from these glosses This constitutes the noun-context of verb v, Each such noun is stored together with a weight w that indicates the level in the sub-hierarchy of the verb concept in whose gloss the noun was found 2 Determine the glosses of the noun sub-hierarchy of nj and determine the nouns in them 3 Compute the conceptual density Cij of the common concepts between the nouns obtained at (1) and the nouns obtained at (2) using the metric EWk = loy(descendentsi) where 4 C,, ranks each pair v, — nj, for all z and j Vanants of this method work for other parts of speech pairs such as noun-noun, noun-verb, verb-verb, verb-noun, adjective-noun and verb-adverb This is a powerful method that works surprisingly well even for free text We haNe tested the method on SemCor, the part of the Brown corpus tagged with WordNet senses With this technique it is possible to rank the senses and to keep not only the first ranked sense, but the second or thud ranked senses especially when the ranking is sufficiently close and there is another way to check the validity of the disambiguation As a last resort, we can use a statistical approach to disambiguate those words that can not be done with any of the methods described so far Consider a collocating word-word pair w1 — w2 in which we consider that wi has been disambiguated already The disambiguation of w2 proceeds as follows { woul,&quot; OR w1w21(1)&quot; OR &quot;w1w;(21)&quot; We have searched the Internet using the AltaVista search engine The number of hits for each similarity list measures the relatedness of wi with each sense to; and thus provides a ranking of the senses The following procedure was used to disambiguate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words - that have only one sense in WordNet (in our experiment 6468 words were found) Step 2 Apply Method 1 - Heuristics - to the remaining 6294 polysemous words Method 1 provides correct disambiguation for 5475 words, thus an accuracy of 87% Out of the remaining 13% of the words, 3% were disambiguated erroneously and 10% could not be done with the heuristics used The collect sense for each word was determined manually by a team of three students We ha‘e found a few s3 nsets such as {commemorate, remember} that have no links to any other synsets, ie no h3 perny ms and no hypomy nis Step 3 Apply Method 2 - Conceptual Density - to the 6294 polysemous words, star ting fresh Step 4 Apply Method 3 - Statistics - to the 6294 words using AltaN ista on the Internet Step 5 The results obtained with Method 1 and Method 2 are combined, that is, take all the words that were disambiguated, and in the case of conflict give priority to Method 1 Step 6 The results from Step 5 are combined with the results given by Method 3 and in the case of conflict give priority to results obtained in Step 5 Table 1 indicates the accuracy obtained at each step An overall accuracy of 94% was achieved Our goal is to improve the technique to be able to disambiguate all words automatically These results must be seen against the background average rate of 59 39% correct sense assignment achieved when the first WordNet sense is assigned to each polysemous word This is considered the baseline performance level for word-sense disambiguation programs (Gale et al 1992) and is consistent with our own measurements</S><S sid = 5 ssid = >Our extension of WordNet intends to serve as a lexico-semantic resource for a variety of NLP applications, many of them requiring pragmatic and common-sense knowledge (Harabagm and Moldovan 1998) It is beneficial to transform the conceptual glosses in logical formulae Approach to implement Logical Form Transformations (LFTs) (1) Traditional lexicographic principles determine the discrimination of any conceptual definitions into a genus and the differentia Our LFTs implement the same distinction by always placing the genus predicate on the first position of the LFT, and the rest of the LFT viewed as the definition differentia In the case when the subject or the object are present in the gloss, they share the corresponding arguments with the action/state/event predicate For example, the LFT of (a person who backs a politician) the gloss of {supporter, protagonist, champion, admirer, booster, friend} is LFT = [person n#1(2,1) Sz back v#1(e1,114)) politician n#2(x2) (4) The role of complements within a phrase is replicated in the LFTs Predicates geneiated from modifiers share the same arguments with the predicates corresponding to the phrase heads Adjective piedicates share the same argument as the predicate corresponding to the noun they modify An exemplification is the LFT of the gloss of {art if act , artefact}, which maps (a man-made object) into [ object n#1(xi) Sc man-made a#1(x1)] Similarly, the argument of adverbial predicate is the argument marking the eventuality of the event/state/action they modify For example, the gloss of the verb synset {hare} is (run quickly), producing the LFT = [run(ei,a,i,x2) & quickly(e&quot;)] under the same syntactic role (e g subject, object or prepositional object) By convention, conjunctionpredicates have a variable number of arguments, since they cover a variable number of predicates The first argument represents the &quot;result&quot; of the logical operation induced by the conjunction (e g a logical and in the case of the and conjunction, or a logical or in the case of the or conjunction) The rest of the aiguments indicate the predicates covered by the conjunction, as they are aiguments of those predicates as well (6) We also geneiate 'medicates for every preposition encountered in the gloss The preposition predicates always have two arguments the first argument corresponding to the predicate of the head of the phi ase to which prepositional phi ase is attached, whereas the second argument corresponds to the prepositional object Sources of information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W99-0501.txt | Citing Article:  P06-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >For example, in eXtended WordNet (Harabagiu et al 1999), the glosses in WordNet are enriched by disambiguating the nouns, verbs, adverbs, and adjectives with synsets.</S> | Reference Offset:  ['2','8'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 8 ssid = >Since the organization of WordNet divides the English vocabulary into four separate domains-nouns, verbs, adjectives, and adverbs- closely related concepts are often entered in more than one of these domains Many (probably most) of these relations can be identified in terms of derivational morphology, e g, the noun execution is derived from the verb execute and so is an example of a deverbal noun WordNet already contains some of this kind of derivational morphology deadjectival nouns are linked to their root adjectives (length is derived twin long), deadjectival adverbs are linked to then root adjectnes (rapidly is derived from rapid), and some denominal adjectives are linked to then root nouns (cellular is derived from cell) In order to increase the connectivity of WordNet it would be desirable to include more such derivational morphology For example, derivational relations between nouns and verbs should be particularly useful (Hull and Gomez 1996) both deverbal nouns (avowal from avow) and denominal verbs (summarize from summary) Such connections would facilitate the recognition that the same idea can be expressed in different ways, e g , that &quot;He summarized the book&quot; and &quot;He gave a summary of the book&quot; are effectively equivalent in meaning Sometimes these morphological relations can be picked up from glosses, as when {disagreement} is defined as (the speech act of disagreeing or arguing or disputing), but these are generally regarded as uninformative definitions, and the reverse relation may not happen to occur Since many of the words are polysemous, morphological relations should not link words, but synsets that have related meanings For example, {execute} meaning (to put to death) should be linked to {execution} meaning (the act of putting a condemned person to death), and {execute} meaning (to carry out a task) should be linked to {execution} meaning (the act of doing something successfully), etc And in cases where the concepts of the noun and verb are different-e g, {womanize} from {woman}-no semantic link would need to be created</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W99-0501.txt | Citing Article:  P07-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We obtain the data of the I relation from eXtended WordNet (Harabagiu et al, 1999), an automatically sense-disambiguated version of WordNet in which every term occurrence in every gloss is linked to the synset it is deemed to belong to.</S> | Reference Offset:  ['2','4'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 4 ssid = >There are several differences between gloss disambiguation and text disambiguation A major difference is that in our project we know the meaning of each gloss, namely the synset to which a gloss applies Second, the glosses contain a definition, comments, and one or more examples We address the word sense disambiguation problem by using three complementary methods (a) heuristics, (b) conceptual density, and (c) statistics on large corpora The first two methods rely entirely on the information contained in WordNet, while the third one uses other corpora Specifically, the sources of knowledge available to us ate (1) lexical information that includes part of speech, position of words (i e head word), and lexical relations (2) collocations and syntactic patterns, (3) synset to which a gloss belongs, (4) hypernyms of sy nset and their glosses (5) synsets of poly semouns words and their glosses, (6) hypernyms of synsets of polysemous words, and their glosses, and so on Method 1 Classes of heuristics for word sense disambiguation A suitable technique for disambiguating dictionaries is to rely on heuristics able to cope with different sources of information Work in tins area was done by Ravin (Rat in 1990) in a similar project at IBM, (Klavans et al 1990), and others We present now some of the heuristics used by us A way of explaining a concept is to specialize a more general concept (i e a hypernym) It is likely that an explanation begins with a phrase whose head is one of its hypernyms, and the features are expressed either as attributes in the same phrase or as phrases attached to the first phrase Example The gloss of synset {intrusion} is (entrance by force or without permission or welcome) It is likely that the syntactic parallelism of two words translates into semantic parallelism and the words may have a common hypernym, or one is a hypernym of the other For adjectives, the hyperny my is replaced by the similarity relation Other heuristics in this class check whether or not two polysemous words belong to the same synset, or one is a hyperny m of the other, or if they belong to the same hierarchy Example The gloss of {interaction} is (a mutual or reciprocal action) In glosses, comments and examples are meant to provide supplemental information It is possible to find the specialization or typical relation linking the comment to the preceding head phrase in one of the synsets (or gloss) of the head phrase Example The gloss of the synset {scuff, scuffing} is (the act of scuffing (scraping or dragging the feet)) Examples in WordNet provide collocatronal information of the words in synsets The intrinsic semantic tag of the word from the synset which is used in the example can occur in the same lexical relation in some other gloss, carrying the semantic tag with it Example Synset {penetration} has the gloss (the act of forcing a way into something) Nouns representing actions are nominalizations of some verbs If a verbal collocation contains a noun, and is also a synonym of some morphologically related verb, then it is likely to be the nommalization source The verb from the gloss of a synonym describing an action, if not the source of the nominalization is likely to belong to the same hierarchy as the true nommalization source, since they must share some properties Example Let s = {escape, flight}, with the gloss (the act of escaping physically) A. lexical relation using a word w both in the gloss of a sy nsct s and in some other gloss signals a property of w associated NI lth S In other cases when two relations [w17w.,] and [zu,1 WA.] are found in two glosses of WordNet, and there are senses of w, and wk that have a common hypernym, it is likely that the correlation between w, and the common hypernym is projected in both collocations Example The gloss of the synset {Underground Railroad} is (abolitionists secret aid to escaping slaves) Method 2 Conceptual density method We have implemented a WSD system for free text that disambiguates multiple words simultaneously (NIrhalcea and NIoldovan, 1999) The method is based on measuring the number of common nouns shared by the verb and noun hierarchies, and thus gets around the lack of connections problem As an example, consider a verb - noun pair of words Denote with < vt,v2„ vh > and < ni, n2, ,711 > the senses of the verb and the noun in dNet For each possible pan v, — n„, the conceptual density is computed as follows 1 Extract all the glosses from the sub-hierarchy of th and determine the nouns from these glosses This constitutes the noun-context of verb v, Each such noun is stored together with a weight w that indicates the level in the sub-hierarchy of the verb concept in whose gloss the noun was found 2 Determine the glosses of the noun sub-hierarchy of nj and determine the nouns in them 3 Compute the conceptual density Cij of the common concepts between the nouns obtained at (1) and the nouns obtained at (2) using the metric EWk = loy(descendentsi) where 4 C,, ranks each pair v, — nj, for all z and j Vanants of this method work for other parts of speech pairs such as noun-noun, noun-verb, verb-verb, verb-noun, adjective-noun and verb-adverb This is a powerful method that works surprisingly well even for free text We haNe tested the method on SemCor, the part of the Brown corpus tagged with WordNet senses With this technique it is possible to rank the senses and to keep not only the first ranked sense, but the second or thud ranked senses especially when the ranking is sufficiently close and there is another way to check the validity of the disambiguation As a last resort, we can use a statistical approach to disambiguate those words that can not be done with any of the methods described so far Consider a collocating word-word pair w1 — w2 in which we consider that wi has been disambiguated already The disambiguation of w2 proceeds as follows { woul,&quot; OR w1w21(1)&quot; OR &quot;w1w;(21)&quot; We have searched the Internet using the AltaVista search engine The number of hits for each similarity list measures the relatedness of wi with each sense to; and thus provides a ranking of the senses The following procedure was used to disambiguate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words - that have only one sense in WordNet (in our experiment 6468 words were found) Step 2 Apply Method 1 - Heuristics - to the remaining 6294 polysemous words Method 1 provides correct disambiguation for 5475 words, thus an accuracy of 87% Out of the remaining 13% of the words, 3% were disambiguated erroneously and 10% could not be done with the heuristics used The collect sense for each word was determined manually by a team of three students We ha‘e found a few s3 nsets such as {commemorate, remember} that have no links to any other synsets, ie no h3 perny ms and no hypomy nis Step 3 Apply Method 2 - Conceptual Density - to the 6294 polysemous words, star ting fresh Step 4 Apply Method 3 - Statistics - to the 6294 words using AltaN ista on the Internet Step 5 The results obtained with Method 1 and Method 2 are combined, that is, take all the words that were disambiguated, and in the case of conflict give priority to Method 1 Step 6 The results from Step 5 are combined with the results given by Method 3 and in the case of conflict give priority to results obtained in Step 5 Table 1 indicates the accuracy obtained at each step An overall accuracy of 94% was achieved Our goal is to improve the technique to be able to disambiguate all words automatically These results must be seen against the background average rate of 59 39% correct sense assignment achieved when the first WordNet sense is assigned to each polysemous word This is considered the baseline performance level for word-sense disambiguation programs (Gale et al 1992) and is consistent with our own measurements</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W99-0501.txt | Citing Article:  P07-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The transformation of WordNet into a graph based on the I relation would of course be nontrivial, but is luckily provided by eXtended WordNet (Harabagiu et al, 1999), a publicly available version of WordNet in which (among other things) each term sk occurring in a WordNet gloss (except those in example phrases) is lemmatized and mapped to the synset in which it belongs.</S> | Reference Offset:  ['2','7'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 7 ssid = >Many NLP problems iely on the recognition of the typical lexico-semantic telationships between linguistic concepts The LFT codification met ely acknowledges the following syntax-based relationships (1) syntactic subjects, (2) syntactic objects (3) prepositional attachments (4) complex norninals and (5) adjectival/adverbial adjuncts Semantic interpretations of utterances, as %%ell as discoui se piocessing require knowledge about the semantic or thematic relationships between concepts The semantic form transformations provide with constraint-based mappings of the syntax-based relations covered in the LFTs into binary thematic relations or semantic relations (We distinguish between thematic telations such as agent, expenencer, etc, and semantic relations such as a-kind-of, part-of, etc) Approach to implement Semantic Form Transformations (SFTs) 1 The syntactic subject relations iecognized in the LFTs by the predicative formula subject(xi )&verb(e, 1, 3,2) can be mapped into a N anety of thematic relations The definition of the thematic relations is entirely based on infoimation Internal to the WordNet database, exptessed as constraints Foi example, all the subjects of verbs that are hyponyms of the verb cause or have this concept as the genus of then glosses are defined to represent the tole of agents (2) The syntactic object telations ate iecognized in the LFTs 1),. the predicative toimula verb(ei,xi,x)) & noun(z2) The definition of the thematic relations in which syntactic objects can be mapped is expressed in terms of verb synsets The constraining verb synsets tepresent the upper-most hypernyms of all verbs that (z) have syntactic objects in the WordNet glosses and (ii) belong to the same hierarchy or ate defined by gloss gent from the same hiei archy (3) The prepositional predicates ale tiansfoimed into thematic °I semantic relations When a WotdNet semantic relation holds between the arguments of a prepositional predicate, that specific relation becomes the semantic transformation of the predicate For example, the PP attachment [sacrament of penance} derived from the gloss of {confession} indicates a semantic kind-of relation due to the fact that in WordNet penance is a hyponym of sacrament (4) The transformation of complex nominal predicates into thematic or semantic constraints is done by first seeking a WordNet relation (or a combination of such relations) between the components of the predicate If such a (chain of) relation(s) is found, predicate nn is transformed into the dominant WordNet semantic relation Otherwise, the nn predicate is transformed into a thematic relation (5) The transformation of adjectival and adverbial adjuncts, represented in the LFTs as predicates sharing the same argument with the concepts they modify shall be connected to their modifiers through attribute relations</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W99-0501.txt | Citing Article:  W07-2043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The eXtended WordNet (Harabagiu et al, 1999) project aims to transform the WordNet glosses into a format that allows the derivation of additional semantic and logic relations.</S> | Reference Offset:  ['2','7'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 7 ssid = >Many NLP problems iely on the recognition of the typical lexico-semantic telationships between linguistic concepts The LFT codification met ely acknowledges the following syntax-based relationships (1) syntactic subjects, (2) syntactic objects (3) prepositional attachments (4) complex norninals and (5) adjectival/adverbial adjuncts Semantic interpretations of utterances, as %%ell as discoui se piocessing require knowledge about the semantic or thematic relationships between concepts The semantic form transformations provide with constraint-based mappings of the syntax-based relations covered in the LFTs into binary thematic relations or semantic relations (We distinguish between thematic telations such as agent, expenencer, etc, and semantic relations such as a-kind-of, part-of, etc) Approach to implement Semantic Form Transformations (SFTs) 1 The syntactic subject relations iecognized in the LFTs by the predicative formula subject(xi )&verb(e, 1, 3,2) can be mapped into a N anety of thematic relations The definition of the thematic relations is entirely based on infoimation Internal to the WordNet database, exptessed as constraints Foi example, all the subjects of verbs that are hyponyms of the verb cause or have this concept as the genus of then glosses are defined to represent the tole of agents (2) The syntactic object telations ate iecognized in the LFTs 1),. the predicative toimula verb(ei,xi,x)) & noun(z2) The definition of the thematic relations in which syntactic objects can be mapped is expressed in terms of verb synsets The constraining verb synsets tepresent the upper-most hypernyms of all verbs that (z) have syntactic objects in the WordNet glosses and (ii) belong to the same hierarchy or ate defined by gloss gent from the same hiei archy (3) The prepositional predicates ale tiansfoimed into thematic °I semantic relations When a WotdNet semantic relation holds between the arguments of a prepositional predicate, that specific relation becomes the semantic transformation of the predicate For example, the PP attachment [sacrament of penance} derived from the gloss of {confession} indicates a semantic kind-of relation due to the fact that in WordNet penance is a hyponym of sacrament (4) The transformation of complex nominal predicates into thematic or semantic constraints is done by first seeking a WordNet relation (or a combination of such relations) between the components of the predicate If such a (chain of) relation(s) is found, predicate nn is transformed into the dominant WordNet semantic relation Otherwise, the nn predicate is transformed into a thematic relation (5) The transformation of adjectival and adverbial adjuncts, represented in the LFTs as predicates sharing the same argument with the concepts they modify shall be connected to their modifiers through attribute relations</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W99-0501.txt | Citing Article:  W03-1023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In parallel, efforts have been made to enrich WordNet by adding information in glosses (Harabagiu et al, 1999).</S> | Reference Offset:  ['2','4'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 4 ssid = >There are several differences between gloss disambiguation and text disambiguation A major difference is that in our project we know the meaning of each gloss, namely the synset to which a gloss applies Second, the glosses contain a definition, comments, and one or more examples We address the word sense disambiguation problem by using three complementary methods (a) heuristics, (b) conceptual density, and (c) statistics on large corpora The first two methods rely entirely on the information contained in WordNet, while the third one uses other corpora Specifically, the sources of knowledge available to us ate (1) lexical information that includes part of speech, position of words (i e head word), and lexical relations (2) collocations and syntactic patterns, (3) synset to which a gloss belongs, (4) hypernyms of sy nset and their glosses (5) synsets of poly semouns words and their glosses, (6) hypernyms of synsets of polysemous words, and their glosses, and so on Method 1 Classes of heuristics for word sense disambiguation A suitable technique for disambiguating dictionaries is to rely on heuristics able to cope with different sources of information Work in tins area was done by Ravin (Rat in 1990) in a similar project at IBM, (Klavans et al 1990), and others We present now some of the heuristics used by us A way of explaining a concept is to specialize a more general concept (i e a hypernym) It is likely that an explanation begins with a phrase whose head is one of its hypernyms, and the features are expressed either as attributes in the same phrase or as phrases attached to the first phrase Example The gloss of synset {intrusion} is (entrance by force or without permission or welcome) It is likely that the syntactic parallelism of two words translates into semantic parallelism and the words may have a common hypernym, or one is a hypernym of the other For adjectives, the hyperny my is replaced by the similarity relation Other heuristics in this class check whether or not two polysemous words belong to the same synset, or one is a hyperny m of the other, or if they belong to the same hierarchy Example The gloss of {interaction} is (a mutual or reciprocal action) In glosses, comments and examples are meant to provide supplemental information It is possible to find the specialization or typical relation linking the comment to the preceding head phrase in one of the synsets (or gloss) of the head phrase Example The gloss of the synset {scuff, scuffing} is (the act of scuffing (scraping or dragging the feet)) Examples in WordNet provide collocatronal information of the words in synsets The intrinsic semantic tag of the word from the synset which is used in the example can occur in the same lexical relation in some other gloss, carrying the semantic tag with it Example Synset {penetration} has the gloss (the act of forcing a way into something) Nouns representing actions are nominalizations of some verbs If a verbal collocation contains a noun, and is also a synonym of some morphologically related verb, then it is likely to be the nommalization source The verb from the gloss of a synonym describing an action, if not the source of the nominalization is likely to belong to the same hierarchy as the true nommalization source, since they must share some properties Example Let s = {escape, flight}, with the gloss (the act of escaping physically) A. lexical relation using a word w both in the gloss of a sy nsct s and in some other gloss signals a property of w associated NI lth S In other cases when two relations [w17w.,] and [zu,1 WA.] are found in two glosses of WordNet, and there are senses of w, and wk that have a common hypernym, it is likely that the correlation between w, and the common hypernym is projected in both collocations Example The gloss of the synset {Underground Railroad} is (abolitionists secret aid to escaping slaves) Method 2 Conceptual density method We have implemented a WSD system for free text that disambiguates multiple words simultaneously (NIrhalcea and NIoldovan, 1999) The method is based on measuring the number of common nouns shared by the verb and noun hierarchies, and thus gets around the lack of connections problem As an example, consider a verb - noun pair of words Denote with < vt,v2„ vh > and < ni, n2, ,711 > the senses of the verb and the noun in dNet For each possible pan v, — n„, the conceptual density is computed as follows 1 Extract all the glosses from the sub-hierarchy of th and determine the nouns from these glosses This constitutes the noun-context of verb v, Each such noun is stored together with a weight w that indicates the level in the sub-hierarchy of the verb concept in whose gloss the noun was found 2 Determine the glosses of the noun sub-hierarchy of nj and determine the nouns in them 3 Compute the conceptual density Cij of the common concepts between the nouns obtained at (1) and the nouns obtained at (2) using the metric EWk = loy(descendentsi) where 4 C,, ranks each pair v, — nj, for all z and j Vanants of this method work for other parts of speech pairs such as noun-noun, noun-verb, verb-verb, verb-noun, adjective-noun and verb-adverb This is a powerful method that works surprisingly well even for free text We haNe tested the method on SemCor, the part of the Brown corpus tagged with WordNet senses With this technique it is possible to rank the senses and to keep not only the first ranked sense, but the second or thud ranked senses especially when the ranking is sufficiently close and there is another way to check the validity of the disambiguation As a last resort, we can use a statistical approach to disambiguate those words that can not be done with any of the methods described so far Consider a collocating word-word pair w1 — w2 in which we consider that wi has been disambiguated already The disambiguation of w2 proceeds as follows { woul,&quot; OR w1w21(1)&quot; OR &quot;w1w;(21)&quot; We have searched the Internet using the AltaVista search engine The number of hits for each similarity list measures the relatedness of wi with each sense to; and thus provides a ranking of the senses The following procedure was used to disambiguate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words - that have only one sense in WordNet (in our experiment 6468 words were found) Step 2 Apply Method 1 - Heuristics - to the remaining 6294 polysemous words Method 1 provides correct disambiguation for 5475 words, thus an accuracy of 87% Out of the remaining 13% of the words, 3% were disambiguated erroneously and 10% could not be done with the heuristics used The collect sense for each word was determined manually by a team of three students We ha‘e found a few s3 nsets such as {commemorate, remember} that have no links to any other synsets, ie no h3 perny ms and no hypomy nis Step 3 Apply Method 2 - Conceptual Density - to the 6294 polysemous words, star ting fresh Step 4 Apply Method 3 - Statistics - to the 6294 words using AltaN ista on the Internet Step 5 The results obtained with Method 1 and Method 2 are combined, that is, take all the words that were disambiguated, and in the case of conflict give priority to Method 1 Step 6 The results from Step 5 are combined with the results given by Method 3 and in the case of conflict give priority to results obtained in Step 5 Table 1 indicates the accuracy obtained at each step An overall accuracy of 94% was achieved Our goal is to improve the technique to be able to disambiguate all words automatically These results must be seen against the background average rate of 59 39% correct sense assignment achieved when the first WordNet sense is assigned to each polysemous word This is considered the baseline performance level for word-sense disambiguation programs (Gale et al 1992) and is consistent with our own measurements</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W99-0501.txt | Citing Article:  C04-1194.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Hence, it is not very surprising that they were criticized, as in (Harabagiu et al, 1999), for not being suitable for Natural Language Processing.</S> | Reference Offset:  ['2','4'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 4 ssid = >There are several differences between gloss disambiguation and text disambiguation A major difference is that in our project we know the meaning of each gloss, namely the synset to which a gloss applies Second, the glosses contain a definition, comments, and one or more examples We address the word sense disambiguation problem by using three complementary methods (a) heuristics, (b) conceptual density, and (c) statistics on large corpora The first two methods rely entirely on the information contained in WordNet, while the third one uses other corpora Specifically, the sources of knowledge available to us ate (1) lexical information that includes part of speech, position of words (i e head word), and lexical relations (2) collocations and syntactic patterns, (3) synset to which a gloss belongs, (4) hypernyms of sy nset and their glosses (5) synsets of poly semouns words and their glosses, (6) hypernyms of synsets of polysemous words, and their glosses, and so on Method 1 Classes of heuristics for word sense disambiguation A suitable technique for disambiguating dictionaries is to rely on heuristics able to cope with different sources of information Work in tins area was done by Ravin (Rat in 1990) in a similar project at IBM, (Klavans et al 1990), and others We present now some of the heuristics used by us A way of explaining a concept is to specialize a more general concept (i e a hypernym) It is likely that an explanation begins with a phrase whose head is one of its hypernyms, and the features are expressed either as attributes in the same phrase or as phrases attached to the first phrase Example The gloss of synset {intrusion} is (entrance by force or without permission or welcome) It is likely that the syntactic parallelism of two words translates into semantic parallelism and the words may have a common hypernym, or one is a hypernym of the other For adjectives, the hyperny my is replaced by the similarity relation Other heuristics in this class check whether or not two polysemous words belong to the same synset, or one is a hyperny m of the other, or if they belong to the same hierarchy Example The gloss of {interaction} is (a mutual or reciprocal action) In glosses, comments and examples are meant to provide supplemental information It is possible to find the specialization or typical relation linking the comment to the preceding head phrase in one of the synsets (or gloss) of the head phrase Example The gloss of the synset {scuff, scuffing} is (the act of scuffing (scraping or dragging the feet)) Examples in WordNet provide collocatronal information of the words in synsets The intrinsic semantic tag of the word from the synset which is used in the example can occur in the same lexical relation in some other gloss, carrying the semantic tag with it Example Synset {penetration} has the gloss (the act of forcing a way into something) Nouns representing actions are nominalizations of some verbs If a verbal collocation contains a noun, and is also a synonym of some morphologically related verb, then it is likely to be the nommalization source The verb from the gloss of a synonym describing an action, if not the source of the nominalization is likely to belong to the same hierarchy as the true nommalization source, since they must share some properties Example Let s = {escape, flight}, with the gloss (the act of escaping physically) A. lexical relation using a word w both in the gloss of a sy nsct s and in some other gloss signals a property of w associated NI lth S In other cases when two relations [w17w.,] and [zu,1 WA.] are found in two glosses of WordNet, and there are senses of w, and wk that have a common hypernym, it is likely that the correlation between w, and the common hypernym is projected in both collocations Example The gloss of the synset {Underground Railroad} is (abolitionists secret aid to escaping slaves) Method 2 Conceptual density method We have implemented a WSD system for free text that disambiguates multiple words simultaneously (NIrhalcea and NIoldovan, 1999) The method is based on measuring the number of common nouns shared by the verb and noun hierarchies, and thus gets around the lack of connections problem As an example, consider a verb - noun pair of words Denote with < vt,v2„ vh > and < ni, n2, ,711 > the senses of the verb and the noun in dNet For each possible pan v, — n„, the conceptual density is computed as follows 1 Extract all the glosses from the sub-hierarchy of th and determine the nouns from these glosses This constitutes the noun-context of verb v, Each such noun is stored together with a weight w that indicates the level in the sub-hierarchy of the verb concept in whose gloss the noun was found 2 Determine the glosses of the noun sub-hierarchy of nj and determine the nouns in them 3 Compute the conceptual density Cij of the common concepts between the nouns obtained at (1) and the nouns obtained at (2) using the metric EWk = loy(descendentsi) where 4 C,, ranks each pair v, — nj, for all z and j Vanants of this method work for other parts of speech pairs such as noun-noun, noun-verb, verb-verb, verb-noun, adjective-noun and verb-adverb This is a powerful method that works surprisingly well even for free text We haNe tested the method on SemCor, the part of the Brown corpus tagged with WordNet senses With this technique it is possible to rank the senses and to keep not only the first ranked sense, but the second or thud ranked senses especially when the ranking is sufficiently close and there is another way to check the validity of the disambiguation As a last resort, we can use a statistical approach to disambiguate those words that can not be done with any of the methods described so far Consider a collocating word-word pair w1 — w2 in which we consider that wi has been disambiguated already The disambiguation of w2 proceeds as follows { woul,&quot; OR w1w21(1)&quot; OR &quot;w1w;(21)&quot; We have searched the Internet using the AltaVista search engine The number of hits for each similarity list measures the relatedness of wi with each sense to; and thus provides a ranking of the senses The following procedure was used to disambiguate 12,762 words from 1000 randomly selected glosses Step 1 Identify and separate the monosemous words - that have only one sense in WordNet (in our experiment 6468 words were found) Step 2 Apply Method 1 - Heuristics - to the remaining 6294 polysemous words Method 1 provides correct disambiguation for 5475 words, thus an accuracy of 87% Out of the remaining 13% of the words, 3% were disambiguated erroneously and 10% could not be done with the heuristics used The collect sense for each word was determined manually by a team of three students We ha‘e found a few s3 nsets such as {commemorate, remember} that have no links to any other synsets, ie no h3 perny ms and no hypomy nis Step 3 Apply Method 2 - Conceptual Density - to the 6294 polysemous words, star ting fresh Step 4 Apply Method 3 - Statistics - to the 6294 words using AltaN ista on the Internet Step 5 The results obtained with Method 1 and Method 2 are combined, that is, take all the words that were disambiguated, and in the case of conflict give priority to Method 1 Step 6 The results from Step 5 are combined with the results given by Method 3 and in the case of conflict give priority to results obtained in Step 5 Table 1 indicates the accuracy obtained at each step An overall accuracy of 94% was achieved Our goal is to improve the technique to be able to disambiguate all words automatically These results must be seen against the background average rate of 59 39% correct sense assignment achieved when the first WordNet sense is assigned to each polysemous word This is considered the baseline performance level for word-sense disambiguation programs (Gale et al 1992) and is consistent with our own measurements</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W99-0501.txt | Citing Article:  S10-1056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >They use sense disambiguated glosses provided by eXtended WordNet (Harabagiu et al, 1999) to link synsets by starting with positive (or negative) sentiment concepts in order to find other concepts with positive (or negative) sentiment values.</S> | Reference Offset:  ['2','8'] | Reference Text:  <S sid = 2 ssid = >WordNet has already been x ecogmzed as a valuable iesource in the human language technology and know ledge processing communities Its applicability has been cited in mote than 200 papers and s)stems have been implemented using WordNet A WordNet brbliogi apt* is maintained at the Universit3 of Penns), 11, ania (http //www cis upenn edu/-3osephr/wnMho html) In Europe, WordNet is being used to develop a multilingual database with basic semantic relations between words for several European languages (the EuroWordNet project) Capabilities WordNet was conceived as a machine-readable dictionary, following psycholinguistic principles Unlike standard alphabetical dictionaries which otganize vocabularies using mot phological similaiities, WordNet structures lexical information in terms of word meanings WordNet maps word forms in word senses using the syntactic category as a parametei Although it covers only foui patts of speech nouns verbs, adjectives and ady erbs, it encompasses a large majority of English words (http //www cogsc: princeton edu/wn) Woids of the same syntactic categoiy that can be used to express the same meaning are grouped into a single synonym set, called synset Words with multiple meanings (polysemous) belong to multiple synsets An important part of the 99 643 synsets encoded in WordNet 1 6 contain word collocations, thus representing complex nominals (e g the synset {manufacturer, maker, manufacturing business} , complex veibals (e g the synset {leave office, quit, step down}, complex adjectivals (e g the synset {true, dead on target} or complex adverbials (e g the synset {out of hand, beyond control} The representation of collocations as synset entries plovides for their semantic interpretation Words and concepts are further connected through a small set of lexico-semantic relations The dominant semantic relation is the hypernymy, which structures the noun concepts in 11 hierarchies and the verb concepts into 312 hierarchies Thiee meionym relations are encoded between noun concepts the has_member, the has_stuff and the has_part relations Logical operations between events or entities ate modeled through entailment and cause_to ielations between vei b concepts or antonymy relations among nouns, vet bs adjectives or adverb words Theie are only a few momphologically motivated connections between words known as pertaynym relations Limitations The main weaknesses of WoidNet cited in the litelature aie 2 Limited number of connections between topically related words 3 The lack of morphological relations 4 The absence of thematic relations/ selectional restrictions 5 Some concepts (word senses) and relations are missing 6 Since glosses were written manually, sometimes theie is a lack of uniformity and consistency in the definitions The key idea in our project is to put to work the rich sourse of information contained in glosses that now can be used only by humans to read the definition of synsets For example, WordNet 16 lists the concept {cat, true cat} with the gloss (feline mammal usually having thick soft fur and being unable to roar, domestic cats, wildcats) Currently, from a concept like this, only a few other concepts could be reached In Extended WordNet, the concept {cat, true cat} will be related to 215 other concepts (10 from its own gloss, 38 from the glosses of its hypernyms, 25 concepts that use it in their glosses as a defining concept plus other 142 concepts with which the concept interacts in these 25 glosses) This level of information is rich enough to presume that the Extended WordNet will work well as a knowledge base for common-sense reasoning</S><S sid = 8 ssid = >Since the organization of WordNet divides the English vocabulary into four separate domains-nouns, verbs, adjectives, and adverbs- closely related concepts are often entered in more than one of these domains Many (probably most) of these relations can be identified in terms of derivational morphology, e g, the noun execution is derived from the verb execute and so is an example of a deverbal noun WordNet already contains some of this kind of derivational morphology deadjectival nouns are linked to their root adjectives (length is derived twin long), deadjectival adverbs are linked to then root adjectnes (rapidly is derived from rapid), and some denominal adjectives are linked to then root nouns (cellular is derived from cell) In order to increase the connectivity of WordNet it would be desirable to include more such derivational morphology For example, derivational relations between nouns and verbs should be particularly useful (Hull and Gomez 1996) both deverbal nouns (avowal from avow) and denominal verbs (summarize from summary) Such connections would facilitate the recognition that the same idea can be expressed in different ways, e g , that &quot;He summarized the book&quot; and &quot;He gave a summary of the book&quot; are effectively equivalent in meaning Sometimes these morphological relations can be picked up from glosses, as when {disagreement} is defined as (the speech act of disagreeing or arguing or disputing), but these are generally regarded as uninformative definitions, and the reverse relation may not happen to occur Since many of the words are polysemous, morphological relations should not link words, but synsets that have related meanings For example, {execute} meaning (to put to death) should be linked to {execution} meaning (the act of putting a condemned person to death), and {execute} meaning (to carry out a task) should be linked to {execution} meaning (the act of doing something successfully), etc And in cases where the concepts of the noun and verb are different-e g, {womanize} from {woman}-no semantic link would need to be created</S> | Discourse Facet:  NA | Annotator: Automatic


