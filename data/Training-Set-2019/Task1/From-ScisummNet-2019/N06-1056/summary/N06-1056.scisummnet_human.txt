Learning For Semantic Parsing With Statistical Machine Translation
We present a novel statistical approach to semantic parsing, WASP, for constructing a complete, formal meaning representation of a sentence.
A semantic parser is learned given a set of sentences annotated with their correct meaning representations.
The main innovation of WASP is its use of state-of-the-art statistical machine translation techniques.
A word alignment model is used for lexical acquisition, and the parsing model itself can be seen as a syntax-based translation model.
We show that WASP performs favorably in terms of both accuracy and coverage compared to existing learning methods requiring similar amount of supervision, and shows better robustness to variations in task complexity and word order.
We use the maximum-entropy model, which defines a conditional probability distribution over derivations given an observed NL sentence.
