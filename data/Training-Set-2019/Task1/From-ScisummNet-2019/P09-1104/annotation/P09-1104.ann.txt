Citance Number: 1 | Reference Article:  P09-1104.txt | Citing Article:  P14-1139.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This directional model has been shown produce state-of-the art results with this setup (Haghighi et al, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>No model significantly improves over the HMM alone, which is consistent with the results of Taskar et al. (2005).</S><S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P09-1104.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In order to reduce spurious derivations, Wu (1997), Haghighi et al (2009), Liu et al (2010) propose different variations of the grammar.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = NA ssid = NA>Wu (1997)’s inversion transduction grammar (ITG) is a synchronous grammar formalism in which derivations of sentence pairs correspond to alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P09-1104.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Haghighi et al (2009) give some restrictions on null-aligned word attachment.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Null productions are also a source of double counting, as there are many possible orders in which to attach null alignments to a bitext cell; we address this by adapting the grammar to force a null attachment order.</S><S sid = NA ssid = NA>(2006), we assume the score a of a potential alignment a) decomposes as where sij are word-to-word potentials and siE and sEj represent English null and foreign null potentials, respectively.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P09-1104.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Four grammars were used to parse these alignments, namely LG (Wu, 1997), HaG (Haghighi et al, 2009), LiuG (Liu et al, 2010) and LGFN (Section 3.3).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = NA ssid = NA>The set of such ITG alignments, AITG, are a strict subset of A1-1 (Wu, 1997).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P09-1104.txt | Citing Article:  P11-2066.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To further study how spurious ambiguity affects the discriminative learning, we implemented a frame work following Haghighi et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Past work on discriminative word alignment has focused on the family of at-most-one-to-one matchings (Melamed, 2000; Taskar et al., 2005; Moore et al., 2006).</S><S sid = NA ssid = NA>In this work, we investigate large-scale, discriminative ITG word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P09-1104.txt | Citing Article:  N10-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Haghighi et al (2009) also describe a pruning heuristic that results in average case runtime of O (n 3).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = NA ssid = NA>For example, we include the average Dice of all the cells in a block.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P09-1104.txt | Citing Article:  N10-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Haghighi et al (2009) also describe a pruning heuristic that results in average case runtime of O (n 3).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = NA ssid = NA>For example, we include the average Dice of all the cells in a block.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P09-1104.txt | Citing Article:  N10-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Haghighi et al (2009) also describe a pruning heuristic that results in average case runtime of O (n 3).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S><S sid = NA ssid = NA>For example, we include the average Dice of all the cells in a block.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>However, the space of block ITG alignments is expressive enough to include the vast majority of patterns observed in hand annotated parallel corpora (Haghighi et al, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We evaluate our proposed alignments (a) against hand-annotated alignments, which are marked with sure (s) and possible (p) alignments.</S><S sid = NA ssid = NA>Indeed, blocks are the primary reason for gold alignments being outside the space of one-to-one ITG alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>MIRA has been used successfully in MT to estimate both alignment models (Haghighi et al, 2009) and translation models (Chiang et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We instead use a variant of MIRA similar to Chiang et al. (2008).</S><S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We also include indicator features on lexical templates for the 50 most common words in each language, as in Haghighi et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For features on one-by-one cells, we consider Dice, the distance features from (Taskar et al., 2005), dictionary features, and features for the 50 most frequent lexical pairs.</S><S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our models yielded the lowest published error for Chinese-English alignment and an increase in downstream translation performance.</S><S sid = NA ssid = NA>We will use BITG to refer to this block ITG variant and ABITG to refer to the alignment family, which is neither contained in nor contains A1-1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P09-1104.txt | Citing Article:  P10-1147.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This supervised base line is a reimplementation of the MIRA-trained model of Haghighi et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our supervised ITG model gave a 1.1 BLEU increase over GIZA++.</S><S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P09-1104.txt | Citing Article:  P11-1043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This training regimen on this data set has provided state-of-the-art unsupervised results that outperform IBM Model 4 (Haghighi et al., 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Table 1 illustrates results for the Hansards data set.</S><S sid = NA ssid = NA>No model significantly improves over the HMM alone, which is consistent with the results of Taskar et al. (2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P09-1104.txt | Citing Article:  N10-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The best published results for this dataset are supervised, and trained on 17 times more data (Haghighi et al, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>All in all, our discriminatively trained, block ITG models produce alignments which exhibit the best AER on the NIST 2002 Chinese-English alignment data set.</S><S sid = NA ssid = NA>The right-hand three columns in Table 2 present supervised results on our Chinese English data set using block features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>When evaluated on parsing and word alignment, this model significantly improves over independently trained baselines: the monolingual parser of Petrov and Klein (2007) and the discriminative word aligner of Haghighi et al (2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also trained an HMM aligner as described in DeNero and Klein (2007) and used the posteriors of this model as features.</S><S sid = NA ssid = NA>No model significantly improves over the HMM alone, which is consistent with the results of Taskar et al. (2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Although this assumption does limit the space of possible word-level alignments, for the domain we consider (Chinese-English word alignment), the reduced space still contains almost all empirically observed alignments (Haghighi et al, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Indeed, blocks are the primary reason for gold alignments being outside the space of one-to-one ITG alignments.</S><S sid = NA ssid = NA>Then, When a* is an ITG alignment (i.e., m* is 0), M(a*) consists only of alignments which have all the sure alignments in a*, but may have some subset of the possible alignments in a*.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We begin with the same set of alignment features as Haghighi et al (2009), which are defined only for terminal bi spans.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For features on one-by-one cells, we consider Dice, the distance features from (Taskar et al., 2005), dictionary features, and features for the 50 most frequent lexical pairs.</S><S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Because of this, given a particular word alignment w, we maximize the marginal probability of the set of derivations A (w) that are consistent with w (Haghighi et al., 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We opt instead to maximize the probability of the set of alignments M(a*) which achieve the same optimal in-class loss.</S><S sid = NA ssid = NA>No model significantly improves over the HMM alone, which is consistent with the results of Taskar et al. (2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P09-1104.txt | Citing Article:  N10-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We prune our ITG forests using the same basic idea as Haghighi et al (2009), but we employ a technique that allows us to be more aggressive.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our second pruning technique is to prune all one-by-one (word-to-word) bitext cells that have a posterior below 10−4 in both HMM models.</S><S sid = NA ssid = NA>Initially, as in Taskar et al. (2005) and Moore et al.</S> | Discourse Facet:  NA | Annotator: Automatic


