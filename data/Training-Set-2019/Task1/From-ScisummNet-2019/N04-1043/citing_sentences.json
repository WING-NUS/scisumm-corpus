[
  {
    "citance_No": 1, 
    "citing_paper_id": "W04-2603", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Robert W., Means | Syrus C., Nemat-Nasser | Adrian T., Fan | Robert, Hecht-Nielsen", 
    "raw_text": "Miller et al (2004) describe a relevant technique for the latter", 
    "clean_text": "Miller et al (2004) describe a relevant technique for the latter.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W06-1615", 
    "citing_paper_authority": 74, 
    "citing_paper_authors": "John, Blitzer | Ryan, McDonald | Fernando, Pereira", 
    "raw_text": "We chose to compare with ASO because it consistently outperforms co training (Blum and Mitchell, 1998) and clustering methods (Miller et al, 2004)", 
    "clean_text": "We chose to compare with ASO because it consistently outperforms cotraining (Blum and Mitchell, 1998) and clustering methods (Miller et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P08-1068", 
    "citing_paper_authority": 112, 
    "citing_paper_authors": "Terry, Koo | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "By using prefixes of various lengths, we can produce clusterings of different granularities (Miller et al, 2004)", 
    "clean_text": "By using prefixes of various lengths, we can produce clusterings of different granularities (Miller et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P08-1068", 
    "citing_paper_authority": 112, 
    "citing_paper_authors": "Terry, Koo | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "Following Miller et al (2004), we use prefixes of the Brown cluster hierarchy to produce clusterings of varying granularity", 
    "clean_text": "Following Miller et al (2004), we use prefixes of the Brown cluster hierarchy to produce clusterings of varying granularity.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P08-1068", 
    "citing_paper_authority": 112, 
    "citing_paper_authors": "Terry, Koo | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "We found that it was nontrivial to select the proper prefix lengths for the dependency parsing task; in particular, the prefix lengths used in the Miller et al (2004) work (between 12 and 20 bits) performed poorly in dependency parsing.2 After experimenting with many different feature configurations, we eventually settled on a simple but effective methodology", 
    "clean_text": "We found that it was nontrivial to select the proper prefix lengths for the dependency parsing task; in particular, the prefix lengths used in the Miller et al (2004) work (between 12 and 20 bits) performed poorly in dependency parsing.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P08-1068", 
    "citing_paper_authority": 112, 
    "citing_paper_authors": "Terry, Koo | Xavier, Carreras | Michael John, Collins", 
    "raw_text": "As mentioned earlier, our approach was inspired bythe success of Miller et al (2004), who demonstrated the effectiveness of using word clusters as features in a discriminative learning approach", 
    "clean_text": "As mentioned earlier, our approach was inspired by the success of Miller et al (2004), who demonstrated the effectiveness of using word clusters as features in a discriminative learning approach.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P11-1037", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Xiaohua, Liu | Shaodian, Zhang | Furu, Wei | Ming, Zhou", 
    "raw_text": "Miller et al (2004) use word clusters (Brown et al, 1992) learned from unlabeled text, resulting in a performance improvement of NER", 
    "clean_text": "Miller et al (2004) use word clusters (Brown et al, 1992) learned from unlabeled text, resulting in a performance improvement of NER.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D11-1133", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Marjorie, Freedman | Lance A., Ramshaw | Elizabeth, Boschee | Ryan, Gabbard | Gary, Kratkiewicz | Nicolas, Ward | Ralph M., Weischedel", 
    "raw_text": "lower than in Miller et al (2004) (an F1 of 90 with less than 25K words of training)", 
    "clean_text": "Given the amount of training, our results are lower than in Miller et al (2004) (an F1 of 90 with less than 25K words of training).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P08-1056", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Sujan Kumar, Saha | Pabitra, Mitra | Sudeshna, Sarkar", 
    "raw_text": "A hierarchical word clustering technique, where clusters are driven automatically from large unan 494 Feature Using Word Features Using Words (I1) Using Words (I2) Using Words (I3 )wi, window (-1, +1) 67.26 66.31 67.53 66.8wi, window (-2, +2) 69.09 72.04 72.9 73.34wi, window (-1, +1), Suffix 73.42 73.85 73.12 74.61wi, window (-1, +1), Prefix, Suffix 72.5 73.52 73.94 74.87wi, window (-1, +1), Prefix, Suffix, Digit 74.26 73.97 74.13 74.7wi, window (-1, +1), Prefix, Suffix, Digit, NomPSP 75.6 75.84 76.6 77.22wi, window (-2, +2), Prefix, Suffix, Digit, NomPSP 72.65 76.69 77.42 79.85 Table 6: F-values for different features in a MaxEnt based Hindi NER with important word based feature reduction [window (? m, +n) refers to the important word or baseline word features corresponding to previous m positions and next n positions; I1 is the class independent important words (4.1), I2 denotes the important words for each class (4.2), I3 denotes the important words for each positions (4.3)] notated corpus, is used by Miller et al (2004) for augmenting annotated training data", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P11-1053", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Ang, Sun | Ralph, Grishman | Satoshi, Sekine", 
    "raw_text": "Though all of them used the same hierarchical word clustering algorithm for the task of name tagging and reported improvements, we noticed that the clusters used by Miller et al (2004) were quite different from that of Ratinov and Roth (2009) and Turian et al (2010)", 
    "clean_text": "Though all of them used the same hierarchical word clustering algorithm for the task of name tagging and reported improvements, we noticed that the clusters used by Miller et al (2004) were quite different from that of Ratinov and Roth (2009) and Turian et al (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W06-0206", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Heng, Ji | Ralph, Grishman", 
    "raw_text": "It has shown promise in improving the performance of many tasks such as name tagging (Miller et al, 2004), semantic class extraction (Lin et al, 2003), chunking (Ando and Zhang, 2005), co reference resolution (Bean and Riloff, 2004) and text classification (Blum and Mitchell, 1998)", 
    "clean_text": "It has shown promise in improving the performance of many tasks such as name tagging (Miller et al, 2004), semantic class extraction (Lin et al, 2003), chunking (Ando and Zhang, 2005), coreference resolution (Bean and Riloff, 2004) and text classification (Blum and Mitchell, 1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P09-1116", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Dekang, Lin | Xiaoyun, Wu", 
    "raw_text": "This method has been shown to be quite successful in named entity recognition (Miller et al. 2004) and dependency parsing (Koo et al, 2008)", 
    "clean_text": "This method has been shown to be quite successful in named entity recognition (Miller et al. 2004) and dependency parsing (Koo et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P09-1116", 
    "citing_paper_authority": 26, 
    "citing_paper_authors": "Dekang, Lin | Xiaoyun, Wu", 
    "raw_text": "Previous approaches ,e.g., (Miller et al 2004) and (Koo et al 2008), have all used the Brown algorithm for clustering (Brown et al 1992)", 
    "clean_text": "Previous approaches ,e.g., (Miller et al 2004) and (Koo et al 2008), have all used the Brown algorithm for clustering (Brown et al 1992).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C10-2137", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ang, Sun | Ralph, Grishman", 
    "raw_text": "Miller et al, (2004) augmented name tagging training data with hierarchical word clusters and encoded cluster membership in features for improving name tagging", 
    "clean_text": "Miller et al, (2004) augmented name tagging training data with hierarchical word clusters and encoded cluster membership in features for improving name tagging.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D11-1090", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Weiwei, Sun | Jia, Xu", 
    "raw_text": "This simple solution has been shown effective for named entity recognition (Miller et al, 2004) and dependency parsing (Koo et al, 2008)", 
    "clean_text": "This simple solution has been shown effective for named entity recognition (Miller et al, 2004) and dependency parsing (Koo et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D11-1090", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Weiwei, Sun | Jia, Xu", 
    "raw_text": "semi-supervised approach has been successfully applied to named entity recognition (Miller et al, 2004) and dependency parsing (Koo et al, 2008)", 
    "clean_text": "Semi-supervised approach has been successfully applied to named entity recognition (Miller et al, 2004) and dependency parsing (Koo et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W12-1914", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Grzegorz, Chrupa{l}a", 
    "raw_text": "Second, learning categories has been cast as unsupervised part-of-speech tagging task (recent work includes Ravi and Knight (2009), Lee et al (2010), Lamar et al (2010), Christodoulopoulos et al (2011)), and primarily motivated as useful for tagging under-resourced languages. Finally, learning categories has also been re searched from the point of view of feature learning, where the induced categories provide an inter me diate level of representation, abstracting away and generalizing over word form features in an NLPap plication (Brown et al 1992, Miller et al 2004, Lin and Wu 2009, Turian et al 2010, Chrupala 2011, Ta ?ckstro? m et al 2012)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "N09-1020", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Gholamreza, Haffari | Yee, Whye Teh", 
    "raw_text": "See Figure 2. (Miller et al, 2004) cut the BCluster tree at acer tain depth k to simplify the tree, meaning every leaf descending from a particular internal node at level k is made an immediate child of that node", 
    "clean_text": "(Miller et al, 2004) cut the BCluster tree at a certain depth k to simplify the tree, meaning every leaf descending from a particular internal node at level k is made an immediate child of that node.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "N09-1032", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Hong Lei, Guo | Huijia, Zhu | Zhili, Guo | Xiaoxun, Zhang | Xian, Wu | Zhong, Su", 
    "raw_text": "In addition, Miller et al (2004) and Freitag (2004) employ distributional and hierarchical clustering methods to improve the performance of NER within a single domain", 
    "clean_text": "In addition, Miller et al (2004) and Freitag (2004) employ distributional and hierarchical clustering methods to improve the performance of NER within a single domain.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P08-1099", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Gideon S., Mann | Andrew, McCallum", 
    "raw_text": "Oneapproach has been that proposed in both Miller et al (2004) and Freitag (2004), uses distributional clustering to induce features from a large corpus, and then uses these features to augment the feature space of the labeled data", 
    "clean_text": "One approach has been that proposed in both Miller et al (2004) and Freitag (2004), uses distributional clustering to induce features from a large corpus, and then uses these features to augment the feature space of the labeled data.", 
    "keep_for_gold": 0
  }
]