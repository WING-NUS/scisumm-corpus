[
  {
    "citance_No": 1, 
    "citing_paper_id": "N04-1001", 
    "citing_paper_authority": 42, 
    "citing_paper_authors": "Radu, Florian | Hany, Hassan | Abraham, Ittycheriah | Hongyan, Jing | Nanda, Kambhatla | Xiaoqiang, Luo | Nicolas, Nicolov | Salim, Roukos", 
    "raw_text": "The segmentation model is similar to the one presented by Lee et al (2003), and obtains an accuracy of about 98% .In addition, special attention is paid to prefixes and suffixes: in order to reduce the number of spurious tokens we re-merge the prefixes or suffixes to their corresponding stem if they are not essential to the classification process", 
    "clean_text": "The segmentation model is similar to the one presented by Lee et al (2003), and obtains an accuracy of about 98%.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P13-1110", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Vladimir, Eidelman | Yuval, Marton | Philip, Resnik", 
    "raw_text": "For training, we used the non-UN portion of theNIST training corpora, which was segmented using an HMMsegmenter (Lee et al, 2003)", 
    "clean_text": "For training, we used the non-UN portion of the NIST training corpora, which was segmented using an HMMsegmenter (Lee et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "N12-1023", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Kevin, Gimpel | Noah A., Smith", 
    "raw_text": "The Arabic data was preprocessed using an HMMsegmenter that splits off attached prepositional phrases, personal pronouns, and the future marker (Lee et al, 2003)", 
    "clean_text": "The Arabic data was preprocessed using an HMM segmenter that splits off attached prepositional phrases, personal pronouns, and the future marker (Lee et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W05-0709", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Imed, Zitouni | Jeffrey S., Sorensen | Xiaoqiang, Luo | Radu, Florian", 
    "raw_text": "Lee et al (2003) demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation", 
    "clean_text": "Lee et al (2003) demonstrates a technique for segmenting Arabic text and uses it as a morphological processing step in machine translation.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W05-0709", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Imed, Zitouni | Jeffrey S., Sorensen | Xiaoqiang, Luo | Radu, Florian", 
    "raw_text": "Differing from (Lee et al, 2003), we have also introduced an explicit model for un1As an example, we do not chain mentions with different gender, number, etc. known words based upon a character unigram model, although this model is dominated by an empirically chosen unknown word penalty", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W05-0709", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Imed, Zitouni | Jeffrey S., Sorensen | Xiaoqiang, Luo | Radu, Florian", 
    "raw_text": "As in (Lee et al, 2003), we used unsupervised training data which is automatically segmented to discover previously unseen stems", 
    "clean_text": "As in (Lee et al, 2003), we used unsupervised training data which is automatically segmented to discover previously unseen stems.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W07-0804", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Walid, Magdy | Kareem, Darwish | Ossama, Emam | Hany, Hassan", 
    "raw_text": "context sensitive Arabicstemmer (Lee et al 2003) to overcome the morphological complexity of Arabic", 
    "clean_text": "context sensitive Arabic stemmer (Lee et al 2003) to overcome the morphological complexity of Arabic.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P06-1073", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Imed, Zitouni | Jeffrey S., Sorensen | Ruhi, Sarikaya", 
    "raw_text": "To separate the Arabic white-space delimited words into segments, we use a segmentation model similar to the one presented by (Lee et al, 2003)", 
    "clean_text": "To separate the Arabic white-space delimited words into segments, we use a segmentation model similar to the one presented by (Lee et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P06-1073", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Imed, Zitouni | Jeffrey S., Sorensen | Ruhi, Sarikaya", 
    "raw_text": "We propose in the following an extension to the aforementioned FST model, where we jointly determines not only diacritics but segmentation into affixes as described in (Lee et al, 2003)", 
    "clean_text": "We propose in the following an extension to the aforementioned FST model, where we jointly determines not only diacritics but segmentation into affixes as described in (Lee et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "H05-1012", 
    "citing_paper_authority": 39, 
    "citing_paper_authors": "Abraham, Ittycheriah | Salim, Roukos", 
    "raw_text": "3.2.2 Arabic Segmentation Features An Arabicsegmenter similar to (Lee et al, 2003) provides the segmentation features", 
    "clean_text": "An Arabicsegmenter similar to (Lee et al, 2003) provides the segmentation features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "N07-1008", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Abraham, Ittycheriah | Salim, Roukos", 
    "raw_text": "This produces a segmentation view of the arabic source words (Lee et al., 2003)", 
    "clean_text": "This produces a segmentation view of the arabic source words (Lee et al., 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W06-3103", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Anas, El Isbihani | Shahram, Khadivi | Oliver, Bender | Hermann, Ney", 
    "raw_text": "In (Lee et al, 2003) a statistical approach for Arabic word segmentation was presented", 
    "clean_text": "In (Lee et al, 2003) a statistical approach for Arabic word segmentation was presented.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W06-3103", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Anas, El Isbihani | Shahram, Khadivi | Oliver, Bender | Hermann, Ney", 
    "raw_text": "In (Lee et al, 2003), (Diab et al, 2004) and (Habash and Rambow, 2005) three supervised segmentation methods are introduced", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W10-3601", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Solomon Teferra, Abate | Laurent, Besacier | Sopheap, Seng", 
    "raw_text": "The algorithm is inspired with the work on the segmentation of Arabic words (Lee et al, 2003)", 
    "clean_text": "The algorithm is inspired with the work on the segmentation of Arabic words (Lee et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P05-1071", 
    "citing_paper_authority": 85, 
    "citing_paper_authors": "Nizar, Habash | Owen, Rambow", 
    "raw_text": "Lee et al (2003) use a corpus of manually segmented words, which appears to be a sub set of the first release of the ATB (110,000 words), and thus comparable to our training corpus", 
    "clean_text": "Lee et al (2003) use a corpus of manually segmented words, which appears to be a subset of the first release of the ATB (110,000 words), and thus comparable to our training corpus.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P05-1071", 
    "citing_paper_authority": 85, 
    "citing_paper_authors": "Nizar, Habash | Owen, Rambow", 
    "raw_text": "Lee et al (2003) show that the unsupervised use of the large corpus for stem identification increases accuracy", 
    "clean_text": "Lee et al (2003) show that the unsupervised use of the large corpus for stem identification increases accuracy.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W09-0805", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Elad, Dinur | Dmitry, Davidov | Ari, Rappoport", 
    "raw_text": "Lee et al (2003) addressed supervised word segmentation in Arabic and have some aspects similar to our approach", 
    "clean_text": "Lee et al (2003) addressed supervised word segmentation in Arabic and have some aspects similar to our approach.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W09-0805", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Elad, Dinur | Dmitry, Davidov | Ari, Rappoport", 
    "raw_text": "As estimated by (Lee et al, 2003), we set the probability of ?u/k? to be 1E? 9", 
    "clean_text": "As estimated by (Lee et al, 2003), we set the probability of ?u/k? to be 1E? 9.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W09-0805", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Elad, Dinur | Dmitry, Davidov | Ari, Rappoport", 
    "raw_text": "We found that the value proposed by (Lee et al, 2003) for Arabic gives good results also for Hebrew", 
    "clean_text": "We found that the value proposed by (Lee et al, 2003) for Arabic gives good results also for Hebrew.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W05-0706", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Roy, Bar-Haim | Khalil, Sima'an | Yoad, Winter", 
    "raw_text": "Moving on to Arabic, Lee et al (2003) describe aword segmentation system for Arabic that uses an n gram language model over morphemes", 
    "clean_text": "Moving on to Arabic, Lee et al (2003) describe a word segmentation system for Arabic that uses an n gram language model over morphemes.", 
    "keep_for_gold": 0
  }
]