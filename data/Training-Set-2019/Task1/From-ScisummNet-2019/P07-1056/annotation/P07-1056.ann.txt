Citance Number: 1 | Reference Article:  P07-1056.txt | Citing Article:  D08-1072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For evaluation we selected two domain adaptation datasets :spam (Jiang and Zhai, 2007) and sentiment (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S><S sid = NA ssid = NA>First, we show how to extend the recently proposed structural correspondence learning (SCL) domain adaptation algorithm (Blitzer et al., 2006) for use in sentiment classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P07-1056.txt | Citing Article:  D08-1072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Blitzer et al (2007) used structural correspondence learning to train a classifier on source data with new features induced from target unlabeled data.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, we showed that for a given source and target domain, we can significantly improve for sentiment classification the structural correspondence learning model of Blitzer et al. (2006).</S><S sid = NA ssid = NA>As we noted in Section 5, we are able to significantly outperform basic structural correspondence learning (Blitzer et al., 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P07-1056.txt | Citing Article:  P14-2008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For these experiments we use the Multi-Domain Sentiment Dataset, introduced by Blitzer et al (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S><S sid = NA ssid = NA>First, we show how to extend the recently proposed structural correspondence learning (SCL) domain adaptation algorithm (Blitzer et al., 2006) for use in sentiment classification.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P07-1056.txt | Citing Article:  P14-2008.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We split the labeled data 80/20 following Blitzer et al (2007) (cf. Chen et al. (2012) train on all "labeled" data and test on the "unlabeled" data).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Finally we note that while Blitzer et al. (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al.</S><S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P07-1056.txt | Citing Article:  D10-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Empirical work on NLP domain shifts has focused on the former. For example, Blitzer et al (2007) learned correspondences between features across domains and Jiang and Zhai (2007) weighted source domain examples by their similarity to the target distribution. We continue in this tradition by making two assumptions about our setting.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Sections 2-5 focused on how to adapt to a target domain when you had a labeled source dataset.</S><S sid = NA ssid = NA>Finally we note that while Blitzer et al. (2006) did combine SCL with labeled target domain data, they only compared using the label of SCL or non-SCL source classifiers as features, following the work of Florian et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P07-1056.txt | Citing Article:  D10-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We selected three data sets commonly used in domain adaptation: spam (Jiang and Zhai, 2007), ACE 2005 named entity recognition (Jiang and Zhai, 2007), and sentiment (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Ando and Zhang (2005) and Blitzer et al. (2006) suggest λ = 10−4, µ = 0, which we have used in our results so far.</S><S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P07-1056.txt | Citing Article:  D10-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In a batch setting this corresponds to learning a linear classifier to discriminate the domains, and Blitzer et al (2007) showed correlations with the error from domain adaptation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, we showed that for a given source and target domain, we can significantly improve for sentiment classification the structural correspondence learning model of Blitzer et al. (2006).</S><S sid = NA ssid = NA>When it is 0, the two domains are indistinguishable using a linear classifier.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P07-1056.txt | Citing Article:  D09-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>However, such methods require the existence of either a parallel corpus/machine translation engine for projecting/translating annotations/lexica from a resource-rich language to the target language (Banea et al., 2008; Wan, 2008), or a domain that is "similar" enough to the target domain (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S><S sid = NA ssid = NA>We augment each labeled target instance xj with the label assigned by the source domain classifier (Florian et al., 2004; Blitzer et al., 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P07-1056.txt | Citing Article:  D09-1061.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use five sentiment classification datasets, including the widely-used movie review dataset [MOV] (Pang et al, 2002) as well as four datasets containing reviews of four different types of products from Amazon [books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT)] (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We constructed a new dataset for sentiment domain adaptation by selecting Amazon product reviews for four different product types: books, DVDs, electronics and kitchen appliances.</S><S sid = NA ssid = NA>We propose solutions to these two questions and evaluate them on a corpus of reviews for four different types of products from Amazon: books, DVDs, electronics, and kitchen appliances2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We show that this constraint is effective on the sentiment classification task (Pang et al, 2002), resulting in scores similar to the ones obtained by the structural correspondence methods (Blitzer et al, 2007) without the need to engineer auxiliary tasks.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Sentiment classification has advanced considerably since the work of Pang et al. (2002), which we use as our baseline.</S><S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We evaluate our approach on adapting sentiment classifiers on 4 domains: books, DVDs, electronics and kitchen appliances (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Adapting classifiers from books to DVDs, for instance, is easier than adapting them from books to kitchen appliances.</S><S sid = NA ssid = NA>This is the case for adapting from kitchen appliances to books.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Both the achieved error reduction and the absolute score match the results reported in (Blitzer et al, 2007) for the best version of the SCL method (SCL-MI, 36%), suggesting that our approach is a viable alternative to SCL.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The relative reduction in error due to adaptation of SCL-MI for this test is 90.8%.</S><S sid = NA ssid = NA>When we report results with SCL and SCL-MI, we require that pivots occur in more than five documents in each domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To evaluate our approach, we consider the same dataset as the one used to evaluate the SCL method (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Second, we evaluate the A-distance (Ben-David et al., 2006) between domains as measure of the loss due to adaptation from one to the other.</S><S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To evaluate our approach, we consider the same dataset as the one used to evaluate the SCLmethod (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Second, we evaluate the A-distance (Ben-David et al., 2006) between domains as measure of the loss due to adaptation from one to the other.</S><S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Instead of using the full set of bigram and unigram counts as features (Blitzer et al, 2007), we use a frequency cut-off of 30 to remove infrequent ngrams.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S><S sid = NA ssid = NA>We chose pivot features using not only common frequency among domains but also mutual information with the source labels.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In Table 1, we also compare the results of our method with the results of the best version of the SCL method (SCL-MI) reported in Blitzer et al (2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Section 4 gives results for SCL and the mutual information method for selecting pivot features.</S><S sid = NA ssid = NA>When we report results with SCL and SCL-MI, we require that pivots occur in more than five documents in each domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Second, the absolute scores achieved in Blitzer et al (2007) are slightly worse than those demonstrated in our experiments both for supervised and semi-supervised methods.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A supervised classifier trained on book reviews cannot assign weight to the kitchen features in the second row of table 2.</S><S sid = NA ssid = NA>We stress that our method improves a supervised baseline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P07-1056.txt | Citing Article:  P11-1007.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our approach results in competitive domain adaptation performance on the sentiment classification task, rivalling that of the state-of-the-art SCLmethod (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, we show how to extend the recently proposed structural correspondence learning (SCL) domain adaptation algorithm (Blitzer et al., 2006) for use in sentiment classification.</S><S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P07-1056.txt | Citing Article:  N09-1056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>On a separate note, previous research has explicitly studied sentiment analysis as an application of transfer learning (Blitzer et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also note that while Florian et al. (2004) and Blitzer et al.</S><S sid = NA ssid = NA>Structural correspondence learning reduces the error due to transfer by 21%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P07-1056.txt | Citing Article:  P12-1043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use the dataset from (Blitzer et al, 2007) for sentiment classification.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Sentiment classification has advanced considerably since the work of Pang et al. (2002), which we use as our baseline.</S><S sid = NA ssid = NA>First, we show how to extend the recently proposed structural correspondence learning (SCL) domain adaptation algorithm (Blitzer et al., 2006) for use in sentiment classification.</S> | Discourse Facet:  NA | Annotator: Automatic


