Citance Number: 1 | Reference Article:  W00-1308.txt | Citing Article:  W02-2001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The primary reason for the large disparity between the Brill tagger output and original Penn Treebank annotation is that it is notoriously difficult to differentiate between particles, prepositions and adverbs (Toutanova and Manning, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We tried to improve the tagger's capability to resolve these ambiguities through adding information on verbs' preferences to take specific words as particles, or adverbs, or prepositions.</S><S sid = NA ssid = NA>This presumably corresponds with Charniak's (2000: 136) observation that Section 23 of the Penn Treebank is easier than some others.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W00-1308.txt | Citing Article:  P14-2025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the future we hope to explore automatically discovering information sources that can be profitably incorporated into maximum entropy part-of-speech prediction.</S><S sid = NA ssid = NA>As seen in Table 1 the features are conjunctions of a boolean function on the history h and a boolean function on the tag t. Features whose first conjuncts are true for more than the corresponding threshold number of histories in the training data are included in the model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W00-1308.txt | Citing Article:  W10-4204.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In order to make a fair comparison between the human texts and our own, we used a part-of-speech (POS) tagger (Toutanova and Manning, 2000) to extract those grammatical categories that we aim to control within our framework, i.e. nouns, verbs, prepositions, adjectives and adverbs.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We tried to improve the tagger's capability to resolve these ambiguities through adding information on verbs' preferences to take specific words as particles, or adverbs, or prepositions.</S><S sid = NA ssid = NA>For example, the accuracy on nouns is greater than the accuracy on adjectives.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W00-1308.txt | Citing Article:  C10-2146.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Toutanova and Manning (2000), Toutanova et al (2003), Lafferty et al (2001) and Vadas and Curran (2005) used additional language-specific morphological or syntactic features.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For a more extensive discussion of maximum entropy methods, see Berger et al. (1996) and Jelinek (1997).</S><S sid = NA ssid = NA>Following Berger et al. (1996), we approximate p(h,t) , the joint distribution of contexts and tags, by the product of r, (h), the empirical distribution of histories h, and the conditional distribution p(t I h): p(h,t) p(h) p(t I h) .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W00-1308.txt | Citing Article:  P08-2017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The features used in this work are typical for modern MEMM POS tagging and are mostly based on work by Toutanova and Manning (2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The work presented in this paper explored just a few information sources in addition to the ones usually used for tagging.</S><S sid = NA ssid = NA>This paper presents results for a maximumentropy-based part of speech tagger, which achieves superior performance principally by enriching the information sources used for tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W00-1308.txt | Citing Article:  C08-1122.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used the Stanford log-linear POS tagger (Toutanova and Manning, 2000) in this study.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Enriching The Knowledge Sources Used In A Maximum Entropy Part-Of-Speech Tagger</S><S sid = NA ssid = NA>There seems to be still considerable room to improve these results, though the attainable accuracy is limited by the accuracy with which these distinctions are marked in the Penn Treebank (on a quick informal study, this accuracy seems to be around 85%).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W00-1308.txt | Citing Article:  P13-1174.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use the Google Web 1T data (Brants and Franz (2006)), and POS-tagged ngrams using Stanford POS Tagger (Toutanova and Manning (2000)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The tagger learns a loglinear conditional probability model from tagged text, using a maximum entropy method.</S><S sid = NA ssid = NA>Among recent top performing methods are Hidden Markov Models (Brants 2000), maximum entropy approaches (Ratnaparkhi 1996), and transformation-based learning (Brill 1994).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W00-1308.txt | Citing Article:  W06-1314.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Under the hypothesis that action item utterances will exhibit particular syntactic patterns, we use a conditional Markov model part-of-speech (POS) tagger (Toutanova and Manning, 2000) trained on the Switchboard corpus (Godfrey et al, 1992) to tag utterance words for part of speech.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These look a lot like the statistics a Markov Model would use.</S><S sid = NA ssid = NA>For instance, in (2), we find the exact same sequence of parts of speech, but (2a) is a particle use of on, while (2b) is a prepositional use.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W00-1308.txt | Citing Article:  N10-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We apply the Stanford POS tagger (Toutanova and Manning, 2000) on Twitter messages, and only select nouns and adjectives as valid candidates for user tags.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For example, the accuracy on nouns is greater than the accuracy on adjectives.</S><S sid = NA ssid = NA>The model assigns a probability for every tag t in the set T of possible tags given a word and its context h, which is usually defined as the sequence of several words and tags preceding the word.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W00-1308.txt | Citing Article:  E09-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the future we hope to explore automatically discovering information sources that can be profitably incorporated into maximum entropy part-of-speech prediction.</S><S sid = NA ssid = NA>As seen in Table 1 the features are conjunctions of a boolean function on the history h and a boolean function on the tag t. Features whose first conjuncts are true for more than the corresponding threshold number of histories in the training data are included in the model.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W00-1308.txt | Citing Article:  W11-2018.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>So we have also used the Stanford POS tagger (Toutanova and Manning, 2000) to tag these transcripts before calculating the Discriminative TFIDF score.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We used a tag dictionary for known words in testing.</S><S sid = NA ssid = NA>Enriching The Knowledge Sources Used In A Maximum Entropy Part-Of-Speech Tagger</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W00-1308.txt | Citing Article:  D11-1034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Next, we replace all nouns with their POS tag; we use the Stanford POS Tagger (Toutanova and Manning, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For instance, in (2), we find the exact same sequence of parts of speech, but (2a) is a particle use of on, while (2b) is a prepositional use.</S><S sid = NA ssid = NA>For example, the accuracy on nouns is greater than the accuracy on adjectives.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W00-1308.txt | Citing Article:  W11-0817.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For POS-tagging, we used the Stanford POS Tagger (Toutanova and Manning, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This paper presents results for a maximumentropy-based part of speech tagger, which achieves superior performance principally by enriching the information sources used for tagging.</S><S sid = NA ssid = NA>Enriching The Knowledge Sources Used In A Maximum Entropy Part-Of-Speech Tagger</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W00-1308.txt | Citing Article:  D11-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We consider a word as a predicate if it is tagged as a verb by a Part-of-Speech tagger (Toutanova and Manning, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The second feature template has the form: The last verb is v and the current word is w and w has been tagged as a particle and the current tag is t. The last verb is the pseudo-symbol NA if there is no verb in the previous three positions.</S><S sid = NA ssid = NA>We added two different feature templates to capture this information, consisting as usual of a predicate on the history h, and a condition on the tag t. The first predicate is true if the current word is often used as a particle, and if there is a verb at most 3 positions to the left, which is &quot;known&quot; to have a good chance of taking the current word as a particle.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W00-1308.txt | Citing Article:  N09-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The Stanford POS tagger (Toutanova and Manning, 2000) and the Stanford parser (Klein and Manning, 2003) were used to produce the part of speech and dependency annotations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Enriching The Knowledge Sources Used In A Maximum Entropy Part-Of-Speech Tagger</S><S sid = NA ssid = NA>An overview of these and other approaches can be found in Manning and Schiitze (1999, ch.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W00-1308.txt | Citing Article:  D08-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It uses a maximum-entropy approach to handle information diversity without assuming predictor independence (Toutanova and Manning, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We adopt a maximum entropy approach because it allows the inclusion of diverse sources of information without causing fragmentation and without necessarily assuming independence between the predictors.</S><S sid = NA ssid = NA>A maximum entropy approach has been applied to partof-speech tagging before (Ratnaparkhi 1996), but the approach's ability to incorporate nonlocal and non-HMM-tagger-type evidence has not been fully explored.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W00-1308.txt | Citing Article:  P12-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For part-of-speech (POS) tagging of the sentences, we used Stanford POS Tagger (Toutanova and Manning, 2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Enriching The Knowledge Sources Used In A Maximum Entropy Part-Of-Speech Tagger</S><S sid = NA ssid = NA>This paper presents results for a maximumentropy-based part of speech tagger, which achieves superior performance principally by enriching the information sources used for tagging.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W00-1308.txt | Citing Article:  W07-1516.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following Toutanova and Manning (2000) approximately, more information is defined for words that are considered rare (which we define here as words that occur fewer than fifteen times).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Rare words are defined to be words that appear less than a certain number of times in the training data (here, the value 7 was used).</S><S sid = NA ssid = NA>Special feature templates exist for rare words in the training data, to increase the model's prediction capacity for unknown words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W00-1308.txt | Citing Article:  W07-1516.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Toutanova and Manning (2000) achieves 96.9% (on seen) and 86.9% (on unseen) with an MEMM.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The best resulting accuracy for the tagger on the Penn Treebank is 96.86% overall, and 86.91% on previously unseen words.</S><S sid = NA ssid = NA>96.83% 86.87%</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W00-1308.txt | Citing Article:  N03-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in Collins (2002), using the same data splits, and a larger error reduction of 12.1% from the more similar best previous log linear model in Toutanova and Manning (2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For example, the error on the proper noun category (NNP) accounts for a significantly larger percent of the total error for unknown words than for known words.</S><S sid = NA ssid = NA>The percentage of the same type of error for known words is 16.2%.</S> | Discourse Facet:  NA | Annotator: Automatic


