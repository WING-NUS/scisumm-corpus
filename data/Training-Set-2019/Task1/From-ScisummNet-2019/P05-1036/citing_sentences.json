[
  {
    "citance_No": 1, 
    "citing_paper_id": "E06-1038", 
    "citing_paper_authority": 48, 
    "citing_paper_authors": "Ryan, McDonald", 
    "raw_text": "Recently Turner and Charniak (2005) presented supervised and semi-supervised versions of the Knight and Marcu noisy-channel model", 
    "clean_text": "Recently Turner and Charniak (2005) presented supervised and semi-supervised versions of the Knight and Marcu noisy-channel model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "N07-1023", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Michel, Galley | Kathleen R., McKeown", 
    "raw_text": "We also exploited more general tree productions known as synchronous tree substitution grammar (STSG) rules, in an approach quite similar to (Turner and Charniak, 2005)", 
    "clean_text": "We also exploited more general tree productions known as synchronous tree substitution grammar (STSG) rules, in an approach quite similar to (Turner and Charniak, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P06-1048", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "James, Clarke | Mirella, Lapata", 
    "raw_text": "Alternatively, the rules of compression are approximated from a non-parallel corpus (e.g., the Penn Treebank) by considering context-free grammar derivations with matching expansions (Turner and Charniak 2005)", 
    "clean_text": "Alternatively, the rules of compression are approximated from a non-parallel corpus (e.g., the Penn Treebank) by considering context-free grammar derivations with matching expansions (Turner and Charniak 2005).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P06-1048", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "James, Clarke | Mirella, Lapata", 
    "raw_text": "Although both models yield comparable performance, Turner and Charniak (2005) show that the latter is not an appropriate compression model since it favours uncompressed sentences over compressed ones.1 Hori and Furui? s (2004) model was originally developed for Japanese with spoken text in mind, 1The noisy-channel model uses a source model trained on uncompressed sentences", 
    "clean_text": "Although both models yield comparable performance, Turner and Charniak (2005) show that the latter is not an appropriate compression model since it favours uncompressed sentences over compressed ones.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P10-1096", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Elif, Yamangil | Stuart M., Shieber", 
    "raw_text": "An unsupervised setup also exists ;methods for the unsupervised problem typically rel yon language models and linguistic/discourse constraints (Clarke and Lapata, 2006a; Turner and Charniak, 2005)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D07-1008", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Trevor, Cohn | Mirella, Lapata", 
    "raw_text": "Solutions to the compression task have been cast mostly in a supervised learning setting (but see Clarke and Lapata (2006a), Hori and Furui (2004), and Turner and Charniak (2005) for unsupervised methods)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D07-1008", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Trevor, Cohn | Mirella, Lapata", 
    "raw_text": "Modifications of this model are reported in Turner and Charniak (2005) and Galley and McKeown (2007) with improved results", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P06-2019", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "James, Clarke | Mirella, Lapata", 
    "raw_text": "Unsupervised approaches to the compression problem are few and far between (see Hori and Furui 2004 and Turner and Charniak 2005 for exceptions)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P06-2019", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "James, Clarke | Mirella, Lapata", 
    "raw_text": "Both variants employed the constraints described in Section 3.2 but differed in that one variant included the significance 2Turner and Charniak (2005) argue that the noisy-channel model is not an appropriate compression model since it usesa source model trained on uncompressed sentences and as aresult tends to consider compressed sentences less likely than uncompressed ones", 
    "clean_text": "Turner and Charniak (2005) argue that the noisy-channel model is not an appropriate compression model since it uses a source model trained on uncompressed sentences and as a result tends to consider compressed sentences less likely than uncompressed ones.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P13-1136", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Lu, Wang | Hema, Raghavan | Vittorio, Castelli | Radu, Florian | Claire, Cardie", 
    "raw_text": "Turner and Charniak (2005) have shown that applying handcrafted rules for trimming sentence scan improve both content and linguistic quality", 
    "clean_text": "Turner and Charniak (2005) have shown that applying handcrafted rules for trimming sentences can improve both content and linguistic quality.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P08-2035", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Elif, Yamangil | Rani, Nelken", 
    "raw_text": "While data sparsity is a common problem of many NLP tasks, it is much more severe for sentence compression, leading Turner and Charniak (2005) to question the applicability of the channel model for this task altogether", 
    "clean_text": "While data sparsity is a common problem of many NLP tasks, it is much more severe for sentence compression, leading Turner and Charniak (2005) to question the applicability of the channel model for this task altogether.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P08-2035", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Elif, Yamangil | Rani, Nelken", 
    "raw_text": "Turner and Charniak (2005) question the viability of a noisy channel model for the sentence compression task", 
    "clean_text": "Turner and Charniak (2005) question the viability of a noisy channel model for the sentence compression task.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W11-1601", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "William, Coster | David, Kauchak", 
    "raw_text": "We also adopt two automatic measures that have been used to evaluate text compression that com pare the system? s output to a reference translation3See (Turner and Charniak, 2005) for a discussion of problems that can occur for text compression when using a language model trained on data from the uncompressed side", 
    "clean_text": "See (Turner and Charniak, 2005) for a discussion of problems that can occur for text compression when using a language model trained on data from the uncompressed side.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W11-1610", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Courtney, Napoles | Chris, Callison-Burch | Juri, Ganitkevitch | Benjamin, van Durme", 
    "raw_text": "Most of the previous research on sentence compression focuses on deletion using syntactic information, (e.g., Galley and McKeown (2007), Knightand Marcu (2002), Nomoto (2009), Galanis and Androutsopoulos (2010), Filippova and Strube (2008), McDonald (2006), Yamangil and Shieber (2010), Cohn and Lapata (2008), Cohn and Lapata (2009), Turner and Charniak (2005))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P06-2109", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Yuya, Unno | Takashi, Ninomiya | Yusuke, Miyao | Jun'ichi, Tsujii", 
    "raw_text": "Turner and Charniak (Turner and Charniak, 2005) added some special rules and applied this method to unsupervised learning to overcome the lack of training data", 
    "clean_text": "Turner and Charniak (Turner and Charniak, 2005) added some special rules and applied this method to unsupervised learning to overcome the lack of training data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P06-2109", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Yuya, Unno | Takashi, Ninomiya | Yusuke, Miyao | Jun'ichi, Tsujii", 
    "raw_text": "Turner and Charniak (Turner and Charniak, 2005) revised and improved Knight and Marcu? s algorithm; however, their algorithm also uses only mother and daughter relations and has the same problem", 
    "clean_text": "Turner and Charniak (Turner and Charniak, 2005) revised and improved Knight and Marcu's algorithm; however, their algorithm also uses only mother and daughter relations and has the same problem.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P06-2109", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Yuya, Unno | Takashi, Ninomiya | Yusuke, Miyao | Jun'ichi, Tsujii", 
    "raw_text": "Turner and Charniak (Turner and Charniak, 2005) solve this problem by appending special rules that are applied when a mother node and its daughter node have the same label", 
    "clean_text": "Turner and Charniak (Turner and Charniak, 2005) solve this problem by appending special rules that are applied when a mother node and its daughter node have the same label.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P13-1151", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "David, Kauchak", 
    "raw_text": "In addition, for some monolingual translation domains, it has been argued that it is not appropriate to train a language model using data from the input domain (Turner and Charniak, 2005) .Although this question arises in other monolingual translation domains, text simplification rep resents an ideal problem area for analysis", 
    "clean_text": "In addition, for some monolingual translation domains, it has been argued that it is not appropriate to train a language model using data from the input domain (Turner and Charniak, 2005).", 
    "keep_for_gold": 0
  }
]