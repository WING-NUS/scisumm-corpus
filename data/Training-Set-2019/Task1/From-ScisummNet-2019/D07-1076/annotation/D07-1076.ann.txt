Citance Number: 1 | Reference Article:  D07-1076.txt | Citing Article:  W08-0603.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the news domain, the best reported results on the ACE dataset have been achieved by a composite kernel which depends partially on a full parse, and partially on a collection of shallow syntactic features (Zhou et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>It depends.</S><S sid = NA ssid = NA>Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7: ),()1(),(),(1 ???-+???=??</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D07-1076.txt | Citing Article:  P14-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As shown in Zhou et al (2007), the context path from root to the phrase node is an effective context information feature.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>becomes context-sensitive with its dependence on the root node path instead of the root node itself.</S><S sid = NA ssid = NA>the tree kernel proposed in Culota and Sorensen (2004) which is context-sensitive, that is, it considers the path from the tree root node to the sub-tree root node.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D07-1076.txt | Citing Article:  P14-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In this paper, we use the same settings in (Zhou et al, 2007), i.e., each phrase node is enriched with its context paths of length 1, 2, 3.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>D= m i NnNn ii C iiii nnTTK 1 ]2[]2[],1[]1[ 11 1111 ])2[],1[(])2[],1[( (3) Where ? ][1 jN i is the set of root node paths with length i in tree T[j] while the maximal length of a root node path is defined by m. ? ])[...(][ 211 jnnnjn ii = is a root node path with length i in tree T[j] , which takes into account the i-1 ancestral nodes in2 [j] of 1n [j] in T[j].</S><S sid = NA ssid = NA>Context-Sensitive Convolution Tree Kernel In this paper, the m parameter of our context-sensitive convolution tree kernel as shown in Equation (3) indicates the maximal length of root node paths and is optimized to 3 using 5-fold cross validation on the ACE RDC 2003 training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D07-1076.txt | Citing Article:  P14-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We compare our method with the standard convolution tree kernel (CTK) on the state-of-the-art context sensitive shortest path-enclosed tree representation (CSPT, Zhou et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>3.2 Context-Sensitive Convolution Tree Kernel.</S><S sid = NA ssid = NA>Zhang et al(2006) systematically explored seven different tree spans, including the Shortest Path-enclosed Tree (SPT) and a Context Sensitive Path-enclosed Tree1 (CSPT), and found that SPT per formed best.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D07-1076.txt | Citing Article:  P14-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We would also like to thank the critical and insightful comments from the four anonymous reviewers.</S><S sid = NA ssid = NA>In the embedded cases, SPT is enough.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D07-1076.txt | Citing Article:  P14-2011.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To resolve this problem, Zhou et al (2007) took the ancestral information of sub-trees into consideration.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>It works by taking ancestral information (i.e. the root node path) of sub-trees into consideration: ? ?</S><S sid = NA ssid = NA>However, there is one problem with this tree kernel: the sub-trees involved in the tree kernel computation are context-free (That is, they do not consider the information outside the sub-trees).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D07-1076.txt | Citing Article:  P09-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We would also like to thank the critical and insightful comments from the four anonymous reviewers.</S><S sid = NA ssid = NA>In the embedded cases, SPT is enough.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D07-1076.txt | Citing Article:  P08-2023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Later, Zhang et al (2006) developed a composite kernel that combined parse tree kernel with entity kernel and Zhou et al (2007) experimented with a context-sensitive kernel by automatically determining context-sensitive tree spans.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7: ),()1(),(),(1 ???-+???=??</S><S sid = NA ssid = NA>3.2 Context-Sensitive Convolution Tree Kernel.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D07-1076.txt | Citing Article:  D10-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Zhou et al (2007) use a context sensitive kernel in conjunction with features they used in their earlier publication (GuoDong et al., 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7: ),()1(),(),(1 ???-+???=??</S><S sid = NA ssid = NA>Zhang et al(2006) also showed that the widely-used Shortest Path-enclosed Tree (SPT) performed best.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D07-1076.txt | Citing Article:  D11-1132.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To the best of our knowledge, the most recent result was reported by (Zhou and Zhu, 2011), who extended their previous work in (Zhou et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As a result, our tree kernel is not limited by the constraints in previous tree kernels (as discussed in Section 2), such as Collins and Duffy (2001), Zhang et al(2006), Culotta and Sorensen (2004) and Bunescu and Mooney (2005a).</S><S sid = NA ssid = NA>Culotta and Sorensen (2004) extended this work to estimate simi larity between augmented dependency trees and achieved the F-measure of 45.8 on the 5 relation types in the ACE RDC 2003 corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D07-1076.txt | Citing Article:  P11-1053.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We would also like to thank the critical and insightful comments from the four anonymous reviewers.</S><S sid = NA ssid = NA>In the embedded cases, SPT is enough.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D07-1076.txt | Citing Article:  P11-1053.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Zhou et al (2007) tested their system on the ACE 2004 data.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>System P(%) R(%) F Linear Kernel 78.2 (77.2) 63.4 (60.7) 70.1 (68.0) Context-Sensitive Con volution Tree Kernel 81.1 (80.1) 66.7 (63.8) 73.2 (71.0) Composite Kernel 82.2 (80.8) 70.2 (68.4) 75.8 (74.1) Table 3: Performance of the compos ite kernel via polynomial interpolation on the major relation types of the ACE RDC 2003 (inside the parentheses) and 2004 (outside the parentheses) corpora Comparison with Other Systems ACE RDC 2003 P(%) R(%) F Ours: composite kernel 80.8 (65.2) 68.4 (54.9) 74.1 (59.6) Zhang et al(2006): composite kernel 77.3 (64.9) 65.6 (51.2) 70.9 (57.2) Ours: context-sensitive convolution tree kernel 80.1 (63.4) 63.8 (51.9) 71.0 (57.1) Zhang et al(2006): convolution tree kernel 76.1 (62.4) 62.6 (48.5) 68.7 (54.6) Bunescu et al(2005): shortest path dependency kernel 65.5 (-) 43.8 (-) 52.5 (-) Culotta et al(2004): dependency kernel 67.1 (-) 35.0 (-) 45.8 (-) Zhou et al (2005): feature-based 77.2 (63.1) 60.7 (49.5) 68.0 (55.5) Kambhatla (2004): feature-based - (63.5) - (45.2) - (52.8) Table 4: Comparison of difference systems on the ACE RDC 2003 corpus over both 5 types (outside the parentheses) and 24 subtypes (inside the parentheses) ACE RDC 2004 P(%) R(%) F Ours: composite kernel 82.2 (70.3) 70.2 (62.2) 75.8 (66.0) Zhang et al(2006): composite kernel 76.1 (68.6) 68.4 (59.3) 72.1 (63.6) Zhao et al(2005):8 composite kernel 69.2 (-) 70.5 (-) 70.4 (-) Ours: context-sensitive convolution tree kernel 81.1 (68.8) 66.7 (60.3) 73.2 (64.3) Zhang et al(2006): convolution tree kernel 72.5 (-) 56.7 (-) 63.6 (-) Table 5: Comparison of difference systems on the ACE RDC 2004 corpus over both 7 types (outside the parentheses) and 23 subtypes (inside the parentheses) Finally, Tables 4 and 5 compare our system with other state-of-the-art systems9 on the ACE RDC 2003 and 2004 corpora, respectively.</S><S sid = NA ssid = NA>Since then, many methods, such as feature-based (Kambhatla 2004; Zhou et al2005, 2006), tree ker nel-based (Zelenko et al2003; Culotta and Sorensen 2004; Bunescu and Mooney 2005a; Zhang et al2006) and composite kernel-based (Zhao and Gris hman 2005; Zhang et al2006), have been proposed in lit erature.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D07-1076.txt | Citing Article:  W11-0216.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Zhou et al (2007) proposed the so called context sensitive tree kernel approach based on PST, which expands PET to include necessary contextual in formation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7: ),()1(),(),(1 ???-+???=??</S><S sid = NA ssid = NA>First, we systematically evaluate the context-sensitive convolution tree kernel and the dynamic context sensitive tree span proposed in this paper.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D07-1076.txt | Citing Article:  C08-1088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Zhou et al (2007) further extend it to Context-Sensitive Shortest Path-enclosed Tree (CS SPT), which dynamically includes necessary predicate-linked path information.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Zhang et al(2006) systematically explored seven different tree spans, including the Shortest Path-enclosed Tree (SPT) and a Context Sensitive Path-enclosed Tree1 (CSPT), and found that SPT per formed best.</S><S sid = NA ssid = NA>It first automatically determines a dynamic context-sensitive tree span for relation ex traction by extending the Shortest Path-enclosed Tree (SPT) to include necessary context information outside SPT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D07-1076.txt | Citing Article:  C08-1088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Zhou et al (2007) point out that both SPT and the convolution tree kernel are context-free.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>3.2 Context-Sensitive Convolution Tree Kernel.</S><S sid = NA ssid = NA>Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7: ),()1(),(),(1 ???-+???=??</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D07-1076.txt | Citing Article:  C08-1088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Zhou et al (2007) describe a composite kernel to integrate a context-sensitive CTK and a state-of-the-art linear kernel.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7: ),()1(),(),(1 ???-+???=??</S><S sid = NA ssid = NA>This suggests that our tree kernel and the state-of-the-art linear kernel are quite complementary, and that our composite kernel can effectively integrate both flat and structured features.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  D07-1076.txt | Citing Article:  C08-1088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Zhou et al (2007) further propose Context-Sensitive SPT (CS-SPT), which can dynamically determine the tree span by extending the necessary predicate-linked path information outside SPT.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>It first automatically determines a dynamic context-sensitive tree span for relation ex traction by extending the Shortest Path-enclosed Tree (SPT) to include necessary context information outside SPT.</S><S sid = NA ssid = NA>First, it automatically determines a dynamic context-sensitive tree span for relation ex traction by extending the widely-used Shortest Path-enclosed Tree (SPT) to include necessary context information outside SPT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  D07-1076.txt | Citing Article:  C08-1088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(2) CS-SPT only captures part of context sensitive information relating to predicate-linked structure (Zhou et al, 2007) and still loses much context-sensitive information.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>information.</S><S sid = NA ssid = NA>3.2 Context-Sensitive Convolution Tree Kernel.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  D07-1076.txt | Citing Article:  C08-1088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In fact, SPT (Zhang et al, 2006) can be arrived at by carrying out part of the above removal operations using a single rule (i.e. all the constituents outside the linking path should be removed) and CS-CSPT (Zhou et al, 2007) further recovers part of necessary context-sensitive information outside SPT, this justifies that SPT performs well, while CS-SPT outperforms SPT.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>That is, SPT even outperforms CSPT.</S><S sid = NA ssid = NA>It first automatically determines a dynamic context-sensitive tree span for relation ex traction by extending the Shortest Path-enclosed Tree (SPT) to include necessary context information outside SPT.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  D07-1076.txt | Citing Article:  C08-1088.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Furthermore, when the UPST (FPT) kernel is combined with a linear state-of-the-state feature based kernel (Zhou et al, 2005) into a composite one via polynomial interpolation in a setting similar to Zhou et al (2007) (i.e. polynomial degree d=2 and coefficient? =0.3), we get the so far best performance of 77.1 in F-measure for 7relation types on the ACE RDC 2004 data set.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Composite Kernel In this paper, a composite kernel via polynomial interpolation, as described Zhang et al(2006), is ap plied to integrate the proposed context-sensitive convolution tree kernel with a state-of-the-art linear kernel (Zhou et al2005) 7: ),()1(),(),(1 ???-+???=??</S><S sid = NA ssid = NA>As the state-of-the-art, Zhang et al(2006) applied the convo lution tree kernel (Collins and Duffy 2001) and achieved comparable performance with a state-of-the art linear kernel (Zhou et al2005) on the 5 relation types in the ACE RDC 2003 corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


