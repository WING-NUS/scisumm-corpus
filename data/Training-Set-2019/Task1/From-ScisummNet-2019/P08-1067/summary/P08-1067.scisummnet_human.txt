Forest Reranking: Discriminative Parsing with Non-Local Features
Conventional n-best reranking techniques often suffer from the limited scope of the nbest list, which rules out many potentially good alternatives.
We instead propose forest reranking, a method that reranks a packed forest of exponentially many parses.
Since exact inference is intractable with non-local features, we present an approximate algorithm inspired by forest rescoring that makes discriminative training practical over the whole Treebank.
Our final result, an F-score of 91.7, outperforms both 50-best and 100-best reranking baselines, and is better than any previously reported systems trained on the Treebank.
We show that the use of non-local features does in fact contribute substantially to parser performance.
To prune the packed forests, we use inside and outside probabilities to compute the distance of the best derivation that traverses a hyper edge away from the globally best derivation.
