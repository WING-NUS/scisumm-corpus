Citance Number: 1 | Reference Article:  P08-1030.txt | Citing Article:  P14-1094.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ji and Grishman (2008) extended the one sense per discourse idea (Yarowsky, 1995) to multiple topically related documents and propagate consistent event arguments across sentences and documents.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We apply the hypothesis of “One Sense Per Discourse” (Yarowsky, 1995) to information extraction (IE), and extend the scope of “discourse” from one single document to a cluster of topically-related documents.</S><S sid = NA ssid = NA>We employ a similar approach to propagate consistent event arguments across sentences and documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P08-1030.txt | Citing Article:  W09-1704.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We then apply the cross-document inference techniques as described in (Ji and Grishman, 2008) to improve trigger and argument labeling performance by favoring interpretation consistency across the test events and background events.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We can take advantage of these alternate descriptions to improve event extraction in the original document, by favoring consistency of interpretation across sentences and documents.</S><S sid = NA ssid = NA>Then we apply</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P08-1030.txt | Citing Article:  P11-2045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Later, Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topic-related documents.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We employ a similar approach to propagate consistent event arguments across sentences and documents.</S><S sid = NA ssid = NA>Based on the fact that many other instances of “hurt” are not “Life_Injure” triggers in the related documents, we can successfully remove this wrong event mention in the test document.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P08-1030.txt | Citing Article:  P11-2045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Ji and Grishman 2008) have observed that the events in a cluster of documents on the same topics as documents in the training corpus can be tagged more confidently.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Fortunately, many of these events will be reported multiple times, in different forms, both within the same document and within topicallyrelated documents (i.e. a collection of documents sharing participants in potential events).</S><S sid = NA ssid = NA>On the other hand, if a word is not tagged as an event trigger in most related documents, then it’s less likely to be correct in the test sentence despite its high local confidence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P08-1030.txt | Citing Article:  P11-2045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We followed Ji and Grishman (2008)'s approach and used the INDRI retrieval system (Strohman et al, 2005) to obtain the top N related documents for each annotated document in the training corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We then use the INDRI retrieval system (Strohman et al., 2005) to obtain the top N (N=25 in this paper3) related documents.</S><S sid = NA ssid = NA>Almost all the current event extraction systems focus on processing single documents and, except for coreference resolution, operate a sentence at a time (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P08-1030.txt | Citing Article:  P11-2045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>XSent-Trigger-Freq(trigger, etype) The weighted frequency of string trigger appearing as the trigger of an event of type etype across all sentences within a document XDoc-Trigger-Freq (trigger, etype) The weighted frequency of string trigger appearing as the trigger of an event of type etype across all documents in a cluster XDoc-Trigger-BestFreq (trigger) Maximum over all etypes of XDoc-Trigger-Freq (trigger, etype) XDoc-Arg-Freq(arg, etype) The weighted frequency of arg appearing as an argument of an event of type etype across all documents in a cluster XDoc-Role-Freq(arg, etype, role) The weighted frequency of arg appearing as an argument of an event of type etype with role role across all documents in a cluster XDoc-Role-BestFreq(arg) Maximum over all etypes and roles of XDoc-Role-Freq(arg, etype, role) XSent-Trigger-Margin(trigger) The margin value of trigger in XSent-Trigger-Freq XDoc-Trigger-Margin(trigger) The margin value of trigger in XDoc-Trigger-Freq XDoc-Role-Margin(arg) The margin value of arg in XDoc-Role-Freq</S><S sid = NA ssid = NA>Based on the fact that many other instances of “hurt” are not “Life_Injure” triggers in the related documents, we can successfully remove this wrong event mention in the test document.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P08-1030.txt | Citing Article:  P11-2045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>There are two common assumptions within a cluster of related documents (Ji and Grishman 2008): Trigger Consistency Per Cluster: if one instance of a word triggers an event, other instances of the same word will trigger events of the same type.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As we shall describe below, we can make use of consistency at several levels: consistency of word sense across different instances of the same word in related documents, and consistency of arguments and roles across different mentions of the same or related events.</S><S sid = NA ssid = NA>So if we can determine the sense (event type) of a word in the related documents, this will allow us to infer its sense in the test document.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P08-1030.txt | Citing Article:  P11-2045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For ST_IR and ST_GI, we retrieved the best N (using N=25, which (Ji and Grishman 2008) found to work best) related texts for each training document from the English TDT5 corpus consisting of 278,108 news texts (from April to September of 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For each test text we retrieved 25 related texts from English TDT5 corpus which in total consists of 278,108 texts (from April to September of 2003).</S><S sid = NA ssid = NA>We used 10 newswire texts from ACE 2005 training corpora (from March to May of 2003) as our development set, and then conduct blind test on a separate set of 40 ACE 2005 newswire texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P08-1030.txt | Citing Article:  D10-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The most salient work for event extraction is Grishman et al (2005) and Jiand and Grishman (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Almost all the current event extraction systems focus on processing single documents and, except for coreference resolution, operate a sentence at a time (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006).</S><S sid = NA ssid = NA>We then use the INDRI retrieval system (Strohman et al., 2005) to obtain the top N (N=25 in this paper3) related documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P08-1030.txt | Citing Article:  D10-1100.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ji and Grishman (2008) further exploit a correlation between senses of verbs (that are triggers for events) and topics of documents. Our work shares some similarities.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For trigger labeling, most of these errors appear for support verbs such as “take” and “get” which can only represent an event mention together with other verbs or nouns.</S><S sid = NA ssid = NA>Fortunately, many of these events will be reported multiple times, in different forms, both within the same document and within topicallyrelated documents (i.e. a collection of documents sharing participants in potential events).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P08-1030.txt | Citing Article:  D12-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topic related documents.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We employ a similar approach to propagate consistent event arguments across sentences and documents.</S><S sid = NA ssid = NA>Based on the fact that many other instances of “hurt” are not “Life_Injure” triggers in the related documents, we can successfully remove this wrong event mention in the test document.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P08-1030.txt | Citing Article:  D12-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Although this figure is very low, it is not surprising: the results on the English ACE 2005 corpus show that the inter-annotator agreement on trigger identification is only about 40% (Ji and Grishman, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As shown in table 5 the inter-annotator agreement on trigger identification is only about 40%.</S><S sid = NA ssid = NA>We used 10 newswire texts from ACE 2005 training corpora (from March to May of 2003) as our development set, and then conduct blind test on a separate set of 40 ACE 2005 newswire texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P08-1030.txt | Citing Article:  D12-1092.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The second reason is that it is hard to identify an event mention due to the failure of following specified annotation guidelines, as mentioned in Ji and Grishman (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For example it’s hard to decide whether “named” represents a “Personnel_Nominate” or “Personnel_Start-Position” event mention; “hacked to death” represents a “Life_Die” or “Conflict_Attack” event mention without following more specific annotation guidelines.</S><S sid = NA ssid = NA>But the same annotation for this mention doesn’t appear again in the related documents, so we can determine it’s a spurious argument.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P08-1030.txt | Citing Article:  C10-2072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use a state-of-the-art IE system (Ji and Grishman, 2008) developed for the Automatic Content Extraction (ACE) program to process texts and automatic speech recognition output.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The event extraction task we are addressing is that of the Automatic Content Extraction (ACE) evaluations2.</S><S sid = NA ssid = NA>In this paper we demonstrate that appreciable improvements are possible over the variety of event types in the ACE (Automatic Content Extraction) evaluation through the use of cross-sentence and cross-document evidence.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P08-1030.txt | Citing Article:  C10-2072.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our work can also be considered as an extension of global back ground inference (e.g. Ji and Grishman, 2008) to cross-media paradigm.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Refining Event Extraction through Cross-Document Inference</S><S sid = NA ssid = NA>We share the view of using global inference to improve event extraction with some recent research.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P08-1030.txt | Citing Article:  P11-1114.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ji and Grishman (2008) enforce event role consistency across different documents.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As we shall describe below, we can make use of consistency at several levels: consistency of word sense across different instances of the same word in related documents, and consistency of arguments and roles across different mentions of the same or related events.</S><S sid = NA ssid = NA>In other words, each entity plays the same argument role, or no role, for events with the same type in a collection of related documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P08-1030.txt | Citing Article:  D09-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Finkel et al (2005) and Ji and Grishman (2008) incorporate global information by enforcing event role or label consistency over a document or across related documents.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Almost all the current event extraction systems focus on processing single documents and, except for coreference resolution, operate a sentence at a time (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006).</S><S sid = NA ssid = NA>We then use the INDRI retrieval system (Strohman et al., 2005) to obtain the top N (N=25 in this paper3) related documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P08-1030.txt | Citing Article:  P13-1024.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A typical event extraction/discovery system (Ji and Grishman, 2008) fails to discover the war event due to the lack of context information (Benson et al, 2011), and thus fails to shed light on the users focus/interests.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Almost all the current event extraction systems focus on processing single documents and, except for coreference resolution, operate a sentence at a time (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006).</S><S sid = NA ssid = NA>For example, for a sentence: the event extractor should detect a “Personnel_End-Position” event mention, with the trigger word, the position, the person who quit the position, the organization, and the time during which the event happened: We define the following standards to determine the correctness of an event mention: We use a state-of-the-art English IE system as our baseline (Grishman et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P08-1030.txt | Citing Article:  P13-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We have also attempted using the results from Dependency Parsing, Relation Extraction and Event Extraction tools (Ji and Grishman, 2008) to enrich the link types.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this section we present the results of applying this inference method to improve ACE event extraction.</S><S sid = NA ssid = NA>We share the view of using global inference to improve event extraction with some recent research.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P08-1030.txt | Citing Article:  D11-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Ji and Grishman (2008) extracts event mentions (belonging to a predefined list of target event types) and their associated arguments.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>ACE defines the following terminology: entity: an object or a set of objects in one of the semantic categories of interest mention: a reference to an entity (typically, a noun phrase) event trigger: the main word which most clearly expresses an event occurrence event arguments: the mentions that are involved in an event (participants) event mention: a phrase or sentence within which an event is described, including trigger and arguments The 2005 ACE evaluation had 8 types of events, with 33 subtypes; for the purpose of this paper, we will treat these simply as 33 distinct event types.</S><S sid = NA ssid = NA>This system extracts events independently for each sentence.</S> | Discourse Facet:  NA | Annotator: Automatic


