Citance Number: 1 | Reference Article:  W03-1719.txt | Citing Article:  W03-1721.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For details on the word segmentation bakeoff, see (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The First International Chinese Word Segmentation Bakeoff</S><S sid = NA ssid = NA>This paper presents the results from the ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff held in 2003 and reported in conjunction with the Second SIGHAN Workshop on Chinese Language Processing, Sapporo, Japan.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W03-1719.txt | Citing Article:  W03-1721.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We refer readers to (Sproat and Emerson, 2003) for details on the evaluation measures.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>See (Yao, 2001; Yao, 2002) for the first and second of these; the third evaluation will be held in August 2003.</S><S sid = NA ssid = NA>Accuracies in the mid 80’s to mid 90’s were reported for the four systems that participated in the first evaluation, with higher scores (many in the high nineties) being reported for the second evaluation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W03-1719.txt | Citing Article:  P14-2032.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We conduct experiments on the SIGHAN 2003 (Sproat and Emerson, 2003) and 2005 (Emerson, 2005) bake-off datasets to evaluate the effectiveness of the proposed dual decomposition algorithm.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This paper presents the results from the ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff held in 2003 and reported in conjunction with the Second SIGHAN Workshop on Chinese Language Processing, Sapporo, Japan.</S><S sid = NA ssid = NA>We then used this dictionary with a simple maximum matching algorithm to segment the test corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W03-1719.txt | Citing Article:  I08-4033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>After analyzing the results presented in the first and second Bakeoffs, (Sproat and Emerson,2003) and (Emerson, 2005), we created a new Chinese word segmentation system named as? Achilles? that consists of four modules mainly: Regular expression extractor, dictionary-based Ngramsegmentation, CRF-based sub word tagging (Zhang et al, 2006), and confidence-based segmentation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>It seems reasonable to treat two systems as significantly different (at the 95% confidence level), if at least one of their recall-based or precision-based confidences are different.</S><S sid = NA ssid = NA>The First International Chinese Word Segmentation Bakeoff</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W03-1719.txt | Citing Article:  I08-4014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the last SIGHAN bakeoff, there is no single system consistently outperforms the others on different test standards of Chinese WS and NER standards (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Part of the problem is also that there is no single accepted segmentation standard: There are several, including the four standards used in this evaluation.</S><S sid = NA ssid = NA>Secondly, as we have already noted, there are at least four distinct standards in active use in the sense that large corpora are being developed according to those standards; see Section 2.1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W03-1719.txt | Citing Article:  I05-3029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The official scorer program is publicly available and described in (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Training material was available starting March 15, testing material was available April 22, and the results had to be returned to the SIGHAN ftp site by April 25 no later than 17:00 EDT.</S><S sid = NA ssid = NA>The detailed instructions for the bakeoff can be found at http://www.sighan. org/bakeoff2003/bakeoff_instr.html (with simplified and traditional Chinese versions also available).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W03-1719.txt | Citing Article:  I05-2039.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Measuring homogeneity by counting word/ lexeme frequencies introduces additional difficulties as it assumes that the word is an obvious, well-defined unit, which is not the case in the Chinese (Sproat and Emerson 2003) or Japanese language (Matsumoto et al, 2002), for instance, where word segmentation is not trivial.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The First International Chinese Word Segmentation Bakeoff</S><S sid = NA ssid = NA>Chinese word segmentation is a difficult problem that has received a lot of attention in the literature; reviews of some of the various approaches can be found in (Wang et al., 1990; Wu and Tseng, 1993; Sproat and Shih, 2001).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W03-1719.txt | Citing Article:  P09-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The out-of-vocabulary (OOV) is defined as tokens in the test set that are not in the training set (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Per normal usage, OOV is defined as the set of words in the test corpus not occurring in the training corpus.2 We expect systems to do at least as well as this baseline.</S><S sid = NA ssid = NA>In this and subsequent tables, we list the word count for the test corpus, test recall (R), test precision (P), F score1, the out-of-vocabulary (OOV) rate for the test corpus, the recall on OOV words (R ), and the recall on in-vocabulary (R ) words.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W03-1719.txt | Citing Article:  P09-1058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following (Sproat and Emerson, 2003), we also measured the recall onOOV (ROOV) tokens and in-vocabulary (RIV) tokens.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this and subsequent tables, we list the word count for the test corpus, test recall (R), test precision (P), F score1, the out-of-vocabulary (OOV) rate for the test corpus, the recall on OOV words (R ), and the recall on in-vocabulary (R ) words.</S><S sid = NA ssid = NA>Figure 2 plots the recall on out-of-vocabulary words (R ) for all systems and all tracks.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W03-1719.txt | Citing Article:  I05-3017.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In 2003 SIGHAN, the Special Interest Group for Chinese Language Processing of the Association for Computational Linguistics (ACL) conducted the first International ChineseWord Segmentation Bakeoff (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This paper presents the results from the ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff held in 2003 and reported in conjunction with the Second SIGHAN Workshop on Chinese Language Processing, Sapporo, Japan.</S><S sid = NA ssid = NA>The First International Chinese Word Segmentation Bakeoff</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W03-1719.txt | Citing Article:  C04-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A recent Chinese word segmentation competition (Sproat and Emerson, 2003) has made comparisons easier.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The First International Chinese Word Segmentation Bakeoff</S><S sid = NA ssid = NA>Without the generous contribution of these resources, this competition would not have been possible.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W03-1719.txt | Citing Article:  C04-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Finally we thank Fei Xia and Qing Ma for their work on the Second meeting of SIGHAN of which this bakeoff is a part.</S><S sid = NA ssid = NA>Results were returned to participants within a couple of days of submission of the segmented test data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W03-1719.txt | Citing Article:  C04-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is due to significant inconsistent segmentation in training and testing (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the closed test, participants could only use training material from the training data for the particular corpus being testing on.</S><S sid = NA ssid = NA>Most of the training data comprise texts about Mainland China, whereas most of the testing data is about Taiwan.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W03-1719.txt | Citing Article:  I05-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>No other material was allowed (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>No other material was allowed.</S><S sid = NA ssid = NA>Upon initial registration sites were required to declare which corpora they would be training and testing on, and whether they would be participating in the open or closed tracks (or both) on each corpus, where these were defined as follows: For the open test sites were allowed to train on the training set for a particular corpus, and in addition they could use any other material including material from other training corpora, proprietary dictionaries, material from the WWW and so forth.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W03-1719.txt | Citing Article:  I05-3001.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In order to show the impact to the evaluation result caused by EIs existing in test data of Bakeoff, we conduct the baseline close test with PK and AS corpora, i.e. we compile lexicons only containing words in their training data and then use the lexicons with a forward maximum matching algorithm to segment their test data respectively (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We then used this dictionary with a simple maximum matching algorithm to segment the test corpus.</S><S sid = NA ssid = NA>Given the problems noted by some of the participants with some of the data, we would also like to see more consistently annotated training and test data, and test data that is more representative of what was seen in the training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W03-1719.txt | Citing Article:  P11-1141.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For instance, 'vice president' is considered to be one word in the Penn Chinese Treebank (Xue et al, 2005), but is split into two words by the Peking University corpus in the SIGHAN Bakeoffs (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Similarly ((corporate) vice president) is segmented as one word in training data but as two words ( / ) in the testing data.</S><S sid = NA ssid = NA>Links to descriptions of the corpora can be found at http://www.sighan.org/bakeoff2003/ bakeoff_instr.html; publications on specific corpora are (Huang et al., 1997) (Academia Sinica), (Xia, 1999) (Chinese Treebank); the Beijing University standard is very similar to that outlined in (GB/T 13715–92, 1993).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W03-1719.txt | Citing Article:  C04-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use three Chinese word-segmented corpora, the Academia Sinica corpus (AS), the Hong Kong City University corpus (HK) and the Beijing University corpus (PK), all of which were used in the First International Chinese Word Segmentation Bake off (Sproat and Emerson, 2003) at ACL-SIGHAN 2003.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The First International Chinese Word Segmentation Bakeoff</S><S sid = NA ssid = NA>Language Information Sciences Research Centre, City University of Hong Kong.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W03-1719.txt | Citing Article:  C04-1067.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The top three systems participated in the SIGHAN Bakeoff (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This paper presents the results from the ACL-SIGHAN-sponsored First International Chinese Word Segmentation Bakeoff held in 2003 and reported in conjunction with the Second SIGHAN Workshop on Chinese Language Processing, Sapporo, Japan.</S><S sid = NA ssid = NA>Accuracies in the mid 80’s to mid 90’s were reported for the four systems that participated in the first evaluation, with higher scores (many in the high nineties) being reported for the second evaluation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W03-1719.txt | Citing Article:  C10-2111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In Chinese text processing context, lexicons are particularly important for dictionary-based word segmentation techniques in which out-of-vocabulary words are an important cause of errors (Sproat and Emerson, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For example, if the system did particularly well on out-of-vocabulary words then the participants were required to explain if, for example, those results could mostly be attributed to having a good dictionary.</S><S sid = NA ssid = NA>The First International Chinese Word Segmentation Bakeoff</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W03-1719.txt | Citing Article:  W04-3236.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Finally we thank Fei Xia and Qing Ma for their work on the Second meeting of SIGHAN of which this bakeoff is a part.</S><S sid = NA ssid = NA>Results were returned to participants within a couple of days of submission of the segmented test data.</S> | Discourse Facet:  NA | Annotator: Automatic


