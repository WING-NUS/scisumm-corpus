[
  {
    "citance_No": 1, 
    "citing_paper_id": "W02-1029", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "James R., Curran", 
    "raw_text": "Curran and Moens (2002b) evaluate thesaurus extractors based on several different models of context on large corpora", 
    "clean_text": "Curran and Moens (2002b) evaluate thesaurus extractors based on several different models of context on large corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W02-1029", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "James R., Curran", 
    "raw_text": "All the systems use the JACCARD similarity metric and TTEST weighting function that were found to be most effective for thesaurus extraction by Curran and Moens (2002a)", 
    "clean_text": "All the systems use the JACCARD similarity metric and TTEST weighting function that were found to be most effective for thesaurus extraction by Curran and Moens (2002a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W02-1029", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "James R., Curran", 
    "raw_text": "Curran and Moens (2002b) have demonstrated that more complex and constrained contexts can yield superior performance, since the correlation between context and target term is stronger than simple window methods", 
    "clean_text": "Curran and Moens (2002b) have demonstrated that more complex and constrained contexts can yield superior performance, since the correlation between context and target term is stronger than simple window methods.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W09-0203", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Klaus, Rothenh&auml;usler | Hinrich, Sch&uuml;tze", 
    "raw_text": "We worked with an implementation of the log likelihood ratio (g-Score) as proposed by Dunning (1993) and two variants of the t-score, one considering all values (t-score) and one where only positive values (t-score+) are kept following the results of Curran and Moens (2002)", 
    "clean_text": "We worked with an implementation of the log likelihood ratio (g-Score) as proposed by Dunning (1993) and two variants of the t-score, one considering all values (t-score) and one where only positive values (t-score+) are kept following the results of Curran and Moens (2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W06-1708", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Davide, Fossati | Gabriele, Ghidoni | Barbara Di, Eugenio | Isabel, Cruz | Huiyong, Xiao | Rajen, Subba", 
    "raw_text": "Another venue of research may be to exploit different thesauri, such as the ones automatically derived as in (CurranandMoens, 2002)", 
    "clean_text": "Another venue of research may be to exploit different thesauri, such as the ones automatically derived as in (Curran and Moens, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P06-2111", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Lonneke, van der Plas | J&ouml;rg, Tiedemann", 
    "raw_text": "Several researchers (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)) have used large monolingual corpora to extract distribution ally similar words", 
    "clean_text": "Several researchers (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)) have used large monolingual corpora to extract distributionally similar words.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P06-2111", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Lonneke, van der Plas | J&ouml;rg, Tiedemann", 
    "raw_text": "Monolingual syntax-based distributional similarity is used in many proposals to find semantically related words (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)) .Several authors have used a monolingual parallel corpus to find paraphrases (Ibrahim et al (2003), Barzilay and McKeown (2001))", 
    "clean_text": "Monolingual syntax-based distributional similarity is used in many proposals to find semantically related words (Curran and Moens (2002), Lin (1998), van der Plas and Bouma (2005)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P06-2111", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Lonneke, van der Plas | J&ouml;rg, Tiedemann", 
    "raw_text": "Curran and Moens (2002) report on a large scale evaluation experiment, where they evaluated the performance of various commonly used methods", 
    "clean_text": "Curran and Moens (2002) report on a large scale evaluation experiment, where they evaluated the performance of various commonly used methods.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P06-2111", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Lonneke, van der Plas | J&ouml;rg, Tiedemann", 
    "raw_text": "Vander Plas and Bouma (2005) present a similar experiment for Dutch, in which they tested most of the best performing measures according to Curran and Moens (2002)", 
    "clean_text": "Vander Plas and Bouma (2005) present a similar experiment for Dutch, in which they tested most of the best performing measures according to Curran and Moens (2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P06-1046", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "Curran and Moens (2002) show that synonymy extraction for lexical semantic resources using distributional similarity produces continuing gains in accuracy as the volume of input data increases. Extracting synonymy relations using distributional similarity is based on the distributional hypothesis that similar words appear in similar contexts", 
    "clean_text": "Curran and Moens (2002) show that synonymy extraction for lexical semantic resources using distributional similarity produces continuing gains in accuracy as the volume of input data increases.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P06-1046", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "Curran and Moens (2002) introduces a vector of canonical attributes (of bounded length k m), selected from the full vector, to represent the term", 
    "clean_text": "Curran and Moens (2002) introduces a vector of canonical attributes (of bounded length k m), selected from the full vector, to represent the term.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P06-1046", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "Comparisons made with these low frequency terms are unreliable (Curranand Moens, 2002)", 
    "clean_text": "Comparisons made with these low frequency terms are unreliable (Curran and Moens, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W05-1202", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Julie, Weeds | David, Weir | Bill, Keller", 
    "raw_text": "Recently, there has been much interest in finding words which are distribution ally similar e.g., Lin (1998), Lee (1999), Curran and Moens (2002), Weeds (2003) and Geffet and Dagan (2004)", 
    "clean_text": "Recently, there has been much interest in finding words which are distribution ally similar e.g., Lin (1998), Lee (1999), Curran and Moens (2002), Weeds (2003) and Geffet and Dagan (2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W09-1706", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Lonneke, van der Plas", 
    "raw_text": "In these experiments we have used a variant of Dice: Dice?, proposed by Curran and Moens (2002)", 
    "clean_text": "In these experiments we have used a variant of Dice, proposed by Curran and Moens (2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D09-1089", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Dmitry, Davidov | Ari, Rappoport", 
    "raw_text": "Pereira et al (1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition", 
    "clean_text": "Pereira et al (1993), Curran and Moens (2002) and Lin (1998) use syntactic features in the vector definition.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P08-3001", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Masato, Hagiwara", 
    "raw_text": "Also, because it has been shown (Curran and Moens, 2002) that negativePMI values worsen the distributional similarity performance, we bound PMI so that wgt (wi ,cj)= 0 if PMI (wi ,cj) &lt; 0", 
    "clean_text": "Also, because it has been shown (Curran and Moens, 2002) that negative PMI values worsen the distributional similarity performance, we bound PMI so that PMI (wi, cj)= 0 if PMI (wi, cj) < 0.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P06-1038", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "Dmitry, Davidov | Ari, Rappoport", 
    "raw_text": "Note that they can also be viewed as algorithms for category discovery, because a subtree in such a hierarchy defines a lexical category. A first major algorithmic approach is to rep re sent word contexts as vectors in some space and use similarity measures and automatic clustering in that space (Curran and Moens, 2002)", 
    "clean_text": "A first major algorithmic approach is to represent word contexts as vectors in some space and use similarity measures and automatic clustering in that space (Curran and Moens, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W05-1011", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "Curran and Moens (2002b) have demonstrated that dramatically increasing the quantity of text used to extract contexts significantly improves synonym quality", 
    "clean_text": "Curran and Moens (2002b) have demonstrated that dramatically increasing the quantity of text used to extract contexts significantly improves synonym quality.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W05-1011", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "For these experiments we use the JACCARD (1) measure and the TTEST (2) weight, as Curran and Moens (2002a) found them to have the best performance in their comparison of many distance measures", 
    "clean_text": "For these experiments we use the JACCARD (1) measure and the TTEST (2) weight, as Curran and Moens (2002a) found them to have the best performance in their comparison of many distance measures.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W05-1011", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "Curran and Moens (2002a) propose an initial heuristic comparison to reduce the number of full O (m) vector comparisons", 
    "clean_text": "Curran and Moens (2002a) propose an initial heuristic comparison to reduce the number of full O(m) vector comparisons.", 
    "keep_for_gold": 0
  }
]