[
  {
    "citance_No": 1, 
    "citing_paper_id": "D10-1069", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Slav, Petrov | Pi-Chuan, Chang | Michael, Ringgaard | Hiyan, Alshawi", 
    "raw_text": "Finally, Suzuki et al (2009) present a very effective semi-supervised approach in which features from multiple generative models estimated on unlabeled data are combined in a discriminative system for structured prediction", 
    "clean_text": "Finally, Suzuki et al (2009) present a very effective semi-supervised approach in which features from multiple generative models estimated on unlabeled data are combined in a discriminative system for structured prediction.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-1043", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Zhenghua, Li | Min, Zhang | Wenliang, Chen", 
    "raw_text": "463 Sup Semi McDonald and Pereira (2006) 91.5? Koo and Collins (2010) [higher-order] 93.04 Zhang and McDonald (2012) [higher-order] 93.06 Zhang and Nivre (2011) [higher-order] 92.9 Koo et al (2008) [higher-order] 92.02 93.16 Chen et al (2009) [higher-order] 92.40 93.16 Suzuki et al (2009) [higher-order, cluster] 92.70 93.79 Zhou et al (2011) [higher-order] 91.98 92.64 Chen et al (2013) [higher-order] 92.76 93.77 This work 92.34 93.19 Table 4: UAS comparison on English test data", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P14-1043", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Zhenghua, Li | Min, Zhang | Wenliang, Chen", 
    "raw_text": "Both Suzuki et al (2009) and Chen et al (2013) adopt the higher order parsing model of Carreras (2007), and Suzuki et al (2009) also incorporate word cluster features proposed by Koo et al (2008) in their system", 
    "clean_text": "Both Suzuki et al (2009) and Chen et al (2013) adopt the higher order parsing model of Carreras (2007), and Suzuki et al (2009) also incorporate word cluster features proposed by Koo et al (2008) in their system.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D11-1116", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Stephen, Tratz | Eduard, Hovy", 
    "raw_text": "Also, some work has incorporated unsupervised word clusters as features, including that of Koo et al (2008) and Suzuki et al (2009), who utilized unsupervised word clusters created using the Brown et al (1992) hierarchical clustering algorithm", 
    "clean_text": "Also, some work has incorporated unsupervised word clusters as features, including that of Koo et al (2008) and Suzuki et al (2009), who utilized unsupervised word clusters created using the Brown et al (1992) hierarchical clustering algorithm.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "N10-1116", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Valentin I., Spitkovsky | Hiyan, Alshawi | Daniel, Jurafsky", 
    "raw_text": "Althoughlarge amounts of unlabeled data are known to improve semi-supervised parsing (Suzuki et al, 2009), the best unsupervised systems use less data than is available for supervised training, relying on complex models instead: Headden et al? s (2009) Extended Valence Grammar (EVG) combats data sparsity with smoothing alone, training on the same small subset of the tree-bank as the classic implementation of theDMV; Cohen and Smith (2009) use more complicated algorithms (variational EM and MBRdecoding) and stronger linguistic hints (tying related parts of speech and syntactically similar bilingual data) .We explore what can be achieved through judicious use of data and simple, scalable techniques", 
    "clean_text": "Although large amounts of unlabeled data are known to improve semi-supervised parsing (Suzuki et al, 2009), the best unsupervised systems use less data than is available for supervised training, relying on complex models instead: Headden et al's (2009) Extended Valence Grammar (EVG) combats data sparsity with smoothing alone, training on the same small subset of the tree-bank as the classic implementation of the DMV; Cohen and Smith (2009) use more complicated algorithms (variational EM and MBRdecoding) and stronger linguistic hints (tying related parts of speech and syntactically similar bilingual data).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P11-2112", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki | Masaaki, Nagata", 
    "raw_text": "We prepared a total of 3.72 billion token text data as unsupervised data following the instructions given in (Suzuki et al, 2009)", 
    "clean_text": "We prepared a total of 3.72 billion token text data as unsupervised data following the instructions given in (Suzuki et al, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P11-2112", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jun, Suzuki | Hideki, Isozaki | Masaaki, Nagata", 
    "raw_text": "= 1e+ 05) 94.33 94.22 3,720M 5.77M (Koo and Collins, 2010) 93.49 93.04 0 N/A (Martins et al, 2010) N/A 93.26 0 55.25M (Koo et al, 2008) 93.30 93.16 43M N/A (Chen et al, 2009) N/A 93.16 43M N/A (Suzuki et al, 2009) 94.13 93.79 3,720M N/A Table 1: Comparison with previous top-line systems on test data", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D11-1137", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Katsuhiko, Hayashi | Taro, Watanabe | Masayuki, Asahara | Yuji, Matsumoto", 
    "raw_text": "On the other hand, many errors remain still in Table 10: Comparison of our best result (using 16-best forests) with other best-performing Systems on the whole section 23 Parser English McDonald et al (2005) 90.9 McDonald and Pereira (2006) 91.5 Koo et al (2008) standard 92.02 Huang and Sagae (2010) 92.1 Koo and Collins (2010 )model1 93.04 Koo and Collins (2010 )model2 92.93 this work 92.89 Koo et al (2008) semi-sup 93.16 Suzuki et al (2009) 93.79 our results", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D11-1137", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Katsuhiko, Hayashi | Taro, Watanabe | Masayuki, Asahara | Yuji, Matsumoto", 
    "raw_text": "We can not directly compare our method with semi-supervised parsers such as Koo et al (2008)? s semi-sup and Suzuki et al (2009), because ours does not use additional unlabeled data for training", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "C10-2015", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Wenliang, Chen | Jun'ichi, Kazama | Yoshimasa, Tsuruoka | Kentaro, Torisawa", 
    "raw_text": "In future work, we can combine our approach with the parser of Chen et al (2009) .Table 5 shows the comparative results for English, where Y& amp; M2003 refers to the parser of Yamada and Matsumoto (2003b), CO2006 refers to the parser of Corston-Oliver et al (2006), Z& amp; C 2008 refers to the combination system of Zhangand Clark (2008), STACK refers to our implementation of the combination parser of Nivre and Mc Donald (2008), KOO2008 refers to the parser of Koo et al (2008), Chen2009 refers to the parser of Chen et al (2009), and Suzuki2009 refers to the parser of Suzuki et al (2009) that is the best reported result for this data", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P10-1040", 
    "citing_paper_authority": 133, 
    "citing_paper_authors": "Joseph P., Turian | Lev, Ratinov | Yoshua, Bengio", 
    "raw_text": "Semi-supervised models such as Ando and Zhang (2005), Suzuki and Isozaki (2008), and Suzuki et al (2009) achieve state-of-the-art accuracy", 
    "clean_text": "Semi-supervised models such as Ando and Zhang (2005), Suzuki and Isozaki (2008), and Suzuki et al (2009) achieve state-of-the-art accuracy.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "E12-1009", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Bernd, Bohnet | Jonas, Kuhn", 
    "raw_text": "Parser UAS LAS (McDonald et al 2005) 90.9 (McDonald and Pereira, 2006) 91.5 (Huang and Sagae, 2010) 92.1 (Zhang and Nivre, 2011) 92.9 (Koo and Collins, 2010) 93.04 (Martins et al 2010) 93.26 T (baseline) 92.7 G2a (baseline) 92.89 T2a 92.94 91.87 T2ab 93.16 92.08 T2ab3a 93.20 92.10 T2ab3b 93.23 92.15 T2ab3c 93.17 92.10 T2ab3abc+ 93.39 92.38 G2a+ 93.1 (Koo et al 2008)? 93.16 (Carreras et al 2008)? 93.5 (Suzuki et al 2009)? 93.79 Table 2: English Attachment Scores for the Penn2Malt conversion of the Penn Treebank for the test set", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W12-3412", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph, Le Roux | Benoit, Favre | Alexis, Nasr | Seyed Abolghasem, Mirroshandel", 
    "raw_text": "Our system also compares favourably with the system of Carreras et al (2008) that relies on a more complex generative model, namely Tree Adjoining Grammars, and the system of Suzuki et al (2009) that makes use of external data (unannotated text)", 
    "clean_text": "Our system also compares favourably with the system of Carreras et al (2008) that relies on a more complex generative model, namely Tree Adjoining Grammars, and the system of Suzuki et al (2009) that makes use of external data (unannotated text).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P13-1104", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Jinho D., Choi | Andrew, McCallum", 
    "raw_text": "The Time column show how many seconds per sentence each parser takes.7 Approach UAS LAS Time Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 0.04 Zhang and Nivre (2011) 92.9 91.8 0.03 Bohnet and Nivre (2012) 93.38 92.44 0.4 McDonald et al (2005) 90.9 Mcdonald and Pereira (2006) 91.5 Sagae and Lavie (2006) 92.7 Koo and Collins (2010) 93.04 Zhang and McDonald (2012) 93.06 91.86 Martins et al (2010) 93.26 Rush et al (2010) 93.8 Koo et al (2008) 93.16 Carreras et al (2008) 93.54 Bohnet and Nivre (2012) 93.67 92.68 Suzuki et al (2009) 93.79bt= 80 ,bd= 80, m= 0.88 92.96 91.93 0.009bt= 80 ,bd= 64, m= 0.88 92.96 91.93 0.009bt= 80 ,bd= 32, m= 0.88 92.96 91.94 0.009bt= 80 ,bd= 16, m= 0.88 92.96 91.94 0.008bt= 80 ,bd= 8, m= 0.88 92.89 91.87 0.006bt= 80 ,bd= 4, m= 0.88 92.76 91.76 0.004bt= 80 ,bd= 2, m= 0.88 92.56 91.54 0.003bt= 80 ,bd= 1, m= 0.88 92.26 91.25 0.002bt= 1 ,bd= 1, m= 0.88 92.06 91.05 0.002Table 4: Parsing accuracies and speeds on the English evaluation set, excluding tokens containing only punctuation", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P12-1023", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Wenliang, Chen | Min, Zhang | Haizhou, Li", 
    "raw_text": "Suzuki2009 (Suzuki et al, 2009) reported the best reported result by combining a Semi supervised Structured Conditional Model (Suzuki and Isozaki, 2008) with the method of (Koo et al, 2008)", 
    "clean_text": "Suzuki 2009 (Suzuki et al, 2009) reported the best reported result by combining a Semi supervised Structured Conditional Model (Suzuki and Isozaki, 2008) with the method of (Koo et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P12-1023", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Wenliang, Chen | Min, Zhang | Haizhou, Li", 
    "raw_text": "Suzuki et al (2009) presented a semi supervised learning approach", 
    "clean_text": "Suzuki et al (2009) presented a semi supervised learning approach.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D12-1133", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Bernd, Bohnet | Joakim, Nivre", 
    "raw_text": "The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al (2010) 93.26 Koo et al (2008)? 93.16 Carreras et al (2008)? 93.5 Suzuki et al (2009)? 93.79 Baseline (k= 1) ,b1= 40 89.42 92.79 91.71 97.28 Bestdev setting ,b1= 40 89.75 93.03 91.92 97.40 Adding G ,b1= 40 90.12 93.38 92.44 97.33 Adding G+C ,b1= 80? 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P11-2123", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Eneko, Agirre | Kepa, Bengoetxea | Koldo, Gojenola | Joakim, Nivre", 
    "raw_text": "Suzuki et al (2009) also experiment with the same method combined with semi-supervised learning", 
    "clean_text": "Suzuki et al (2009) also experiment with the same method combined with semi-supervised learning.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P14-2106", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Kepa, Bengoetxea | Eneko, Agirre | Joakim, Nivre | Yue, Zhang | Koldo, Gojenola", 
    "raw_text": "Suzuki et al (2009), Sagae and Gordon (2009) and Candito and Seddah (2010) also experiment with the same cluster method", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]