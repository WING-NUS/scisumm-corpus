[
  {
    "citance_No": 1, 
    "citing_paper_id": "C94-2149", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Christine, Doran | Dania, Egedi | Beth Ann, Hockey | Srinivas, Bangalore | Martin, Zaidel", 
    "raw_text": "Of the 1600 IBM sentences that have been parsed (those available from the Penn Treebank [Marcus et al, 19931), only 67 overlapped with the IBM-manual tree bank that was bracketed by University of Lancaster", 
    "clean_text": "Of the 1600 IBM sentences that have been parsed (those available from the Penn Treebank [Marcus et al, 19931), only 67 overlapped with the IBM-manual treebank that was bracketed by University of Lancaster.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2047", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Junyi Jessy, Li | Marine, Carpuat | Ani, Nenkova", 
    "raw_text": "The Penn Discourse Treebank (PDTB) (Prasad et al., 2008) provides annotations for the arguments and relation senses of one hundred pre-selected discourse connectives over the news portion of the Penn Treebank corpus (Marcus et al, 1993)", 
    "clean_text": "The Penn Discourse Treebank (PDTB) (Prasad et al., 2008) provides annotations for the arguments and relation senses of one hundred pre-selected discourse connectives over the news portion of the Penn Treebank corpus (Marcus et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W95-0105", 
    "citing_paper_authority": 39, 
    "citing_paper_authors": "Philip, Resnik", 
    "raw_text": "54 It is quite small, by current corpus standards (on the order of hundreds of thousands of words, rather than millions or tens of millions); the direct annotation methodology used to create it is labor intensive (Marcus et al (1993) found that direct annotation takes twice as long as automatic tagging plus correction, for part of-speech annotation); and the output quality reflects the difficulty of the task (inter-annotator disagreement is on the order of 10%, as contrasted with the approximately 3% error rate reported for part-of-speech annotation by Marcus et al)", 
    "clean_text": "Marcus et al (1993) found that direct annotation takes twice as long as automatic tagging plus correction, for part-of-speech annotation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "S12-1031", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Andrew, MacKinlay | Rebecca, Dridan | Diana, McCarthy | Timothy, Baldwin", 
    "raw_text": "Agirre et al (2008) applied two state-of-the-art tree bank parsers to the sense tagged subset of the Brown corpus version of the Penn Treebank (Marcus et al, 1993), and added sense annotation to the training data to evaluate their impact on parse selection and specifically on PP attachment", 
    "clean_text": "Agirre et al (2008) applied two state-of-the-art tree bank parsers to the sense tagged subset of the Brown corpus version of the Penn Treebank (Marcus et al, 1993), and added sense annotation to the training data to evaluate their impact on parse selection and specifically on PP attachment.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W99-0621", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Marcia, Munoz | Vasin, Punyakanok | Dan, Roth | Dav, Zimak", 
    "raw_text": "These data sets were based on the Wall Street Journal corpus in the Penn Treebank (Marcus et al, 1993)", 
    "clean_text": "These data sets were based on the Wall Street Journal corpus in the Penn Treebank (Marcus et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P10-1036", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jonathan K., Kummerfeld | Jessika, Roesner | Tim, Dawborn | James, Haggerty | James R., Curran | Stephen, Clark", 
    "raw_text": "We have used Sections 02-21 of CCGbank (Hock en maier and Steedman, 2007), the CCG version of the Penn Treebank (Marcus et al, 1993), as training data for the newspaper domain", 
    "clean_text": "We have used Sections 02-21 of CCG bank (Hockenmaier and Steedman, 2007), the CCG version of the Penn Treebank (Marcus et al, 1993), as training data for the newspaper domain.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W02-1039", 
    "citing_paper_authority": 61, 
    "citing_paper_authors": "Heidi J., Fox", 
    "raw_text": "When an S alignment exists, there will always also exist a P alignment such that P A S. The English sentences were parsed using a state-of-the-art statistical parser (Charniak, 2000) trained on the University of Pennsylvania Treebank (Marcus et al, 1993)", 
    "clean_text": "The English sentences were parsed using a state-of-the-art statistical parser (Charniak, 2000) trained on the University of Pennsylvania Treebank (Marcus et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W05-0305", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Nikhil, Dinesh | Alan, Lee | Eleni, Miltsakaki | Rashmi, Prasad | Aravind K., Joshi | Bonnie Lynn, Webber", 
    "raw_text": "The overall goal of the Penn Discourse Treebank (PDTB) is to annotate the million word WSJcor pus in the Penn TreeBank (Marcus et al, 1993 )witha layer of discourse annotations", 
    "clean_text": "The overall goal of the Penn Discourse Treebank (PDTB) is to annotate the million word WSJ corpus in the Penn TreeBank (Marcus et al, 1993 ) with a layer of discourse annotations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N06-1022", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Eugene, Charniak | Mark, Johnson | Micha, Elsner | Joseph, Austerweil | David, Ellis | Isaac, Haxton | Catherine, Hill | R., Shrivaths | Jeremy, Moore | Michael, Pozar | Theresa, Vu", 
    "raw_text": "These remain fixed at all levels to the standard Penn-tree-bank set Marcus et al (1993)", 
    "clean_text": "These remain fixed at all levels to the standard Penn-tree-bank set Marcus et al (1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P04-1082", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Richard, Campbell", 
    "raw_text": "This paper describes an algorithm for detecting empty nodes in the Penn Treebank (Marcus et al, 1993), finding their antecedents, and assigning them function tags, without access to lexical information such as valency", 
    "clean_text": "This paper describes an algorithm for detecting empty nodes in the Penn Treebank (Marcus et al, 1993), finding their antecedents, and assigning them function tags, without access to lexical information such as valency.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P04-1082", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Richard, Campbell", 
    "raw_text": "In the Penn Treebank (Marcus et al, 1993), null elements, or empty categories, are used to indicate non-local dependencies, discontinuous constituents, and certain missing elements", 
    "clean_text": "In the Penn Treebank (Marcus et al, 1993), null elements, or empty categories, are used to indicate non-local dependencies, discontinuous constituents, and certain missing elements.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W97-0202", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Janyce, Wiebe | Julie, Maples | Lei, Duan | Rebecca F., Bruce", 
    "raw_text": "This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al 1993)", 
    "clean_text": "This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W07-2204", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Jennifer, Foster | Joachim, Wagner | Djam&eacute;, Seddah | Josef, van Genabith", 
    "raw_text": "The sentences included in the gold standard were chosen at random from the BNC, subject to the condition that they contain a verb which does not occur in the training sections of the WSJsection of the PTB (Marcus et al, 1993)", 
    "clean_text": "The sentences included in the gold standard were chosen at random from the BNC, subject to the condition that they contain a verb which does not occur in the training sections of the WSJ section of the PTB (Marcus et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P14-1099", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Shay B., Cohen | Michael John, Collins", 
    "raw_text": "We use the Penn WSJ tree bank (Marcus et al, 1993) for our experiments", 
    "clean_text": "We use the Penn WSJ treebank (Marcus et al, 1993) for our experiments.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D11-1058", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ai, Azuma | Yuji, Matsumoto", 
    "raw_text": "Therefore, this task is a typical interesting case where a sequence labeling depends on the out put from other sequence labelers. The data used for our experiment consist of English sentences from the Penn Treebank project (Marcus et al, 1993) consisting of 10948 sentences and 259104 words", 
    "clean_text": "The data used for our experiment consist of English sentences from the Penn Treebank project (Marcus et al, 1993) consisting of 10948 sentences and 259104 words.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "C08-1025", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Tejaswini, Deoskar", 
    "raw_text": "For instance, about 38% of verbs in the training sections of the Penn Treebank (PTB) (Marcus et al, 1993) occur only once? the lexical properties of these verbs (such as their most common sub categorization frames) can not be rep resented accurately in a model trained exclusively on the Penn Treebank", 
    "clean_text": "For instance, about 38% of verbs in the training sections of the Penn Treebank (PTB) (Marcus et al, 1993) occur only once the lexical properties of these verbs.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "N10-1086", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Michael, Heilman | Noah A., Smith", 
    "raw_text": "The third corpus was Section 23 of the Wall Street Journal data in the Penn Treebank (Marcus et al, 1993) .10 The training set included 284 questions about 8 articles, and the test set included 190questions about 2 articles from this corpus", 
    "clean_text": "The third corpus was Section 23 of the Wall Street Journal data in the Penn Treebank (Marcus et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W02-1031", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Wen, Wang | Mary P., Harper", 
    "raw_text": "We have observed in several experiments that the number of SuperARVsdoes not grow signi cantly as training set size in creases; the moderate-sized Resource Managementcorpus (Price et al, 1988) with 25,168 words produces 328 SuperARVs, compared to 538 SuperARVs for the 1 million word Wall Street Journal (WSJ) Penn Treebank set (Marcus et al, 1993), and 791forthe 37 million word training set of the WSJcontinuous speech recognition task.SuperARVs can be accumulated from a corpus an notated with CDG relations and stored directly with words in a lexicon, so we can learn their frequency of occurrence for the corresponding word", 
    "clean_text": "We have observed in several experiments that the number of SuperARVs does not grow significantly as training set size in creases; the moderate-sized Resource Management corpus (Price et al, 1988) with 25,168 words produces 328 SuperARVs, compared to 538 SuperARVs for the 1 million word Wall Street Journal (WSJ) Penn Treebank set (Marcus et al, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P02-1055", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Antal, van den Bosch | Sabine, Buchholz", 
    "raw_text": "In one experiment, it has to be performed on the basis of the? gold-standard?, assumed-perfect POS taken directly from the training data, the Penn Treebank (Marcus et al, 1993), so as to abstract from a particular POS tagger and to provide an upper bound. In another experiment, parsing is done on the basis of the words alone", 
    "clean_text": "In one experiment, it has to be performed on the basis of the gold-standard, assumed-perfect POS taken directly from the training data, the Penn Treebank (Marcus et al, 1993), so as to abstract from a particular POS tagger and to provide an upper bound.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P02-1055", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Antal, van den Bosch | Sabine, Buchholz", 
    "raw_text": "Our chunks and functions are based on the annotations in the third release of the Penn Treebank (Marcus et al, 1993)", 
    "clean_text": "Our chunks and functions are based on the annotations in the third release of the Penn Treebank (Marcus et al, 1993).", 
    "keep_for_gold": 0
  }
]