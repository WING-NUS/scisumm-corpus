Citance Number: 1 | Reference Article:  P08-1119.txt | Citing Article:  W09-1703.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Kozareva et al, 2008) proposed the use of a doubly-anchored hyponym pattern and a graph to represent the links between hyponym occurrences in these patterns.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We will refer to these as hyponym patterns.</S><S sid = NA ssid = NA>We present two algorithms that use hyponym pattern linkage graphs (HPLGs) to represent popularity and productivity information.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P08-1119.txt | Citing Article:  P10-1150.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We are particularly interested in the usage of recursive patterns for the learning of semantic relations not only because it is a novel method, but also because recursive patterns of the DAP fashion are known to: (1) learn concepts with high precision compared to singly-anchored pat terns (Kozareva et al, 2008), (2) use only one seed instance for the discovery of new previously unknown terms, and (3) harvest knowledge with minimal supervision.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Combining hyponym patterns with pattern linkage graphs is an effective way to produce a highly accurate semantic class learner that requires truly minimal supervision: just the class name and one class member as a seed.</S><S sid = NA ssid = NA>Each new class member is then used as a seed instance in the bootstrapping loop.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P08-1119.txt | Citing Article:  E12-1027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>With the same goal, Kozareva et al (2008) apply similar textual patterns to the web.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The KnowItAll system (Etzioni et al., 2005) also uses hyponym patterns to extract class instances from the web and then evaluates them further by computing mutual information scores based on web queries.</S><S sid = NA ssid = NA>Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P08-1119.txt | Citing Article:  D10-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similarly, (Kozareva et al,2008) evaluated only a small number (a few hundreds) of harvested instances.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.</S><S sid = NA ssid = NA>We evaluated our algorithms on four semantic categories: U.S. states, countries, singers, and fish.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P08-1119.txt | Citing Article:  D10-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In our experiments, we use the doubly-anchored lexico-syntactic patterns and bootstrapping algorithm introduced by (Kozareva et al., 2008) and (Hovy et al, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well.</S><S sid = NA ssid = NA>Our popularity-based algorithm was very effective and is practical to use.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P08-1119.txt | Citing Article:  N09-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In response, many automatic and semi-automatic methods of creating sets of named entities have been proposed, some are supervised (Zhou and Su, 2001), unsupervised (Pantel and Lin 2002, Nadeau et al 2006), and others semi-supervised (Kozareva et al 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user.</S><S sid = NA ssid = NA>These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P08-1119.txt | Citing Article:  P10-2023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Approaches in the first category use lexical-syntactic formulation to define patterns, either manually (Kozareva et al, 2008) or automatically (Girju et al, 2006), and apply those patterns to mine instances of the patterns.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We will refer to these as hyponym patterns.</S><S sid = NA ssid = NA>Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P08-1119.txt | Citing Article:  P10-2023.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>One approach for taxonomy deduction is to use explicit expressions (Iwaska et al, 2000) or lexical and semantic patterns such as is a (Snow et al, 2004), similar usage (Kozareva et al, 2008), synonyms and antonyms (Lin et al, 2003), purpose (Cimiano and Wenderoth, 2007), and employed by (Bunescu and Mooney, 2007) to extract and organize terms.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.</S><S sid = NA ssid = NA>Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P08-1119.txt | Citing Article:  D09-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Kozareva et al., 2008) introduced a bootstrapping scheme using the doubly-anchored pattern (DAP) that is guided through graph ranking.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To evaluate the performance of the doubly-anchored pattern, we began by using the pattern to search the web and embedded this process in a simple bootstrapping loop, which is presented in Figure 1.</S><S sid = NA ssid = NA>We describe this pattern as being doubly-anchored because it is instantiated with both the name of the semantic class as well as a class member.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P08-1119.txt | Citing Article:  D09-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To assess how well our algorithm compares with previous semantic class learning methods, we compared our results to those of (Kozareva et al, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A variety of methods have been developed for automatic semantic class identification, under the rubrics of lexical acquisition, hyponym acquisition, semantic lexicon induction, semantic class learning, and web-based information extraction.</S><S sid = NA ssid = NA>Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P08-1119.txt | Citing Article:  D09-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Consequently, we can compare the results produced by the first iteration of our algorithm (before intermediate concepts are learned) to those of (Kozareva et al, 2008) for the Animal and People categories, and then compare again after 10 bootstrapping iterations of intermediate concept learning.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For the state and country categories, however, we can compare our results with that of other web-based semantic class learners such as Pasca (Pas¸ca, 2007a) and the KnowItAll system (Etzioni et al., 2005).</S><S sid = NA ssid = NA>It can be difficult to compare the results of different semantic class learners because there is no standard set of benchmark categories, so researchers report results for different classes.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P08-1119.txt | Citing Article:  D09-1099.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Bootstrapping with intermediate concepts produces nearly 5 times as many basic-level concepts and instances than (Kozareva et al, 2008) obtain, while maintaining similar levels of precision.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>High precision is achieved only with low levels of recall for countries.</S><S sid = NA ssid = NA>(Pas¸ca, 2007a) reports results of 100% precision for the first 25 instances generated, and 82% precision for the first 150 instances generated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P08-1119.txt | Citing Article:  E12-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To group adjectives, we use a bootstrapping technique (Kozareva et al 2008) that learns which adjectives tend to co-occur, and groups these together to form an at tribute class.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Pasca also developed a second technique (Pas¸ca, 2007b) that creates context vectors for a group of seed instances by searching web query logs, and uses them to learn similar instances.</S><S sid = NA ssid = NA>Intuitively, we expect true class members to occur frequently in pattern contexts with other class members.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P08-1119.txt | Citing Article:  E09-1095.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Kozareva et al (2008) use a boot strapping approach that extends the fixed-pattern approach of Hearst (1992) in two intriguing ways.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>(Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups by acquiring contexts around the pattern.</S><S sid = NA ssid = NA>Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P08-1119.txt | Citing Article:  E09-1095.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The approach we describe here is most similar to that of Kozareva et al (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the next section, we present a new approach that creates a Hyponym Pattern Linkage Graph to steer bootstrapping and improve accuracy.</S><S sid = NA ssid = NA>These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P08-1119.txt | Citing Article:  E09-1095.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Kozareva et al (2008) test their approach on relatively simple and objective categories like states, countries (both closed sets), singers and fish (both open, the former more so than the latter), but not on complex categories in which members are tied both to a general category, like food, and to a stereotypical property, like sweet (Veale and Hao, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The singers and fish categories are much larger, open classes.</S><S sid = NA ssid = NA>We evaluated our algorithms on four semantic categories: U.S. states, countries, singers, and fish.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P08-1119.txt | Citing Article:  E09-1095.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following Kozareva et al (2008), we can either indulge in reckless bootstrapping, which ignores the question of noise until all bootstrapping is finished, or we can apply a noise filter after each incremental step.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, we perform reckless bootstrapping for a class name and seed until no new instances are generated.</S><S sid = NA ssid = NA>We will refer to this process as reckless bootstrapping because there are no checks of any kind.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P08-1119.txt | Citing Article:  N12-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Kozareva et al (2008) and Navigli et al (2011) both develop systems that create taxonomies end to-end, i.e., discover the terms, their relations, and how these are hierarchically organized.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003).</S><S sid = NA ssid = NA>These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P08-1119.txt | Citing Article:  N12-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similarly to Kozareva et al (2008) and Navigli et al (2011), our model operates over a graph whose nodes represent terms and edges their relationships.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The Out-degree (outD) score for vertex v is the weighted sum of v’s outgoing edges, normalized by the number of other nodes in the graph.</S><S sid = NA ssid = NA>The Total-degree (totD) score for vertex v is the weighted sum of both incoming and outgoing edges, normalized by the number of other nodes in the graph.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P08-1119.txt | Citing Article:  D12-1098.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We apply boot strapping (Kozareva et al 2008) on the word graphs by manually selecting 10 seeds for concrete and abstract words (see Table 10).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We experimented with three scoring functions for selecting nodes.</S><S sid = NA ssid = NA>A candidate word is productive if it frequently leads to the discovery of other words.</S> | Discourse Facet:  NA | Annotator: Automatic


