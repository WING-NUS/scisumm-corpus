[
  {
    "citance_No": 1, 
    "citing_paper_id": "W03-1014", 
    "citing_paper_authority": 90, 
    "citing_paper_authors": "Ellen, Riloff | Janyce, Wiebe", 
    "raw_text": "For example, (Pang et al, 2002) collected reviews from a movie database and rated them as positive, negative, or neutral based on the rating (e.g., number of stars) given by the reviewer", 
    "clean_text": "For example, (Pang et al, 2002) collected reviews from a movie database and rated them as positive, negative, or neutral based on the rating (e.g., number of stars) given by the reviewer.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2008", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Charles, Jochim | Hinrich, Sch\u00c3\u00bctze", 
    "raw_text": "It is the case in many sentiment analysis corpora that only positive and negative instances are included ,e.g., (Pang et al, 2002)", 
    "clean_text": "It is the case in many sentiment analysis corpora that only positive and negative instances are included, e.g., (Pang et al, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "C10-1072", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Shoushan, Li | Sophia Yat Mei, Lee | Ying, Chen | Chu-Ren, Huang | Guodong, Zhou", 
    "raw_text": "Sentiment classification is a special task of text classification whose objective is to classify a text according to the sentimental polarities of opinions it contains (Pang et al, 2002) ,e.g., favorable or unfavorable, positive or negative", 
    "clean_text": "Sentiment classification is a special task of text classification whose objective is to classify a text according to the sentimental polarities of opinions it contains (Pang et al, 2002), e.g., favorable or unfavorable, positive or negative.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P09-1079", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Sajib, Dasgupta | Vincent, Ng", 
    "raw_text": "For evaluation, we use five sentiment classification datasets, including the widely-used movie re view dataset [MOV] (Pang et al, 2002) as well as four datasets that contain reviews of four different types of product from Amazon [books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT)] (Blitzer et al, 2007)", 
    "clean_text": "For evaluation, we use five sentiment classification datasets, including the widely-used movie review dataset [MOV] (Pang et al, 2002) as well as four datasets that contain reviews of four different types of product from Amazon [books (BOO), DVDs (DVD), electronics (ELE), and kitchen appliances (KIT)] (Blitzer et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "N09-1001", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Fangzhong, Su | Katja, Markert", 
    "raw_text": "Important strands of work include the identification of subjective content and the deter mi nation of its polarity ,i.e. whether a favourable or unfavourable opinion is expressed. Automatic identification of subjective content of ten relies on word indicators, such as unigrams (Pang et al, 2002) or predetermined sentiment lex ica (Wilson et al, 2005)", 
    "clean_text": "Automatic identification of subjective content of ten relies on word indicators, such as unigrams (Pang et al, 2002) or predetermined sentiment lexica (Wilson et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W10-0216", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Shilpa, Arora | Elijah, Mayfield | Carolyn Penstein, Ros&eacute; | Eric H., Nyberg", 
    "raw_text": "? 2 Baseline: For our training data, after filtering infrequent unigrams and stop words, we get 7http: //svmlight.joachims.org/ 8Full movie review data by Pang et al (2002) 9http: //nlp.stanford.edu/ IR-book/html/htmledition/dropping-common-terms-stop-words-1.html (with one modification: removed? will?, added? this?) 8424 features", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W11-1717", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Balamurali, A. R. | Aditya, Joshi | Pushpak, Bhattacharyya", 
    "raw_text": "For the purpose of this work, we follow the definition of Pang et al (2002)& amp; Turney (2002) and consider a binary classification task for output labels as positive and negative. Lexeme-based (bag-of-words) features are commonly used for supervised sentiment classification (Pang and Lee, 2008)", 
    "clean_text": "For the purpose of this work, we follow the definition of Pang et al (2002) and Turney (2002) and consider a binary classification task for output labels as positive and negative.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W11-1717", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Balamurali, A. R. | Aditya, Joshi | Pushpak, Bhattacharyya", 
    "raw_text": "The low recall for adjective POS based synsets can be detrimental to classification since adjectives are known to express direct sentiment (Pang et al, 2002)", 
    "clean_text": "The low recall for adjective POS based synsets can be detrimental to classification since adjectives are known to express direct sentiment (Pang et al, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W11-1717", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Balamurali, A. R. | Aditya, Joshi | Pushpak, Bhattacharyya", 
    "raw_text": "We choose to use SVM since it performs the best for sentiment classification (Pang et al, 2002)", 
    "clean_text": "We choose to use SVM since it performs the best for sentiment classification (Pang et al, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W06-1639", 
    "citing_paper_authority": 46, 
    "citing_paper_authors": "Matt, Thomas | Bo, Pang | Lillian, Lee", 
    "raw_text": "In our experiments, we employed the well-known classifier SVMlight to obtain individual-document classification scores, treating Y as the positive class and using plain unigrams as features.5 Fol lowing standard practice in sentiment analysis (Pang et al, 2002), the input to SVMlight consisted of normalized presence-of-feature (rather than frequency-of-feature) vectors", 
    "clean_text": "Following standard practice in sentiment analysis (Pang et al, 2002), the input to SVMlight consisted of normalized presence-of-feature (rather than frequency-of-feature) vectors.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "H05-1045", 
    "citing_paper_authority": 35, 
    "citing_paper_authors": "Yejin, Choi | Claire, Cardie | Ellen, Riloff | Siddharth, Patwardhan", 
    "raw_text": "Much of this research explores sentiment classification, a text categorization task in which the goal is to classifya document as having positive or negative polarity (e.g., Das and Chen (2001), Pang et al (2002), Turney (2002), Dave et al (2003), Pang and Lee (2004))", 
    "clean_text": "Much of this research explores sentiment classification, a text categorization task in which the goal is to classify a document as having positive or negative polarity (e.g., Das and Chen (2001), Pang et al (2002), Turney (2002), Dave et al (2003), Pang and Lee (2004)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W12-3712", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Phillip, Smith | Mark, Lee", 
    "raw_text": "We experimented with three standard super vised machine learning algorithms: standard Na? ?ve Bayes (NB), multinomial Na? ?ve Bayes (MN NB) and Support Vector Machines (SVM) classification. Each has proven to be effective in previous sentiment analysis studies (Pang et al, 2002), so as this experiment is rooted in sentiment classification, these methods were also assumed to perform well in this cross-discourse setting", 
    "clean_text": "Each has proven to be effective in previous sentiment analysis studies (Pang et al, 2002), so as this experiment is rooted in sentiment classification, these methods were also assumed to perform well in this cross-discourse setting.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W12-3712", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Phillip, Smith | Mark, Lee", 
    "raw_text": "These results support experiments carried out for topic based classification using Bayesianclassifiers by McCallum and Nigam (1998), but differs from sentiment classification results from Pang et al (2002) that suggest that term-based models perform better than the frequency-based alternative", 
    "clean_text": "These results support experiments carried out for topic based classification using Bayesianclassifiers by McCallum and Nigam (1998), but differs from sentiment classification results from Pang et al (2002) that suggest that term-based models perform better than the frequency-based alternative.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W12-3712", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Phillip, Smith | Mark, Lee", 
    "raw_text": "Pang et al (2002) applied these classifiers to the movie review domain, which produced good results", 
    "clean_text": "Pang et al (2002) applied these classifiers to the movie review domain, which produced good results.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-1039", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Kavita, Ganesan | ChengXiang, Zhai | Jiawei, Han", 
    "raw_text": "Most existing work in Opin ion Summarization focus on predicting sentiment orientation on an entity (Pang et al, 2002) (Pang and Lee, 2004) or attempt to generate aspect-based ratings for that entity (Snyder and Barzilay, 2007) (Lu et al, 2009) (Lerman et al, 2009) (TitovandMcdonald, 2008)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D11-1147", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Vahed, Qazvinian | Emily, Rosengren | Dragomir R., Radev | Qiaozhu, Mei", 
    "raw_text": "Previouswork has used machine learning techniques to identify positive and negative movie reviews (Pang et al., 2002)", 
    "clean_text": "Previouswork has used machine learning techniques to identify positive and negative movie reviews (Pang et al., 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W06-1650", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Soo-Min, Kim | Patrick, Pantel | Timothy, Chklovski | Marco, Pennacchiotti", 
    "raw_text": "Pang et al (2002) and Turney (2002) classified sentiment polarity of reviews at the document level", 
    "clean_text": "Pang et al (2002) and Turney (2002) classified sentiment polarity of reviews at the document level.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "C10-2153", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Rui, Xia | Chengqing, Zong", 
    "raw_text": "Although the discriminative model (e.g., SVM) is proven to be more effective on unigrams (Pang et al, 2002) for its ability of capturing the complexity of more relevant features, WR features are more inclined to work better in the generative model (e.g., NB) since the feature independence assumption holds well in this case", 
    "clean_text": "Although the discriminative model (e.g., SVM) is proven to be more effective on unigrams (Pang et al, 2002) for its ability of capturing the complexity of more relevant features, WR features are more inclined to work better in the generative model (e.g., NB) since the feature independence assumption holds well in this case.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P13-2088", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mohamed, Aly | Amir, Atiya", 
    "raw_text": "Rating classification: where the goal is to predict the rating of the review on a scale of 1 to 5. To this end, we divided the dataset into separate training and test sets, with a ratio of 8:2. We do this because we already have enough training data, so there is no need to resort to cross-validation (Pang et al, 2002)", 
    "clean_text": "We do this because we already have enough training data, so there is no need to resort to cross-validation (Pang et al, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D10-1025", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "John C., Platt | Kristina, Toutanova | Scott Wen-Tau, Yih", 
    "raw_text": "Cross-language text categorization? Appli cations of text categorization, such as sentiment classification (Pang et al, 2002), are now required to run on multiple languages", 
    "clean_text": "Applications of text categorization, such as sentiment classification (Pang et al, 2002), are now required to run on multiple languages.", 
    "keep_for_gold": 0
  }
]