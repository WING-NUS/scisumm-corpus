Citance Number: 1 | Reference Article:  W06-2915.txt | Citing Article:  P06-1133.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Given a pair of document collections A and B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al, 2006), but to determine if the document collection pair (A, B) convey opposing perspectives.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Given a new document W with a unknown document perspective, the perspective D� is calculated based on the following conditional probability.</S><S sid = NA ssid = NA>A system that can automatically identify the perspective from which a document is written will be a valuable tool for people analyzing huge collections of documents from different perspectives.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W06-2915.txt | Citing Article:  P14-2068.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In some cases, the author may also introduce their own perspective (Lin et al, 2006) through the use of framing (Greene and Resnik, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005).</S><S sid = NA ssid = NA>We introduce a new binary random variable, S, to model how strongly a perspective is reflected at the sentence level.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W06-2915.txt | Citing Article:  P10-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Hierarchical Bayesian modelling has recently gained notable popularity in many core areas of natural language processing, from morphological segmentation (Goldwater et al, 2009) to opinion modelling (Lin et al, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005).</S><S sid = NA ssid = NA>Research on the automatic classification of movie or product reviews as positive or negative (e.g., (Pang et al., 2002; Morinaga et al., 2002; Turney and Littman, 2003; Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Hu and Liu, 2004)) is perhaps the most similar to our work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W06-2915.txt | Citing Article:  D10-1028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We show that using adaptive naive Bayes improves on state of the art classification using the Bitter Lemons corpus (Lin et al, 2006), a document collection that has been used by a variety of authors to evaluate perspective classification.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Using this model, we obtain a classification accuracy of only 0.7529, which is much lower than the accuracy previously achieved at the document level.</S><S sid = NA ssid = NA>As an alternative, we evaluate how accurately LSPM predicts the perspective of a document, again using 10-fold cross validation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W06-2915.txt | Citing Article:  D10-1028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The support vector machine (SVM), NB B and LSPM results are taken directly from Lin et al (2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We evaluate three different models for the task of identifying perspective at the document level: two naive Bayes models (NB) with different inference methods and Support Vector Machines (SVM) (Cristianini and Shawe-Taylor, 2000).</S><S sid = NA ssid = NA>We compare NB with SVM not only because SVM has been very effective for classifying topical documents (Joachims, 1998), but also to contrast generative models like NB with discriminative models like SVM.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W06-2915.txt | Citing Article:  P10-2047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We report 4-fold cross-validation (DP-4) using the folds in Greene and Resnik (2009), where training and testing data come from different websites for each of the sides, as well as 10-fold cross-validation performance on the entire corpus, irrespective of the site. Bitter Lemons (BL): We use the GUEST part of the BitterLemons corpus (Lin et al, 2006), containing 296 articles published in 2001-2005 on http: //www.bitterlemons.org by more than 200 different Israeli and Palestinian writers on issues re lated to the conflict. Bitter Lemons International (BL-I): We collected 150 documents each by a different per2Ratings are from :http: //www.OnTheIssues.org/.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To evaluate the statistical models, we train them on the documents in the bitterlemons corpus and calculate how accurately each model predicts document perspective in ten-fold cross-validation experiments.</S><S sid = NA ssid = NA>As an alternative, we evaluate how accurately LSPM predicts the perspective of a document, again using 10-fold cross validation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W06-2915.txt | Citing Article:  P10-2047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The first half of burn-in samples are discarded.</S><S sid = NA ssid = NA>Given a new document W with a unknown document perspective, the perspective D� is calculated based on the following conditional probability.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W06-2915.txt | Citing Article:  W11-1701.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For these features we replace the opinion words with their positive or negative polarity equivalents (Lin et al, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A positive or negative opinion toward a particular movie or product is fundamentally different from an overall perspective.</S><S sid = NA ssid = NA>So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W06-2915.txt | Citing Article:  P11-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>They attempt to identify a position of a debate, such as ideological (Somasundaran et al, 2010, Lin et al, 2006) or product comparison debate (Somasundaran et al, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005).</S><S sid = NA ssid = NA>Research on the automatic classification of movie or product reviews as positive or negative (e.g., (Pang et al., 2002; Morinaga et al., 2002; Turney and Littman, 2003; Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Hu and Liu, 2004)) is perhaps the most similar to our work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W06-2915.txt | Citing Article:  P11-1035.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>These experiments were conducted in political debate corpus (Lin et al 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005).</S><S sid = NA ssid = NA>There has been research in discourse analysis that examines how different perspectives are expressed in political discourse (van Dijk, 1988; Pan et al., 1999; Geis, 1987).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W06-2915.txt | Citing Article:  W12-3810.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Lin et al, 2006) explores relationships between sentence-level and document-level classification for a stance-like prediction task. Among the literature on ideological subjectivity, perhaps most similar to our work is (Somasundaran and Wiebe, 2010).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Identifying perspectives at the sentence level is thus more difficult than identifying perspectives at the document level.</S><S sid = NA ssid = NA>As with review classification, we treat perspective identification as a document-level classification task, discriminating, in a sense, between different types of opinions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W06-2915.txt | Citing Article:  W11-0413.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Some sentences are written from a certain perspective (Lin et al, 2006) or point of view.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>By perspective we mean a point of view, for example, from the perspective of Democrats or Republicans.</S><S sid = NA ssid = NA>While by its very nature we expect much of the language that is used when presenting a perspective or point-of-view to be subjective, labeling a document or a sentence as subjective is not enough to identify the perspective from which it is written.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W06-2915.txt | Citing Article:  W11-0413.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As it is easy for a human to identify the perspective of an author (Lin et al, 2006), this measure facilitated the annotation task.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We include the results for the naive Bayes models from Table 3 for easy comparison.</S><S sid = NA ssid = NA>So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W06-2915.txt | Citing Article:  N09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In our second study, we make a direct comparison with prior state-of-the-art classification using the Bitter Lemons corpus of Lin et al (2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We model the process of generating documents from a particular perspective as follows: First, the parameters π and θ are sampled once from prior distributions for the whole corpus.</S><S sid = NA ssid = NA>So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W06-2915.txt | Citing Article:  N09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Israeli-Palestinian Conflict In order to make a direct comparison here with prior state-of-the-art work on sentiment analysis, we re port on sentiment classification using OPUS features in experiments using a publicly available corpus involving opposing perspectives, the Bitter Lemons corpus introduced by Lin et al (2006) .Corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Denote a training corpus as a set of documents Wn and their perspectives labels Dn, n = 1, ... , N, where N is the total number of documents in the corpus.</S><S sid = NA ssid = NA>We model the process of generating documents from a particular perspective as follows: First, the parameters π and θ are sampled once from prior distributions for the whole corpus.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W06-2915.txt | Citing Article:  N09-1057.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Within computational linguistics, what we call implicit sentiment was introduced as a topic of study by Lin et al (2006) under the rubric of identifying perspective, though similar work had begun earlier in the realm of political science.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Although their research may have some similar goals, they do not take a computational approach to analyzing large collections of documents.</S><S sid = NA ssid = NA>Research on the automatic classification of movie or product reviews as positive or negative (e.g., (Pang et al., 2002; Morinaga et al., 2002; Turney and Littman, 2003; Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Hu and Liu, 2004)) is perhaps the most similar to our work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W06-2915.txt | Citing Article:  P13-1162.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>They often belong to controversial subjects (e.g., religion, terrorism, etc.) where the same event can beseen from two or more opposing perspectives, like the IsraeliPalestinian conflict (Lin et al, 2006).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al., 2004; Riloff et al., 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al., 2003), and discriminating between positive and negative language (Pang et al., 2002; Morinaga et al., 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al., 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al., 2005).</S><S sid = NA ssid = NA>We compare NB with SVM not only because SVM has been very effective for classifying topical documents (Joachims, 1998), but also to contrast generative models like NB with discriminative models like SVM.</S> | Discourse Facet:  NA | Annotator: Automatic


