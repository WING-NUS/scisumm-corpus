[
  {
    "citance_No": 1, 
    "citing_paper_id": "P03-1071", 
    "citing_paper_authority": 48, 
    "citing_paper_authors": "Michel, Galley | Kathleen R., McKeown | Eric, Fosler-Lussier | Hongyan, Jing", 
    "raw_text": "Since it has been argued in (Pevzner and Hearst, 2002) that Pk has some weaknesses, we also include results ac cording to the WindowDiff (WD) metric (which is described in the same work)", 
    "clean_text": "Since it has been argued in (Pevzner and Hearst, 2002) that Pk has some weaknesses, we also include results according to the WindowDiff (WD) metric (which is described in the same work).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P13-1167", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Chris, Fournier", 
    "raw_text": "198? 200), WindowDiff (WD; Pevzner and Hearst 2002, p. 10), and most recently Segmentation Similarity (S; FournierandInkpen 2012, p. 154? 156)", 
    "clean_text": "To select an automatic segmenter for a particular task, a variety of segmentation evaluation metrics have been proposed, including Pk (Beeferman and Berger, 1999, pp. 198-200), WindowDiff (WD; Pevzner and Hearst 2002, p. 10), and most recently Segmentation Similarity (S; Fournier and Inkpen 2012, p. 154-156).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P13-1167", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Chris, Fournier", 
    "raw_text": "Pevzner and Hearst (2002, pp", 
    "clean_text": "Pevzner and Hearst (2002, pp. 3-4) explain Pk well: a window of size k \u2014 where k is half of the mean manual segmentation length \u2014 is slid across both automatic and manual segmentations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P13-1167", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Chris, Fournier", 
    "raw_text": "Pevzner and Hearst (2002, pp", 
    "clean_text": "Pevzner and Hearst (2002, pp. 5-10) identified that Pk: i) penalizes false negatives (FNs)2 more than false positives (FPs); ii) does not penalize full misses within k units of a reference boundary; iii) penalize near misses too harshly in some situations; and iv) is sensitive to internal segment size variance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P13-1167", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Chris, Fournier", 
    "raw_text": "To solve Pk? s issues, Pevzner and Hearst (2002, pp", 
    "clean_text": "To solve Pk's issues, Pevzner and Hearst (2002, pp. 10) proposed a modification referred to as WindowDiff (WD).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D07-1088", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Donghui, Feng | Gully, Burns | Eduard, Hovy", 
    "raw_text": "Hence the standard Pk (Beeferman et al, 1997) and WinDiff (Pevzner and Hearst, 2002) measures for text segmentation are not so suitable for our task", 
    "clean_text": "Hence the standard Pk (Beeferman et al, 1997) and WinDiff (Pevzner and Hearst, 2002) measures for text segmentation are not so suitable for our task.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D07-1037", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Irina, Matveeva | Gina-Anne, Levow", 
    "raw_text": "1http: //www1.cs.columbia.edu/galley/tools.html 2http: //nist.gov/speech/tests/tdt/tdt98/ 3http: //www.lemurproject.org/ 4http: //www.cis.upenn.edu/dbikel/software.html Evaluation For the TDT data we use the error metric pk (Beeferman et al, 1999) and WindowDiff (Pevzner and Hearst, 2002) which are implemented in the LCseg toolkit", 
    "clean_text": "For the TDT data we use the error metric pk (Beeferman et al, 1999) and WindowDiff (Pevzner and Hearst, 2002) which are implemented in the LCseg toolkit.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "N12-1016", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Chris, Fournier | Diana Zaiu, Inkpen", 
    "raw_text": "Precision is the proportion of boundaries chosen that agree with a reference segmentation, and recall is the proportion of boundaries chosen that agree with a reference segmentation out of all boundaries in the reference and hypothesis (Pevzner and Hearst, 2002, p. 3)", 
    "clean_text": "Precision is the proportion of boundaries chosen that agree with a reference segmentation, and recall is the proportion of boundaries chosen that agree with a reference segmentation out of all boundaries in the reference and hypothesis (Pevzner and Hearst, 2002, p. 3).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N12-1016", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Chris, Fournier | Diana Zaiu, Inkpen", 
    "raw_text": "Pevzner and Hearst (2002, pp", 
    "clean_text": "To attempt to mitigate the shortcomings of Pk, Pevzner and Hearst (2002, p. 10) proposed a modified metric which changed how penalties were counted, named WindowDiff (WD).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "N12-1016", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Chris, Fournier | Diana Zaiu, Inkpen", 
    "raw_text": "When Pevzner and Hearst (2002) proposed WD, they demonstrated that it was not as sensitive as Pk to variations in the size of segments inside a segmentation", 
    "clean_text": "When Pevzner and Hearst (2002) proposed WD, they demonstrated that it was not as sensitive as Pk to variations in the size of segments inside a segmentation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "N12-1016", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Chris, Fournier | Diana Zaiu, Inkpen", 
    "raw_text": "To show this, they simulated how WD performs upon a segmentation comprised of1000 segments with four different uniformly distributed ranges of internal segment sizes (keeping the mean at approximately 25 units) in comparison to a hypothesis segmentation with errors (false positives, false negatives, and both) uniformly distributed within segments (Pevzner and Hearst, 2002, pp", 
    "clean_text": "To show this, they simulated how WD performs upon a segmentation comprised of 1000 segments with four different uniformly distributed ranges of internal segment sizes (keeping the mean at approximately 25 units) in comparison to a hypothesis segmentation with errors (false positives, false negatives, and both) uniformly distributed within segments (Pevzner and Hearst, 2002, pp. 11-12).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P07-1061", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Olivier, Ferret", 
    "raw_text": "We also give the value of WindowDiff (WD), a variant of Pk proposed in (Pevzner and Hearst, 2002) that corrects some of its insufficiencies", 
    "clean_text": "We also give the value of WindowDiff (WD), a variant of Pk proposed in (Pevzner and Hearst, 2002) that corrects some of its insufficiencies.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "N06-2032", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Andrew, Rosenberg | Julia, Hirschberg", 
    "raw_text": "In these tables, we report the F-measure of identifying the precise lo cation of a story boundary as well as three metrics designed specifically for this type of segmentation task: the pk metric (Beeferman et al, 1999), WindowDiff (Pevzner and Hearst, 2002) and Cseg (Pseg= 0.3) (Doddington, 1998)", 
    "clean_text": "In these tables, we report the F-measure of identifying the precise location of a story boundary as well as three metrics designed specifically for this type of segmentation task: the pk metric (Beeferman et al, 1999), WindowDiff (Pevzner and Hearst, 2002) and Cseg (Pseg= 0.3) (Doddington, 1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D07-1087", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Sander, Canisius | Caroline, Sporleder", 
    "raw_text": "As a last measure for segmentation quality we used WindowDiff (Pevzner and Hearst, 2002), which only evaluates segment boundaries not the labels assigned to them", 
    "clean_text": "As a last measure for segmentation quality we used WindowDiff (Pevzner and Hearst, 2002), which only evaluates segment boundaries not the labels assigned to them.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P06-1003", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Matthew, Purver | Konrad P., Kording | Thomas L., Griffiths | Joshua B., Tenenbaum", 
    "raw_text": "For each set of annotations, we therefore performed two sets of segmentations: one in which the threshold was set for each meeting to give the known gold standard number of segments, and one in which the threshold was set on a separate development set to give the overall corpus-wide average number of segments, and held constant for all test meet ings.2 This also allows us to compare our results with those of (Galley et al, 2003), who apply asimilar threshold to their lexical cohesion function and give corresponding results produced with known/unknown numbers of segments. Segmentation We assessed segmentation performance using the Pk and WindowDiff (WD )error measures proposed by (Beeferman et al, 1999) and (Pevzner and Hearst, 2002) respectively; both intuitively provide a measure of the probability that two points drawn from the meeting will be incorrectly separated by a hypothesized segment boundary? thus, lower Pk and WD figures indicate better agreement with the human-annotatedresults.3 For the numbers of segments we are dealing with, a baseline of segmenting the discourse into equal-length segments gives both Pk and WD about 50%", 
    "clean_text": "We assessed segmentation performance using the Pk and WindowDiff (WD) error measures proposed by (Beeferman et al, 1999) and (Pevzner and Hearst, 2002) respectively.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W06-1320", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Maria, Georgescul | Alexander, Clark | Susan, Armstrong", 
    "raw_text": "Pevzner and Hearst (2002) highlighted several problems of the Pk metric", 
    "clean_text": "Pevzner and Hearst (2002) highlighted several problems of the Pk metric.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W06-1320", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Maria, Georgescul | Alexander, Clark | Susan, Armstrong", 
    "raw_text": "Pevzner and Hearst (2002) propose the alternative metric called WindowDiff", 
    "clean_text": "Pevzner and Hearst (2002) propose the alternative metric called WindowDiff.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W06-1320", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Maria, Georgescul | Alexander, Clark | Susan, Armstrong", 
    "raw_text": "(Pevzner and Hearst, 2002)", 
    "clean_text": "However, unlike Pk and Pk, WindowDiff takes into account how many boundaries fall within the window and is penalizing in 'how many discrepancies occur between the reference and the system results' rather than 'determining how often two units of text are incorrectly labeled as being in different segments' (Pevzner and Hearst, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W06-1320", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Maria, Georgescul | Alexander, Clark | Susan, Armstrong", 
    "raw_text": "(Pevzner and Hearst, 2002)", 
    "clean_text": "Another issue regarding WindowDiff is that it is not clear 'how does one interpret the values produced by the metric' (Pevzner and Hearst, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P10-2028", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Minwoo, Jeong | Ivan, Titov", 
    "raw_text": "For all evaluations, we apply standard stemming algorithm and remove common stop words. Evaluationmetrics To measure the quality of segmentation of the lecture transcript, we use two standard metrics, Pk (Beeferman et al, 1999) and WindowDiff (WD) (Pevzner and Hearst, 2002), but both metrics disregard the alignment links (i.e. the topic labels)", 
    "clean_text": "To measure the quality of segmentation of the lecture transcript, we use two standard metrics, Pk (Beeferman et al, 1999) and WindowDiff (WD) (Pevzner and Hearst, 2002), but both metrics disregard the alignment links (i.e. the topic labels).", 
    "keep_for_gold": 0
  }
]