Citance Number: 1 | Reference Article:  W07-2012.txt | Citing Article:  W07-2089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>UNN-WePS achieved an average purity of 0.6, and inverse purity of 0.73 in Semeval Task 13, achieving seventh position out of sixteen competing systems (Artiles et al 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Therefore, achieving a high inverse purity should be rewarded more than having high purity.</S><S sid = NA ssid = NA>Inverse Purity is defined as: 67 Inverse Purity = ? i |Li| n max Precision(Li, Cj)For the final ranking of systems we used the har monic mean of purity and inverse purity F?=0,5 . The F measure is defined as follows: F = 1 ? 1Purity + (1?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W07-2012.txt | Citing Article:  W07-2089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We have described a system, UNN-WePS that disambiguates individuals in web pages as required for Semeval task 13 (Artiles et al 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>The trial data consisted of an adapted version of the WePS corpus described in (Artiles et al, 2006).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W07-2012.txt | Citing Article:  D12-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used three datasets in our experiments, WePS1 Training and Testing (Artiles et al 2007), WePS2 Testing (Javier et al 2009). These datasets collected names from three different resources including Wikipedia names, program committee of a computer science conference and US census.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Finally, ten additional names were ran domly selected from the Program Committee listing of a Computer Science conference (ECDL 2006).This set offers a scenario of potentially low am biguity (computer science scholars usually have a stronger Internet presence than other professionalfields) with the added value of the a priori knowl edge of a domain specific type of entity (scholar) present in the data.</S><S sid = NA ssid = NA>We also specified the source of each ambiguous name in the training data (Wikipedia, ECDL conference and US Census).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W07-2012.txt | Citing Article:  D12-1076.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We adopt the same evaluation process as (Han and Zhao, 2009), and evaluating these models using Purity, Inverse Purity and the F-measure (also used in WePS Task Artiles et al 2007)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Inverse Purity is defined as: 67 Inverse Purity = ? i |Li| n max Precision(Li, Cj)For the final ranking of systems we used the har monic mean of purity and inverse purity F?=0,5 . The F measure is defined as follows: F = 1 ? 1Purity + (1?</S><S sid = NA ssid = NA>The human annotation was used as the gold standard for the evaluation.Each system was evaluated using the standard pu rity and inverse purity clustering measures Purity isrelated to the precision measure, well known in In formation Retrieval.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W07-2012.txt | Citing Article:  P10-1006.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We adopted the standard data sets used in the First Web People Search Clustering Task (WePS1) (Artiles et al, 2007) and the Second Web People Search Clustering Task (WePS2) (Artiles et al, 2009).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S><S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W07-2012.txt | Citing Article:  W07-2058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We consider the problem of disambiguating person names in a Web searching scenario as described by the Web People Search Task in SemEval 2007 (Artiles et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W07-2012.txt | Citing Article:  W07-2058.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Two different evaluation measures are reported as described by the task: F=0.5 is a harmonic mean of purity and inverse purity of the clustering result, and F? =0.2 is a version of F that gives more importance to inverse purity (Artiles et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Inverse Purity is defined as: 67 Inverse Purity = ? i |Li| n max Precision(Li, Cj)For the final ranking of systems we used the har monic mean of purity and inverse purity F?=0,5 . The F measure is defined as follows: F = 1 ? 1Purity + (1?</S><S sid = NA ssid = NA>In this case purity always gives its maximum value, while inverse purity will decrease with larger classes.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W07-2012.txt | Citing Article:  W07-2075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Sections 3 and 4 presents in more detail the implementation of the framework for the Semeval 2007 WEPS task (Artiles et al, 2007) and Semeval-.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>This paper presents the task definition, resources, participation, and comparative re sults for the Web People Search task, which was organized as part of the SemEval-2007 evaluation exercise.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W07-2012.txt | Citing Article:  W07-2075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In this section we will explain in more detail how we implemented the general schema described in the previous section to the Web People Search task (Artiles et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This section of thecorpus was used for the systems evaluation.</S><S sid = NA ssid = NA>Finally, Section 4 presents some con clusions.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W07-2012.txt | Citing Article:  W07-2019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The data we have used for training our system were made available in the framework of the SemEval (task 13: Web People Search) competition (Artileset al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W07-2012.txt | Citing Article:  W07-2019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For both categories the number of target output clusters equals (number of RIPPER output clusters+ the number of documents*0.2). Although the clustering results with the best set tings for hierarchical and agglomerative clustering were very close with regard to F-score (combining purity and inverse purity, see (Artiles et al, 2007) for a more detailed description), manual inspection of the content of the clusters has revealed big differences between the two approaches.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Note that there is no a priori knowledge about the number of entities that will be discovered in a document set.</S><S sid = NA ssid = NA>Our task is rather a case of Word Sense Discrimination, because the number of ?senses?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W07-2012.txt | Citing Article:  N09-3002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We evaluate our methods using the benchmark test collection from the ACL SemEval-2007 web person search task (WePS hereafter) (Artiles et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W07-2012.txt | Citing Article:  N09-3002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Hence the performance reported here is comparable to the official evaluation results (Artiles et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Out of them, 16 teams submitted results within the deadline; their results are reported below.</S><S sid = NA ssid = NA>The task description and the initial trial data set were publicly released before the start of the official evaluation.The official evaluation period started with the simultaneous release of both training and test data, to gether with a scoring script with the main evaluation measures to be used.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W07-2012.txt | Citing Article:  W07-2030.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The goal of the Web People Search task (Artiles et al 2007) is to assign Web pages to groups, where each group contains all (and only those) pages that refer to one unique entity.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>pages).</S><S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W07-2012.txt | Citing Article:  W07-2069.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In this paper, we described our participating system in the SemEval-2007 Web People Search Task (Artiles et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>This paper presents the task definition, resources, participation, and comparative re sults for the Web People Search task, which was organized as part of the SemEval-2007 evaluation exercise.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W07-2012.txt | Citing Article:  P11-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The research on cross-document entity coreference resolution can be traced back to the Web People Search task (Artiles et al, 2007) and ACE2008 (e.g. Baron and Freedman, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W07-2012.txt | Citing Article:  W07-2063.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Here, we concentrate on the following SemEval 2007 Web People Search Task (Artiles et al, 2007): a search engine user types in a person name as a query.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W07-2012.txt | Citing Article:  C10-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Recently, there is significant research interest in a related task called Web Person Search (WePS) (Artiles et al, 2007), which seeks to determine whether two documents refer to the same person given a person name search query.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>All datasets consist of collections of web pages obtained from the 100 top results for a person name query to an Internet search engine 2.</S><S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W07-2012.txt | Citing Article:  C10-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The more recent Web Person Search (WePS) task (Artiles et al, 2007) has created a benchmark dataset which is also used in this work.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The SemEval-2007 WePS Evaluation: Establishing a benchmark for the Web People Search Task</S><S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W07-2012.txt | Citing Article:  C10-1055.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similar IR features are also used by other WePS systems as they are more robust to the variety of web pages (Artiles et al, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>pages).</S><S sid = NA ssid = NA>And this is, in essence, the WePS (Web People Search) task we have proposed to SemEval-2007 participants: systems receive a set of web pages(which are the result of a web search for a per son name), and they have to cluster them in as many sets as entities sharing the name.</S> | Discourse Facet:  NA | Annotator: Automatic


