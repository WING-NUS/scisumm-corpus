Using Syntactic Dependency As Local Context To Resolve Word Sense Ambiguity
Most previous corpus-based algorithms disambiguate a word with a classifier trained from previous usages of the same word.
Separate classifiers have to be trained for different words.
We present an algorithm that uses the same knowledge sources to disambiguate different words.
The algorithm does not require a sense-tagged corpus and exploits the fact that two different words are likely to have similar meanings if they occur in identical local contexts.
We define the similarity between two objects to be the amount of information contained in the commonolity between the objects divided by the amount of information in the descriptions of the objects.
