[
  {
    "citance_No": 1, 
    "citing_paper_id": "P05-1069", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Christoph, Tillmann | Tong, Zhang", 
    "raw_text": "A DP-based beam search procedure identical to the one used in (Tillmann,2004) is used to maximize over all oriented block segmentations \u000e X\u0010 \u0012 \u0013 \u0010 \u0012 \u0015. During decoding orientation bi-", 
    "clean_text": "A DP-based beam search procedure identical to the one used in (Tillmann,2004) is used to maximize over all oriented block segmentations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P05-1069", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Christoph, Tillmann | Tong, Zhang", 
    "raw_text": "For details see (Tillmann, 2004)", 
    "clean_text": "For details see (Tillmann, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P05-1069", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Christoph, Tillmann | Tong, Zhang", 
    "raw_text": "As in (Tillmann, 2004), we model the block bigram probability as ff \u000e \u0018 \u0013 \u0018 R T N \u0013 Q W fl \u0018 ?ffi \u0012 \u0013 \u0018ffi \u0012 \u0015 in Eq", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P13-1156", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "ThuyLinh, Nguyen | Stephan, Vogel", 
    "raw_text": "(e, f ,ph (a))) .We focus on improving the modelling of re ordering within Hiero and include discriminative reordering features (Tillmann, 2004) and a distance cost feature, both of which are not modeled in the original Hiero system", 
    "clean_text": "We focus on improving the modelling of reordering within Hiero and include discriminative reordering features (Tillmann, 2004) and a distance cost feature, both of which are not modeled in the original Hiero system.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P10-2003", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Jinsong, Su | Yang, Liu | Yajuan, L&uuml; | Haitao, Mi | Qun, Liu", 
    "raw_text": "The phrase-based reordering model (Tillmann, 2004) determines the presence of the adjacent bilingual phrase located in position (s? 1 ,v+1) and then treats the orientation of bp as S. Given no constraint on maximum phrase length, the hierarchical phrase reordering model (Galley and Manning, 2008) also analyzes the adjacent bilingual phrases for bp and identifies its orientation as S.However, given a bilingual phrase, the above mentioned models just consider the presence of an adjacent bilingual phrase rather than the number of adjacent bilingual phrases", 
    "clean_text": "The phrase-based reordering model (Tillmann, 2004) determines the presence of the adjacent bilingual phrase located in position (s-1,v+1) and then treats the orientation of bp as S.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P10-2003", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Jinsong, Su | Yang, Liu | Yajuan, L&uuml; | Haitao, Mi | Qun, Liu", 
    "raw_text": "1The phrase-based lexical reordering model (Tillmann, 2004) is also closely related to our model", 
    "clean_text": "The phrase-based lexical reordering model (Tillmann, 2004) is also closely related to our model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W10-1704", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Alexandre, Allauzen | Josep M., Crego | Ilknur, Durgar El-Kahlout | Fran&ccedil;ois, Yvon", 
    "raw_text": "One novelty this yea rare the introduction of lexicalized reordering mod els (Tillmann, 2004)", 
    "clean_text": "One novelty this year are the introduction of lexicalized reordering models (Tillmann, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "N10-1140", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Michel, Galley | Christopher D., Manning", 
    "raw_text": "Both Moses an dour system are evaluated with and without lexical ized reordering (Tillmann, 2004) .4 We believe it to be fair to compare Joshua against phrase-based systems that exploit lexicalized reordering, since Hiero? s hierarchical rules are also lexically sensitive.5The language pair for our experiments is Chinese to-English", 
    "clean_text": "Both Moses and our system are evaluated with and without lexicalized reordering (Tillmann, 2004) .", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N10-1140", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Michel, Galley | Christopher D., Manning", 
    "raw_text": "As far as this reordering model is concerned, we treat discontinuous phrases as continuous ,i.e., we simply ignore what lies within gaps to determine phrase orientation.5 (Tillmann, 2004) learns for each phrase a tendency to either remain monotone or to swap with other phrases", 
    "clean_text": "(Tillmann, 2004) learns for each phrase a tendency to either remain monotone or to swap with other phrases.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W11-2142", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Markus, Freitag | Gregor, Leusch | Joern, Wuebker | Stephan, Peitz | Hermann, Ney | Teresa, Herrmann | Jan, Niehues | Alex, Waibel | Alexandre, Allauzen | Gilles, Adda | Josep Maria, Crego | Bianka, Buschbeck-Wolf | Tonio, Wandmacher | Jean, Senellart", 
    "raw_text": "This is performed by a stochastic finite-state reordering model, which uses part-of-speech information3 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a weak distance-based distortion model; and finally a word bonus model and a tuple-bonus model which compensate for the system preference for short translations", 
    "clean_text": "In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a weak distance-based distortion model; and finally a word bonus model and a tuple-bonus model which compensate for the system preference for short translations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W09-2310", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Maxim, Khalilov | Jos&eacute; A. R., Fonollosa | Mark, Dras", 
    "raw_text": "1http: //www.statmt.org/moses/In baseline experiments we used a phrase dependent lexicalized reordering model, as proposed inTillmann (2004)", 
    "clean_text": "In baseline experiments we used a phrase dependent lexicalized reordering model, as proposed in Tillmann (2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W08-0304", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Daniel, Cer | Daniel, Jurafsky | Christopher D., Manning", 
    "raw_text": "Phrases were extracted using the typical approach described in Koehn et al (2003) of running GIZA++ (Och& amp; Ney, 2003) in both directions and then merging the alignments using the grow-diag-final heuristic. From the merged alignments we also extracted a bi directional lexical reordering model conditioned on the source and the target phrases (Tillmann, 2004) (Koehn et al, 2007)", 
    "clean_text": "From the merged alignments we also extracted a bidirectional lexical reordering model conditioned on the source and the target phrases (Tillmann, 2004) (Koehn et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "N06-1004", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Roland, Kuhn | Denis, Yuen | Michel, Simard | Patrick, Paul | George, Foster | Eric, Joanis | Howard, Johnson", 
    "raw_text": "The (Tillmann, 2004) paper introduced lexical features for distortion modeling", 
    "clean_text": "The (Tillmann, 2004) paper introduced lexical features for distortion modeling.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "N06-1004", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Roland, Kuhn | Denis, Yuen | Michel, Simard | Patrick, Paul | George, Foster | Eric, Joanis | Howard, Johnson", 
    "raw_text": "An other obvious system improvement would be to incorporate more advanced word-based features in the DTs, such as questions about word classes (Tillmann and Zhang 2005, Tillmann 2004)", 
    "clean_text": "An other obvious system improvement would be to incorporate more advanced word-based features in the DTs, such as questions about word classes (Tillmann and Zhang 2005, Tillmann 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W12-4207", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Dan, Han | Katsuhito, Sudoh | Xianchao, Wu | Kevin, Duh | Hajime, Tsukada | Masaaki, Nagata", 
    "raw_text": "Tillmann (2004) used a lexical reordering model, and Galley et al (2004) followed a syntactic-based model", 
    "clean_text": "Tillmann (2004) used a lexical reordering model, and Galley et al (2004) followed a syntactic-based model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W12-3140", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Stephan, Peitz | Hai-Son, Le | Markus, Freitag | Matthias, Huck | Thomas, Lavergne | Teresa, Herrmann | Alex, Waibel | Jean, Senellart | Jan, Niehues | Bianka, Buschbeck-Wolf | Alexandre, Allauzen | H., Ney | Josep M., Crego", 
    "raw_text": "This is performed by a stochastic finite state reordering model, which uses part-of-speechinformation3 to generalize reordering patterns beyond lexical regularities. In addition to the translation model, eleven feature functions are combined: a target-language model; four lexicon models; two lexicalized reordering models (Tillmann, 2004) aiming at predicting the orientation of the next translation unit; a? weak? distance-based distortion model; and finally a word bonus model and a tuple-bonus model which compensate for the system preference for short translations", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]