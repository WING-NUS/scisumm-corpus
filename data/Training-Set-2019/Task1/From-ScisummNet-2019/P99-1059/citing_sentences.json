[
  {
    "citance_No": 1, 
    "citing_paper_id": "W01-1404", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mark-Jan, Nederhof", 
    "raw_text": "For certain lexicalized context-free models we even obtain higher time complexities when the size of the grammar is not to be considered as a parameter (Eisner and Satta, 1999)", 
    "clean_text": "For certain lexicalized context-free models we even obtain higher time complexities when the size of the grammar is not to be considered as a parameter (Eisner and Satta, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W01-1404", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mark-Jan, Nederhof", 
    "raw_text": "can be translated by ?il me pla?? t? .We can reduce the generative power of context free transduction grammars by a syntactic restriction that corresponds to the bi lexical context-free grammars (Eisner and Satta, 1999)", 
    "clean_text": "We can reduce the generative power of context free transduction grammars by a syntactic restriction that corresponds to the bi lexical context-free grammars (Eisner and Satta, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P14-1100", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ankur, Parikh | Shay B., Cohen | Eric P., Xing", 
    "raw_text": "While this criterion is in general NP-hard (Desper and Gascuel, 2005), for projective trees we find that a bi lexical parsing algorithm can be used to find an exact solution efficiently (Eisner and Satta, 1999)", 
    "clean_text": "While this criterion is in general NP-hard (Desper and Gascuel, 2005), for projective trees we find that a bi lexical parsing algorithm can be used to find an exact solution efficiently (Eisner and Satta, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P14-1100", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ankur, Parikh | Shay B., Cohen | Eric P., Xing", 
    "raw_text": "However, if we restrict u to be in U, as we do in the above, then maximizing c? (u) over U can be solved using the bi lexical parsing algorithm from Eisner and Satta (1999)", 
    "clean_text": "However, if we restrict u to be in U, as we do in the above, then maximizing c(u) over U can be solved using the bi lexical parsing algorithm from Eisner and Satta (1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P09-1087", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Michel, Galley | Christopher D., Manning", 
    "raw_text": "Indeed, synchronous CFG parsing with m-grams runs in O (n3m) time, where n is the length of the sentence.1Furthermore, synchronous CFG approaches often only marginally outperform the most com 1The algorithmic complexity of (Wu, 1996) is O (n3+4 (m? 1)), though Huang et al (2005) present a more efficient factorization inspired by (Eisner and Satta, 1999) that yields an overall complexity of O (n3+3 (m? 1)) ,i.e., O (n3m)", 
    "clean_text": "The algorithmic complexity of (Wu, 1996) is O (n3+4 (m1)), though Huang et al (2005) present a more efficient factorization inspired by (Eisner and Satta, 1999) that yields an overall complexity of O (n3+3 (m1)), i.e., O(n3m).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P09-1087", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Michel, Galley | Christopher D., Manning", 
    "raw_text": "While it seems difficult to improve the asymptotic running time of the Eisner algorithm beyond what is presented in (Eisner and Satta, 1999), McDonald et al", 
    "clean_text": "While it seems difficult to improve the asymptotic running time of the Eisner algorithm beyond what is presented in (Eisner and Satta, 1999), McDonald et al.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P13-1044", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Matthew R., Gormley | Jason M., Eisner", 
    "raw_text": "Parses Since we are interested in projecting the fractional parse onto the space of projective spanning trees, we can simply employ a dynamic programming parsing algorithm (Eisner and Satta, 1999) where the weight of each edge is given as the fraction of the edge variable", 
    "clean_text": "Since we are interested in projecting the fractional parse onto the space of projective spanning trees, we can simply employ a dynamic programming parsing algorithm (Eisner and Satta, 1999) where the weight of each edge is given as the fraction of the edge variable.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P06-2122", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Hao, Zhang | Daniel, Gildea", 
    "raw_text": "(Eisner and Satta, 1999) and therefore reduces complexity", 
    "clean_text": "The new model, which bilexicalizes within languages, allows us to use the \"hook trick\" (Eisner and Satta, 1999) and therefore reduces complexity.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D08-1017", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Andr&eacute; Filipe, Torres Martins | Dipanjan, Das | Noah A., Smith | Eric P., Xing", 
    "raw_text": "In the projective case, the arc-factored assumption can be weakened in certain ways while maintaining polynomial parser runtime (Eisner and Satta, 1999), but not in the non projective case (McDonald and Satta, 2007), where finding the highest-scoring tree becomes NP-hard.McDonald and Pereira (2006) adopted an approximation based on O (n3) projective parsing followed by rearrangement to permit crossing arcs, achieving higher performance", 
    "clean_text": "In the projective case, the arc-factored assumption can be weakened in certain ways while maintaining polynomial parser runtime (Eisner and Satta, 1999), but not in the non projective case (McDonald and Satta, 2007), where finding the highest-scoring tree becomes NP-hard.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W05-1504", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Jason M., Eisner | Noah A., Smith", 
    "raw_text": "Throughout this paper we will use split bi lexical grammars, or SBGs (Eisner, 2000), a notationally simpler variant of split head-automaton grammars, or SHAGs (Eisner and Satta, 1999)", 
    "clean_text": "Throughout this paper we will use split bi lexical grammars, or SBGs (Eisner, 2000), a notationally simpler variant of split head-automaton grammars, or SHAGs (Eisner and Satta, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W05-1504", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Jason M., Eisner | Noah A., Smith", 
    "raw_text": "On this point, see (Eisner and Satta, 1999,? 8 and footnote 6)", 
    "clean_text": "On this point, see (Eisner and Satta, 1999, and footnote 6).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W05-1504", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Jason M., Eisner | Noah A., Smith", 
    "raw_text": "We give two ways to achieve runtime of O (nk2) .First, we observe without details that we can easily achieve this by starting instead with the algorithm of Eisner (2000) ,20 rather than EisnerandSatta (1999), and again refusing to add long tree dependencies", 
    "clean_text": "First, we observe without details that we can easily achieve this by starting instead with the algorithm of Eisner (2000), rather than Eisner and Satta (1999), and again refusing to add long tree dependencies.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W05-1504", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Jason M., Eisner | Noah A., Smith", 
    "raw_text": "roots along a? vine.? 28The obvious reduction for unsplit head automaton gram mars, say, is only O (n4)? O (n3k), following (Eisner and Satta, 1999)", 
    "clean_text": "The obvious reduction for unsplit head automaton grammars, say, is only O(n4) O (n3k), following (Eisner and Satta, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "E09-1034", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Carlos, G&oacute;mez-Rodr&iacute;guez | David, Weir | John, Carroll", 
    "raw_text": "In the case of dependency parsers it is also possible to use grammars (Eisner and Satta,1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamadaand Matsumoto, 2003)", 
    "clean_text": "In the case of dependency parsers it is also possible to use grammars (Eisner and Satta, 1999), but many algorithms use a data-driven approach instead, making individual decisions about which dependencies to create by using probabilistic models (Eisner, 1996) or classifiers (Yamada and Matsumoto, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "N06-1022", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Eugene, Charniak | Mark, Johnson | Micha, Elsner | Joseph, Austerweil | David, Ellis | Isaac, Haxton | Catherine, Hill | R., Shrivaths | Jeremy, Moore | Michael, Pozar | Theresa, Vu", 
    "raw_text": "It achieves its speed in part because it uses the Eisner and Satta (1999 )algorithm for n3 bi lexical parsing, but also because dependency parsing has a much lower grammar constant than does standard PCFG parsing? after all, there are no phrasal constituents to consider", 
    "clean_text": "It achieves its speed in part because it uses the Eisner and Satta (1999) algorithm for n3 bi lexical parsing, but also because dependency parsing has a much lower grammar constant than does standard PCFG parsing after all, there are no phrasal constituents to consider.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "H05-1036", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Jason M., Eisner | Eric, Goldlust | Noah A., Smith", 
    "raw_text": "Folding introduces new intermediate items, perhaps exploiting the distributive law ;applications include parsing speedups such as (Eisner and Satta, 1999), as well as well-known techniques for speeding up multi-way database joins, constraint programming, or marginalization of graphical mod els", 
    "clean_text": "Folding introduces new intermediate items, perhaps exploiting the distributive law; applications include parsing speedups such as (Eisner and Satta, 1999), as well as well-known techniques for speeding up multi-way database joins, constraint programming, or marginalization of graphical models.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "N09-1012", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "William P., Headden III | Mark, Johnson | David, McClosky", 
    "raw_text": "In the sections that follow, we frame various dependency models as a particular variety of CFGs known as split-head bi lexical CFGs (Eisner and Satta, 1999)", 
    "clean_text": "In the sections that follow, we frame various dependency models as a particular variety of CFGs known as split-head bi lexical CFGs (Eisner and Satta, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D08-1016", 
    "citing_paper_authority": 38, 
    "citing_paper_authors": "David A., Smith | Jason M., Eisner", 
    "raw_text": "CHILDSEQi scores i? s sequence of children; hence it consults all variables of the form Lij. Thescoring follows the parametrization of a weighted split head-automaton grammar (Eisner and Satta, 1999)", 
    "clean_text": "The scoring follows the parametrization of a weighted split head-automaton grammar (Eisner and Satta, 1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P05-1022", 
    "citing_paper_authority": 315, 
    "citing_paper_authors": "Eugene, Charniak | Mark, Johnson", 
    "raw_text": "As shown by Eisner (Eisner and Satta,1999) the dynamic programming algorithms for bi lexicalized PCFGs require O (m3) states, so a n-best parser would require O (nm3) states", 
    "clean_text": "As shown by Eisner (Eisner and Satta,1999) the dynamic programming algorithms for bi lexicalized PCFGs require O (m3) states, so a n-best parser would require O (nm3) states.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W06-2929", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Markus, Dreyer | David A., Smith | Noah A., Smith", 
    "raw_text": "dence between the left yield and the right yield of a given head, given the head (Eisner, 1997) .3 The best known parsing algorithm for such a model is O (n3) (Eisner and Satta, 1999)", 
    "clean_text": "The best known parsing algorithm for such a model is O (n3) (Eisner and Satta, 1999).", 
    "keep_for_gold": 0
  }
]