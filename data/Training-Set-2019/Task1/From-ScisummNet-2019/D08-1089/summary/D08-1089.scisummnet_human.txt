A Simple and Effective Hierarchical Phrase Reordering Model
While phrase-based statistical machine translation systems currently deliver state-of-the- art performance, they remain weak on word order changes.
Current phrase reordering models can properly handle swaps between adjacent phrases, but they typically lack the ability to perform the kind of long-distance reorderings possible with syntax-based systems.
In this paper, we present a novel hierarchical phrase reordering model aimed at improving non-local reorderings, which seamlessly integrates with a standard phrase-based system with little loss of computational efficiency.
We show that this model can successfully handle the key examples often used to motivate syntax-based systems, such as the rotation of a prepositional phrase around a noun phrase.
We contrast our model with reordering models commonly used in phrase-based systems, and show that our approach provides statistically significant BLEU point gains for two language pairs: Chinese-English (+0.53 on MT05 and +0.71 on MT08) and Arabic-English (+0.55 on MT05).
Our hierarchical orientation model captures non-local phrase reordering by a shift reduce algorithm.
We introduce a deterministic shift-reduce parser into decoding, so that the decoder always has access to the largest possible previous block, given the current translation history.
We introduce three orientation models for lexicalized reordering: word-based, phrase-based and hierarchical orientation model.
