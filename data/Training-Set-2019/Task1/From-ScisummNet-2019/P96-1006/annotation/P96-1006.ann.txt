Citance Number: 1 | Reference Article:  P96-1006.txt | Citing Article:  P14-1082.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used the method of extraction by Ng and Lee (1996) and encoded all keywords in a binary bag of words model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The method for extraction of local collocations is similar to that for extraction of keywords.</S><S sid = NA ssid = NA>It is unclear how Yarowsky's method will fare on WSD of a common test data set like the one we used, nor has his method been tested on a large data set with highly ambiguous words tagged with the refined senses of WORDNET.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P96-1006.txt | Citing Article:  W02-0812.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Likewise, (Ng and Lee, 1996) report overall accuracy for the noun interest of 87%, and find that that when their feature set only consists of co-occurrence features the accuracy only drops to 80%.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>LEXAS achieves a mean accuracy of 87.4% on this data set, which is higher than the accuracy of 78% reported in (Bruce and Wiebe, 1994).</S><S sid = NA ssid = NA>The average accuracy of LEXAS over 100 random trials is 87.4%, and the standard deviation is 1.37%.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P96-1006.txt | Citing Article:  W04-0839.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We would like to thank: Dr Paul Wu for sharing the Brown Corpus and Wall Street Journal Corpus; Dr Christopher Ting for downloading and installing WORDNET and SEMCOR, and for reformatting the corpora; the 12 undergraduates from the Linguistics Program of the National University of Singapore for preparing the sense-tagged corpus; and Prof K. P. Mohanan for his support of the sense-tagging project.</S><S sid = NA ssid = NA>Local collocations are common expressions containing the word to be disambiguated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P96-1006.txt | Citing Article:  W04-0839.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We would like to thank: Dr Paul Wu for sharing the Brown Corpus and Wall Street Journal Corpus; Dr Christopher Ting for downloading and installing WORDNET and SEMCOR, and for reformatting the corpora; the 12 undergraduates from the Linguistics Program of the National University of Singapore for preparing the sense-tagged corpus; and Prof K. P. Mohanan for his support of the sense-tagging project.</S><S sid = NA ssid = NA>Local collocations are common expressions containing the word to be disambiguated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P96-1006.txt | Citing Article:  W02-0813.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Previous experiments (Ng and Lee, 1996) have explored the relative contribution of different knowledge sources to WSD and have concluded that collocational information is more important than syntactic information.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The work of (McRoy, 1992) pointed out that a diverse set of knowledge sources are important to achieve WSD, but no quantitative evaluation was given on the relative importance of each knowledge source.</S><S sid = NA ssid = NA>In order to evaluate the relative contribution of the knowledge sources, including (1) POS and morphological form; (2) unordered set of surrounding words; (3) local collocations; and (4) verb to the left (verb-object syntactic relation), we conducted 4 separate runs of 100 random trials each.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P96-1006.txt | Citing Article:  W00-1326.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The DSO collection (Ng and Lee, 1996) focuses on 191 frequent and polysemous words (nouns and verbs), and contains around 1,000 sentences per word.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>These sense tagged word occurrences consist of 191 most frequently occurring and most ambiguous nouns and verbs.</S><S sid = NA ssid = NA>These 192,800 word occurrences consist of 121 nouns and 70 verbs which are the most frequently occurring and most ambiguous words of English.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P96-1006.txt | Citing Article:  W97-0321.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Exemplar-based method makes use of typical contexts (exemplars) of a word sense, e.g., verb noun collocations or adjective-noun collocations, and identifies the correct sense of a word in a particular context by comparing the context with the exemplars (Ng and Lee, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The task of Word Sense Disambiguation (WSD) is to identify the correct sense of a word in context.</S><S sid = NA ssid = NA>In the output, each word occurrence w is tagged with its correct sense (according to the context) in the form of a sense number i, where i corresponds to the i-th sense definition of w as given in some dictionary.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P96-1006.txt | Citing Article:  W97-0321.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Moreover, the effectiveness of this method on disambiguating words in large-scale corpora into fine-grained sense distinctions needs to be further investigated (Ng and Lee, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The effectiveness of unsupervised learning on disambiguating words into the refined sense distinction of WORDNET needs to be further investigated.</S><S sid = NA ssid = NA>To our knowledge, this is the first time that a WSD program has been tested on such a large scale, and yielding results better than the most frequent heuristic on highly ambiguous words with the refined sense distinctions of WORDNET.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P96-1006.txt | Citing Article:  W07-2054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Hence, besides gathering examples from the widely usedSEMCOR corpus, we also gathered training examples from 6 English-Chinese parallel corpora and the DSO corpus (Ng and Lee, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>If the distance between two examples is small, then the two examples are similar.</S><S sid = NA ssid = NA>The distance between two examples is the sum of the distances between the values of all the features of the two examples.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P96-1006.txt | Citing Article:  W07-2054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Besides SEMCOR, the DSO corpus (Ng and Lee, 1996) also contains manually annotated examples for WSD.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>If the distance between two examples is small, then the two examples are similar.</S><S sid = NA ssid = NA>To test the scalability of LEXAS, we have gathered a corpus in which 192,800 word occurrences have been manually tagged with senses from WORD NET 1.5.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P96-1006.txt | Citing Article:  W02-0809.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our approach to memory-based all-words WSD follows the memory based approach of (Ng and Lee, 1996), and the work by (Veenstra et al, 2000) on a memory based approach to the English lexical sample task of SENSEVAL-1.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper, we present a new approach for WSD using an exemplar-based learning algorithm.</S><S sid = NA ssid = NA>In this paper, we have presented a new approach for WSD using an exemplar based learning algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P96-1006.txt | Citing Article:  W02-0809.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The keywords were selected through a selection method suggested by (Ng and Lee, 1996) within three sentences around the ambiguous word; only content words were used as candidates.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>All the word tokens other than the word occurrence w in a sentence s are candidates for consideration as keywords.</S><S sid = NA ssid = NA>It is unclear how Yarowsky's method will fare on WSD of a common test data set like the one we used, nor has his method been tested on a large data set with highly ambiguous words tagged with the refined senses of WORDNET.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P96-1006.txt | Citing Article:  N09-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the following testing phase, a word is classified into senses (Mihalcea, 2002) (Ng and Lee, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>LEXAS builds one exemplar-based classifier for each content word w. It operates in two phases: training phase and test phase.</S><S sid = NA ssid = NA>We first set aside two subsets for testing.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P96-1006.txt | Citing Article:  N07-1025.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This feature set is similar to the one used by (Ngand Lee, 1996), as well as by a number of state-of the-art word sense disambiguation systems participating in the SENSEVAL-2 and SENSEVAL-3evaluations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Improvement in the accuracy of identifying the correct word sense will result in better machine translation systems, information retrieval systems, etc.</S><S sid = NA ssid = NA>The task of Word Sense Disambiguation (WSD) is to identify the correct sense of a word in context.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P96-1006.txt | Citing Article:  W02-0817.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The high accuracy of the LEXAS system (Ng and Lee, 1996) is due in part to the use of large corpora.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In each of our 100 random trials, the accuracy of LEXAS is always higher than the accuracy of 78% reported in (Bruce and Wiebe, 1994).</S><S sid = NA ssid = NA>The accuracy of LEXAS on these two test sets is given in Table 5.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P96-1006.txt | Citing Article:  S10-1028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The disambiguation is then done using k-NN (Ng and Lee, 1996) where the k nearest neighbors of the test sentence are identified using this scoring function.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper, we present a new approach for word sense disambiguation (WSD) using an exemplar-based learning algorithm.</S><S sid = NA ssid = NA>For each training sentence with an occurrence of w, LEXAS extracts the parts of speech (POS) of words surrounding w, the morphological form of w, the words that frequently co-occur with w in the same sentence, and the local collocations containing w. For disambiguating a noun w, the verb which takes the current noun w as the object is also identified.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P96-1006.txt | Citing Article:  W07-2047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The idea of using supervised machine learning for WSD is not new and was used for example in (Ng and Lee, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>That is, it uses supervised learning, in particular exemplar-based learning, to achieve WSD.</S><S sid = NA ssid = NA>In this paper, we present a new approach for WSD using an exemplar-based learning algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P96-1006.txt | Citing Article:  N01-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We report results of comparing our lexicon with theWordNet cousins as well as the inter-annotator disagreement observed between two semantically an notated corpora: WordNet Semcor (Landes et al, 1998) and DSO (Ng and Lee, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The work of (Miller et al., 1994; Leacock et al., 1993; Yarowsky, 1992) used only the unordered set of surrounding words to perform WSD, and they used statistical classifiers, neural networks, or IR-based techniques.</S><S sid = NA ssid = NA>The work of (Miller et al., 1994) is the only prior work we know of which attempted to evaluate WSD on a large data set and using the refined sense distinction of WORDNET.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P96-1006.txt | Citing Article:  N01-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To test if the sense partitions in our lexicon constitute an appropriate (or useful) level of granularity, we applied it to the inter-annotator disagreement observed in two semantically annotated corpora: WordNet Semcor (Landes et al, 1998) and DSO (Ng and Lee, 1996).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This default strategy has been advocated as the baseline performance level for comparison with WSD programs (Gale et al., 1992).</S><S sid = NA ssid = NA>The work of (Miller et al., 1994) is the only prior work we know of which attempted to evaluate WSD on a large data set and using the refined sense distinction of WORDNET.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P96-1006.txt | Citing Article:  C02-1115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The set of features needed for the training of the system is described in figure 1, and is based on the feature selection made by Ng and Lee (1996) and Escudero et al (2000).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>During the training phase, the appropriate set of features is extracted based on the method described in Section 3.1.</S><S sid = NA ssid = NA>The work of (Miller et al., 1994; Leacock et al., 1993; Yarowsky, 1992) used only the unordered set of surrounding words to perform WSD, and they used statistical classifiers, neural networks, or IR-based techniques.</S> | Discourse Facet:  NA | Annotator: Automatic


