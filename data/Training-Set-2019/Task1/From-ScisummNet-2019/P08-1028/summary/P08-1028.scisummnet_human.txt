Vector-based Models of Semantic Composition
This paper proposes a framework for representing the meaning of phrases and sentences in vector space.
Central to our approach is vector composition which we operationalize in terms of additive and multiplicative functions.
Under this framework, we introduce a wide range of composition models which we evaluate empirically on a sentence similarity task.
Experimental results demonstrate that the multiplicative models are superior to the additive alternatives when compared against human judgments.
We propose a general framework in which meaning representations for complex expressions are computed compositionally by combining the vector representations of the individual words of the complex expression.
