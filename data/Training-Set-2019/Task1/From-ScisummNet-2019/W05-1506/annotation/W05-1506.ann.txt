Citance Number: 1 | Reference Article:  W05-1506.txt | Citing Article:  N06-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We will present an algorithm for determinizing weighted finite tree recognizers, and use a variant of the procedure found in (Huang and Chiang, 2005) to obtain -best lists of trees that are weighted correctly and contain no repetition.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Following Klein and Manning (2001), we use weighted directed hypergraphs (Gallo et al, 1993) as an abstraction of the probabilistic parsing problem.Definition 1.</S><S sid = NA ssid = NA>Collins (2000), in his parse-reranking experiments, used his Model 2 parser (Collins, 2003) with a beam width of 10?3 together with a cell limit of 100 to obtain k-best lists; the average number of parses obtained per sentence was 29.2, the maximum, 101.7 Charniak and Johnson (2005) use coarse-to-fine parsing on top of the Charniak (2000) parser and get 50-best lists for section 23.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W05-1506.txt | Citing Article:  N06-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our thanksalso go to Dan Gildea, Jonathan Graehl, Julia Hock enmaier, Aravind Joshi, Kevin Knight, Daniel Marcu,Mitch Marcus, Ryan McDonald, Fernando Pereira, Gior gio Satta, Libin Shen, and Hao Zhang.</S><S sid = NA ssid = NA>= {(u, v) | ?e ? BS (v), u ? T (e)}.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W05-1506.txt | Citing Article:  W12-0902.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We follow the third algorithm in Huang and Chiang (2005), where first a traditional Viterbi-chart is created, which enumerates in an efficient way all possible sub derivations.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The traditional 1-best Viterbi algorithm traverses the hypergraph in topological order and for each vertex v, calculates its 1-best derivation D1(v) using all incoming hy perarcs e ? BS(v) (see Figure 3).</S><S sid = NA ssid = NA>| 1 ? l ? |e|} (again, as in Algorithm 1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W05-1506.txt | Citing Article:  P11-1003.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In terms of decoding time, even though we used Algorithm 3 described in (Huang and Chiang, 2005), which lazily generated the N-best translation candidates, the decoding time tended to be increased because more rules were available during cube pruning.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Time: O(k).</S><S sid = NA ssid = NA>We also implemented Algorithms 2 and 3 in a parsing-based MT decoder (Chiang, 2005) and report results on decoding speed.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W05-1506.txt | Citing Article:  D11-1004.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The latter function uses bi nary lazy enumeration in a manner similar to (Huang and Chiang, 2005), and relies on two global variables: I and L.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In the literature of k shortest-path problems, Minieka (1974) generalized the Floyd algorithm in a way very similar to our Algorithm 0 and Lawler (1977) improvedit using an idea similar to but a little slower than the bi nary branching case of our Algorithm 1.</S><S sid = NA ssid = NA>k? is the global k 2: if |D?(v)| ? k then . kth derivation already computed?</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W05-1506.txt | Citing Article:  P13-1045.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The k= 200-best parses at the top cell of the chart are calculated using the efficient algorithm of (Huang and Chiang, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We suspect this is due to the cell limit of 100 pruning awaypotentially good parses too early in the chart.</S><S sid = NA ssid = NA>We also did a comparison between our Algorithm 3 and the Jime?nez and Marzal algorithm in terms of average 5In beam search, or threshold pruning, each cell in the chart (typically containing all the items corresponding to a span [i, j]) is reduced by discarding all items that are worse than ? times the score of the best item in the cell.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W05-1506.txt | Citing Article:  D09-1161.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This technique utilizes a bunch of linguistic features to re-rank the k-best (Huang and Chiang 2005) output on the forest level or tree level.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The derivation forest of CFG parsing under the CKY algorithm, for instance, can be represented as a CFD while the forest of Earley algorithm can not.</S><S sid = NA ssid = NA>The k-best derivations problem has potentially more applications in tree generation (Knight and Graehl,2005), which can not be modeled by hyperpaths.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W05-1506.txt | Citing Article:  P06-1109.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We could also have used the more efficient k-best hyper graph parsing technique by Huang and Chiang (2005), but we have not yet incorporated this into our implementation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The graph projection of a hypergraph H = ?V, E, t,R? is a directed graph G = ?V, E??</S><S sid = NA ssid = NA>We define the arity of a hyper graph to be the maximum arity of its hyperarcs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W05-1506.txt | Citing Article:  C10-1051.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>N-best list not the lazy algorithm of (Huang and Chiang, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Algorithm 1).</S><S sid = NA ssid = NA>| 1 ? l ? |e|} (again, as in Algorithm 1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W05-1506.txt | Citing Article:  P10-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>It is found to be well handled by the K-Best parsing method in Huang and Chiang (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Better K-Best Parsing</S><S sid = NA ssid = NA>They apply this method to the Charniak (2000)parser to get 50-best lists for reranking, yielding an im provement in parsing accuracy.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W05-1506.txt | Citing Article:  W10-2501.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Those weighted tree languages are recognizable and there exist algorithms (Huang and Chiang, 2005) that efficiently extract the k-best parse trees (i.e., those with the highest probability) for further processing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For ex ample, the distribution of parse trees for a given sentence under a PCFG can be represented as a packed forest from which the highest-probability tree can be easily extracted.However, when the objective function f has no com patible packed representation, exact inference would beintractable.</S><S sid = NA ssid = NA>A simi lar situation occurs when the parser can produce multiple derivations that are regarded as equivalent (e.g., multiplelexicalized parse trees corresponding to the same unlexi calized parse tree); if we want the maximum a posteriori parse, we have to sum over equivalent derivations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W05-1506.txt | Citing Article:  W12-4410.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>k-best lists are extracted from the CRF trellis using the lazy enumeration algorithm of Huang and Chiang (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>| 1 ? l ? |e|} (again, as in Algorithm 1).</S><S sid = NA ssid = NA>Algorithm 1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W05-1506.txt | Citing Article:  C10-1036.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Translation hyper graphs are generated by each baseline system during the MAPde coding phase, and 1000-best lists used for MERT algorithm are extracted from hyper graphs by the k-best parsing algorithm (Huang and Chiang, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Algorithm 3assumes an initial parsing phase that generates the hyper graph and finds the 1-best derivation of each item; then in the second phase, it proceeds as in Algorithm 2, but starts at the goal item and calls itself recursively only as necessary.</S><S sid = NA ssid = NA>| 1 ? l ? |e|} (again, as in Algorithm 1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W05-1506.txt | Citing Article:  P10-4002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Although Viterbi and k-best extraction algorithms are often expressed as INSIDE algorithms with the tropical semiring ,cdec provides a separate derivation extraction framework that makes use of a &lt; operator (Huang and Chiang, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>out of |e| best sub derivations (this is a generalization of the binary operator ? in a semiring); second, min?, which chooses the betterof two derivations (same as the ? operator in an idem potent semiring (Mohri, 2002)).</S><S sid = NA ssid = NA>The four algorithms, along with the 1-best Viterbi algo rithm and the generalized Jime?nez and Marzal algorithm, are compared in Table 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W05-1506.txt | Citing Article:  P09-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The amount of work done in the k-best phase is no more than the amount of work done by the algorithm of Huang and Chiang (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our work differes from (Nielsen et al, 2005) in two aspects.</S><S sid = NA ssid = NA>| 1 ? l ? |e|} (again, as in Algorithm 1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W05-1506.txt | Citing Article:  P09-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In a certain sense, described in greater detail below, this precomputation of exact heuristics is equivalent to the k-best extraction algorithm of Huang and Chiang (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Similarly, Chiang (2005) uses the k-best pars ing algorithm described below in a CFG-based log-linear translation model in order to learn feature weights which maximize BLEU.</S><S sid = NA ssid = NA>Algorithm 1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W05-1506.txt | Citing Article:  P09-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>By exploiting a local ordering amongst derivations, we can be more conservative about combination and gain the advantages of a lazy successor function (Huang and Chiang, 2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The ordering on weights in R induces an ordering on derivations: D ? D? iff w(D) ? w(D?).</S><S sid = NA ssid = NA>1: function M???(e, k) 2: cand ? {?e, 1?}</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W05-1506.txt | Citing Article:  P09-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This triggering is similar to the lazy frontier used by Huang and Chiang (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>lexicalized PCFGmodel (Bikel, 2004; Collins, 2003) and Chiang?s syn chronous CFG based decoder (Chiang, 2005) for machine translation.</S><S sid = NA ssid = NA>In each iteration the current frontier is shown in oval boxes, with the bold-face denoting the best element among them.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W05-1506.txt | Citing Article:  P09-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As a baseline, we compared KAâˆ— to the approach of Huang and Chiang (2005), which we will call EXH (see below for more explanation) since it requires exhaustive parsing in the bottom-up pass.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Another instance of this k-best approach is cascadedoptimization.</S><S sid = NA ssid = NA>We also implemented Algorithms 2 and 3 in a parsing-based MT decoder (Chiang, 2005) and report results on decoding speed.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W05-1506.txt | Citing Article:  P09-1108.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While formulated very differently, one limiting case of our algorithm relates closely to the EXH algorithm of Huang and Chiang (2005).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Algorithm 1).</S><S sid = NA ssid = NA>| 1 ? l ? |e|} (again, as in Algorithm 1).</S> | Discourse Facet:  NA | Annotator: Automatic


