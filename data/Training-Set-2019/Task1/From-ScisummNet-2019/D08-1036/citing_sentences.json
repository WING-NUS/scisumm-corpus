[
  {
    "citance_No": 1, 
    "citing_paper_id": "P13-2112", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Long, Duong | Paul, Cook | Steven, Bird | Pavel, Pecina", 
    "raw_text": "Using our final model with unsupervisedHMM methods might improve the final performance too ,i.e. use our final model as the initial state for HMM, then experiment with different inference algorithms such as ExpectationMaximization (EM), Variational Bayers (VB) or Gibbs sampling (GS) .5 Gao and Johnson (2008) compare EM, VB and GS for unsupervised English POS tagging", 
    "clean_text": "Gao and Johnson (2008) compare EM, VB and GS for unsupervised English POS tagging.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "D10-1020", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Taesun, Moon | Katrin, Erk | Jason, Baldridge", 
    "raw_text": "We use a Gibbs sampler (Gao and Johnson, 2008) to learn the parameters of this andall other models under consideration", 
    "clean_text": "We use a Gibbs sampler (Gao and Johnson, 2008) to learn the parameters of this and all other models under consideration.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "N10-1082", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Percy, Liang | Michael I., Jordan | Dan, Klein", 
    "raw_text": "All of these methods maintain distributions over (or settings of) the latent variables of the model and update the representation iteratively (see Gao and Johnson (2008) for an overview in the context of POS induction)", 
    "clean_text": "All of these methods maintain distributions over (or settings of) the latent variables of the model and update the representation iteratively (see Gao and Johnson (2008) for an overview in the context of POS induction).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "N10-1068", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "David, Chiang | Jonathan, Graehl | Kevin, Knight | Adam, Pauls | Sujith, Ravi", 
    "raw_text": "Gao and Johnson (2008) employed blocked sampling for POS tagging, and the approach works nicely for arbitrary derivation lattices", 
    "clean_text": "Gao and Johnson (2008) employed blocked sampling for POS tagging, and the approach works nicely for arbitrary derivation lattices.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "N10-1068", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "David, Chiang | Jonathan, Graehl | Kevin, Knight | Adam, Pauls | Sujith, Ravi", 
    "raw_text": "The approximation can be corrected using the Metropolis-Hastings algorithm, in which the sample drawn from the proposal lattice is accepted only with a certain probability?; but Gao and Johnson (2008) report that?& gt; 0.99, so we skip this step", 
    "clean_text": "The approximation can be corrected using the Metropolis-Hastings algorithm, in which the sample drawn from the proposal lattice is accepted only with a certain probability a; but Gao and Johnson (2008) report that a > 0.99, so we skip this step.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D10-1056", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Christos, Christodoulopoulos | Sharon, Goldwater | Mark, Steedman", 
    "raw_text": "[cross val]: Cross-validation accuracy (Gao and Johnson, 2008) is intended to address the problem with many-to-one accuracy which is that assigning each word to its own class yields a perfect score", 
    "clean_text": "[cross val]: Cross-validation accuracy (Gao and Johnson, 2008) is intended to address the problem with many-to-one accuracy which is that assigning each word to its own class yields a perfect score.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P10-2040", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Michael, Lamar | Yariv, Maron | Mark, Johnson | Elie, Bienenstock", 
    "raw_text": "Subsequently, a number of methods for POS tagging without a dictionary were examined ,e.g., by Clark (2000), Clark (2003), Haghighi and Klein (2006), John son (2007), Goldwater and Griffiths (2007), Gao and Johnson (2008), and Gra? a et al (2009)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P10-2040", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Michael, Lamar | Yariv, Maron | Mark, Johnson | Elie, Bienenstock", 
    "raw_text": "We selected the three evaluation criteria of Gao and Johnson (2008): M-to-1, 1-to-1, and VI", 
    "clean_text": "We selected the three evaluation criteria of Gao and Johnson (2008): M-to-1, 1-to-1, and VI.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P10-2040", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Michael, Lamar | Yariv, Maron | Mark, Johnson | Elie, Bienenstock", 
    "raw_text": "M-to-1 and 1-to1 are the tagging accuracies under the best many to-one map and the greedy one-to-one map respectively; VI is a map-free information theoretic criterion? see Gao and Johnson (2008) for details", 
    "clean_text": "M-to-1 and 1-to-1 are the tagging accuracies under the best many-to-one map and the greedy one-to-one map respectively; VI is a map-free information theoretic criterion - see Gao and Johnson (2008) for details.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P10-2040", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Michael, Lamar | Yariv, Maron | Mark, Johnson | Elie, Bienenstock", 
    "raw_text": "To further gain insight into how successful current models are at disambiguating when they have the power to do so, we examined a collection of HMM-VB runs (Gao and Johnson 2008) and asked how the accuracy scores would change if, after training was completed, the model were forced to assign the same label to all tokens of the same type", 
    "clean_text": "To further gain insight into how successful current models are at disambiguating when they have the power to do so, we examined a collection of HMM-VB runs (Gao and Johnson 2008) and asked how the accuracy scores would change if, after training was completed, the model were forced to assign the same label to all tokens of the same type.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P10-1132", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Omri, Abend | Roi, Reichart | Ari, Rappoport", 
    "raw_text": "GJ: (Gao and Johnson, 2008), 1.17M tokens, fine tags ,k=50", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P10-1101", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Michael, Connor | Yael, Gertner | Cynthia, Fisher | Dan, Roth", 
    "raw_text": "This trick has been used before in speech recognition work (Rabiner, 2We tuned the prior using the same set of 8 value pairs suggested by Gao and Johnson (2008), using a held out set of POS-tagged CDS to evaluate final performance", 
    "clean_text": "We tuned the prior using the same set of 8 value pairs suggested by Gao and Johnson (2008), using a held out set of POS-tagged CDS to evaluate final performance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "D11-1118", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Valentin I., Spitkovsky | Hiyan, Alshawi | Angel, Chang | Daniel, Jurafsky", 
    "raw_text": "8They are also competitive with Bayesian estimators, on larger data sets, with cross-validation (Gao and Johnson, 2008)", 
    "clean_text": "They are also competitive with Bayesian estimators, on larger data sets, with cross-validation (Gao and Johnson, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W10-2911", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Roi, Reichart | Omri, Abend | Ari, Rappoport", 
    "raw_text": "We experimented with the following models: ARR10 (Abend et al,2010), Clark03 (Clark, 2003), GG07 (Goldwater and Griffiths, 2007), GJ08 (Gao and Johnson, 2008), and GVG09 (Van Gael et al, 2009) (three models)", 
    "clean_text": "We experimented with the following models: ARR10 (Abend et al,2010), Clark03 (Clark, 2003), GG07 (Goldwater and Griffiths, 2007), GJ08 (Gao and Johnson, 2008), and GVG09 (Van Gael et al, 2009) (three models).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W11-2205", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Andreas, Vlachos", 
    "raw_text": "For example, Gao and Johnson (2008) proposed to induce a many to-one mapping of state identifiers to PoS tags from one half of the corpus and evaluate on the second half, which is referred to as cross-validation accuracy", 
    "clean_text": "For example, Gao and Johnson (2008) proposed to induce a many-to-one mapping of state identifiers to PoS tags from one half of the corpus and evaluate on the second half, which is referred to as cross-validation accuracy.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D10-1078", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Michael, Lamar | Yariv, Maron | Elie, Bienenstock", 
    "raw_text": "When using PTB45 as the gold standard, models induce 50 labels, to allow comparison with Gao and Johnson (2008) and Lamar et al (2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D10-1078", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Michael, Lamar | Yariv, Maron | Elie, Bienenstock", 
    "raw_text": "804 Table 1 compares the tagging accuracy of LDC with several recent models of Gao and Johnson (2008) and Lamar et al (2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D10-1078", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Michael, Lamar | Yariv, Maron | Elie, Bienenstock", 
    "raw_text": "Note that LDC significantly outperforms all HMMs (Gao and Johnson, 2008) in every case except PTB45 under the OTO mapping", 
    "clean_text": "Note that LDC significantly outperforms all HMMs (Gao and Johnson, 2008) in every case except PTB45 under the OTO mapping.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "C10-2016", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Alex, Cheng | Fei, Xia | Jianfeng, Gao", 
    "raw_text": "Gao and Johnson (2008) compared EM, VB and GS in English against the Penn Treebank Wall Street Journal (WSJ) text", 
    "clean_text": "Gao and Johnson (2008) compared EM, VB and GS in English against the Penn Treebank Wall Street Journal (WSJ) text.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D12-1086", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Enis, Sert | Mehmet Ali, Yatbaz | Deniz, Yuret", 
    "raw_text": "Each of these techniques provide significant improvements over the standard HMM model: for example Gao and Johnson (2008) show that sparse priors can gain from 4% (.62 to .66with a 1M word corpus) in cross-validated many to-one accuracy", 
    "clean_text": "Each of these techniques provide significant improvements over the standard HMM model: for example Gao and Johnson (2008) show that sparse priors can gain from 4% (.62 to .66 with a 1M word corpus) in cross-validated many to-one accuracy.", 
    "keep_for_gold": 1
  }
]