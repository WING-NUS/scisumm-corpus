Extracting Relations With Integrated Information Using Kernel Methods
Entity relation detection is a form of information extraction that finds predefined relations between pairs of entities in text.
This paper describes a relation detection approach that combines clues from different levels of syntactic processing using kernel methods.
Information from three different levels of processing is considered: tokenization, sentence parsing and deep dependency analysis.
Each source of information is represented by kernel functions.
Then composite kernels are developed to integrate and extend individual kernels so that processing errors occurring at one level can be overcome by information from other levels.
We present an evaluation of these methods on the 2004 ACE relation detection task, using Support Vector Machines, and show that each level of syntactic processing contributes useful information for this task.
When evaluated on the official test data, our approach produced very competitive ACE value scores.
We also compare the SVM with KNN on different kernels.
We define several feature based composite kernels to integrate diverse features for relation extraction and achieved the F-measure of 70.4 on the 7 relation types of the ACE RDC 2004 corpus.
We show that adding local information to deep syntactic information improved IE results.
We extract bigram of the words between the two mentions, aiming to provide more order information of the tokens between the two mentions.
