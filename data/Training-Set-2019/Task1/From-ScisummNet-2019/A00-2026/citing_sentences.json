[
  {
    "citance_No": 1, 
    "citing_paper_id": "P01-1032", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Rebecca, Green | Lisa, Pearl | Bonnie Jean, Dorr | Philip, Resnik", 
    "raw_text": "More recently, context-based models of disambiguation have been shown to represent significant improvements over the baseline (Bangalore and Ram bow, 2000), (Ratnaparkhi, 2000)", 
    "clean_text": "More recently, context-based models of disambiguation have been shown to represent significant improvements over the baseline (Bangalore and Rambow, 2000), (Ratnaparkhi, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P04-3009", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Charles B., Callaway", 
    "raw_text": "In the case of Ratnaparkhi &apos; s generator for ight information in the air travel domain (Ratnaparkhi, 2000), the transformation algorithm is trivial as the generator uses the corpus itself (annotated with semantic information such as destination or ight number) as input to a surface realizer with ann-gram model of the domain, along with a maximum entropy probability model for selecting when to use which phrase", 
    "clean_text": "In the case of Ratnaparkhi's generator for flight information in the air travel domain (Ratnaparkhi, 2000), the transformation algorithm is trivial as the generator uses the corpus itself (annotated with semantic information such as destination or flight number) as input to a surface realizer with an n-gram model of the domain, along with a maximum entropy probability model for selecting when to use which phrase.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W05-1601", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Anja, Belz", 
    "raw_text": "The likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications :summarisation construed as term selection and ordering [Witbrock and Mittal, 1999], grammar-free stochastic surface realisation [Oh and Rudnicky, 2000], and surface realisation construed as attribute selection and lexical choice [Ratnaparkhi, 2000] .Some of the above papers compare the purely statistical methods to other machine learning methods such as memory-based learning and reinforcement learning", 
    "clean_text": "The likelihood of realisations given concepts or semantic representations has been modeled directly, but is probably limited to small-scale and specialised applications: summarisation construed as term selection and ordering [Witbrock and Mittal, 1999], grammar-free stochastic surface realisation [Oh and Rudnicky, 2000], and surface realisation construed as attribute selection and lexical choice [Ratnaparkhi, 2000]. Some of the above papers compare the purely statistical methods to other machine learning methods such as memory-based learning and reinforcement learning.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W05-1627", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Sebastian, Varges", 
    "raw_text": "[Ratnaparkhi, 2000] describes a sentence realizer that had been trained on a domain-specific corpus (in theair travel domain) augmented with semantic attribute value pairs", 
    "clean_text": "[Ratnaparkhi, 2000] describes a sentence realizer that had been trained on a domain-specific corpus (in the air travel domain) augmented with semantic attribute value pairs.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P06-1130", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Aoife, Cahill | Josef, van Genabith", 
    "raw_text": "Ratnaparkhi (2000) uses maximum entropy models to drive generation with word bigram or dependency representations taking into account (unrealised) semantic features", 
    "clean_text": "Ratnaparkhi (2000) uses maximum entropy models to drive generation with word bigram or dependency representations taking into account (unrealised) semantic features.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W10-1617", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Eder, Novais | Thiago, Tadeu | Ivandr&eacute;, Paraboni", 
    "raw_text": "Our work is more related to Ratnaparkhi (2000) in the sense that we also use a large collection of generation templates for surface realization, but still distinct in that we intend to generate text from minimal input", 
    "clean_text": "Our work is more related to Ratnaparkhi (2000) in the sense that we also use a large collection of generation templates for surface realization, but still distinct in that we intend to generate text from minimal input.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C08-1038", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Yuqing, Guo | Josef, van Genabith | Haifeng, Wang", 
    "raw_text": "An exception isRatnaparkhi (2000), who presents maximum entropy models to learn attribute ordering and lexical choice for sentence generation from a semantic representation of attribute-value pairs, restricted to an air travel domain", 
    "clean_text": "An exception is Ratnaparkhi (2000), who presents maximum entropy models to learn attribute ordering and lexical choice for sentence generation from a semantic representation of attribute-value pairs, restricted to an air travel domain.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C02-1064", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kiyotaka, Uchimoto | Satoshi, Sekine | Hitoshi, Isahara", 
    "raw_text": "Ratnaparkhi proposed models to generate text from semantic attributes (Ratnaparkhi, 2000)", 
    "clean_text": "Ratnaparkhi proposed models to generate text from semantic attributes (Ratnaparkhi, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P05-2026", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Jeffrey, Russell", 
    "raw_text": "A number of statistical surface realizers have been described, notably the FERGUS (BangaloreandRambow, 2000) and HALogen systems (LangkildeGeary, 2002), as well as experiments in (Ratnaparkhi, 2000)", 
    "clean_text": "A number of statistical surface realizers have been described, notably the FERGUS (BangaloreandRambow, 2000) and HALogen systems (LangkildeGeary, 2002), as well as experiments in (Ratnaparkhi, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W11-2011", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Nina, Dethlefs | Heriberto, Cuay&#xE1;huitl | Jette, Viethen", 
    "raw_text": "More generally, the NLG problem of non-deterministic decision making has been addressed from many different angles, including PENMAN-style choosers (Mann and Matthiessen,1983), corpus-based statistical knowledge (Langkilde and Knight, 1998), tree-based stochastic models (Bangalore and Rambow, 2000), maximum entropy based ranking (Ratnaparkhi, 2000), combinatorial pattern discovery (Duboue and McKeown, 2001), instance-based ranking (Varges, 2003), chart generation (White, 2004), planning (Koller and Stone, 2007), or probabilistic generation spaces (Belz, 2008) to name just a few", 
    "clean_text": "More generally, the NLG problem of non-deterministic decision making has been addressed from many different angles, including PENMAN-style choosers (Mann and Matthiessen,1983), corpus-based statistical knowledge (Langkilde and Knight, 1998), tree-based stochastic models (Bangalore and Rambow, 2000), maximum entropy based ranking (Ratnaparkhi, 2000), combinatorial pattern discovery (Duboue and McKeown, 2001), instance-based ranking (Varges, 2003), chart generation (White, 2004), planning (Koller and Stone, 2007), or probabilistic generation spaces (Belz, 2008) to name just a few.", 
    "keep_for_gold": 0
  }
]