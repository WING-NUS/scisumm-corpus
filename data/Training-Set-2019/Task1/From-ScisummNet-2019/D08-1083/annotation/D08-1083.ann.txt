Citance Number: 1 | Reference Article:  D08-1083.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.</S><S sid = NA ssid = NA>For brevity, we refer to NEG(1) and NEG(N) collectively as NEG, and NEGEX(1) and NEGEX(N) collectively as NEGEX.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  D08-1083.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Content-word negators are words that are not function words, but act semantically as negators (Choi and Cardie, 2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>On the other hand, the NEGEX methods (87.7%) that do consider content-word negators as well as function-word negators perform better than VOTE.</S><S sid = NA ssid = NA>For SC-NEGEX, we count the number of content-word negators as well as function-word negators to determine whether the final polarity should be flipped.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  D08-1083.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also thank Eric Breck, Lillian Lee, Mats Rooth, the members of the Cornell NLP reading seminar, and the EMNLP reviewers for insightful comments on the submitted version of the paper.</S><S sid = NA ssid = NA>For brevity, we refer to NEG(1) and NEG(N) collectively as NEG, and NEGEX(1) and NEGEX(N) collectively as NEGEX.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  D08-1083.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For the general-purpose polarity lexicon, we expand the polarity lexicon of Wilson et al (2005) with General Inquirer dictionary as suggested by Choi and Cardie (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We also add a number of boolean features that provide following properties of xi using the polarity lexicon and the negator lexicon: – whether xi is a function-word negator – whether xi is a content-word negator – whether xi is a negator of any kind – the polarity of xi according to Wilson et al. (2005)’s polarity lexicon – the polarity of xi according to the lexicon derived from the General Inquirer dictionary – conjunction of the above two features As in the heuristic-based compositional semantics approach (§ 2.2), we experiment with two variations of this learning-based approach: CCI-COMPOPR and CCI-COMPOMC, whose compositional inference rules are COMPOPR and COMPOMC respectively.</S><S sid = NA ssid = NA>However, Wilson et al. (2005) formulated the task differently by limiting their evaluation to individual words that appear in their polarity lexicon.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  D08-1083.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>According to Choi and Cardie (2008), voting algorithms that recognize content-word negators achieve a competitive performance, so we will use a variant of it for simplicity.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For the purpose of voting, if a word is defined as a negator per the voting scheme, then that word does not participate in the majority vote.</S><S sid = NA ssid = NA>On the other hand, the NEGEX methods (87.7%) that do consider content-word negators as well as function-word negators perform better than VOTE.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  D08-1083.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Because none of the algorithms proposed by Choi and Cardie (2008) is designed to handle the neutral polarity, we invent our own version as shown in Figure 2.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In particular, we exploit the fact that in our task, we can automatically construct a reasonably accurate gold standard for z, denoted as z*: as shown in Figure 2, we simply rely on the negator and polarity lexicons.</S><S sid = NA ssid = NA>The exact procedure is given in Figure 1, and will be discussed again shortly.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  D08-1083.txt | Citing Article:  D09-1062.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi and Cardie (2008) also focus on the expression-level polarity classification, but their evaluation setting is not as practical as ours in that they assume the inputs are guaranteed to be either strongly positive or negative.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We evaluate on all strong (i.e., intensity of expression is ‘medium’ or higher), sentimentbearing (i.e., polarity is ‘positive’ or ‘negative’) expressions.8 As a result, we can assume the boundaries of the expressions are given.</S><S sid = NA ssid = NA>That is, we count the number of positive polarity words and negative polarity words in a given expression, and assign the majority polarity to the expression.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  D08-1083.txt | Citing Article:  P14-1029.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi and Cardie (2008) proposed a learning-based framework.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper, we begin to close the gap between learning-based approaches to expression-level polarity classification and those founded on compositional semantics: we present a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.</S><S sid = NA ssid = NA>The learningbased approach proposed in this paper takes a first step in this direction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  D08-1083.txt | Citing Article:  W10-3111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi and Cardie (2008) present a more lightweight approach using compositional semantics towards classifying the polarity of expressions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To this end, we present a novel learning-based approach that incorporates inference rules inspired by compositional semantics into the learning procedure (§3.2).</S><S sid = NA ssid = NA>In this paper, we begin to close the gap between learning-based approaches to expression-level polarity classification and those founded on compositional semantics: we present a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  D08-1083.txt | Citing Article:  W10-3111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The rules presented by Choi and Cardie (2008) are, however, much more specific, as they define syntactic contexts of the polar expressions.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We presented a novel learning-based approach that incorporates structural inference motivated by compositional semantics into the learning procedure.</S><S sid = NA ssid = NA>We evaluate on all strong (i.e., intensity of expression is ‘medium’ or higher), sentimentbearing (i.e., polarity is ‘positive’ or ‘negative’) expressions.8 As a result, we can assume the boundaries of the expressions are given.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  D08-1083.txt | Citing Article:  W10-3111.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Unlike Choi and Cardie (2008), these rules require a proper parse and reflect grammatical relationships between different constituents.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Unlike function-word negators, such as “not” or “never”, content-word negators have been recognized and utilized less actively in previous work.</S><S sid = NA ssid = NA>However, their notion of polarity is quite different from that assumed here and in the literature on sentiment analysis.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  D08-1083.txt | Citing Article:  W10-3110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In this work we focus on explicit negation mentions, also called functional negation by Choi and Cardie (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Note that if the second argument is a negator, we do not flip the polarity of the first argument, because the first argument in general is not in the semantic scope of the negation.4 Instead, we treat the second argument as a constituent with negative polarity.</S><S sid = NA ssid = NA>Next we present experimental results in §4, followed by related work in §5.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  D08-1083.txt | Citing Article:  W10-3110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi and Cardie (2008) combine different kinds of negators with lexical polarity items through various compositional semantic models, both heuristic and machine learned, to improve phrasal sentiment analysis.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>However, their notion of polarity is quite different from that assumed here and in the literature on sentiment analysis.</S><S sid = NA ssid = NA>Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  D08-1083.txt | Citing Article:  D11-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Here, the verbs prevent and ease act as content-word negators (Choi and Cardie, 2008) in that they modify the negative sentiment of their direct object arguments so that the phrase as a whole is perceived as somewhat positive.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>On the other hand, the NEGEX methods (87.7%) that do consider content-word negators as well as function-word negators perform better than VOTE.</S><S sid = NA ssid = NA>For SC-NEGEX, we count the number of content-word negators as well as function-word negators to determine whether the final polarity should be flipped.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  D08-1083.txt | Citing Article:  D11-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi and Cardie (2008), for example, propose an algorithm for phrase-based sentiment analysis that learns proper assignments of intermediate sentiment analysis decision variables given the a priori (i.e., out of context) polarity of the words in the phrase and the (correct) phrase-level polarity.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis</S><S sid = NA ssid = NA>The experiments below evaluate our heuristic- and learning-based methods for subsentential sentiment analysis (§ 4.1).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  D08-1083.txt | Citing Article:  D11-1016.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi and Cardie (2008) hand-code compositional rules in order to model compositional effects of combining different words in the phrase.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Whereas the heuristics above use voting-based inference, those below employ a set of hand-written rules motivated by compositional semantics.</S><S sid = NA ssid = NA>Once we determine the intermediate decision variables, we apply the heuristic rules motivated by compositional semantics (from Table 2) in order to obtain the final polarity y of x.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  D08-1083.txt | Citing Article:  P11-1033.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We extract all sentences containing strong (i.e. intensity is medium or higher), sentiment-bearing (i.e. polarity is positive or negative) expressions following Choi and Cardie (2008).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We evaluate on all strong (i.e., intensity of expression is ‘medium’ or higher), sentimentbearing (i.e., polarity is ‘positive’ or ‘negative’) expressions.8 As a result, we can assume the boundaries of the expressions are given.</S><S sid = NA ssid = NA>Determining the polarity of sentiment-bearing expressions at or below the sentence level requires more than a simple bag-of-words approach.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  D08-1083.txt | Citing Article:  W12-3802.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>An English polarity reversing word dictionary was constructed from the General Inquirer dictionary in the same way as Choi and Cardie (2008), by collecting words which belong to either NOTLW or DECREAS categories (The dictionary contains 121 polarity reversing words).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For each xi in x, we encode the following features: with unseen words in the test data, we add features that describe word categories based on the General Inquirer dictionary.</S><S sid = NA ssid = NA>For the (function- and content-word) negator lexicon, we collect a handful of seed words as well as General Inquirer words that appear in either NOTLW or DECREAS category.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  D08-1083.txt | Citing Article:  N10-1120.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi and Cardie (2008) categorized polarity reversing words into two categories: function-word negators such as not and content-word negators such as eliminate.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>On the other hand, the NEGEX methods (87.7%) that do consider content-word negators as well as function-word negators perform better than VOTE.</S><S sid = NA ssid = NA>For SC-NEGEX, we count the number of content-word negators as well as function-word negators to determine whether the final polarity should be flipped.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  D08-1083.txt | Citing Article:  N10-1120.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Choi and Cardie (2008) proposed a method to classify the sentiment polarity of a sentence basing on compositional semantics.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our experiments show that (1) simple heuristics based on compositional semantics can perform better than learning-based methods that do not incorporate compositional semantics (accuracy of 89.7% vs. 89.1%), but (2) a method that integrates compositional semantics into learning performs better than all other alternatives (90.7%).</S><S sid = NA ssid = NA>Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis</S> | Discourse Facet:  NA | Annotator: Automatic


