A Memory-Based Approach to Learning Shallow Natural Language Patterns
Recognizing shallow linguistic patterns, such as basic syntactic relationships between words, is a common task in applied natural language and text processing.
The common practice for approaching this task is by tedious manual definition of possible pattern structures, often in the form of regular expressions or finite automata.
This paper presents a novel memory-based learning method that recognizes shallow patterns in new text based on a bracketed training corpus.
The training data are stored as-is, in efficient suffix-tree data structures.
Generalization is performed on-line at recognition time by comparing subsequences of the new text to positive and negative evidence in the corpus.
This way, no information in the training is lost, as can happen in other learning systems that construct a single generalized model at the time of training.
The paper presents experimental results for recognizing noun phrase, subject-verb and verb-object patterns in English.
Since the learning approach enables easy porting to new domains, we plan to apply it to syntactic patterns in other languages and to sub-language patterns for information extraction.
We segment the POS sequence of a multi-word into small POS titles, count tile frequency in the new word and non-new-word on the training set respectively and detect new words using these counts.
