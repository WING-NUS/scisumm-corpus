[
  {
    "citance_No": 1, 
    "citing_paper_id": "P14-2114", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Deyu, Zhou | Liangyu, Chen | Yulan, He", 
    "raw_text": "We distinguish between location entities, denoted as l, and non-location entities such as person or organization, denoted as y. 1http: //nlp.stanford.edu/software/sutime.shtml 2http: //nlp.stanford.edu/software/ CRFNER.shtml 3http: //github.com/aritter/twitter-nlp 701 Finally, we use a POS tagger 4 trained on tweets (Gimpel et al, 2011) to perform POS tagging on the tweets data and apart from the previously recognised named entities, only words tagged with nouns, verbs or adjectives are kept", 
    "clean_text": "Finally, we use a POS tagger trained on tweets (Gimpel et al, 2011) to perform POS tagging on the tweets data and apart from the previously recognised named entities, only words tagged with nouns, verbs or adjectives are kept.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P13-2090", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Svitlana, Volkova | Theresa, Wilson | David, Yarowsky", 
    "raw_text": "However, POS taggers for Twitter are only available for a limited number of languages such as English (Gimpel et al, 2011)", 
    "clean_text": "However, POS taggers for Twitter are only available for a limited number of languages such as English (Gimpel et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P14-1017", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chenhao, Tan | Lillian, Lee | Bo, Pang", 
    "raw_text": "Table 3: Explicit requests for sharing (where only occurrences POS-tagged as verbs count, according to the Gimpel et al (2011) tagger)", 
    "clean_text": "Table 3: Explicit requests for sharing (where only occurrences POS-tagged as verbs count, according to the Gimpel et al (2011) tagger).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P14-1017", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chenhao, Tan | Lillian, Lee | Bo, Pang", 
    "raw_text": "Our POS results, gathered using a Twitter-specific tagger (Gimpel et al, 2011), echo those of Ashok et al (2013) who looked at predict 14 Of course, simply inserting garbage isn? t going to lead to more re tweets, but adding more information generally involves longer text", 
    "clean_text": "Our POS results, gathered using a Twitter-specific tagger (Gimpel et al, 2011), echo those of Ashok et al (2013) who looked at predict 14 Of course, simply inserting garbage isn't going to lead to more re-tweets, but adding more information generally involves longer text.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P14-2071", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Bing, Xiang | Liang, Zhou", 
    "raw_text": "The training and testing data are run through tweet-specific tokenization, similar to that used in the CMU Twitter NLP tool (Gimpel et al, 2011) .It is shown in Section 5 that such customized tok enization is helpful", 
    "clean_text": "The training and testing data are run through tweet-specific tokenization, similar to that used in the CMU Twitter NLP tool (Gimpel et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P13-1018", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Wang, Ling | Guang, Xiang | Chris, Dyer | Alan W., Black | Isabel, Trancoso", 
    "raw_text": "This poses considerable problems for traditional NLP tools, which we redeveloped with other domains in mind, which of ten make strong assumptions about orthographic uniformity (i.e., there is just one way to spell you) .One approach to cope with this problem is to an notate in-domain data (Gimpel et al, 2011)", 
    "clean_text": "This poses considerable problems for traditional NLP tools, which we redeveloped with other domains in mind, which of ten make strong assumptions about orthographic uniformity (i.e., there is just one way to spell you). One approach to cope with this problem is to annotate in-domain data (Gimpel et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P14-2083", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Barbara, Plank | Dirk, Hovy | Anders, S\u00c3\u00b8gaard", 
    "raw_text": "More specifically, we had lay annotators on the crowd sourcing platform Crowdflower re-annotate the training section of Gimpel et al (2011)", 
    "clean_text": "More specifically, we had lay annotators on the crowd sourcing platform Crowdflower re-annotate the training section of Gimpel et al (2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P14-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Dirk, Hovy | Barbara, Plank | Anders, S\u00c3\u00b8gaard", 
    "raw_text": "We crowd source the training section of the data from Gimpel et al (2011) 2 with POS tags", 
    "clean_text": "We crowd source the training section of the data from Gimpel et al (2011) 2 with POS tags.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W12-0601", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "William M., Darling | Michael, Paul | Fei, Song", 
    "raw_text": "With spelling errors, abbreviations, uncommon acronyms, and excessive use of slang, systems that are designed for traditional corpora such as news articles may perform poorly when given difficult input such as a Twitter feed (Ritter et al, 2010) .Recognizing the limitations of existing systems, Gimpel et al (2011) develop a POS tagger specifically for Twitter, by creating a training corpus as well as devising a tag set that includes parts of speech that are uniquely found in on line language, such as emoticons (smilies)", 
    "clean_text": "Recognizing the limitations of existing systems, Gimpel et al (2011) develop a POS tagger specifically for Twitter, by creating a training corpus as well as devising a tag set that includes parts of speech that are uniquely found in on line language, such as emoticons (smilies).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W12-0601", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "William M., Darling | Michael, Paul | Fei, Song", 
    "raw_text": "In this work, we focus on Twitter because the labeled corpus by Gimpel et al (2011) allows us to quantitatively evaluate our approach", 
    "clean_text": "In this work, we focus on Twitter because the labeled corpus by Gimpel et al (2011) allows us to quantitatively evaluate our approach.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W12-0601", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "William M., Darling | Michael, Paul | Fei, Song", 
    "raw_text": "We then present POS tagging results on the Twitter POS dataset (Gimpel et al, 2011)", 
    "clean_text": "We then present POS tagging results on the Twitter POS dataset (Gimpel et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W12-0601", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "William M., Darling | Michael, Paul | Fei, Song", 
    "raw_text": "Our data is the re cent Twitter POS dataset released at ACL 2011 by Gimpel et al (2011) consisting of approximately 26,000 words across 1,827 tweets", 
    "clean_text": "Our data is the recent Twitter POS dataset released at ACL 2011 by Gimpel et al (2011) consisting of approximately 26,000 words across 1,827 tweets.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W12-0601", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "William M., Darling | Michael, Paul | Fei, Song", 
    "raw_text": "The Twitter dataset uses adomain-dependent tag set of 25 tags that are described in (Gimpel et al, 2011)", 
    "clean_text": "The Twitter dataset uses a domain-dependent tag set of 25 tags that are described in (Gimpel et al, 2011).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W12-0601", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "William M., Darling | Michael, Paul | Fei, Song", 
    "raw_text": "For this experiment, we again make use of the Twitter POS dataset (Gimpel et al, 2011)", 
    "clean_text": "For this experiment, we again make use of the Twitter POS dataset (Gimpel et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P14-1146", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Duyu, Tang | Furu, Wei | Nan, Yang | Ming, Zhou | Ting, Liu | Bing, Qin", 
    "raw_text": "Wetokenize each tweet with TwitterNLP (Gimpel et al, 2011), remove the@ user and URLs of each tweet, and filter the tweets that are too short (&lt; 7 words)", 
    "clean_text": "We tokenize each tweet with Twitter NLP (Gimpel et al, 2011), remove the @ user and URLs of each tweet, and filter the tweets that are too short (< 7 words).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P14-2009", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Li, Dong | Furu, Wei | Chuanqi, Tan | Duyu, Tang | Ming, Zhou | Ke, Xu", 
    "raw_text": "A tweet-specific tokenizer (Gimpel et al, 2011) is employed, and the dependency parsing results are computed by Stanford Parser (Klein and Manning, 2003)", 
    "clean_text": "A tweet-specific tokenizer (Gimpel et al, 2011) is employed, and the dependency parsing results are computed by Stanford Parser (Klein and Manning, 2003).", 
    "keep_for_gold": 0
  }
]