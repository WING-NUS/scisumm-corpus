[
  {
    "citance_No": 1, 
    "citing_paper_id": "P06-1109", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "We should keep in mind that (1) a tree bank PCFG is not state-of-the-art: its performance is mediocre compared to e.g. Bod (2003) or McClosky et al (2006), and (2) that our tree bank PCFG is binarized as in Klein and Manning (2005) to make results comparable", 
    "clean_text": "We should keep in mind that (1) a tree bank PCFG is not state-of-the-art: its performance is mediocre compared to e.g. Bod (2003) or McClosky et al (2006), and (2) that our tree bank PCFG is binarized as in Klein and Manning (2005) to make results comparable.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P06-1109", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "McClosky et al 2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W10-2105", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Barbara, Plank | Gertjan, van Noord", 
    "raw_text": "For instance, McClosky et al (2006) improved a statistical parser by self-training", 
    "clean_text": "For instance, McClosky et al (2006) improved a statistical parser by self-training.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D08-1071", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Hal, Daum&eacute; III", 
    "raw_text": "Its success stories range from parsing (McClosky et al, 2006) to machine translation (Ueffing, 2006)", 
    "clean_text": "Its success stories range from parsing (McClosky et al, 2006) to machine translation (Ueffing, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D08-1071", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Hal, Daum&eacute; III", 
    "raw_text": "glish (previously used for self-training of parsers (McClosky et al, 2006))", 
    "clean_text": "previously used for self-training of parsers (McClosky et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P13-1043", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Muhua, Zhu | Yue, Zhang | Wenliang, Chen | Min, Zhang | Jingbo, Zhu", 
    "raw_text": "91.4 91.8 91.6 McClosky et al (2006) 92.1 92.5 92.3 Table 7: Comparison of our parsers and related work on the English test set", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P13-1043", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Muhua, Zhu | Yue, Zhang | Wenliang, Chen | Min, Zhang | Jingbo, Zhu", 
    "raw_text": "as the performance of self-trained parsers, except for McClosky et al (2006), which is based on the combination of re ranking and self-training", 
    "clean_text": "We note that the performance is on the same level as the performance of self-trained parsers, except for McClosky et al. (2006), which is based on the combination of reranking and self-training.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P10-1036", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jonathan K., Kummerfeld | Jessika, Roesner | Tim, Dawborn | James, Haggerty | James R., Curran | Stephen, Clark", 
    "raw_text": "Clark et al (2003) were unable to improve the accuracy of POS tagging using self-training. In contrast, McClosky et al (2006a) report improved accuracy through self-training for a two stage parser and re-ranker", 
    "clean_text": "In contrast, McClosky et al (2006a) report improved accuracy through self-training for a two stage parser and re-ranker.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P10-1036", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jonathan K., Kummerfeld | Jessika, Roesner | Tim, Dawborn | James, Haggerty | James R., Curran | Stephen, Clark", 
    "raw_text": "This method has been used effectively to improve parsing performance on newspaper text (McClosky et al, 2006a), as well as adapting a Penn Treebank parser to a new domain (McClosky et al, 2006b)", 
    "clean_text": "This method has been used effectively to improve parsing performance on newspaper text (McClosky et al, 2006a), as well as adapting a Penn Treebank parser to a new domain (McClosky et al, 2006b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P07-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Rens, Bod", 
    "raw_text": "The NANC corpus contains approximately 2 million WSJ sentences that do not overlap with Penn? s WSJ and has been previously used by McClosky et al (2006) in improving a supervised parser by self training", 
    "clean_text": "The NANC corpus contains approximately 2 million WSJ sentences that do not overlap with Penn's WSJ and has been previously used by McClosky et al (2006) in improving a supervised parser by self training.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D10-1002", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Zhongqiang, Huang | Mary P., Harper | Slav, Petrov", 
    "raw_text": "McClosky et al (2006 )presented a very effective method for self-training a two-stage parsing system consisting of a first-stage generative lexicalized parser and a second-stage discriminative re ranker", 
    "clean_text": "McClosky et al (2006) presented a very effective method for self-training a two-stage parsing system consisting of a first-stage generative lexicalized parser and a second-stage discriminative reranker.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "D10-1002", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Zhongqiang, Huang | Mary P., Harper | Slav, Petrov", 
    "raw_text": "8Our ST-Reg grammars are trained in the same way as in Type Parser LP LR EX S IN G L E Charniak (2000) 89.9 89.5 37.2 Petrov and Klein (2007) 90.2 90.1 36.7Carreras et al (2008) 91.4 90.7 R E Charniak and Johnson (2005) 91.8 91.2 44.8 Huang (2008) 92.2 91.2 43.5 S E L F Huang and Harper (2009) 8 91.6 91.1 40.4 McClosky et al (2006) 92.5 92.1 45.3 C O M B O Petrov (2010) 92.0 91.7 41.9Sagae and Lavie (2006) 93.2 91.0 Fossum and Knight (2009) 93.2 91.7 Zhang et al (2009) 93.3 92.0 This Paper Best Single 91.8 91.4 40.3 Best Product 92.7 92.2 43.1 Table 7: Final test set accuracies on WSJ.Although our models are based on purely generative PCFG grammars, our best product model performs competitively to the self-trained two-step discriminative re ranking parser of McClosky et al (2006), which makes use of many non-local rerank ing features", 
    "clean_text": "Although our models are based on purely generative PCFG grammars, our best product model performs competitively to the self-trained two-step discriminative reranking parser of McClosky et al (2006), which makes use of many non-local reranking features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "D10-1002", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Zhongqiang, Huang | Mary P., Harper | Slav, Petrov", 
    "raw_text": "We expect that replacing the first-step generative parsing model in McClosky et al (2006) with a product of latent variable grammars would give even higher parsing accuracies. On the Broadcast News test set, our best performing single and product grammars (bolded in Table 6) obtained F scores of 88.7 and 89.6, respectively. While there is no prior work using our setup, we expect these numbers to set a high baseline", 
    "clean_text": "We expect that replacing the first-step generative parsing model in McClosky et al (2006) with a product of latent variable grammars would give even higher parsing accuracies.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "E09-1033", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Alexander, Fraser | Renjing, Wang | Hinrich, Sch&uuml;tze", 
    "raw_text": "Third, we hope that the improved parses of bitextwill serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky et al, 2006)", 
    "clean_text": "Third, we hope that the improved parses of bitext will serve as higher quality training data for improving monolingual parsing using a process similar to self-training (McClosky et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-2146", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Shulamit, Umansky-Pesin | Roi, Reichart | Ari, Rappoport", 
    "raw_text": "Our work is related to self-training (McClosky et al, 2006a; Reichart and Rappoport, 2007 )asthe algorithm used its own tagging of the sentences collected from the web in order to produce a better final tagging", 
    "clean_text": "Our work is related to self-training (McClosky et al, 2006a; Reichart and Rappoport, 2007) as the algorithm used its own tagging of the sentences collected from the web in order to produce a better final tagging.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W10-2604", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Fei, Huang | Alexander, Yates", 
    "raw_text": "SELF-CRF: Following the self-training paradigm (e.g., (McClosky et al, 2006b; McClosky et al, 2006a)), we train our baseline first on the training set, then apply it to the test set, then retrain it on the training set plus the automatically labeled test set", 
    "clean_text": "SELF-CRF: Following the self-training paradigm (e.g., (McClosky et al, 2006b; McClosky et al, 2006a)), we train our baseline first on the training set, then apply it to the test set, then retrain it on the training set plus the automatically labeled test set.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W11-1607", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Micha, Elsner | Deepak, Santhanam", 
    "raw_text": "To produce this, we segment sentences with MXTerminator (Reynar and Ratnaparkhi, 1997) and parse the corpus with the self trained Charniak parser (McClosky et al, 2006)", 
    "clean_text": "To produce this, we segment sentences with MXTerminator (Reynar and Ratnaparkhi, 1997) and parse the corpus with the self trained Charniak parser (McClosky et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "C10-1120", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Anders, S&oslash;gaard | Christian, Rish&oslash;j", 
    "raw_text": "A note able exception in constituent-based parsing is the work of McClosky et al (2006) who show that self-training is possible if a re ranker is used to inform the underlying parser", 
    "clean_text": "A noteable exception in constituent-based parsing is the work of McClosky et al (2006) who show that self-training is possible if a reranker is used to inform the underlying parser.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "E09-3005", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Barbara, Plank", 
    "raw_text": "Of these, McClosky et al (2006) deal specifically with self training for data-driven statistical parsing", 
    "clean_text": "Of these, McClosky et al (2006) deal specifically with self training for data-driven statistical parsing.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P13-2112", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Long, Duong | Paul, Cook | Steven, Bird | Pavel, Pecina", 
    "raw_text": "If p (wtj |wsi)& gt; S, where S is a threshold which we heuristically set to 0.7, we replace Ttj by Tsi. Self-training can suffer from over-fitting, in which errors in the original model are repeated and amplified in the new model (McClosky et al, 2006)", 
    "clean_text": "Self-training can suffer from over-fitting, in which errors in the original model are repeated and amplified in the new model (McClosky et al, 2006).", 
    "keep_for_gold": 1
  }
]