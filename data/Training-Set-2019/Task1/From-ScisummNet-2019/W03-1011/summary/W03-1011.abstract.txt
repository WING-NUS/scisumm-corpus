We present a general framework for distributional similarity based on the concepts of precision and recall.
Different parameter settings within this framework approximate different existing similarity measures as well as many more which have, until now, been unexplored.
We show that optimal parameter settings outperform two existing state-of-the-art similarity measures on two evaluation tasks for high and low frequency nouns.
