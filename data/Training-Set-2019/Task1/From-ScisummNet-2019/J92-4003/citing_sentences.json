[
  {
    "citance_No": 1, 
    "citing_paper_id": "P95-1025", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Alpha K., Luk", 
    "raw_text": "On the other hand, the thesaurus-based method of Yarowsky (1992) may suffer from loss of information (since it is semi-class-based) as well as data sparseness (ince H Classes used in Resnik (1992) are based on the WordNet taxonomy while classes of Brown et al (1992) and Pereira et al (1993) are derived from statistical data collected from corpora", 
    "clean_text": "On the other hand, the thesaurus-based method of Yarowsky (1992) may suffer from loss of information (since it is semi-class-based) as well as data sparseness since H Classes used in Resnik (1992) are based on the WordNet taxonomy while classes of Brown et al (1992) and Pereira et al (1993) are derived from statistical data collected from corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-1100", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ankur, Parikh | Shay B., Cohen | Eric P., Xing", 
    "raw_text": "For all languages we use Brown clustering (Brown et al, 1992) to construct a log (C)+ C feature vector where the first log (C) elements indicate which mer gable cluster the word belongs to, and the last C elements indicate the cluster identity", 
    "clean_text": "For all languages we use Brown clustering (Brown et al, 1992) to construct a log (C)+ C feature vector where the first log (C) elements indicate which mer gable cluster the word belongs to, and the last C elements indicate the cluster identity.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "C10-2013", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Marie, Candito | Joakim, Nivre | Pascal, Denis | Enrique, Henestroza Anguiano", 
    "raw_text": "(2009) using Percy Liang? s implementation8 of the Brown unsupervised clustering algorithm (Brown et al, 1992)", 
    "clean_text": "We use the word clusters computed by Candito and Crabbe (2009) using Percy Liang's implementation of the Brown unsupervised clustering algorithm (Brown et al, 1992).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W01-1004", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Kalina, Bontcheva | Christopher, Brewster | Fabio, Ciravegna | Hamish, Cunningham | Louise, Guthrie | Robert J., Gaizauskas | Yorick, Wilks", 
    "raw_text": "In the literature approaches to construction of taxonomies of concepts have been proposed (Brown et al 1992, McMahon and Smith 1996, Sanderson and Croft 1999)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P13-1041", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Kashyap, Popat | Balamurali, A. R. | Pushpak, Bhattacharyya | Gholamreza, Haffari", 
    "raw_text": "One of the obvious syntagmas is words, and words are grouped into equivalence classes or clusters, thus reducing the model parameters of a statistical NLP system (Brown et al, 1992)", 
    "clean_text": "One of the obvious syntagmas is words, and words are grouped into equivalence classes or clusters, thus reducing the model parameters of a statistical NLP system (Brown et al, 1992).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P13-1041", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Kashyap, Popat | Balamurali, A. R. | Pushpak, Bhattacharyya | Gholamreza, Haffari", 
    "raw_text": "Agglomerative clustering algorithm by Brown et al (1992) is used for this purpose", 
    "clean_text": "Agglomerative clustering algorithm by Brown et al (1992) is used for this purpose.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P13-1041", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Kashyap, Popat | Balamurali, A. R. | Pushpak, Bhattacharyya | Gholamreza, Haffari", 
    "raw_text": "Formally, as mentioned in Brown et al (1992), let C be a hard clustering function which maps vocabulary V to one of the K clusters", 
    "clean_text": "Formally, as mentioned in Brown et al (1992), let C be a hard clustering function which maps vocabulary V to one of the K clusters.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P13-1041", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Kashyap, Popat | Balamurali, A. R. | Pushpak, Bhattacharyya | Gholamreza, Haffari", 
    "raw_text": "j=1 p (wj|C (wj)) p (C (wj) |wj? 1)) (3) Note this is different from the likelihood estimation of Brown et al (1992) (Equation (1)), where C (wj) was conditioned on C (wj? 1)", 
    "clean_text": "Note this is different from the likelihood estimation of Brown et al (1992).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P12-1081", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Emily, Pitler", 
    "raw_text": "The features were all derived from the publicly available clusters produced by running the Brown clustering algorithm (Brown et al, 1992) over the BLLIP corpus with the Penn Treebank sentences excluded.5 Preposition and conjunction-inspired features (motivated by Section 4) are described below: 5people.csail.mit.edu/maestro/papers/bllip-clusters.gz 772 Web Counts: For each set of words of interest ,wecompute the PMI between the words, and then include binary features for whether the mutual information is undefined, if it is negative, and whether it is greater than each positive integer", 
    "clean_text": "The features were all derived from the publicly available clusters produced by running the Brown clustering algorithm (Brown et al, 1992) over the BLLIP corpus with the Penn Treebank sentences excluded.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D11-1144", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Duangmanee, Putthividhya | Jun, Hu", 
    "raw_text": "Popular clustering algorithms used prevalently in many NER systems are, for example, the combination of distributional and morphological similarity work of (Clark 2003) or the classic N -gramlanguage model based clustering algorithm of (Brown et al 1992)", 
    "clean_text": "Popular clustering algorithms used prevalently in many NER systems are, for example, the combination of distributional and morphological similarity work of (Clark 2003) or the classic N-gram language model based clustering algorithm of (Brown et al 1992).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "E12-1033", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Michael, Wiegand | Dietrich, Klakow", 
    "raw_text": "As a state of-the-art clustering method, we consider Brown clustering (Brown et al 1992) as implemented in the SRILM-toolkit (Stolcke, 2002)", 
    "clean_text": "As a state of-the-art clustering method, we consider Brown clustering (Brown et al 1992) as implemented in the SRILM-toolkit (Stolcke, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "C00-2121", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Aristomenis, Thanopoulos | Nikos D., Fakotakis | George K., Kokkinakis", 
    "raw_text": "Methods that use bi grams (Brown et al, 1992) or trigrams (Martin et al, 1998) cluster words considering as a word &apos; s context he one or two immediately adjacent words and employ as clustering criteria the minimal loss of average 836nmtual information and the perplexity improvement respectively", 
    "clean_text": "Methods that use bigrams (Brown et al, 1992) or trigrams (Martin et al, 1998) cluster words considering as a word's context he one or two immediately adjacent words and employ as clustering criteria the minimal loss of average information and the perplexity improvement respectively.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "C00-2121", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Aristomenis, Thanopoulos | Nikos D., Fakotakis | George K., Kokkinakis", 
    "raw_text": "Brown et al (1992) also proposed a window method introducing the concept of& quot; semantic stickiness& quot; of two words as the relatively frequent close occurrence between them (less than 500 words distance)", 
    "clean_text": "Brown et al (1992) also proposed a window method introducing the concept of semantic stickiness of two words as the relatively frequent close occurrence between them (less than 500 words distance).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D10-1056", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Christos, Christodoulopoulos | Sharon, Goldwater | Mark, Steedman", 
    "raw_text": "We find that the oldest system tested (Brown et al, 1992) produces the best prototypes, and that using these prototypes as input to Haghighi and Klein? s system yields state of-the-art performance on WSJ and improvements on seven of the eight non-English corpora", 
    "clean_text": "We find that the oldest system tested (Brown et al, 1992) produces the best prototypes, and that using these prototypes as input to Haghighi and Klein's system yields state of-the-art performance on WSJ and improvements on seven of the eight non-English corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D10-1056", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Christos, Christodoulopoulos | Sharon, Goldwater | Mark, Steedman", 
    "raw_text": "The systems are as follows:1 [brown]: Class-based n-grams (Brown et al,1992)", 
    "clean_text": "The systems are as follows:1 [brown]: Class-based n-grams (Brown et al,1992).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D10-1056", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Christos, Christodoulopoulos | Sharon, Goldwater | Mark, Steedman", 
    "raw_text": "We found that the old est system (Brown et al, 1992) yielded the best prototypes, and that using these prototypes gave state-of-the-art performance on WSJ, as well as improvements on nearly all of the non-English corpora", 
    "clean_text": "We found that the oldest system (Brown et al, 1992) yielded the best prototypes, and that using these prototypes gave state-of-the-art performance on WSJ, as well as improvements on nearly all of the non-English corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W97-0211", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Roberto, Basili | Michelangelo, Della Rocca | Maria Teresa, Pazienza", 
    "raw_text": "Many authors claim that class-based methods are more robust against data sparseness problems (Dagan,1994), (Pereira, 1993), (Brown et al.,1992)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "N10-1046", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Saeedeh, Momtazi | Sanjeev P., Khudanpur | Dietrich, Klakow", 
    "raw_text": "The idea was introduced by Brown et al (1992) and used in different applications, including speech recognition, named entity tagging, machine translation, query expansion, text categorization, and word sense disambiguation", 
    "clean_text": "The idea was introduced by Brown et al (1992) and used in different applications, including speech recognition, named entity tagging, machine translation, query expansion, text categorization, and word sense disambiguation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "N10-1046", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Saeedeh, Momtazi | Sanjeev P., Khudanpur | Dietrich, Klakow", 
    "raw_text": "To this end, the Brownalgorithm (Brown et al, 1992) is applied to pairwise word co-occurrence statistics based on different definitions of word co-occurrence", 
    "clean_text": "To this end, the Brown algorithm (Brown et al, 1992) is applied to pairwise word co-occurrence statistics based on different definitions of word co-occurrence.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "N10-1046", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Saeedeh, Momtazi | Sanjeev P., Khudanpur | Dietrich, Klakow", 
    "raw_text": "To calculate P (Cqi |S), each cluster is con side red an atomic entity, with Q and S interpreted as sequences of such entities. In order to cluster lexical items, we use the algorithm proposed by Brown et al (1992), as implemented in the SRILM toolkit (Stolcke, 2002)", 
    "clean_text": "In order to cluster lexical items, we use the algorithm proposed by Brown et al (1992), as implemented in the SRILM toolkit (Stolcke, 2002).", 
    "keep_for_gold": 0
  }
]