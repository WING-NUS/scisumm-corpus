Unsupervised Multilingual Learning for Morphological Segmentation
For centuries, the deep connection between languages has brought about major discoveries about human communication.
In this paper we investigate how this powerful source of information can be exploited for unsupervised language learning.
In particular, we study the task of morphological segmentation of multiple languages.
We present a non-parametric Bayesian model that jointly induces morpheme segmentations of each language under consideration and at the same time identifies cross-lingual morpheme patterns, or abstract morphemes.
We apply our model to three Semitic languages: Arabic, Hebrew, Aramaic, as well as to English.
Our results demonstrate that learning morphological models in tandem reduces error by up to 24% relative to monolingual models.
Furthermore, we provide evidence that our joint model achieves better performance when applied to languages from the same family.
We use bilingual information but the segmentation is learned independently from translation modeling.
