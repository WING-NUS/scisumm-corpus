Citance Number: 1 | Reference Article:  P02-1047.txt | Citing Article:  N04-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>A similar approach has been advocated for the interpretation of discourse relations by Marcu and Echihabi (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>An Unsupervised Approach To Recognizing Discourse Relations</S><S sid = NA ssid = NA>We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P02-1047.txt | Citing Article:  N04-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Apart from the fact that we present an alternative model, our work differs from Marcu and Echihabi (2002) in two important ways.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.</S><S sid = NA ssid = NA>In spite of the difficulty of determining the discourse relations that hold between arbitrary text spans, it is clear that such an ability is important in many applications.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P02-1047.txt | Citing Article:  D11-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Inspired by Marcu and Echihabi (2002), to construct relatively low noise discourse instances for unsupervised methods using cue phrases, we grouped the 13 relations into the following 5 relations: Contrast is a union of Antithesis, Concession, Otherwise and Contrast from RST.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The advantage of operating with coarsely defined discourse relations is that it enables us to automatically construct relatively low-noise datasets that can be used for learning.</S><S sid = NA ssid = NA>That is, we considered that a CONTRAST relation held between two text spans if a human annotator labeled the relation between those spans as ANTITHESIS, CONCESSION, OTHERWISE or CONTRAST.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P02-1047.txt | Citing Article:  D11-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Cue-phrase-based patterns could find only limited number of discourse instances with high precision (Marcu and Echihabi, 2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We did this because when trying to determine whether a CONTRAST relation holds between two spans of texts separated by the cue phrase “but”, for example, we want to take advantage of the cue phrase occurrence as well.</S><S sid = NA ssid = NA>Table 2 lists some of the cue phrases we used in order to extract CONTRAST, CAUSEEXPLANATION-EVIDENCE, ELABORATION, and CONDITION relations and the number of examples extracted from the Raw corpus for each type of discourse relation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P02-1047.txt | Citing Article:  D11-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Nouns (except for named entities) and verbs were most representative words in discourse recognition (Marcu and Echihabi, 2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We call these the most representative words of a sentence/discourse unit.</S><S sid = NA ssid = NA>We wrote a simple program that extracted the nouns, verbs, and cue phrases in each sentence/clause.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P02-1047.txt | Citing Article:  D11-1015.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This work was supported by the National Science Foundation under grant number IIS-0097846 and by the Advanced Research and Development Activity (ARDA)’s Advanced Question Answering for Intelligence (AQUAINT) Program under contract number MDA908-02-C-0007.</S><S sid = NA ssid = NA>Table 1 shows the definitions of the relations we considered.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P02-1047.txt | Citing Article:  P08-1118.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Presently, there exist methods for learning oppositional terms (Marcu and Echihabi, 2002) and paraphrase learning has been thoroughly studied, but successfully extending these techniques to learn incompatible phrases poses difficulties because of the data distribution.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This ensures that our classifiers do not learn, for example, that the word pair if – then is a good indicator of a CONDITION relation, which would simply amount to learning to distinguish between the extraction patterns used to construct the corpus.</S><S sid = NA ssid = NA>Also, since the learning curve for the BLIPP corpus is steeper than the learning curve for the Raw corpus, this suggests that discourse relation classifiers trained on most representative word pairs and millions of training examples can achieve higher levels of performance than classifiers trained on all word pairs (unannotated data).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P02-1047.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Some of existing works attempt to perform relation recognition without hand-annotated corpora (Marcu and Echihabi, 2002), (Sporleder and Lascarides, 2008) and (Blair-Goldensohn, 2007).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We automatically extracted from this manually annotated corpus all CONTRAST, CAUSE-EXPLANATION-EVIDENCE, CONDITION and ELABORATION relations that hold between two adjacent elementary discourse units.</S><S sid = NA ssid = NA>For example, the RST-annotated corpus of Carlson et al. (2001) contains 238 CONTRAST relations that hold between two adjacent elementary discourse units.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P02-1047.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Marcu and Echihabi, 2002) used a pattern based approach to extract instances of discourse relations such as Contrast and Elaboration from unlabeled corpora.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>To achieve this, we used the patterns in Table 2 to extract examples of discourse relations from the BLIPP corpus.</S><S sid = NA ssid = NA>Table 2 lists some of the cue phrases we used in order to extract CONTRAST, CAUSEEXPLANATION-EVIDENCE, ELABORATION, and CONDITION relations and the number of examples extracted from the Raw corpus for each type of discourse relation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P02-1047.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>There are other efforts that attempt to extend the work of (Marcu and Echihabi, 2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>However, empirical work of Marcu (2000) and Carlson et al. (2001) suggests that the majority of occurrences of “but”, for example, do signal CONTRAST relations.</S><S sid = NA ssid = NA>In our work, we decide to focus only on four types of relations, which we call: CONTRAST, CAUSE-EXPLANATIONEVIDENCE (CEV), CONDITION, and ELABORATION.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P02-1047.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Saito et al., 2006) followed the method of (Marcu and Echihabi, 2002) and conducted experiments with combination of cross-argument word pairs and phrasal patterns as features to recognize implicit relations between adjacent sentences in a Japanese corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For example, the RST-annotated corpus of Carlson et al. (2001) contains 238 CONTRAST relations that hold between two adjacent elementary discourse units.</S><S sid = NA ssid = NA>The learning curves in Figure 1 are illuminating as they show that if one uses as features only the most representative word pairs, one needs only about 100,000 training examples to achieve the same level of performance one achieves using 1,000,000 training examples and features defined over all word pairs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P02-1047.txt | Citing Article:  C10-2172.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Blair-Goldensohn, 2007) extended the work of (Marcu and Echihabi, 2002) by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>However, empirical work of Marcu (2000) and Carlson et al. (2001) suggests that the majority of occurrences of “but”, for example, do signal CONTRAST relations.</S><S sid = NA ssid = NA>The values are computed using maximum likelihood estimators, which are smoothed using the Laplace method (Manning and Sch¨utze, 1999).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P02-1047.txt | Citing Article:  P13-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To overcome the shortage of manually annotated training data, (Marcu and Echihabi, 2002) proposed a pattern-based approach to automatically generate training data from raw corpora.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We retrained then all classifiers on the Raw corpus, but this time without removing from the corpus the cue phrases that were used to generate the training examples.</S><S sid = NA ssid = NA>The results in Table 5 show that the classifiers learned from automatically generated training data can be used to distinguish between certain types of RST relations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P02-1047.txt | Citing Article:  P13-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Sporleder and Lascarides, 2008) conducted a study of the pattern-based approach presented by (Marcu and Echihabi, 2002) and showed that the model built on synthetical implicit data has not generalize well on natural implicit data.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Developing lower-noise methods for automatically collecting training data and discovering features of higher predictive power for discourse relation classification than the features presented in this paper appear to be research avenues that are worthwhile to pursue.</S><S sid = NA ssid = NA>In our paper, we show that massive amounts of data can have a major impact on discourse processing research as well.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P02-1047.txt | Citing Article:  P13-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Previous work (Marcu and Echihabi, 2002) and (Sporleder and Lascarides, 2008) adopted predefined pattern-based approach to generate synthetic labeled data, where each predefined pattern has one discourse relation label.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We label such examples NO-RELATION-SAME-TEXT.</S><S sid = NA ssid = NA>In Lascarides and Asher’s theory (1993), we would label the relation between 2.a and 2.b as EXPLANATION because the event in 2.b explains why the event in 2.a happened (perhaps by CAUSING it).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P02-1047.txt | Citing Article:  N06-2034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Marcu and Echihabi 2002) proposed a method to identify discourse relations between text segments using Naive Bayes classifiers trained on a huge corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A program trained only on Carlson et al.’s corpus, would, therefore, identify at most 79 of the 307 relations correctly.</S><S sid = NA ssid = NA>But a direct comparison between two classifiers trained on different corpora is not fair because with just 100,000 examples per relation, the systems trained on the Raw corpus are much worse than those trained on the BLIPP data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P02-1047.txt | Citing Article:  N06-2034.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>When we consider the frequency of discourse relations, i.e. 43% for ELABORATION, 32% for CONTRAST etc., the weighted accuracy was 53% using only lexical information, which is comparable to the similar experiment by (Marcu and Echihabi 2002) of 49.7%.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In general, we hypothesize that lexical item pairs can provide clues about the discourse relations that hold between the text spans in which the lexical items occur.</S><S sid = NA ssid = NA>This corresponds to an increase in accuracy from to .</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P02-1047.txt | Citing Article:  P12-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>An unsupervised approach was proposed to recognize discourse relations in (Marcu and Echihabi, 2002), which extracts discourse relations that hold between arbitrary spans of text making use of cue phrases.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We present an unsupervised approach to discourse relations of hold between arbitrary spans of texts.</S><S sid = NA ssid = NA>An Unsupervised Approach To Recognizing Discourse Relations</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P02-1047.txt | Citing Article:  N07-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We adopt the approach of Marcu and Echihabi (2002), using a small set of patterns to build relation models, and extend their work by refining the training and classification process using parameter optimization, topic segmentation and syntactic parsing.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The values are computed using maximum likelihood estimators, which are smoothed using the Laplace method (Manning and Sch¨utze, 1999).</S><S sid = NA ssid = NA>For each discourse relation pair , we train a word-pair-based classifier using the automatically derived training examples in the Raw corpus, from which we first removed the cue-phrases used for extracting the examples.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P02-1047.txt | Citing Article:  N07-1054.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We draw on and extend the work of Marcu and Echihabi (2002).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>However, empirical work of Marcu (2000) and Carlson et al. (2001) suggests that the majority of occurrences of “but”, for example, do signal CONTRAST relations.</S><S sid = NA ssid = NA>In our work, we decide to focus only on four types of relations, which we call: CONTRAST, CAUSE-EXPLANATIONEVIDENCE (CEV), CONDITION, and ELABORATION.</S> | Discourse Facet:  NA | Annotator: Automatic


