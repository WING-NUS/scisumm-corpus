[
  {
    "citance_No": 1, 
    "citing_paper_id": "C02-1008", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Wen-Hsiang, Lu | Lee-Feng, Chien | Hsi-Jian, Lee", 
    "raw_text": "On the other hand, the alternative approach using comparable or unrelated text corpora were studied by Rapp (1999) and Fung et al (1998)", 
    "clean_text": "On the other hand, the alternative approach using comparable or unrelated text corpora were studied by Rapp (1999) and Fung et al (1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W11-1205", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Emmanuel, Morin | Emmanuel, Prochasson", 
    "raw_text": "For instance, good results are obtained from large corpora? several million words? for which the accuracy of the proposed translation is between 76% (Fung, 1998) and 89% (Rapp, 1999) for the first 20 candidates", 
    "clean_text": "For instance, good results are obtained from large corpora several million words for which the accuracy of the proposed translation is between 76% (Fung, 1998) and 89% (Rapp, 1999) for the first 20 candidates.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "I08-1053", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Nikesh, Garera | David, Yarowsky", 
    "raw_text": "This can be accomplished as in Rapp (1999) and Schafer and Yarowsky (2002) by creating bag-of-words context vectors around both the source and target language words and then projecting the source vectors into the (English) target space via the current small translation dictionary", 
    "clean_text": "This can be accomplished as in Rapp (1999) and Schafer and Yarowsky (2002) by creating bag-of-words context vectors around both the source and target language words and then projecting the source vectors into the (English) target space via the current small translation dictionary.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C04-1149", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Takehito, Utsuro | Kohei, Hino | Mitsuhiro, Kida | Seiichi, Nakagawa | Satoshi, Sato", 
    "raw_text": "Here, a standard technique of estimating bilingual term correspondences from com parable corpora (e.g., Fung and Yee (1998 )andRapp (1999)) is employed", 
    "clean_text": "Here, a standard technique of estimating bilingual term correspondences from com parable corpora (e.g., Fung and Yee (1998) and Rapp (1999)) is employed.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C04-1149", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Takehito, Utsuro | Kohei, Hino | Mitsuhiro, Kida | Seiichi, Nakagawa | Satoshi, Sato", 
    "raw_text": "For example, Rapp (1999) filtered out bilingual term pairs with low monolingual frequencies (those below 100 times), while Fung and Yee (1998) restricted candidate bilingual term pairs to be pairs of the most frequent 118 unknown words", 
    "clean_text": "For example, Rapp (1999) filtered out bilingual term pairs with low monolingual frequencies (those below 100 times), while Fung and Yee (1998) restricted candidate bilingual term pairs to be pairs of the most frequent 118 unknown words.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C10-1070", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Audrey, Laroche | Philippe, Langlais", 
    "raw_text": "The approach we investigate for identifying term translations in comparable corpora is similar to (Rapp, 1999) and many others", 
    "clean_text": "The approach we investigate for identifying term translations in comparable corpora is similar to (Rapp, 1999) and many others.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-1070", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Audrey, Laroche | Philippe, Langlais", 
    "raw_text": "Complex linguistic tools such as terminological extractors (Daille and Morin,2005), parsers (Yu and Tsujii, 2009) or lemma tizers (Rapp, 1999) are sometimes used", 
    "clean_text": "Complex linguistic tools such as terminological extractors (Daille and Morin,2005), parsers (Yu and Tsujii, 2009) or lemma tizers (Rapp, 1999) are sometimes used.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-1070", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Audrey, Laroche | Philippe, Langlais", 
    "raw_text": "Context length can be based on a number of units, for instance 3 sentences (Daille and Morin, 2005), windows of 3 (Rapp, 1999) or 25 words (Prochasson et al, 2009), etc. It is an important parameter of the projection-based approach", 
    "clean_text": "Context length can be based on a number of units, for instance 3 sentences (Daille and Morin, 2005), windows of 3 (Rapp, 1999) or 25 words (Prochasson et al, 2009), etc.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C10-1070", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Audrey, Laroche | Philippe, Langlais", 
    "raw_text": "As al ready noted, most authors use the log-likelihood ratio to measure the association between collocates; some, like (Rapp, 1999), informally compare the performance of a small number of association measures, or combine the results obtained with different association measures (Daille and Morin, 2005)", 
    "clean_text": "As already noted, most authors use the log-likelihood ratio to measure the association between collocates; some, like (Rapp, 1999), informally compare the performance of a small number of association measures, or combine the results obtained with different association measures (Daille and Morin, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W12-0114", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mireia, Ginest&Atilde;&shy;-Rosell | Johanna, Geiss | Anthony, Hartley | Bogdan, Babych | Reinhard, Rapp | Kurt, Eberle | Serge, Sharoff | Martin, Thomas", 
    "raw_text": "comparable corpora as proposed in a study by Rapp (1999)", 
    "clean_text": "Expand the dictionary of step 3 using comparable corpora as proposed in a study by Rapp (1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W12-0114", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mireia, Ginest&Atilde;&shy;-Rosell | Johanna, Geiss | Anthony, Hartley | Bogdan, Babych | Reinhard, Rapp | Kurt, Eberle | Serge, Sharoff | Martin, Thomas", 
    "raw_text": "From a previous pilot study (Rapp, 1999) it can be expected that this methodology achieves an accuracy in the order of 70%, which means that only a relatively modest amount of manual post editing is required", 
    "clean_text": "From a previous pilot study (Rapp, 1999) it can be expected that this methodology achieves an accuracy in the order of 70%, which means that only a relatively modest amount of manual post editing is required.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P04-1022", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Yajuan, L&uuml; | Ming, Zhou", 
    "raw_text": "(Rapp, 1999) and (Koehn and Knight, 2002) extract new word translations from non-parallel corpus", 
    "clean_text": "(Rapp, 1999) and (Koehn and Knight, 2002) extract new word translations from non-parallel corpus.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "C10-1073", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Bo, Li | Eric, Gaussier", 
    "raw_text": "This approach to bilingual lexicon extraction from comparable corpora radically differs, to our knowledge, from previous approaches 650 C0 CH C? H C1 C2 C1 new& gt; C1,& gt; C0 C2 new& gt; C2,& gt; C0 WL 0.114 0.144 0.125 0.136 0.181 0.156 2.0%, 4.2% 0.205 2.4%, 9.1% WM 0.233 0.313 0.270 0.345 0.401 0.369 2.4%, 3.6% 0.433 3.2%, 20.0% WH 0.417 0.456 0.377 0.568 0.633 0.581 1.3%, 16.4% 0.643 1.0%, 22.6% All 0.205 0.224 0.189 0.258 0.310 0.278 2.0%, 7.3% 0.333 2.3%, 12.8% Table 4: Precision of the different approaches on different corpora which are mainly variants of the standard method proposed in (Fung and Yee, 1998) and (Rapp, 1999)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C10-2055", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Azniah, Ismail | Suresh, Manandhar", 
    "raw_text": "To identify the context terms CT (WS) of a source word WS, as in (Rapp, 1999), we use log likelihood ratio (LL) Dunning (1993)", 
    "clean_text": "To identify the context terms CT (WS) of a source word WS, as in (Rapp, 1999), we use log likelihood ratio (LL) Dunning (1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "E12-1014", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Alexandre, Klementiev | Ann, Irvine | Chris, Callison-Burch | David, Yarowsky", 
    "raw_text": "Using large, unrelated English and German corpora (with 163m and 135mwords) and a small German-English bilingual dictionary (with 22k entires), Rapp (1999) demonstrated that reasonably accurate translations could be learned for 100 German nouns that were not contained in the seed bilingual dictionary", 
    "clean_text": "Using large, unrelated English and German corpora (with 163m and 135mwords) and a small German-English bilingual dictionary (with 22k entires), Rapp (1999) demonstrated that reasonably accurate translations could be learned for 100 German nouns that were not contained in the seed bilingual dictionary.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "E12-1014", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Alexandre, Klementiev | Ann, Irvine | Chris, Callison-Burch | David, Yarowsky", 
    "raw_text": "We extend the vector space approach of Rapp (1999) to compute similarity between phrases in the source and tar get languages", 
    "clean_text": "We extend the vector space approach of Rapp (1999) to compute similarity between phrases in the source and target languages.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "E12-1014", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Alexandre, Klementiev | Ann, Irvine | Chris, Callison-Burch | David, Yarowsky", 
    "raw_text": "This sparse projected vector is compared to the vectors representing all English phrases e. Each phrase pair in the phrase table is assigned a contextual similarity score c (f, e) based on the similarity between e and the projection of f. Various means of computing the component values and vector similarity measures have been proposed in literature (e.g. Rapp (1999), Fung and Yee (1998))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D09-1040", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Yuval, Marton | Chris, Callison-Burch | Philip, Resnik", 
    "raw_text": "One approach that can, in principle, better exploit both alignments from bitextsand make use of non-parallel corpora is the distributional col locational approach ,e.g., as used by Fung and Yee (1998) and Rapp (1999)", 
    "clean_text": "One approach that can, in principle, better exploit both alignments from bitexts and make use of non-parallel corpora is the distributional co-locational approach, e.g., as used by Fung and Yee (1998) and Rapp (1999).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D09-1040", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Yuval, Marton | Chris, Callison-Burch | Philip, Resnik", 
    "raw_text": "Some successful combinations are cos CP (Schuetze and Pedersen, 1997), Lin PMI (Lin, 1998), City LL (Rapp, 1999), and Jensen? Shannon divergence of conditional prob abilities (JSD CP)", 
    "clean_text": "Some successful combinations are cos CP (Schuetze and Pedersen, 1997), Lin PMI (Lin, 1998), City LL (Rapp, 1999), and Jensen Shannon divergence of conditional probabilities (JSD CP).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P13-1109", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Majid, Razmara | Maryam, Siahbani | Reza, Haffari | Anoop, Sarkar", 
    "raw_text": "|wi? V} 1106 The counts can be collected in positional3 (Rapp, 1999) or non-positional way (count all the word occurrences within the sliding window)", 
    "clean_text": "The counts can be collected in positional (Rapp, 1999) or non-positional way (count all the word occurrences within the sliding window).", 
    "keep_for_gold": 0
  }
]