[
  {
    "citance_No": 1, 
    "citing_paper_id": "W07-0405", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Liang, Huang", 
    "raw_text": "Avery similar system for the reverse direction is described in (Liu et al, 2006)", 
    "clean_text": "A very similar system for the reverse direction is described in (Liu et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P10-1034", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Xianchao, Wu | Takuya, Matsuzaki | Jun'ichi, Tsujii", 
    "raw_text": "We perform derivation-level combination as described in (Liu et al, 2009b) for mixing different types of translation rules within one derivation. For tree-to-string translation, we use a bottom up beam search algorithm (Liu et al, 2006) for decoding an HPSG tree Et. We keep at most 10 best derivations with distinct? (d) s at each node", 
    "clean_text": "We perform derivation-level combination as described in (Liu et al, 2009b) for mixing different types of translation rules within one derivation.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P08-1064", 
    "citing_paper_authority": 42, 
    "citing_paper_authors": "Min, Zhang | Hongfei, Jiang | Aiti, Aw | Haizhou, Li | Chew Lim, Tan | Sheng, Li", 
    "raw_text": "Liu et al (2006) propose a tree-to-string model", 
    "clean_text": "Liu et al (2006) propose a tree-to-string model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P08-1064", 
    "citing_paper_authority": 42, 
    "citing_paper_authors": "Min, Zhang | Hongfei, Jiang | Aiti, Aw | Haizhou, Li | Chew Lim, Tan | Sheng, Li", 
    "raw_text": "4) Liu et al (2006) treat all bilingual phrases as lexicalized tree-to-string rules, including those non-syntactic phrases in training corpus", 
    "clean_text": "Liu et al (2006) treat all bilingual phrases as lexicalized tree-to-string rules, including those non-syntactic phrases in training corpus.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D10-1043", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Hui, Zhang | Min, Zhang | Haizhou, Li | Eng Siong, Chng", 
    "raw_text": "Liu et al (2006) propose a tree-to-string translation model", 
    "clean_text": "Liu et al (2006) propose a tree-to-string translation model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W07-0706", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Deyi, Xiong | Qun, Liu | Shouxun, Lin", 
    "raw_text": "Also, several other tree-based decoding algorithms introduced by Eisner (2003), Quirk et al (2005) and Liu et al (2006) can be classified as the chart-style parsing algorithm too", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W07-0706", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Deyi, Xiong | Qun, Liu | Shouxun, Lin", 
    "raw_text": "Our language model is cal cu lated during decoding while Quirk? s language modelis computed after decoding because of the complexity of their decoding. The DTSC model is also quite distinct from previous tree-string models by Marcu et al (2006) and Liu et al (2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P13-1081", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Bing, Xiang | Xiaoqiang, Luo | Bowen, Zhou", 
    "raw_text": "For example, for a hierarchical MT system, some phrase pairs and Hiero (Chiang, 2005) rules can be extracted with recovered *pro* and *PRO* at the Chinese side. In this work we also take advantages of the augmented Chinese parse trees (with ECs projected to the surface) and extract tree-to-string grammar (Liu et al, 2006) for a tree-to-string MT system", 
    "clean_text": "In this work we also take advantages of the augmented Chinese parse trees (with ECs projected to the surface) and extract tree-to-string grammar (Liu et al, 2006) for a tree-to-string MT system.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W09-2301", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Greg, Hanneman | Alon, Lavie", 
    "raw_text": "Liu et al (2006) also add non-syntactic PBSMT phrases into their tree-to-string translation system", 
    "clean_text": "Liu et al (2006) also add non-syntactic PBSMT phrases into their tree-to-string translation system.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W08-2119", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Thai Phuong, Nguyen | Akira, Shimazu | Tu Bao, Ho | Minh Le, Nguyen | Vinh Van, Nguyen", 
    "raw_text": "Liu et al (2006) changed the translation unit from phrases to tree-to-string alignment templates (TATs) while we do not", 
    "clean_text": "Liu et al (2006) changed the translation unit from phrases to tree-to-string alignment templates (TATs) while we do not.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W08-2119", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Thai Phuong, Nguyen | Akira, Shimazu | Tu Bao, Ho | Minh Le, Nguyen | Vinh Van, Nguyen", 
    "raw_text": "Method Rule form Rule function Rulelexicalization level Koehn et al (2003) no no no Yamada and Knight (2001) SCFG rule reorder and function-word ins./del .unlexicalized Melamed (2003) SCFG rule reorder and word choice full Chiang (2005) SCFG rule reorder and word choice full Quirk et al (2005) Treelet pair word choice full Galley et al (2006) x Rs rule reorder and word choice full Liu et al (2006) x Rs rule reorder and word choice full Our work SCFG rule reorder unlexicalized Table 9: A comparison of syntactic SMT methods (part 2)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P13-1080", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Fabienne, Braune | Nina, Seemann | Daniel, Quernheim | Andreas, Maletti", 
    "raw_text": "Huang et al (2006) and Liu et al (2006) use syntactic annotations on the source language side and show significant improvements in translation quality", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W12-3201", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Dragomir R., Radev | Amjad, Abu-Jbara", 
    "raw_text": "2006 Liu et al (2006) experimented with tree-to-string translation models that utilize source side parse trees.", 
    "clean_text": "Liu et al (2006) experimented with tree-to-string translation models that utilize source side parse trees.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C10-2059", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Wenbin, Jiang | Yajuan, L&uuml; | Yang, Liu | Qun, Liu", 
    "raw_text": "When using the projected parser in a tree based translation model (Liu et al, 2006), we achieve translation performance comparable with using a state-of-the-art supervised parser trained on thousands of CTB trees", 
    "clean_text": "When using the projected parser in a tree based translation model (Liu et al, 2006), we achieve translation performance comparable with using a state-of-the-art supervised parser trained on thousands of CTB trees.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-2059", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Wenbin, Jiang | Yajuan, L&uuml; | Yang, Liu | Qun, Liu", 
    "raw_text": "We first ex tract the tree-to-string translation rules from the training corpus by the algorithm of (Liu et al, 2006), and train a 4-gram language model on the Xinhua portion of GIGAWORD corpus with Kneser-Ney smoothing using the SRI Language Modeling Toolkit (Stolcke and Andreas, 2002)", 
    "clean_text": "We first extract the tree-to-string translation rules from the training corpus by the algorithm of (Liu et al, 2006), and train a 4-gram language model on the Xinhua portion of GIGAWORD corpus with Kneser-Ney smoothing using the SRI Language Modeling Toolkit (Stolcke and Andreas, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P11-1086", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Ashish, Vaswani | Haitao, Mi | Liang, Huang | David, Chiang", 
    "raw_text": "However, if one were to use rule Markov models with a conventional CKY-style bottom-up decoder (Liu et al, 2006), the complexity would increase to O (n Cm? 1|V |4 (g? 1)), where C is the maximum number of outgoing hyper edges for each node in the translation forest, and m is the order of the rule Markov model", 
    "clean_text": "However, if one were to use rule Markov models with a conventional CKY-style bottom-up decoder (Liu et al, 2006), the complexity would increase to O (n Cm 1|V |4 (g 1)), where C is the maximum number of outgoing hyper edges for each node in the translation forest, and m is the order of the rule Markov model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P12-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Hui, Zhang | David, Chiang", 
    "raw_text": "Originally, the output of the parser stage was a single parse tree, and this type of system has been shown to outperform phrase-based translation on, for instance, Chinese to-English translation (Liu et al, 2006)", 
    "clean_text": "Originally, the output of the parser stage was a single parse tree, and this type of system has been shown to outperform phrase-based translation on, for instance, Chinese to-English translation (Liu et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P09-2032", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hongfei, Jiang | Muyun, Yang | Tiejun, Zhao | Sheng, Li | Bo, Wang", 
    "raw_text": "For example, (Chiang, 2007) adopts a CKY style span-based decoding while (Liu et al, 2006) applies a linguistically syntax node based bottom-up decoding, which are difficult to integrate", 
    "clean_text": "For example, (Chiang, 2007) adopts a CKY style span-based decoding while (Liu et al, 2006) applies a linguistically syntax node based bottom-up decoding, which are difficult to integrate.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D08-1010", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Qun, Liu | Zhongjun, He | Yang, Liu | Shouxun, Lin", 
    "raw_text": "In this paper, we incorporate the MERS model into a state of-the-art linguistically syntax-based SMT model, the tree-to-string alignment template (TAT) model (Liu et al, 2006)", 
    "clean_text": "In this paper, we incorporate the MERS model into a state of-the-art linguistically syntax-based SMT model, the tree-to-string alignment template (TAT) model (Liu et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D08-1010", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Qun, Liu | Zhongjun, He | Yang, Liu | Shouxun, Lin", 
    "raw_text": "Our baseline system is Lynx (Liu et al, 2006), which is a linguistically syntax-based SMT system", 
    "clean_text": "Our baseline system is Lynx (Liu et al, 2006), which is a linguistically syntax-based SMT system.", 
    "keep_for_gold": 0
  }
]