Citance Number: 1 | Reference Article:  W03-0301.txt | Citing Article:  P04-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA></S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In particular, we would like to thank Dan Melamed for suggesting the two different subtasks (limited and unlimited resources), and Michael Carl and Phil Resnik for initiating interesting discussions regarding phrase-based evaluations.</S><S sid = NA ssid = NA>A total of 447 English-French aligned sentences (Och and Ney, 2000), and 248 Romanian-English aligned sentences were released one week prior to the deadline.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W03-0301.txt | Citing Article:  P04-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use the data provided forthe French-English shared task of the 2003 HLTNAACL Workshop on Building and Using Parallel Texts (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S><S sid = NA ssid = NA>As part of the HLT/NAACL 2003 workshop on ”Building and Using Parallel Texts: Data Driven Machine Translation and Beyond”, we organized a shared task on word alignment, where participating teams were provided with training and test data, consisting of sentence aligned parallel texts, and were asked to provide automatically derived word alignments for all the words in the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W03-0301.txt | Citing Article:  P04-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The evaluation is done using the performance measures described in (Mihalcea and Pedersen, 2003): precision, recall and F-score on the probable and sure alignments, as well as the Alignment Error Rate (AER), which in our case is a weighted average of the recall on the sure alignments and the precision on the probable.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We conducted therefore 14 evaluations for each submission file: AER, Sure/Probable Precision, Sure/Probable Recall, and Sure/Probable F-measure, with a different figure determined for NULL-Align and NO-NULL-Align alignments.</S><S sid = NA ssid = NA>The intersection of the Sure alignments produced by the two annotators led to the final Sure aligned set, while the reunion of the Probable alignments led to the final Probable aligned set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W03-0301.txt | Citing Article:  P04-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>HLT-03 best F is Ralign.EF.1 and best AER is XRCE.Nolem.EF.3 (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For English-French, Ralign.EF.1 has the best performance for limited resources, while ProAlign.EF.1 has again the largest number of top ranked figures for unlimited resources.</S><S sid = NA ssid = NA>BiBr.EF.1 BiBr.EF.2 BiBr.EF.3 BiBr.EF.4 BiBr.EF.5 BiBr.EF.6 BiBr.EF.7 BiBr.EF.8 Limited Unlimited Unlimited Limited Unlimited Unlimited Limited Unlimited baseline of bilingual bracketing baseline of bilingual bracketing + English POS tagging baseline of bilingual bracketing + English POS tagging and base NP reverse direction of BiBr.EF.1 reverse direction of BiBr.EF.2 reverse direction of BiBr.EF.3 intersection of BiBr.EF.1 & BiBr.EF.3 intersection of BiBr.EF.3 & BiBr.EF.6 ProAlign.EF.1 Unlimited cohesion between source and target language + English parser + distributional similarity for English words Ralign.EF.1 Limited Giza (IBM Model 2) + recursive parallel segmentation UMD.EF.1 Limited IBM Model 2, trained with 1/20 of the corpus, distortion 2, iterations 4 XRCE.Base.EF.1 XRCE.Nolem.EF.2 XRCE.Nolem.EF.3 Limited GIZA++ (IBM Model 4) with English and French lemmatizer GIZA++ only (IBM Model 4), trained with 1/4 of the corpus GIZA++ only (IBM Model 4), trained with 1/2 of the corpus Table 2: Short description for English-French systems System Resources Description BiBr.RE.1 BiBr.RE.2 BiBr.RE.3 Limited Unlimited Unlimited baseline of bilingual bracketing baseline of bilingual bracketing + English POS tagging baseline of bilingual bracketing + English POS tagging and base NP</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W03-0301.txt | Citing Article:  P04-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>HLT-03 best is Ralign.EF.1 (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For English-French, Ralign.EF.1 has the best performance for limited resources, while ProAlign.EF.1 has again the largest number of top ranked figures for unlimited resources.</S><S sid = NA ssid = NA>BiBr.EF.1 BiBr.EF.2 BiBr.EF.3 BiBr.EF.4 BiBr.EF.5 BiBr.EF.6 BiBr.EF.7 BiBr.EF.8 Limited Unlimited Unlimited Limited Unlimited Unlimited Limited Unlimited baseline of bilingual bracketing baseline of bilingual bracketing + English POS tagging baseline of bilingual bracketing + English POS tagging and base NP reverse direction of BiBr.EF.1 reverse direction of BiBr.EF.2 reverse direction of BiBr.EF.3 intersection of BiBr.EF.1 & BiBr.EF.3 intersection of BiBr.EF.3 & BiBr.EF.6 ProAlign.EF.1 Unlimited cohesion between source and target language + English parser + distributional similarity for English words Ralign.EF.1 Limited Giza (IBM Model 2) + recursive parallel segmentation UMD.EF.1 Limited IBM Model 2, trained with 1/20 of the corpus, distortion 2, iterations 4 XRCE.Base.EF.1 XRCE.Nolem.EF.2 XRCE.Nolem.EF.3 Limited GIZA++ (IBM Model 4) with English and French lemmatizer GIZA++ only (IBM Model 4), trained with 1/4 of the corpus GIZA++ only (IBM Model 4), trained with 1/2 of the corpus Table 2: Short description for English-French systems System Resources Description BiBr.RE.1 BiBr.RE.2 BiBr.RE.3 Limited Unlimited Unlimited baseline of bilingual bracketing baseline of bilingual bracketing + English POS tagging baseline of bilingual bracketing + English POS tagging and base NP</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W03-0301.txt | Citing Article:  P04-1064.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>hlt-03 best is xrce.nolem (mihalcea and pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For Romanian-English, limited resources, XRCE systems (XRCE.Nolem-56k.RE.2 and XRCE.Trilex.RE.3) seem to lead to the best results.</S><S sid = NA ssid = NA>For unlimited resources, ProAlign.RE.1 has the best performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W03-0301.txt | Citing Article:  P14-1138.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We evaluated the alignment performance of the proposed models with two tasks: Japanese English word alignment with the Basic Travel Expression Corpus (BTEC) (Takezawa et al, 2002) and French-English word alignment with the Hansard dataset (Hansards) from the 2003 NAACL shared task (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S><S sid = NA ssid = NA>The word alignment result files had to include one line for each word-to-word alignment.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W03-0301.txt | Citing Article:  D07-1089.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As a point of comparison, the SMT community has been evaluating performance of word-alignment systems on an even smaller dataset of 447 pairs of non-overlapping sentences (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A total of 447 English-French aligned sentences (Och and Ney, 2000), and 248 Romanian-English aligned sentences were released one week prior to the deadline.</S><S sid = NA ssid = NA>Participants were required to run their word alignment systems on these two sets, and submit word alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W03-0301.txt | Citing Article:  W05-0809.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>(Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S><S sid = NA ssid = NA>As part of the HLT/NAACL 2003 workshop on ”Building and Using Parallel Texts: Data Driven Machine Translation and Beyond”, we organized a shared task on word alignment, where participating teams were provided with training and test data, consisting of sentence aligned parallel texts, and were asked to provide automatically derived word alignments for all the words in the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W03-0301.txt | Citing Article:  W05-0809.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This is the same training data set as used in the 2003 word alignment evaluation (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The only evaluation set where Romanian-English data leads to better performance is the Probable alignments set.</S><S sid = NA ssid = NA>An Evaluation Exercise For Word Alignment</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W03-0301.txt | Citing Article:  W05-0818.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The evaluation was run with respect to precision, recall, F-measure, and alignment error rate (AER) considering sure and probable alignments but not NULL ones (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We conducted therefore 14 evaluations for each submission file: AER, Sure/Probable Precision, Sure/Probable Recall, and Sure/Probable F-measure, with a different figure determined for NULL-Align and NO-NULL-Align alignments.</S><S sid = NA ssid = NA>Participants were required to run their word alignment systems on these two sets, and submit word alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W03-0301.txt | Citing Article:  P06-1009.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For parameter tuning, we used the 17 sentence trial set from the Romanian-English corpus in the 2003 NAACL task (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Trial sets consisted of 37 English-French, and 17 Romanian-English aligned sentences.</S><S sid = NA ssid = NA>The only evaluation set where Romanian-English data leads to better performance is the Probable alignments set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  W03-0301.txt | Citing Article:  P11-1042.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>To choose the regularization strength and the initial learning rate 0,3 we trained several models on a 10,000-sentence-pair subset of the French English Hansards, and chose values that minimized the alignment error rate, as evaluated on a 447 sentence set of manually created alignments (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The Sure alignment set is guaranteed to be a subset of the Probable alignment set.</S><S sid = NA ssid = NA>Trial sets consisted of sentence aligned texts, provided together with manually determined word alignments.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  W03-0301.txt | Citing Article:  W04-3225.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This comes back to the task of word alignment, which is a very difficult task for computers (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S><S sid = NA ssid = NA>Seven teams from around the world participated in the word alignment shared task.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  W03-0301.txt | Citing Article:  N07-2053.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In this section, we report experiments conducted with Canadian Hansards data from the 2003 HLT NAACL word-alignment workshop (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S><S sid = NA ssid = NA>As part of the HLT/NAACL 2003 workshop on ”Building and Using Parallel Texts: Data Driven Machine Translation and Beyond”, we organized a shared task on word alignment, where participating teams were provided with training and test data, consisting of sentence aligned parallel texts, and were asked to provide automatically derived word alignments for all the words in the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  W03-0301.txt | Citing Article:  H05-1010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We applied this matching algorithm to word level alignment using the English-French Hansards data from the 2003 NAACL shared task (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S><S sid = NA ssid = NA>As part of the HLT/NAACL 2003 workshop on ”Building and Using Parallel Texts: Data Driven Machine Translation and Beyond”, we organized a shared task on word alignment, where participating teams were provided with training and test data, consisting of sentence aligned parallel texts, and were asked to provide automatically derived word alignments for all the words in the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  W03-0301.txt | Citing Article:  P06-1065.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We used the same training and test data as in our previous work, a subset of the Canadian Hansards bilingual corpus supplied for the bilingual word alignment workshop held at HLT-NAACL 2003 (Mihalcea and Pedersen, 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As part of the HLT/NAACL 2003 workshop on ”Building and Using Parallel Texts: Data Driven Machine Translation and Beyond”, we organized a shared task on word alignment, where participating teams were provided with training and test data, consisting of sentence aligned parallel texts, and were asked to provide automatically derived word alignments for all the words in the test set.</S><S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  W03-0301.txt | Citing Article:  P06-1123.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The French/English data were those used by Mihalcea and Pedersen (2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For English and French, we used a version of the tokenizers provided within the EGYPT Toolkit2.</S><S sid = NA ssid = NA>For Romanian, we used our own tokenizer.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  W03-0301.txt | Citing Article:  E06-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The alignments produced by MEBA were compared to the ones produced by YAWA and evaluated against the Gold Standard (GS) annotations used in the Word Alignment Shared Tasks (Romanian-English track) organized at HLT-NAACL2003 (Mihalcea and Pedersen 2003).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The gold standard for the two language pair alignments were produced using slightly different alignment procedures, which allowed us to study different schemes for producing gold standards for word aligned data.</S><S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  W03-0301.txt | Citing Article:  P04-3014.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The 2003 HLT-NAACL Workshop on Building and Using Parallel Texts (Mihalcea and Pedersen, 2003) reflected the increasing importance of the word alignment task, and established standard performance measures and some benchmark tasks.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>A shared task on word alignment was organized as part of the HLT/NAACL 2003 Workshop on Building and Using Parallel Texts.</S><S sid = NA ssid = NA>As part of the HLT/NAACL 2003 workshop on ”Building and Using Parallel Texts: Data Driven Machine Translation and Beyond”, we organized a shared task on word alignment, where participating teams were provided with training and test data, consisting of sentence aligned parallel texts, and were asked to provide automatically derived word alignments for all the words in the test set.</S> | Discourse Facet:  NA | Annotator: Automatic


