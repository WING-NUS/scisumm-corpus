In this paper, we explore the power of randomized algorithm to address the challenge of working with very large amounts of data.
We apply these algorithms to generate noun similarity lists from 70 million pages.
We reduce the running time from quadratic to practically linear in the number of elements to be computed.
