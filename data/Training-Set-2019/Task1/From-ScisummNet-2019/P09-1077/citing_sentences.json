[
  {
    "citance_No": 1, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "Another research line is to exploit various linguistically informed features under the framework of supervised models, (Pitler et al, 2009a) and (Lin et al, 2009) ,e.g., polarity features, semantic classes, tense, production rules of parse trees of arguments, etc. Our study on PDTB test data shows that the average f-score for the most general 4 senses can r2ach 91.8% when we simply mapped the ground truth implicit connective of each test instance toits most frequent sense", 
    "clean_text": "Another research line is to exploit various linguistically informed features under the framework of supervised models, (Pitler et al, 2009a) and (Lin et al, 2009), e.g., polarity features, semantic classes, tense, production rules of parse trees of arguments, etc. Our study on PDTB test data shows that the average f-score for the most general 4 senses can reach 91.8% when we simply mapped the ground truth implicit connective of each test instance to its most frequent sense.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "In this paper, we include 9 types of features in our system due to their superior performance in previous studies ,e.g., polarity features ,seman tic classes of verbs, contextual sense, modality, inquirer tags of words, first-last words of arguments, cross-argument word pairs, ever used in (Pitler et al, 2009a), production rules of parse trees of arguments used in (Lin et al, 2009), and intra-argument word pairs inspired by the work of (Saito et al, 2006)", 
    "clean_text": "In this paper, we include 9 types of features in our system due to their superior performance in previous studies, e.g., polarity features, semantic classes of verbs, contextual sense, modality, inquirer tags of words, first-last words of arguments, cross-argument word pairs, ever used in (Pitler et al, 2009a), production rules of parse trees of arguments used in (Lin et al, 2009), and intra-argument word pairs inspired by the work of (Saito et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "Here we provide the details of the 9 features, shown as follows: Verbs: Similar to the work in (Pitler et al, 2009a), the verb features consist of the number of pairs of verbs in Arg1 and Arg2 if they are from the same class based on their highest Levin verb class level (Dorr, 2001)", 
    "clean_text": "Here we provide the details of the 9 features, shown as follows: Verbs: Similar to the work in (Pitler et al, 2009a), the verb features consist of the number of pairs of verbs in Arg1 and Arg2 if they are from the same class based on their highest Levin verb class level (Dorr, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "Following the work of (Pitler et al, 2009a), we used sections 2-20astraining set, sections 21-22 as test set, and sections 0-1 as development set for parameter optimization", 
    "clean_text": "Following the work of (Pitler et al, 2009a), we used sections 2-20 as training set, sections 21-22 as test set, and sections 0-1 as development set for parameter optimization.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "22 as test set, so the test set is representative of2Here the numbers of training and test instances for Expansion relation are different from those in (Pitler et al, 2009a)", 
    "clean_text": "Here the numbers of training and test instances for Expansion relation are different from those in (Pitler et al, 2009a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "3.2.1 Result of baseline system Table 2 summarizes the best performance achieved by the baseline system in comparison with previous state-of-the-art performance achieved in (Pitler et al, 2009a)", 
    "clean_text": "Table 2 summarizes the best performance achieved by the baseline system in comparison with previous state-of-the-art performance achieved in (Pitler et al, 2009a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "The second and third column show the best performance achieved by the baseline system and 1511 Table 2: Performance comparison of the baseline system with the system of (Pitler et al, 2009a) on test set", 
    "clean_text": "Table 2: Performance comparison of the baseline system with the system of (Pitler et al, 2009a) on test set.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "vs. Other F1 (Acc) F1 (Acc) F1 (Acc) F1 (Acc) Using the best single feature (Pitler et al, 2009a) 21.01 (52.59) 36.75 (62.44) 71.29 (59.23) 15.93 (61.20) Using the best feature subset (Pitler et al, 2009a) 21.96 (56.59) 47.13 (67.30) 76.42 (63.62) 16.76 (63.49) The baseline system 30.72 (78.26) 45.38 (40.17) 65.95 (57.94) 16.46 (29.96) the first algorithm using predicted connectives as additional features. Table 3: Performance comparison of the algorithm in Section 2.2 with the baseline system on test set", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "Al though on Comparison relation there is only aslight improvement (+1.07%), our two best systems both got around 10% improvements of f score over a state-of-the-art system in (Pitler et al, 2009a)", 
    "clean_text": "Although on Comparison relation there is only as light improvement (+1.07%), our two best systems both got around 10% improvements of f score over a state-of-the-art system in (Pitler et al, 2009a).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "This also encourage sour future work on finding the most suitable connectives for implicit relation recognition. From this table, we found that, using only predicted implicit connectives achieved an comparable performance to (Pitler et al, 2009a), although it was still a bit lower than our best baseline", 
    "clean_text": "This also encourages our future work on finding the most suitable connectives for implicit relation recognition. From this table, we found that, using only predicted implicit connectives achieved an comparable performance to (Pitler et al, 2009a), although it was still a bit lower than our best baseline.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "Since (Pitler et al, 2009a) 1512 Table 4: Performance comparison of the algorithm in Section 2.3 with the baseline system on test set", 
    "clean_text": "Since (Pitler et al, 2009a) used different selection of instances for Expansion sense, we cannot make a direct comparison.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "Specifically, the model for the Comparison relation achieves an f-score of 26.02% (5% over the previous work in (Pitler et al, 2009a))", 
    "clean_text": "Specifically, the model for the Comparison relation achieves an f-score of 26.02% (5% over the previous work in (Pitler et al, 2009a)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "Furthermore, the models for Contingency and Temporal relation achieve 35.72% and 13.76% f-score respectively, which are comparable to the previous work in (Pitler et al, 2009a)", 
    "clean_text": "Furthermore, the models for Contingency and Temporal relation achieve 35.72% and 13.76% f-score respectively, which are comparable to the previous work in (Pitler et al, 2009a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C10-2172", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zhi-Min, Zhou | Yu, Xu | Zhengyu, Niu | Man, Lan | Jian, Su | Chew Lim, Tan", 
    "raw_text": "(Pitler et al, 2009a) performed implicit relation classification on the second version of the PDTB", 
    "clean_text": "(Pitler et al, 2009a) performed implicit relation classification on the second version of the PDTB.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P13-2013", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Or, Biran | Kathleen R., McKeown", 
    "raw_text": "Each relation has two arguments, Arg1 and Arg2, and the annotators decide whether it is explicit or implicit. The first to evaluate directly on PDTB in a realistic setting were Pitler et al (2009)", 
    "clean_text": "Each relation has two arguments, Arg1 and Arg2, and the annotators decide whether it is explicit or implicit. The first to evaluate directly on PDTB in a realistic setting were Pitler et al (2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P13-2013", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Or, Biran | Kathleen R., McKeown", 
    "raw_text": "However, the approach taken by Pitler et al (2009) and repeated in more recent work (training directly on PDTB) is problematic as well: when training a model with so many sparse features on a dataset the size of PDTB (there are 22, 141 non-explicit relations overall), it is likely that many important word pairs will not be seen in training", 
    "clean_text": "However, the approach taken by Pitler et al (2009) and repeated in more recent work (training directly on PDTB) is problematic as well: when training a model with so many sparse features on a dataset the size of PDTB (there are 22, 141 non-explicit relations overall), it is likely that many important word pairs will not be seen in training.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P13-2013", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Or, Biran | Kathleen R., McKeown", 
    "raw_text": "An analysis in (Pitler et al, 2009) also shows that the top word pairs (ranked by information gain) all contain common functional words, and are not at all the semantically-related content words that were imagined", 
    "clean_text": "An analysis in (Pitler et al, 2009) also shows that the top word pairs (ranked by information gain) all contain common functional words, and are not at all the semantically-related content words that were imagined.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P13-2013", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Or, Biran | Kathleen R., McKeown", 
    "raw_text": "Results are shown in Table 1. Our word pair features outperform the previous formulation (represented by the results reported by (Pitler et al, 2009), but used by virtually all previous work on this task)", 
    "clean_text": "Our word pair features outperform the previous formulation (represented by the results reported by (Pitler et al, 2009), but used by virtually all previous work on this task).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P13-2013", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Or, Biran | Kathleen R., McKeown", 
    "raw_text": "33Significance was verified for our own results in all experiments shown in this paper with a standard t-test 71 Comparison Contingency Expansion Temporal Pitler et al, 2009 21.96 (56.59) 45.6 (67.1) 63.84 (60.28) 16.21 (61.98 )tfidf, no stop list 23 (61.72) 44.03 (66.78) 66.48 (60.93) 19.54 (68.09 )pmiidf, no stop list 24.38 (61.72) 38.96 (61.52) 62.22 (57.26) 16 (65.53 )tfidf, with stop list 23.77 44.33 65.33 16.98 Table 1: Main evaluation", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P13-2013", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Or, Biran | Kathleen R., McKeown", 
    "raw_text": "F-measure (accuracy) for various implementations of the word pairs features Comparison Contingency Expansion Temporal Best System 25.4 (63.36) 46.94 (68.09) 75.87 (62.84) 20.23 (68.35) features used pmi+1,2,3,6 tf+ALL tf+8 tf+3,9 Pitler et al, 2009 21.96 (56.59) 47.13 (67.3) 76.42 (63.62) 16.76 (63.49) Zhou et al, 2010 31.79 (58.22) 47.16 (48.96) 70.11 (54.54) 20.3 (55.48) Park and Cardie, 2012 31.32 (74.66) 49.82 (72.09) 79.22 (69.14) 26.57 (79.32) Table 2: Secondary evaluation", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]