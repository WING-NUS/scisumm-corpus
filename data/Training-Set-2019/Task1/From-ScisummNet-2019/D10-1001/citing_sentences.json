[
  {
    "citance_No": 1, 
    "citing_paper_id": "D10-1125", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "Terry, Koo | Alexander M., Rush | Michael John, Collins | Tommi, Jaakkola | David, Sontag", 
    "raw_text": "Finally, in other recent work, Rush et al (2010) describe dual decomposition approaches for other NLP problems", 
    "clean_text": "Finally, in other recent work, Rush et al (2010) describe dual decomposition approaches for other NLP problems.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2032", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mengqiu, Wang | Rob, Voigt | Christopher D., Manning", 
    "raw_text": ") This method is called dual decomposition (DD) (Rush et al, 2010)", 
    "clean_text": "This method is called dual decomposition (DD) (Rush et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D12-1131", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Alexander M., Rush | Michael John, Collins | Roi, Reichart | Amir, Globerson", 
    "raw_text": "In NLP, Rush et al (2010) and Koo et al (2010) applied dual decomposition to enforce agreement between different sentence-level algorithms for parsing and POS tagging", 
    "clean_text": "In NLP, Rush et al (2010) and Koo et al (2010) applied dual decomposition to enforce agreement between different sentence-level algorithms for parsing and POS tagging.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D12-1131", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Alexander M., Rush | Michael John, Collins | Roi, Reichart | Amir, Globerson", 
    "raw_text": "It is a slight variation of the proof given by Rush et al (2010)", 
    "clean_text": "It is a slight variation of the proof given by Rush et al (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D11-1012", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Vivek, Srikumar | Dan, Roth", 
    "raw_text": "Our approach is conceptually similar to that of Rush et al (2010), which combined separately trained models by enforcing agreement using global inference and solving its linear programming relaxation", 
    "clean_text": "Our approach is conceptually similar to that of Rush et al (2010), which combined separately trained models by enforcing agreement using global inference and solving its linear programming relaxation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "E12-1044", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Atsushi, Hanamoto | Jun'ichi, Tsujii | Takuya, Matsuzaki", 
    "raw_text": "It is becoming popular in the NLP community and has been shown to work effectively on several NLP tasks (Rush et al 2010)", 
    "clean_text": "It is becoming popular in the NLP community and has been shown to work effectively on several NLP tasks (Rush et al 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "E12-1044", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Atsushi, Hanamoto | Jun'ichi, Tsujii | Takuya, Matsuzaki", 
    "raw_text": "In dual decomposition, we solve min u max x, y (f (x)+ g (y)+ u (x? y)) instead of the original problem. To find the minimum value, we can use a sub gradient method (Rush et al 2010)", 
    "clean_text": "To find the minimum value, we can use a subgradient method (Rush et al 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "E12-1044", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Atsushi, Hanamoto | Jun'ichi, Tsujii | Takuya, Matsuzaki", 
    "raw_text": "The answer does not always solve the original problem Eq (2), but previous works (e.g., (Rush et al 2010)) has shown that it is effective in practice", 
    "clean_text": "The answer does not always solve the original problem Eq (2), but previous works (e.g., (Rush et al 2010)) has shown that it is effective in practice.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "E12-1044", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Atsushi, Hanamoto | Jun'ichi, Tsujii | Takuya, Matsuzaki", 
    "raw_text": "We follows the formulation by Rush et al (2010)", 
    "clean_text": "We follows the formulation by Rush et al (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "N12-1024", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Michael, Paul | Jason M., Eisner", 
    "raw_text": "2An example that oscillates can be constructed along lines similar to the one given by Rush et al (2010)", 
    "clean_text": "An example that oscillates can be constructed along lines similar to the one given by Rush et al (2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P11-1163", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "David, McClosky | Mihai, Surdeanu | Christopher D., Manning", 
    "raw_text": "Parsing using dual-decomposition (Rush et al, 2010) seems especially promising in this area", 
    "clean_text": "Parsing using dual-decomposition (Rush et al, 2010) seems especially promising in this area.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P14-1056", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Sam, Anzaroot | Alexandre, Passos | David, Belanger | Andrew, McCallum", 
    "raw_text": "Alternatively, one can em ploy dual decomposition (Rush et al, 2010)", 
    "clean_text": "Alternatively, one can employ dual decomposition (Rush et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P13-1020", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Miguel, Almeida | Andre, Martins", 
    "raw_text": "3. AD3 resembles the sub gradient based algorithm of Rush et al (2010), but it enjoys a faster convergence rate", 
    "clean_text": "AD resembles the subgradient based algorithm of Rush et al (2010), but it enjoys a faster convergence rate.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D12-1103", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Simon, Carter | Marc, Dymetman | Guillaume, Bouchard", 
    "raw_text": "Dual decomposition is a generic method that has been proposed for handling decoding (i.e. optimization) with such models, by decoupling the problem into two alternating steps that can each be handled by dynamic programming or other polynomial-time algorithms (Rush et al 2010), an approach that has been applied to Statistical Ma chine Translation (phrase-based (Chang and Collins, 1133 2011) and hierarchical (Rush and Collins, 2011)) among others", 
    "clean_text": "Dual decomposition is a generic method that has been proposed for handling decoding (i.e. optimization) with such models, by decoupling the problem into two alternating steps that can each be handled by dynamic programming or other polynomial-time algorithms (Rush et al 2010), an approach that has been applied to Statistical Ma chine Translation (phrase-based (Chang and Collins, 1133 2011) and hierarchical (Rush and Collins, 2011)) among others.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P12-2003", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Valentin I., Spitkovsky | Wanxiang, Che | Ting, Liu", 
    "raw_text": "Though Mate scored higher overall, Berkeley? sparser was better at recovering longer-distance relations, suggesting that a combined approach could perhaps work better still (Rush et al, 2010,? 4.2)", 
    "clean_text": "Though Mate scored higher overall, Berkeley's parser was better at recovering longer-distance relations, suggesting that a combined approach could perhaps work better still (Rush et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P11-1048", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Michael, Auli | Adam, Lopez", 
    "raw_text": "We optimize the values of the u (i, t) variables using the same algorithm as Rush et al (2010) for their tagging and parsing problem (essentially a perceptron update) .4 An advantages of DD is that, on convergence, it recovers exact solutions to the combined problem", 
    "clean_text": "We optimize the values of the u (i, t) variables using the same algorithm as Rush et al (2010) for their tagging and parsing problem (essentially a perceptron update).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P11-1048", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Michael, Auli | Adam, Lopez", 
    "raw_text": "However, if it does not converge or we stop early, an approximation must be returned: following Rush et al (2010) we used the highest scoring output of the parsing submodel over all iterations", 
    "clean_text": "However, if it does not converge or we stop early, an approximation must be returned: following Rush et al (2010) we used the highest scoring output of the parsing submodel over all iterations.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P13-1104", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Jinho D., Choi | Andrew, McCallum", 
    "raw_text": "The Time column show how many seconds per sentence each parser takes.7 Approach UAS LAS Time Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 0.04 Zhang and Nivre (2011) 92.9 91.8 0.03 Bohnet and Nivre (2012) 93.38 92.44 0.4 McDonald et al (2005) 90.9 Mcdonald and Pereira (2006) 91.5 Sagae and Lavie (2006) 92.7 Koo and Collins (2010) 93.04 Zhang and McDonald (2012) 93.06 91.86 Martins et al (2010) 93.26 Rush et al (2010) 93.8 Koo et al (2008) 93.16 Carreras et al (2008) 93.54 Bohnet and Nivre (2012) 93.67 92.68 Suzuki et al (2009) 93.79bt= 80 ,bd= 80, m= 0.88 92.96 91.93 0.009bt= 80 ,bd= 64, m= 0.88 92.96 91.93 0.009bt= 80 ,bd= 32, m= 0.88 92.96 91.94 0.009bt= 80 ,bd= 16, m= 0.88 92.96 91.94 0.008bt= 80 ,bd= 8, m= 0.88 92.89 91.87 0.006bt= 80 ,bd= 4, m= 0.88 92.76 91.76 0.004bt= 80 ,bd= 2, m= 0.88 92.56 91.54 0.003bt= 80 ,bd= 1, m= 0.88 92.26 91.25 0.002bt= 1 ,bd= 1, m= 0.88 92.06 91.05 0.002Table 4: Parsing accuracies and speeds on the English evaluation set, excluding tokens containing only punctuation", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P11-1043", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "John, DeNero | Klaus, Macherey", 
    "raw_text": "However, we can employ dual decomposition as an approximate inference technique (Rush et al., 2010)", 
    "clean_text": "However, we can employ dual decomposition as an approximate inference technique (Rush et al., 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P11-1043", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "John, DeNero | Klaus, Macherey", 
    "raw_text": "Onesubgraph Ga includes all of the vertices corresponding to variables a and c. The other subgraph Gb includes vertices for variables b and c. Every edge inthe graph belongs to exactly one of these two sub graphs. The dual decomposition inference approach al lows us to exploit this sub-graph structure (Rush et al., 2010)", 
    "clean_text": "The dual decomposition inference approach allows us to exploit this sub-graph structure (Rush et al., 2010).", 
    "keep_for_gold": 0
  }
]