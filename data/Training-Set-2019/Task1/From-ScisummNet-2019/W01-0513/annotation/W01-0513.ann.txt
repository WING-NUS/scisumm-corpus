Citance Number: 1 | Reference Article:  W01-0513.txt | Citing Article:  W03-1812.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Schone and Jurafsky (2001) applied LSA to the analysis of MWEs in the task of MWE discovery, by way of rescoring MWEs extracted from a corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Can semantic-only rescoring help?</S><S sid = NA ssid = NA>Although this strategy for evaluation is vectors for any word in a corpus (Schone and not flawless, it is reasonable and makes dynamic Jurafsky, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  W01-0513.txt | Citing Article:  W03-1812.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Indeed, Schone and Jurafsky (2001) provide evidence that suggests that WordNet is as effective an evaluation resource as the web for MWE detection methods, despite its inherent size limitations and static nature.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>WordNet has definite advantages as an evaluation resource.</S><S sid = NA ssid = NA>Since WordNet is static and cannot report on all of a corpus’ n-grams, one may expect different performance by using a more all-encompassing, dynamic resource.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  W01-0513.txt | Citing Article:  H05-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Schone and Jurafsky (Schone and Jurafsky, 2001) applied Latent-Semantic Analysis (LSA) to the analysis of MWEs in the task of MWE discovery, by way of rescoring MWEs extracted from the corpus.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As an attempt to improve MWU headword induction, we introduce several algorithms using Latent Semantic Analysis (LSA).</S><S sid = NA ssid = NA>Deerwester, et al (1990) introduced Latent Semantic Analysis (LSA) as a computational technique for inducing semantic relationships between words and documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  W01-0513.txt | Citing Article:  D11-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Regarding (i), Schone and Jurafsky (2001) compare the semantic vector of a phrase p and the vectors of its component words in two ways: one includes the contexts of p in the construction of the semantic vectors of the parts and one does not.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This seems to be a significant semantic vectors with weights (wi) set to either 1.0 component.</S><S sid = NA ssid = NA>Table 4 shows the algorithms’ compute semantic vectors for every proposed word performance (including proper nouns). n-gram C=X X ...X Since LSA involves word Though Internet dictionaries and WordNet are counts, we can also compute semantic vectors completely separate “gold standards,” results are surprisingly consistent.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  W01-0513.txt | Citing Article:  D11-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Statistical association measures are frequently used for MWU detection and collocation extraction (e.g. Schone and Jurafsky (2001), Evert and Krenn (2001), Pecina (2010)).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Table 1 (see next page) shows nine commonly-used probabilistic MWU-induction approaches.</S><S sid = NA ssid = NA>Many collocation-finders exist, so one might suspect that most could suffice for finding MWU dictionary headwords.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  W01-0513.txt | Citing Article:  D11-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>We use all measures used by Schone and Jurafsky (2001) that can be derived from a phrase's contingency table.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Table 1 (see next page) shows nine commonly-used probabilistic MWU-induction approaches.</S><S sid = NA ssid = NA>Although this strategy for evaluation is vectors for any word in a corpus (Schone and not flawless, it is reasonable and makes dynamic Jurafsky, 2000).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  W01-0513.txt | Citing Article:  D11-1073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As our baseline, we use two methods of comparing semantic vectors: sj1 and sj2, both introduced by Schone and Jurafsky (2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Although this strategy for evaluation is vectors for any word in a corpus (Schone and not flawless, it is reasonable and makes dynamic Jurafsky, 2000).</S><S sid = NA ssid = NA>Deerwester, et al (1990) introduced Latent Semantic Analysis (LSA) as a computational technique for inducing semantic relationships between words and documents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  W01-0513.txt | Citing Article:  P08-1028.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Examples include automatic thesaurus extraction (Grefenstette, 1994), word sense discrimination (Schutze, 1998) and disambiguation (McCarthy et al, 2004), collocation extraction (Schone and Jurafsky, 2001), text segmentation (Choi et al, 2001), and notably information retrieval (Salton et al, 1975).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et. al, 1996; Brent, 1996; de Marcken, 1996) or on tokenizing Asian and Indian languages that do not normally include word delimiters in their orthography (Sproat, et al, 1996; Ponte and Croft 1996; Shimohata, 1997; Teahan, et al., 2000; and many others).</S><S sid = NA ssid = NA>Furthermore, we use two separate evaluation gold standards: (1) WordNet (Miller, et al, 1990) and (2) a collection of Internet MRDs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  W01-0513.txt | Citing Article:  P05-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>By contrast, Schone and Jurafsky (2001) evaluate the identification of phrasal terms without grammatical filtering on a 6.7 million word extract from the TREC databases, applying both WordNet and on line dictionaries as gold standards.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>We evaluate using two completely separate gold standards: (1) WordNet and (2) a compendium of Internet dictionaries.</S><S sid = NA ssid = NA>Using two gold standards helps valid MWUs.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  W01-0513.txt | Citing Article:  P05-1075.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Since Schone and Jurafsky (2001) demonstrated similar results whether WordNet or on line dictionaries were used as a gold standard, WordNet was selected.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>One can conclude that WordNet may safely be used as a gold standard in future MWU headword evaluations.</S><S sid = NA ssid = NA>Thus, one could safely use WordNet as a gold standard for future evaluations.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  W01-0513.txt | Citing Article:  W07-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>There have also been a number of papers focusing on the detection of semantic non-compositional items in recent years beginning with the work of Schone and Jurafsky (2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In other words, MWUs are typically non-compositional at some linguistic level.</S><S sid = NA ssid = NA>Non-compositionality is a key component of valid MWUs, so we may desire to emphasize n-grams that are semantically non-compositional.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  W01-0513.txt | Citing Article:  D12-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Furthermore, lists of topical unigrams are often made only marginally interpretable by virtue of their non-compositionality, the principle that a collocation's meaning typically is not derivable from its constituent words (Schone and Jurafsky, 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In other words, MWUs are typically non-compositional at some linguistic level.</S><S sid = NA ssid = NA>For example, a compositional phrase would typically be excluded from a hard-copy dictionary since its constituent words would already be listed.</S> | Discourse Facet:  NA | Annotator: Automatic


