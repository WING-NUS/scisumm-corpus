Citance Number: 1 | Reference Article:  P98-1012.txt | Citing Article:  W03-0405.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Biographic Data Past work on this task (e.g. Bagga and Baldwin, 1998) has primarily approached personal name disambiguation using document context profiles or vectors, which recognize and distinguish identical name instances based on partially indicative words in context such as computer or car in the Clark case.</S> | Reference Offset:  ['0','71'] | Reference Text:  <S sid = 0 ssid = >Entity-Based Cross-Document Core f erencing Using the Vector Space Model</S><S sid = 71 ssid = >While the (Vilain 95) provides intuitive results for coreference scoring, it however does not work as well in the context of evaluating cross document coreference.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P98-1012.txt | Citing Article:  W11-2213.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Some refer to the task as cross-document co reference resolution (Bagga and Baldwin, 1998), name discrimination (Pedersen et al, 2005) or Web People Search (WebPS) (Artiles et al, 2007).</S> | Reference Offset:  ['3','10'] | Reference Text:  <S sid = 3 ssid = >In this paper we describe a cross-document coreference resolution algorithm which uses the Vector Space Model to resolve ambiguities between people having the same name.</S><S sid = 10 ssid = >In this paper we describe a highly successful crossdocument coreference resolution algorithm which uses the Vector Space Model to resolve ambiguities between people having the same name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P98-1012.txt | Citing Article:  P05-1020.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In our experiments, we use the training texts to acquire co reference classifiers and evaluate the resulting systems on the test texts with respect to two commonly-used co reference scoring programs: the MUC scorer (Vilain et al, 1995) and the B-CUBED scorer (Bagga and Baldwin, 1998).</S> | Reference Offset:  ['60','87'] | Reference Text:  <S sid = 60 ssid = >The first was the standard algorithm for within-document coreference chains which was used for the evaluation of the systems participating in the MUC-6 and the MUC-7 coreference tasks.</S><S sid = 87 ssid = >This distinction is not reflected in the (Vilain 95) scorer which scores both responses as having a precision score of 90% (Figure 9).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P98-1012.txt | Citing Article:  P06-1127.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Four-fold cross validation is employed and B-CUBED metric (Bagga and Baldwin, 1998) is adopted to evaluate the clustering results.</S> | Reference Offset:  ['71','102'] | Reference Text:  <S sid = 71 ssid = >While the (Vilain 95) provides intuitive results for coreference scoring, it however does not work as well in the context of evaluating cross document coreference.</S><S sid = 102 ssid = >Further details about the B-CUBED algorithm including a model theoretic version of the algorithm can be found in (Bagga 98a).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P98-1012.txt | Citing Article:  N07-1043.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We employed the B-CUBED metric (Bagga and Baldwin, 1998) to evaluate the clustering results.</S> | Reference Offset:  ['102','116'] | Reference Text:  <S sid = 102 ssid = >Further details about the B-CUBED algorithm including a model theoretic version of the algorithm can be found in (Bagga 98a).</S><S sid = 116 ssid = >In comparison, Figure 12 shows the results (using the B-CUBED scoring algorithm) when the vector space model constructed the space of terms from the articles input to the system (it still used the summaries when computing the similarity).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P98-1012.txt | Citing Article:  W04-0703.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Bagga and Baldwin (1998) proposed entity based cross-document co-referencing which uses co-reference chains of each document to generate its summary and then use the summary rather than the whole article to select informative words to be the features of the document.</S> | Reference Offset:  ['43','58'] | Reference Text:  <S sid = 43 ssid = >The VSM-Disambiguate module, for each summary Si, computes the similarity of that summary with each of the other summaries.</S><S sid = 58 ssid = >Assuming that each of the documents in the data set was about a single John Smith, the cross-document coreference chains produced by the system could now be evaluated by scoring the corresponding within-document coreference chains in the meta document.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P98-1012.txt | Citing Article:  W09-1121.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >BCubed (Bagga and Baldwin, 1998) is an attractive measure that addresses both completeness and homogeneity.</S> | Reference Offset:  ['118','121'] | Reference Text:  <S sid = 118 ssid = >The highest F-Measure for the former case is 84.6% while the highest F-Measure for the latter case is 78.0%.</S><S sid = 121 ssid = >Figures 13 and 14 show the precision, recall, and F-Measure calculated using the MUC scoring algorithm.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P98-1012.txt | Citing Article:  W07-1703.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Similar approach was developed by (Bagga and Baldwin, 1998), who created first order context vectors that represent the instance in which the ambiguous name occurs.</S> | Reference Offset:  ['18','50'] | Reference Text:  <S sid = 18 ssid = >Figure 1 shows the architecture of the crossdocument system developed.</S><S sid = 50 ssid = >The answer keys regarding the cross-document chains were manually created, but the scoring was completely automated.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P98-1012.txt | Citing Article:  W07-1703.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >In this paper, we present a new text semantic similarity approach for fine-grained person name categorization and discrimination which is similar to those of (Pedersen et al, 2005) and (Bagga and Baldwin, 1998), but instead of simple word co-occurrences, we consider the whole text segment and relate the deduced semantic information of Latent Semantic Analysis (LSA) to trace the text cohesion between thousands of sentences containing named entities which belong to different fine-grained categories or individuals.</S> | Reference Offset:  ['75','76'] | Reference Text:  <S sid = 75 ssid = >This follows from the convention in coreference annotation of not identifying those entities that are markable as possibly coreferent with other entities in the text.</S><S sid = 76 ssid = >Rather, entities are only marked as being coreferent if they actually are coreferent with other entities in the text.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P98-1012.txt | Citing Article:  P09-1047.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The original work in (Bagga and Baldwin, 1998) proposed a CDC system by first performing WDC and then disambiguating based on the summary sentences of the chains.</S> | Reference Offset:  ['26','43'] | Reference Text:  <S sid = 26 ssid = >The coreference chains output by CAMP for the two extracts are shown in Figures 3 and 5. tractor module produces a &quot;summary&quot; of the article with respect to the entity of interest.</S><S sid = 43 ssid = >The VSM-Disambiguate module, for each summary Si, computes the similarity of that summary with each of the other summaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P98-1012.txt | Citing Article:  W07-2019.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Mann and Yarowsky (2003) have proposed a Web based clustering technique relying on a feature space combining biographic facts and associated names, whereas Bagga and Baldwin (1998) have looked for coreference chains within each document, take the context of these chains for creating summaries about each entity and convert these summaries into a bag of words.</S> | Reference Offset:  ['115','127'] | Reference Text:  <S sid = 115 ssid = >The Vector Space Model in this case constructed the space of terms only from the summaries extracted by SentenceExtractor.</S><S sid = 127 ssid = >Our system takes summaries about an entity of interest and uses various information retrieval metrics to rank the similarity of the summaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P98-1012.txt | Citing Article:  P09-2090.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We base our work partly on previous work done by Bagga and Baldwin (Bagga and Baldwin, 1998), which has also been used in later work (Chen and Martin, 2007).</S> | Reference Offset:  ['71','125'] | Reference Text:  <S sid = 71 ssid = >While the (Vilain 95) provides intuitive results for coreference scoring, it however does not work as well in the context of evaluating cross document coreference.</S><S sid = 125 ssid = >Details about these experiments can be found in (Bagga 98b).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P98-1012.txt | Citing Article:  D09-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >To score the output of a coreference model, we employ three scoring programs: MUC (Vilain et al, 1995), B3 (Bagga and Baldwin, 1998), and 3 -CEAF (Luo, 2005).</S> | Reference Offset:  ['56','59'] | Reference Text:  <S sid = 56 ssid = >In order to score the cross-document coreference chains output by the system, we had to map the cross-document coreference scoring problem to a within-document coreference scoring problem.</S><S sid = 59 ssid = >We used two different scoring algorithms for scoring the output.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P98-1012.txt | Citing Article:  D09-1101.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The aforementioned complication does not arise from the construction of the mapping, but from the fact that Bagga and Baldwin (1998) and Luo (2005) do not specify how to apply B3 and CEAF to score partitions generated from system mentions.</S> | Reference Offset:  ['67','123'] | Reference Text:  <S sid = 67 ssid = >First, let S be an equivalence set generated by the key, and let R1 ... R,â€ž. be equivalence classes generated by the response.</S><S sid = 123 ssid = >The high initial precision is mainly due to the fact that the MUC algorithm assumes that all errors are equal.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P98-1012.txt | Citing Article:  W06-1640.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >We use the B3 (Bagga and Baldwin, 1998) evaluation measure as well as precision, recall, and F1 measured on the (positive) pairwise decisions.</S> | Reference Offset:  ['114','120'] | Reference Text:  <S sid = 114 ssid = >Figure 11 shows the precision, recall, and F-Measure (with equal weights for both precision and recall) using the B-CUBED scoring algorithm.</S><S sid = 120 ssid = >Their performance using our Threshold Figure 11: Precision, Recall, and F-Measure Using the B-CUBED Algorithm With Training On the Summaries scoring algorithm is 23% precision, and 100% recall.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P98-1012.txt | Citing Article:  W07-2073.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Early work in the field of name disambiguation is that of (Bagga and Baldwin, 1998) who proposed cross-document coreference resolution algorithm which uses vector space model to resolve the ambiguities between people sharing the same name.</S> | Reference Offset:  ['3','10'] | Reference Text:  <S sid = 3 ssid = >In this paper we describe a cross-document coreference resolution algorithm which uses the Vector Space Model to resolve ambiguities between people having the same name.</S><S sid = 10 ssid = >In this paper we describe a highly successful crossdocument coreference resolution algorithm which uses the Vector Space Model to resolve ambiguities between people having the same name.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P98-1012.txt | Citing Article:  P11-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >On this dataset, our proposed model yields a B3 (Bagga and Baldwin, 1998) F1 score of 73.7%, improving over the baseline by 16% absolute (corresponding to 38% error reduction).</S> | Reference Offset:  ['86','122'] | Reference Text:  <S sid = 86 ssid = >It is our position that the second error is more damaging because, compared to the first error, the second error makes more entities coreferent that should not be.</S><S sid = 122 ssid = >Also, the baseline case when all the John Smiths are considered to be the same person achieves 83% precision and 100% recall.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P98-1012.txt | Citing Article:  P11-1080.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >One of the first approaches to cross-document coreference (Bagga and Baldwin, 1998) uses an idf-based cosine-distance scoring function for pairs of contexts, similar to the one we use.</S> | Reference Offset:  ['11','56'] | Reference Text:  <S sid = 11 ssid = >In addition, we also describe a scoring algorithm for evaluating the cross-document coreference chains produced by our system and we compare our algorithm to the scoring algorithm used in the MUC-6 (within document) coreference task.</S><S sid = 56 ssid = >In order to score the cross-document coreference chains output by the system, we had to map the cross-document coreference scoring problem to a within-document coreference scoring problem.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P98-1012.txt | Citing Article:  D09-1056.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >The disambiguation of person names in Web results is usually compared to two other Natural Language Processing tasks: Word Sense Disambiguation (WSD) (Agirre and Edmonds, 2006) and Cross-document Coreference (CDC) (Bagga and Baldwin, 1998).</S> | Reference Offset:  ['71','124'] | Reference Text:  <S sid = 71 ssid = >While the (Vilain 95) provides intuitive results for coreference scoring, it however does not work as well in the context of evaluating cross document coreference.</S><S sid = 124 ssid = >We have also tested our system on other classes of cross-document coreference like names of companies, and events.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P98-1012.txt | Citing Article:  N09-3002.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset: NA | Citation Text:  <S sid =  ssid = >Cross document coreference (CDC) (Bagga and Baldwin, 1998) is a distinct technology that consolidates named entities across documents according to their real referents.</S> | Reference Offset:  ['12','13'] | Reference Text:  <S sid = 12 ssid = >Cross-document coreference is a distinct technology from Named Entity recognizers like IsoQuest's NetOwl and IBM's Textract because it attempts to determine whether name matches are actually the same individual (not all John Smiths are the same).</S><S sid = 13 ssid = >Neither NetOwl or Textract have mechanisms which try to keep same-named individuals distinct if they are different people.</S> | Discourse Facet:  NA | Annotator: Automatic


