One of the most exciting recent directions in machine learning is the discovery that the combination of multiple classifiers often results in significantly better performance than what can be achieved with a single classifier.
In this paper, we first show that the errors made from three different state of the art part of speech taggers are strongly complementary.
Next, we show how this complementary behavior can be used to our advantage.
By using contextual cues to guide tagger combination, we are able to derive a new tagger that achieves performance significantly greater than any of the individual taggers.
