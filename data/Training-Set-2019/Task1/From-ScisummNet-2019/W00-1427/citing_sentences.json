[
  {
    "citance_No": 1, 
    "citing_paper_id": "W02-0908", 
    "citing_paper_authority": 45, 
    "citing_paper_authors": "James R., Curran | Marc, Moens", 
    "raw_text": "term is modified by a prepositional phrase The relation tuple is then converted to root form using the Sussex morphological analyser (Minnen et al, 2000) and the POS tags are removed", 
    "clean_text": "The relation tuple is then converted to root form using the Sussex morphological analyser (Minnen et al, 2000) and the POS tags are removed.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "N12-1056", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Brian, Kjersten | Benjamin, Van Durme", 
    "raw_text": "Setup Following Chambers and Jurafsky (2008), we extracted and lemmatized the verbs from the New York Times section of the Gigaword Corpus using the Stanford POS tagger (Toutanova et al, 2004) and the Morphalemmatizer (Minnen et al, 2000)", 
    "clean_text": "Following Chambers and Jurafsky (2008), we extracted and lemmatized the verbs from the New York Times section of the Gigaword Corpus using the Stanford POS tagger (Toutanova et al, 2004) and the Morphalemmatizer (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W04-2410", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mark, McLauchlan", 
    "raw_text": "Each word was reduced to its morphological root using the morphological analyser described in (Minnen et al, 2000)", 
    "clean_text": "Each word was reduced to its morphological root using the morphological analyser described in (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W02-1029", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "James R., Curran", 
    "raw_text": "term is modified by a prepositional phrase The relation tuple is then converted to root form using the Sussex morphological analyser (Minnenetal., 2000) and the POS tags are stripped", 
    "clean_text": "The relation tuple is then converted to root form using the Sussex morphological analyser (Minnen et al., 2000) and the POS tags are stripped.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W07-1009", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Beatrice, Alex | Barry, Haddow | Claire, Grover", 
    "raw_text": "Information on lemmatisa tion, as well as abbreviations and their long forms, is added using the morpha lemmatiser (Minnen et al, 2000) and the ExtractAbbrev script of Schwartz and Hearst (2003), respectively", 
    "clean_text": "Information on lemmatisation, as well as abbreviations and their long forms, is added using the morpha lemmatiser (Minnen et al, 2000) and the ExtractAbbrev script of Schwartz and Hearst (2003), respectively.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "N03-3006", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Gerold, Schneider", 
    "raw_text": "Heads are extracted from the chunks and lem matized (Minnen et al, 2000)", 
    "clean_text": "Heads are extracted from the chunks and lemmatized (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W06-0701", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ben, Hachey | Gabriel, Murray | David, Reitter", 
    "raw_text": "Furtherlinguistic markup is added using the morpha lem matiser (Minnen et al, 2000) and the C& amp; C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7", 
    "clean_text": "Further linguistic markup is added using the morpha lemmatiser (Minnen et al, 2000) and the C&C named entity tagger (Curran and Clark, 2003) trained on the data from MUC-7.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W02-2001", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Timothy, Baldwin | Aline, Villavicencio", 
    "raw_text": "In order to chunk parse the WSJ, we first tagged the full WSJ and Brown corpora using the Brill tagger, and then converted them into chunks based on the original Penn Treebank parse trees, with the aid of the conversion script used in preparing theCoNLL-2000 shared task data.3 We next lemma tised the data using morph (Minnen et al, 2000), and chunk parsed the WSJ with TiMBL 4.1 (Daelemans et al, 2001) using the Brown corpus as training data", 
    "clean_text": "We next lemmatised the data using morpha (Minnen et al, 2000), and chunk parsed the WSJ with TiMBL 4.1 (Daelemans et al, 2001) using the Brown corpus as training data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W07-1019", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Barry, Haddow | Michael, Matthews", 
    "raw_text": "Tokenisation, species word identification and chunking were implemented in-house using the LTXML2 tools (Grover and Tobin, 2006), whilst abbreviation extraction used the Schwartz and Hearst abbreviation extractor (Schwartz and Hearst, 2003) and lemmatisation used morpha (Minnen et al, 2000)", 
    "clean_text": "Tokenisation, species word identification and chunking were implemented in-house using the LTXML2 tools (Grover and Tobin, 2006), whilst abbreviation extraction used the Schwartz and Hearst abbreviation extractor (Schwartz and Hearst, 2003) and lemmatisation used morpha (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "S10-1060", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Laura, Rimell | Stephen, Clark", 
    "raw_text": "We used the morpha lemmatizer (Minnen et al, 2000), which is built into the C& amp; C tools, to match tokens across T and H; and we converted all tokens to lowercase", 
    "clean_text": "We used the morpha lemmatizer (Minnen et al, 2000), which is built into the C&C tools, to match tokens across T and H; and we converted all tokens to lowercase.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "S10-1074", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Claire, Grover | Richard, Tobin | Beatrice, Alex | Kate, Byrne", 
    "raw_text": "Part-of-speech (POS) tagging is done using the C& amp; C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000)", 
    "clean_text": "Part-of-speech (POS) tagging is done using the C&C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W05-1011", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "The Grefenstette (1994) relation extractor produces context relations that are then lemmatised using the Minnen et al (2000) morphological analyser", 
    "clean_text": "The Grefenstette (1994) relation extractor produces context relations that are then lemmatised using the Minnen et al (2000) morphological analyser.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W08-0325", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Zden&#x11B;k, &#x17D;abokrtsk&yacute; | Jan, Pt&aacute;&#x10D;ek | Petr, Pajas", 
    "raw_text": "B5: Lemmatize the tokens using morpha, (Minnen et al, 2000)", 
    "clean_text": "B5: Lemmatize the tokens using morpha, (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W08-0603", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Barry, Haddow", 
    "raw_text": "Thetokenisation, sentence boundary detection, head word identification and chunking components were implemented with the lt-xml2tools (Grover and Tobin, 2006), and the lemmatisa tion used morpha (Minnen et al, 2000)", 
    "clean_text": "The tokenisation, sentence boundary detection, head word identification and chunking components were implemented with the lt-xml2tools (Grover and Tobin, 2006), and the lemmatisation used morpha (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P02-1030", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "James R., Curran | Marc, Moens", 
    "raw_text": "Since MINIPAR performs morphological analysis onthe context relations we have added an existing morphological analyser (Minnen et al, 2000) to the other extractors", 
    "clean_text": "Since MINIPAR performs morphological analysis on the context relations we have added an existing morphological analyser (Minnen et al, 2000) to the other extractors.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W05-1008", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Timothy, Baldwin", 
    "raw_text": "For our purposes, we use a Penn tree bank-style tagger custom-built using fnTBL 1.0 (Ngai and Florian, 2001), and further lemmatise the output of the tagger using morph (Minnen et al, 2000)", 
    "clean_text": "For our purposes, we use a Penn tree bank-style tagger custom-built using fnTBL 1.0 (Ngai and Florian, 2001), and further lemmatise the output of the tagger using morph (Minnen et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P10-1140", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Swati, Tata | Barbara Di, Eugenio", 
    "raw_text": "We use amorphological tool (Minnen et al, 2000) to obtain the base form from the original verb or noun, so that YAG can generate grammatical sentences. Figure 5 shows the regenerated review from Figure 1", 
    "clean_text": "We use a morphological tool (Minnen et al, 2000) to obtain the base form from the original verb or noun, so that YAG can generate grammatical sentences.", 
    "keep_for_gold": 0
  }
]