Citance Number: 1 | Reference Article:  N01-1020.txt | Citing Article:  H05-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>There is work on lexicon induction using string distance or other phonetic/orthographic comparison techniques, such as Mann and Yarowsky (2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Multipath Translation Lexicon Induction Via Bridge Languages</S><S sid = NA ssid = NA>Learning string distance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  N01-1020.txt | Citing Article:  H05-1110.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Moreover, while some techniques (e.g., Mann and Yarowsky (2001)) use multiple languages, the languages used have resources such as dictionaries between some language pairs.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.</S><S sid = NA ssid = NA>Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  N01-1020.txt | Citing Article:  W06-2005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) present a method for inducing translation lexicons based on trasduction modules of cognate pairs via bridge languages.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper, we explore ways of using cognate pairs to create translation lexicons.</S><S sid = NA ssid = NA>In this paper, we explore ways of using cognate pairs to create translation lexicons.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  N01-1020.txt | Citing Article:  W06-2005.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Similarly to Mann and Yarowsky (2001), we show that languages are often close enough to others within their language family so that cognate pairs between the two are common, and significant portions of the translation lexicon can be induced with high accuracy where no bilingual dictionary or parallel corpora may exist.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.</S><S sid = NA ssid = NA>Finally, the use of multiple bridge languages and of the high degree of intra-family language similarity for dictionary induction is new.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  N01-1020.txt | Citing Article:  W06-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) applied the stochastic transducer of Ristad and Yianilos (1998) for inducing translation lexicons between two languages, but found that in some cases it offered no improvement over Levenshtein distance.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Machine transliter- Linguistics, E. Ristad and P. Yianilos.</S><S sid = NA ssid = NA>Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  N01-1020.txt | Citing Article:  W06-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>LLW stands for Levenshtein with learned weights, which is a modification of RY proposed by Mann and Yarowsky (2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The rank-based scoring method takes each proposed target and combines the rank of that proposal across all classifiers, and chooses the translation with the lowest resulting rank (rank 1 is the best proposed translation).</S><S sid = NA ssid = NA>Also, empirical evidence suggests that the best method is achieved through learning weights with stochastic transducers and then using these weights in the L-S framework. for each word o E 0 for each bridge language B Translate o b E B Vt E T, Calculate D(b,t) Rank t by D(b,t) Score t using information from all bridges Select highest scored t Produce mapping o t Two scoring methods were investigated for the above algorithm: one based on rank and the other on distance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  N01-1020.txt | Citing Article:  W06-1107.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As mentioned in (Mann and Yarowsky, 2001), it appears that there are significant differences between the pronunciation task and the cognate identification task.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This is a more difficult task than that used for direct induction (selecting between 100 and 900 potential translation candidates for each sourcelanguage word), so the system's performance is lower than the Section 3 results.</S><S sid = NA ssid = NA>Dictionaries for Russian and Ukrainian were converted into romanized pronunciation dictionaries.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  N01-1020.txt | Citing Article:  P07-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) saw little improvement over Edit Distance when applying this transducer to cognates, even when filtering the transducer's probabilities into different weight classes to better approximate Edit Distance.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The weights in these two systems were produced by filtering the probabilities obtained from the stochastic transducer into three weight classes: 0.5, 0.75, and 1.</S><S sid = NA ssid = NA>within an edit-distance of 3) from the remaining word-pairs as training data.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  N01-1020.txt | Citing Article:  P07-1083.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>For example, Mann and Yarowsky (2001) define a word pair (e, f) to be cognate if they are a translation pair (same meaning) and their Edit Distance is less than three (same form).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>within an edit-distance of 3) from the remaining word-pairs as training data.</S><S sid = NA ssid = NA>For L-S, the cost matrix was separately trained for each language pair, and for L-A, it was trained collectively over all the Romance languages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  N01-1020.txt | Citing Article:  W09-1117.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The marked difference in the availability of monolingual vs parallel corpora has led several researchers to develop methods for automatically learning bilingual lexicons, either by using monolingual corpora (Rapp, 1999; Koehn and Knight, 2002; Schafer and Yarowsky, 2002; Haghighi et al., 2008) or by exploiting the cross-language evidence of closely related "bridge" languages that have more resources (Mann and Yarowsky, 2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Using cognates to align sentences in bilingual corpora.</S><S sid = NA ssid = NA>Hajie et al. (2000) has studied the exploitation of language similarity for use in machine translation in the case of the very closely related languages (Czech/Slovak).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  N01-1020.txt | Citing Article:  W05-0606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) investigated the induction of translation lexicons via bridge languages.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Multipath Translation Lexicon Induction Via Bridge Languages</S><S sid = NA ssid = NA>As a final note, Table 9 shows the cross-language translation rates for some of the investigated languages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  N01-1020.txt | Citing Article:  W05-0606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) developed yet another model, which outperformed all other similarity measures.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Various machine learning techniques, including co-training and mutual bootstrapping, could employ these additional measures in creating better estimates.</S><S sid = NA ssid = NA>Various machine learning techniques, including co-training and mutual bootstrapping, could employ these additional measures in creating better estimates.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  N01-1020.txt | Citing Article:  W05-0606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The HMM model of (Mann and Yarowsky, 2001) is of distinctly different design than our PHMM model.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The metrics depicted in the first three lines, namely Levenshtein distance (L), the HMM fenonic model (H), and the stochastic transducer (S), were previously described in Section 2.</S><S sid = NA ssid = NA>While early statistical machine translation models, such as Brown et al. (1993), did not use any cognate based information to seed their wordto-word translation probabilities, subsequent models (Chen, 1993 and Simard et al., 1992) incorporated some simple deterministic heuristics to increase the translation model probabilities for cognates.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  N01-1020.txt | Citing Article:  W11-2605.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) present a method for inducing translation lexicons based on transduction models of cognate pairs via bridge languages.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this paper, we explore ways of using cognate pairs to create translation lexicons.</S><S sid = NA ssid = NA>In this paper, we explore ways of using cognate pairs to create translation lexicons.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  N01-1020.txt | Citing Article:  P07-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Our work is inspired by Mann and Yarowsky (2001).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>7 Related Work Probabilistic string edit distance learning techniques have been studied by Ristad and Yianilos (1998) for use in pronunciation modeling for speech recognition.</S><S sid = NA ssid = NA>In both cases, the great potential of this work is the ability to leverage a single bilingual dictionary into translation lexicons for its entire language family, without any additional resources beyond raw wordlists for the other languages in the family.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  N01-1020.txt | Citing Article:  P07-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) distinguish between static metrics, which are sufficiently general to be applied to any language pair, and adaptive metrics, which are adapted to a specific language pair.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>For L-S, the cost matrix was separately trained for each language pair, and for L-A, it was trained collectively over all the Romance languages.</S><S sid = NA ssid = NA>The metrics depicted in the first three lines, namely Levenshtein distance (L), the HMM fenonic model (H), and the stochastic transducer (S), were previously described in Section 2.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  N01-1020.txt | Citing Article:  P07-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) use variants of Levenshtein distance as a static metric, and a Hidden Markov Model (HMM) and a stochastic transducer trained with the Expectation-Maximisation (EM) algorithm as adaptive metrics.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The metrics depicted in the first three lines, namely Levenshtein distance (L), the HMM fenonic model (H), and the stochastic transducer (S), were previously described in Section 2.</S><S sid = NA ssid = NA>Two adaptively trained variants, L-S and L-A, are shown in the last two lines of Table 1.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  N01-1020.txt | Citing Article:  P07-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Mann and Yarowsky (2001) consider a word pair as cognate if the Levenshtein distance between the two words is less than 3.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>As can be observed from Table 1, pure Levenshtein distance (L) works surprisingly well.</S><S sid = NA ssid = NA>In Table 8 &quot;Cvg&quot; or cognate coverage is the percentage words in the source language for which any of the bridge languages contains a cognate to the target translation.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  N01-1020.txt | Citing Article:  P07-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>This finding is consistent with the results of Mann and Yarowsky (2001), although our experiments show more clear-cut differences.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Trends across subsets are relatively consistent.</S><S sid = NA ssid = NA>Trends across subsets are relatively consistent.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  N01-1020.txt | Citing Article:  P07-3010.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Using the same models, Mann and Yarowsky (2001) induced over 90% of the Spanish-Portuguese cognate vocabulary.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>When there is a drop in accuracy on the cognate vocabulary by adding an additional bridge language there tends to be an improvement in accuracy on the full vocabulary due to significantly more cognate pathways (yielding greater coverage).</S><S sid = NA ssid = NA>In Table 6, we present the results obtained by applying different combination algorithms for the pathway from English to Portuguese using one of the other Romance languages (Spanish, Italian, French, and Romanian) as bridges and compare with the single best path (English-Spanish-Portuguese).</S> | Discourse Facet:  NA | Annotator: Automatic


