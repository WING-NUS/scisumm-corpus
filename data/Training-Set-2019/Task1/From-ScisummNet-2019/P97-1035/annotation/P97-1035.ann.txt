Citance Number: 1 | Reference Article:  P97-1035.txt | Citing Article:  W97-0601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the remainder of this paper, we discuss the PARADISE framework (PARAdigm for Dialogue System Evaluation) (Walker et al, 1997), and that it addresses these limitations, as well as others.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>This paper describes PARADISE, a general framework for evaluating spoken dialogue agents that addresses these limitations.</S><S sid = NA ssid = NA>This paper presents PARADISE (PARAdigm for DIalogue System Evaluation), a general framework for evaluating spoken rlialogue agents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 2 | Reference Article:  P97-1035.txt | Citing Article:  W97-0601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Instead, predictions about user satisfaction can be made on the basis of the predictor variables, which is illustrated in the application of PARADISE to sub dialogues in (Walker et al., 1997).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Instead, predictions about user satisfaction can be made on the basis of the predictor variables, as illustrated in the application of PARADISE to subdialogues.</S><S sid = NA ssid = NA>PARADISE represents each cost measure as a function ci that can be applied to any (sub)dialogue.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 3 | Reference Article:  P97-1035.txt | Citing Article:  W97-0601.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>While we discussed the representation of an information-seeking dialogue here, AVM representations for negotiation and diagnostic dialogue tasks are also easily constructed (Walker et al, 1997).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Thus, even though the dialogue strategies in Figures 2 and 3 are radically different, the AVM task representation for these dialogues is identical and the performance of the system for the same task can thus be assessed on the basis of the AVM representation.</S><S sid = NA ssid = NA>We propose that an attribute value matrix (AVM) can represent many dialogue tasks.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 4 | Reference Article:  P97-1035.txt | Citing Article:  W12-1803.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The first approach to predict user judgments on the basis of interaction metrics is the well-known PARADISE model (Walker et al, 1997).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In this case, on the basis of the model in Figure 1, US is treated as the predicted factor.</S><S sid = NA ssid = NA>One widely used approach to evaluation is based on the notion of a reference answer (Hirschman et al., 1990).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 5 | Reference Article:  P97-1035.txt | Citing Article:  W01-0906.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>There are also well-known evaluation efforts such as EAGLES (Sparck Jones and Galliers, 1996) and the Paradise evaluation framework (Walker et al, 1997).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Such generalization requires the identification of factors that affect performance (Cohen, 1995; Sparck-Jones and Galliers, 1996).</S><S sid = NA ssid = NA>This paper presents PARADISE (PARAdigm for DIalogue System Evaluation), a general framework for evaluating spoken rlialogue agents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 6 | Reference Article:  P97-1035.txt | Citing Article:  W02-0219.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Walker et al (1997) identified three factors which carry an influence on the performance of SDSs, and which therefore are thought to contribute to its quality perceived by the user: agent factors (mainly related to the dialogue and the system itself), task factors (related to how the SDS captures the task it has been developed for) and environmental factors (e.g. factors related to the acoustic environment and the transmission channel).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In addition to agent factors such as dialogue strategy, task factors such as database size and environmental factors such as background noise may also be relevant predictors of performance.</S><S sid = NA ssid = NA>Finally, to our knowledge, we are the first to propose using user satisfaction to determine weights on factors related to performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 7 | Reference Article:  P97-1035.txt | Citing Article:  W02-0219.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>The PARADISE framework (Walker et al, 1997) produces such a relationship for a specific scenario, using multivariate linear regression.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Multiple linear regression produces a set of coefficients (weights) describing the relative contribution of each predictor factor in accounting for the variance in a predicted factor.</S><S sid = NA ssid = NA>Given a set of dialogues for which user satisfaction (US), is and the set of ci have been collected experimentally, the weights a and wi can be solved for using multiple linear regression.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 8 | Reference Article:  P97-1035.txt | Citing Article:  W02-0219.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>As stated above, the separation of environmental, agent and task factors was motivated by Walker et al (1997).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>In addition to agent factors such as dialogue strategy, task factors such as database size and environmental factors such as background noise may also be relevant predictors of performance.</S><S sid = NA ssid = NA>PARADISE supports comparisons among dialogue strategies with a task representation that decouples what an agent needs to achieve in terms of the task requirements from how the agent carries out the task via dialogue.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 9 | Reference Article:  P97-1035.txt | Citing Article:  W02-0219.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In the PARADISE framework, user satisfaction is composed of maximal task success and minimal dialogue costs (Walker et al, 1997), thus a type of efficiency in the way it was defined here.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The PARADISE performance measure is a function of both task success (K) and dialogue costs (ci), and has a number of advantages.</S><S sid = NA ssid = NA>The model further posits that two types of factors are potential relevant contributors to user satisfaction (namely task success and dialogue costs), and that two types of factors are potential relevant contributors to costs (Walker, 1996).</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 10 | Reference Article:  P97-1035.txt | Citing Article:  N12-1081.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>User satisfaction is a function of task success and the number of user turns based on the PARADISE framework (Walker et al, 1997) and CAS refers to the proportion of repetition and variation in surface forms.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Performance is modeled as a weighted function of a task-based success measure and dialogue-based cost measures, where weights are computed by correlating user satisfaction with performance.</S><S sid = NA ssid = NA>The PARADISE performance measure is a function of both task success (K) and dialogue costs (ci), and has a number of advantages.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 11 | Reference Article:  P97-1035.txt | Citing Article:  W08-0126.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Previous studies (E.g., Walker et al, 1997) use a corpus level semantic accuracy measure (semantic Accuracy) to capture the system's understanding ability.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our performance measure also captures information similar to concept accuracy, where low concept accuracy scores translate into either higher costs for acquiring information from the user, or lower K scores.</S><S sid = NA ssid = NA>In addition, this approach is broadly integrative, incorporating aspects of transaction success, concept accuracy, multiple cost measures, and user satisfaction.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 12 | Reference Article:  P97-1035.txt | Citing Article:  A00-2027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Once they had completed all tasks in sequence using one system, they filled out a questionnaire to assess user satisfaction by rating 8-9 statements, similar to those in (Walker et al, 1997), on a scale of 1-5, where 5 indicated highest satisfaction.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>User satisfaction is typically calculated with surveys that ask users to specify the degree to which they agree with one or more statements about the behavior or the performance of the system.</S><S sid = NA ssid = NA>Finally, to our knowledge, we are the first to propose using user satisfaction to determine weights on factors related to performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 13 | Reference Article:  P97-1035.txt | Citing Article:  A00-2027.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Following the PARADISE evaluation scheme (Walker et al, 1997), we divided performance features into four groups.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>First, in our scheme (Figure 6), the greetings (turns 1 and 2) are tagged with all the attributes.</S><S sid = NA ssid = NA>The PARADISE methodology consists of the following steps: Note that all of these steps are required to develop the performance function.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 14 | Reference Article:  P97-1035.txt | Citing Article:  P08-1071.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Some studies (e.g., (Walker et al, 1997)) build regression models to predict user satisfaction scores from the system log as well as the user survey.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>Our performance measure also captures information similar to concept accuracy, where low concept accuracy scores translate into either higher costs for acquiring information from the user, or lower K scores.</S><S sid = NA ssid = NA>Section 2.4 describes the use of linear regression and user satisfaction to estimate the relative contribution of the success and cost measures in a single performance function.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 15 | Reference Article:  P97-1035.txt | Citing Article:  W06-1301.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Future work focuses on usability tests of the prototype system, e.g. using the PARADISE evaluation framework to evaluate the general usability of the system (Walker et al, 1997).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>The PARADISE model posits that performance can be correlated with a meaningful external criterion such as usability, and thus that the overall goal of a spoken dialogue agent is to maximize an objective related to usability.</S><S sid = NA ssid = NA>PARADISE is a general framework for evaluating spoken dialogue agents that integrates and enhances previous work.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 16 | Reference Article:  P97-1035.txt | Citing Article:  W02-0221.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>They then derived dialogue act metrics from the DATE tags and showed that when these metrics were used in the PARADISE evaluation framework (Walker et al, 1997) that they improved models of user satisfaction by an absolute 5%, and that the new metrics could be used to understand which system's dialogue strategies were most effective.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>One widely used approach to evaluation is based on the notion of a reference answer (Hirschman et al., 1990).</S><S sid = NA ssid = NA>We have presented the PARADISE framework, and have used it to evaluate two hypothetical dialogue agents in a simplified train timetable task domain.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 17 | Reference Article:  P97-1035.txt | Citing Article:  W08-1113.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Such metrics have been introduced in other fields, including PARADISE (Walker et al, 1997) for spoken dialogue systems, BLEU (Papineni et al, 2002) for machine translation, and ROUGE (Lin, 2004) for summarisation.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>PARADISE: A Framework For Evaluating Spoken Dialogue Agents</S><S sid = NA ssid = NA>This paper presented the PARADISE framework for evaluating spoken dialogue agents.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 18 | Reference Article:  P97-1035.txt | Citing Article:  W01-1606.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In doing so, we are essentially exploring system behaviour in a glass box approach: this does not constitute an evaluation method for dialogue performance [Walker et al, 1997].</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>One widely used approach to evaluation is based on the notion of a reference answer (Hirschman et al., 1990).</S><S sid = NA ssid = NA>One limitation of the PARADISE approach is that the task-based success measure does not reflect that some solutions might be better than others.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 19 | Reference Article:  P97-1035.txt | Citing Article:  W11-2031.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>In particular, unlike the PARADISE framework (Walker et al, 1997), which aims to evaluate dialogue agent strategies by relating overall user satisfaction to various other metrics (task success, efficiency measures, and qualitative measures) our approach takes the agent's dialogue strategy for granted.</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>PARADISE uses its AVM representation to link the information goals of the task to any arbitrary dialogue behavior, by tagging the dialogue with the attributes for the task.9 This makes it possible to evaluate any potential dialogue strategies for achieving the task, as well as to evaluate dialogue strategies that operate at the level of dialogue subtasks (subdialogues).</S><S sid = NA ssid = NA>PARADISE uses a decision-theoretic framework to specify the relative contribution of various factors to an agent's overall performance.</S> | Discourse Facet:  NA | Annotator: Automatic


Citance Number: 20 | Reference Article:  P97-1035.txt | Citing Article:  P11-2115.txt | Citation Marker Offset:  NA | Citation Marker: NA | Citation Offset:  NA | Citation Text:  <S sid = NA ssid = NA>Previous work has therefore suggested to learn a reward function from human data as in the PARADISE framework (Walker et al, 1997).</S> | Reference Offset:  NA | Reference Text:  <S sid = NA ssid = NA>PARADISE is a general framework for evaluating spoken dialogue agents that integrates and enhances previous work.</S><S sid = NA ssid = NA>We believe that the framework is also applicable to other dialogue modalities, and to human-human task-oriented dialogues.</S> | Discourse Facet:  NA | Annotator: Automatic


