[
  {
    "citance_No": 1, 
    "citing_paper_id": "W07-0701", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Arul, Menezes | Chris, Quirk", 
    "raw_text": "Since we approach decoding as xR transduction, the process is identical to that of constituency based algorithms (e.g. Huang and Chiang, 2007)", 
    "clean_text": "Since we approach decoding as xR transduction, the process is identical to that of constituency based algorithms (e.g. Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2022", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kenneth, Heafield | Michael, Kayser | Christopher D., Manning", 
    "raw_text": "Traditional decoders (Huang and Chiang,2007) try thousands of combinations of hypotheses and phrases, hoping to find ones that the language model likes", 
    "clean_text": "Traditional decoders (Huang and Chiang, 2007) try thousands of combinations of hypotheses and phrases, hoping to find ones that the language model likes.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D10-1063", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Mark, Hopkins | Greg, Langmead", 
    "raw_text": "Thus they can not integrate LM scoring into their decoding, requiring them to rescore the decoder output with a variant of cube growing (Huang and Chiang, 2007)", 
    "clean_text": "Thus they cannot integrate LM scoring into their decoding, requiring them to rescore the decoder output with a variant of cube growing (Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P09-1067", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Zhifei, Li | Jason M., Eisner | Sanjeev P., Khudanpur", 
    "raw_text": "3A hyper graph is analogous to a parse forest (Huang and Chiang, 2007)", 
    "clean_text": "A hyper graph is analogous to a parse forest (Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W11-2167", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Baskaran, Sankaran | Gholamreza, Haffari | Anoop, Sarkar", 
    "raw_text": "Kriya supports the entire translation pipeline of SCFG rule extraction and decoding with cube pruning (Huang and Chiang, 2007 )andLM integration (Chiang, 2007)", 
    "clean_text": "Kriya supports the entire translation pipeline of SCFG rule extraction and decoding with cube pruning (Huang and Chiang, 2007) and LM integration (Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D08-1012", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Slav, Petrov | Aria, Haghighi | Dan, Klein", 
    "raw_text": "Huang and Chiang (2007) searches with the full model, but makes assumptions about the the amount of reordering the language model can trigger in order to limit exploration", 
    "clean_text": "Huang and Chiang (2007) searches with the full model, but makes assumptions about the the amount of reordering the language model can trigger in order to limit exploration.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D12-1107", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Kenneth, Heafield | Philipp, Koehn | Alon, Lavie", 
    "raw_text": "Vilar and Ney (2011) study several modifications to cube pruning and cube growing (Huang and Chiang, 2007)", 
    "clean_text": "Vilar and Ney (2011) study several modifications to cube pruning and cube growing (Huang and Chiang, 2007).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P10-1076", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Tong, Xiao | Jingbo, Zhu | Muhua, Zhu | Huizhen, Wang", 
    "raw_text": "Beam search and cube pruning (Huang and Chiang, 2007) are used to prune the search space in all the three baseline systems", 
    "clean_text": "Beam search and cube pruning (Huang and Chiang, 2007) are used to prune the search space in all the three baseline systems.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W11-2142", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Markus, Freitag | Gregor, Leusch | Joern, Wuebker | Stephan, Peitz | Hermann, Ney | Teresa, Herrmann | Jan, Niehues | Alex, Waibel | Alexandre, Allauzen | Gilles, Adda | Josep Maria, Crego | Bianka, Buschbeck-Wolf | Tonio, Wandmacher | Jean, Senellart", 
    "raw_text": "The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007)", 
    "clean_text": "The search is typically carried out using the cube pruning algorithm (Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "N12-1035", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Matthias, Huck | Hermann, Ney", 
    "raw_text": "In our experiments, we use the cube pruning algorithm (Huang and Chiang, 2007) to carry out the search", 
    "clean_text": "In our experiments, we use the cube pruning algorithm (Huang and Chiang, 2007) to carry out the search.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P11-1128", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yang, Liu | Qun, Liu | Yajuan, L&uuml;", 
    "raw_text": "Tree-to-string decoding with STSG is usually treated as forest rescoring (Huang and Chiang,2007) that involves two steps", 
    "clean_text": "Tree-to-string decoding with STSG is usually treated as forest rescoring (Huang and Chiang, 2007) that involves two steps.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P10-4002", 
    "citing_paper_authority": 67, 
    "citing_paper_authors": "Chris, Dyer | Adam, Lopez | Juri, Ganitkevitch | Jonathan, Weese | Ferhan, Ture | Philip, Blunsom | Hendra, Setiawan | Vladimir, Eidelman | Philip, Resnik", 
    "raw_text": "cdec therefore supports three pruning strategies that can be used during intersection: full unpruned intersection (useful for tagging models to incorporate ,e.g., Markov features ,butnot generally practical for translation), cube pruning, and cube growing (Huang and Chiang, 2007)", 
    "clean_text": "cdec therefore supports three pruning strategies that can be used during intersection: full unpruned intersection (useful for tagging models to incorporate, e.g., Markov features, but not generally practical for translation), cube pruning, and cube growing (Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W11-2211", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Matthias, Huck | David, Vilar | Daniel, Stein | Hermann, Ney", 
    "raw_text": "In hierarchical phrase-based translation (Chiang,2005) a weighted synchronous context-free gram mar is induced from parallel text, the search is based on CYK+ parsing (Chappelier and Rajman,1998) and typically carried out using the cube pruning algorithm (Huang and Chiang, 2007)", 
    "clean_text": "In hierarchical phrase-based translation (Chiang, 2005) a weighted synchronous context-free grammar is induced from parallel text, the search is based on CYK+ parsing (Chappelier and Rajman, 1998) and typically carried out using the cube pruning algorithm (Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D08-1022", 
    "citing_paper_authority": 35, 
    "citing_paper_authors": "Haitao, Mi | Liang, Huang", 
    "raw_text": "Nevertheless we suspect that their extraction algorithm is in principle similar to ours, although they do not provide details of forest-based fragmentation (Algorithm 1) which we think is non-trivial. The forest concept is also used in machine translation decoding, for example to characterize the search space of decoding with integrated language models (Huang and Chiang, 2007)", 
    "clean_text": "The forest concept is also used in machine translation decoding, for example to characterize the search space of decoding with integrated language models (Huang and Chiang, 2007).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D10-1027", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Liang, Huang | Haitao, Mi", 
    "raw_text": "Furthermore, language model integration becomes more expensive here since the decoder now has to maintain target-language boundary words at both ends of a sub translation (Huang and Chiang, 2007), whereas a phrase-based decoder only needs to do this at one end since the translation is always growing left-to-right", 
    "clean_text": "Furthermore, language model integration becomes more expensive here since the decoder now has to maintain target-language boundary words at both ends of a sub translation (Huang and Chiang, 2007), whereas a phrase-based decoder only needs to do this at one end since the translation is always growing left-to-right.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D10-1027", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "Liang, Huang | Haitao, Mi", 
    "raw_text": "The complexity of this dynamic programming algorithm for g-gram decoding is O (2nn2|V |g? 1) where n is the sentence length and |V| is the English vocabulary size (Huang and Chiang, 2007)", 
    "clean_text": "The complexity of this dynamic programming algorithm for g-gram decoding is O (2nn2|V|g-1) where n is the sentence length and |V| is the English vocabulary size (Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "N10-1033", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Chris, Dyer", 
    "raw_text": "An alternative approach to computing a synchronous parse forest is based on cube pruning (Huang and Chiang, 2007)", 
    "clean_text": "An alternative approach to computing a synchronous parse forest is based on cube pruning (Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W12-3137", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Malte, Nuhn | Matthias, Huck | Hermann, Ney | Stephan, Peitz | Markus, Freitag", 
    "raw_text": "We utilize the cube pruning algorithm (Huang and Chiang, 2007) for decoding and optimize the model weights with MERT", 
    "clean_text": "We utilize the cube pruning algorithm (Huang and Chiang, 2007) for decoding and optimize the model weights with MERT.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P11-1065", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "Per Non-Terminal Pruning The decoder uses a combination of beam and cube-pruning (Huang and Chiang, 2007)", 
    "clean_text": "Per Non-Terminal Pruning The decoder uses a combination of beam and cube-pruning (Huang and Chiang, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "N09-2036", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Michael, Pust | Kevin, Knight", 
    "raw_text": "Huang and Chiang (2007 )de 143 5x108 1x109 1.5x109 2x109 2.5x109 3x109 edges created 42000 43000 44000 45000 mod el cos t lazy cube generation exhaustive cube generation Figure 3: Number of edges produced by the decoder ,versus model cost of 1-bestdecodings.scribe a variation of cube pruning called cube growing, and they apply it to a source-tree to target string translator", 
    "clean_text": "Huang and Chiang (2007) describe a variation of cube pruning called cube growing, and they apply it to a source-tree to target string translator.", 
    "keep_for_gold": 0
  }
]