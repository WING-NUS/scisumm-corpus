Forest Rescoring: Faster Decoding with Integrated Language Models
Efficient decoding has been a fundamental problem in machine translation, especially with an integrated language model which is essential for achieving good translation quality.
We develop faster approaches for this problem based on k-best parsing algorithms and demonstrate their effectiveness on both phrase-based and syntax-based MT systems.
In both cases, our methods achieve significant speed improvements, often by more than a factor of ten, over the conventional beam-search method at the same levels of search error and translation accuracy.
We make assumptions about the the amount of reordering the language model can trigger in order to limit exploration.
We introduce cube pruning and and its variation, cube growing.
We use the forest concept to characterize the search space of decoding with integrated language models.
