[
  {
    "citance_No": 1, 
    "citing_paper_id": "D07-1045", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Holger, Schwenk | Marta Ruiz, Costa-Juss&agrave; | Jos&eacute; A. R., Fonollosa", 
    "raw_text": "This could be addressed by the so-called factored phrase-based model as implemented in the Moses decoder (Koehnet al, 2007)", 
    "clean_text": "This could be addressed by the so-called factored phrase-based model as implemented in the Moses decoder (Koehn et al, 2007).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2122", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Xiaolin, Wang | Masao, Utiyama | Andrew, Finch | Eiichiro, Sumita", 
    "raw_text": "For the bilingual tasks, the publicly available system of Moses (Koehn et al, 2007) with default settings is employed to perform machine translation, and BLEU (Papineni et al, 2002) was used to evaluate the quality", 
    "clean_text": "For the bilingual tasks, the publicly available system of Moses (Koehn et al, 2007) with default settings is employed to perform machine translation, and BLEU (Papineni et al, 2002) was used to evaluate the quality.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "S12-1105", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yashar, Mehdad | Jose, Souza | Matteo, Negri", 
    "raw_text": "Subsequently, we extracted the bi-lingual phrase table from the aligned corpora using the Moses toolkit (Koehn et al., 2007)", 
    "clean_text": "Subsequently, we extracted the bi-lingual phrase table from the aligned corpora using the Moses toolkit (Koehn et al., 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "S12-1105", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Yashar, Mehdad | Jose, Souza | Matteo, Negri", 
    "raw_text": "Finally, we extract the semantic phrase table from the augmented aligned corpora using the Moses toolkit (Koehn et al, 2007)", 
    "clean_text": "Finally, we extract the semantic phrase table from the augmented aligned corpora using the Moses toolkit (Koehn et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W11-2143", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Hanneman | Alon, Lavie", 
    "raw_text": "Bidirectional lexical scores for all rules with lexical items, calculated from a unigram lexicon over Viterbi-aligned word pairs as in the Moses decoder (Koehn et al, 2007)", 
    "clean_text": "Bidirectional lexical scores for all rules with lexical items, calculated from a unigram lexicon over Viterbi-aligned word pairs as in the Moses decoder (Koehn et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P14-2024", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Graham, Neubig | Kevin, Duh", 
    "raw_text": "The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al, 2007)", 
    "clean_text": "The first two baselines are standard systems using PBMT or Hiero trained using Moses (Koehn et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W10-1756", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Abhishek, Arun | Barry, Haddow | Philipp, Koehn", 
    "raw_text": "Our baseline system is phrase-based Moses (Koehn et al, 2007) with feature weights trained using MERT", 
    "clean_text": "Our baseline system is phrase-based Moses (Koehn et al, 2007) with feature weights trained using MERT.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P14-2127", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Kai, Zhao | Liang, Huang | Haitao, Mi | Abe, Ittycheriah", 
    "raw_text": "We evaluate MAXFORCE for HIERO over two CHEN corpora, IWSLT09 and FBIS, and compare the performance with vanilla n-best MERT (Och, 2003) from Moses (Koehn et al, 2007), Hypergraph MERT (Kumar et al, 2009), and PRO (Hopkins and May, 2011) from cdec", 
    "clean_text": "We evaluate MAXFORCE for HIERO over two CHEN corpora, IWSLT09 and FBIS, and compare the performance with vanilla n-best MERT (Och, 2003) from Moses (Koehn et al, 2007), Hypergraph MERT (Kumar et al, 2009), and PRO (Hopkins and May, 2011) from cdec.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D09-1117", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Andrew, Finch | Eiichiro, Sumita", 
    "raw_text": "For our experiments we use the phrase-based ma chine translation techniques described in (Koehn, 2004) and (Koehn et al, 2007), integrating our models within a log-linear framework (Och and Ney, 2002)", 
    "clean_text": "For our experiments we use the phrase-based machine translation techniques described in (Koehn, 2004) and (Koehn et al, 2007), integrating our models within a log-linear framework (Och and Ney, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D09-1117", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Andrew, Finch | Eiichiro, Sumita", 
    "raw_text": "Each instance of the decoder is a standard phrase based machine translation decoder that operates according to the same principles as the publicly available PHARAOH (Koehn, 2004) and MOSES (Koehn et al, 2007) SMT decoders", 
    "clean_text": "Each instance of the decoder is a standard phrase based machine translation decoder that operates according to the same principles as the publicly available PHARAOH (Koehn, 2004) and MOSES (Koehn et al, 2007) SMT decoders.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D09-1117", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Andrew, Finch | Eiichiro, Sumita", 
    "raw_text": "(Koehn et al, 2007) was also included in the scores for partial hypothesis during the decoding", 
    "clean_text": "(Koehn et al, 2007) was also included in the scores for partial hypothesis during the decoding.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W12-0113", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Santanu, Pal | Sivaji, Bandyopadhyay", 
    "raw_text": "An automatic extraction of bilingual MWEs is carried out by Ren et al (2009), using a log likelihood ratio based hierarchical reducing algorithm to investigate the usefulness of bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al, 2007)", 
    "clean_text": "An automatic extraction of bilingual MWEs is carried out by Ren et al (2009), using a log likelihood ratio based hierarchical reducing algorithm to investigate the usefulness of bilingual MWEs in SMT by integrating bilingual MWEs into the Moses decoder (Koehn et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W12-0113", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Santanu, Pal | Sivaji, Bandyopadhyay", 
    "raw_text": "The effectiveness of the MWE-aligned and chunk aligned parallel corpus is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phrase-extraction heuristics described in (Koehn et al, 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model trained using SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing (Kneser and Ney, 1995) and the Moses decoder (Koehn et al, 2007)", 
    "clean_text": "The effectiveness of the MWE-aligned and chunk aligned parallel corpus is demonstrated by using the standard log-linear PB-SMT model as our baseline system: GIZA++ implementation of IBM word alignment model 4, phrase-extraction heuristics described in (Koehn et al, 2003), minimum-error-rate training (Och, 2003) on a held-out development set, target language model trained using SRILM toolkit (Stolcke, 2002) with Kneser-Ney smoothing (Kneser and Ney, 1995) and the Moses decoder (Koehn et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P11-1004", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Ann, Clifton | Anoop, Sarkar", 
    "raw_text": "We then trained the Moses phrase-based system (Koehn et al, 2007) on the segmented andmarked text", 
    "clean_text": "We then trained the Moses phrase-based system (Koehn et al, 2007) on the segmented and marked text.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P11-1004", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Ann, Clifton | Anoop, Sarkar", 
    "raw_text": "In all the experiments conducted in this paper, we used the Moses5 phrase-based translation system (Koehn et al, 2007), 2008 version", 
    "clean_text": "In all the experiments conducted in this paper, we used the Moses5 phrase-based translation system (Koehn et al, 2007), 2008 version.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W12-3117", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Johann, Roturier | Fred, Hollowood | Raphael, Rubino | Rasul, Samad Zadeh Kaljahi | Jennifer, Foster | Joachim, Wagner", 
    "raw_text": "Backward 2-gram and 3-gram source and target log probabilities: as proposed by Duchateau et al (2002)? Log probability of target segments on 5-gram MT-output-based LM: using MOSES (Koehn et al, 2007) trained on the provided parallel corpus, we translated the English side of this corpus into Spanish, assuming that the MT output contains mistakes", 
    "clean_text": "Backward 2-gram and 3-gram source and target log probabilities: as proposed by Duchateau et al (2002) Log probability of target segments on 5-gram MT-output-based LM: using MOSES (Koehn et al, 2007) trained on the provided parallel corpus, we translated the English side of this corpus into Spanish, assuming that the MT output contains mistakes.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W11-2022", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Thomas, Meyer | Andrei, Popescu-Belis | Sandrine, Zufferey | Bruno, Cartoni", 
    "raw_text": "195 When an ambiguous connective is explicitly translated by another connective, the incorrect rendering of its sense can lead to erroneous translations, as in the second and third examples in Table 1, which are translated by the Moses SMT decoder (Koehnetal., 2007) trained on the Europarl corpus", 
    "clean_text": "When an ambiguous connective is explicitly translated by another connective, the incorrect rendering of its sense can lead to erroneous translations, as in the second and third examples in Table 1, which are translated by the Moses SMT decoder (Koehn et al., 2007) trained on the Europarl corpus.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W11-2129", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sara, Stymne | Nicola, Cancedda", 
    "raw_text": "We used two decoders, Matrax (Simardetal., 2005) and Moses (Koehn et al, 2007), both standard statistical phrase based decoders", 
    "clean_text": "We used two decoders, Matrax (Simardetal., 2005) and Moses (Koehn et al, 2007), both standard statistical phrase based decoders.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W09-0429", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Philipp, Koehn | Barry, Haddow", 
    "raw_text": "In this paper we describe the speed improvements to the Moses decoder (Koehn et al,2007), as well as a novel framework to specify re ordering constraints with XML markup, which we tested with punctuation-based constraints", 
    "clean_text": "In this paper we describe the speed improvements to the Moses decoder (Koehn et al,2007), as well as a novel framework to specify reordering constraints with XML markup, which we tested with punctuation-based constraints.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W12-3146", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Ond&Aring;\u2122ej, Du&Aring;&iexcl;ek | David, Mare&#x10D;ek | Rudolf, Rosa", 
    "raw_text": "on parallel sentences from the Prague Czech-English Dependency Treebank (PCEDT) 2.0 (Bojar et al, 2012), comparing the gold standard Czech translations to the output of an SMT system (Koehn et al, 2007) and estimating the MaximumLikelihood probabilities of errors for each part-of speech tag", 
    "clean_text": "on parallel sentences from the Prague Czech-English Dependency Treebank (PCEDT) 2.0 (Bojar et al, 2012), comparing the gold standard Czech translations to the output of an SMT system (Koehn et al, 2007) and estimating the Maximum Likelihood probabilities of errors for each part-of-speech tag.", 
    "keep_for_gold": 0
  }
]