[
  {
    "citance_No": 1, 
    "citing_paper_id": "W06-1605", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Saif, Mohammad | Graeme, Hirst", 
    "raw_text": "Patwardhan and Pedersen (2006) create aggregate co-occurrence vectors for a WordNet sense by adding the co-occurrence vectors of the words in its WordNet gloss", 
    "clean_text": "Patwardhan and Pedersen (2006) create aggregate co-occurrence vectors for a WordNet sense by adding the co-occurrence vectors of the words in its WordNet gloss.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2087", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Tong, Wang | Graeme, Hirst", 
    "raw_text": "An extension by Patwardhan and Pedersen (2006) differentiated context word senses and extended shorter glosses with related glosses in WordNet", 
    "clean_text": "An extension by Patwardhan and Pedersen (2006) differentiated context word senses and extended shorter glosses with related glosses in WordNet.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P07-2038", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Deirdre, Hogan", 
    "raw_text": "This is because identical words occur more often in coordinate head words than in other lexical dependencies (there were 43 pairs with identical words in the coordination set, compared to 3 such pairs in the 150 SimTestncoordxcoord SDcoordnnonCoordxnonCoord SDnonCoord 95% CI p-value coordDistrib 503 0.11 0.13 485 0.06 0.09 [0.04 0.07] 0.000 (Resnik, 1995) 444 3.19 2.33 396 2.43 2.10 [0.46 1.06] 0.000 (Lin, 1998) 444 0.27 0.26 396 0.19 0.22 [0.04 0.11] 0.000 (Jiang and Conrath, 1997) 444 0.13 0.65 395 0.07 0.08 [-0.01 0.11] 0.083 (Wu and Palmer, 1994) 444 0.63 0.19 396 0.55 0.19 [0.06 0.11] 0.000 (Leacock and Chodorow, 1998) 444 1.72 0.51 396 1.52 0.47 [0.13 0.27] 0.000 (Hirst and St-Onge, 1998) 459 1.599 2.03 447 1.09 1.87 [0.25 0.76] 0.000 (Banerjee and Pedersen, 2003) 451 114.12 317.18 436 82.20 168.21 [-1.08 64.92] 0.058 (Patwardhan and Pedersen, 2006) 459 0.67 0.18 447 0.66 0.2 [-0.02 0.03] 0.545 random 483 0.89 0.17 447 0.88 0.18 [-0.02 0.02] 0.859 Table 1: Summary statistics for 9 different word similarity measures (plus one random measure) :ncoord and nnonCoord are the sample sizes for the coordinate and non-coordinate noun pairs samples, respectively ;xcoord, SDcoord and xnonCoord, SDnonCoord are the sample means and standard deviations for the two sets", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P07-2038", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Deirdre, Hogan", 
    "raw_text": "Onepossible explanation for the unsuitability of the measures of (Patwardhan and Pedersen, 2006) for the coordinate similarity task could be based on how context is defined when building context vectors", 
    "clean_text": "One possible explanation for the unsuitability of the measures of (Patwardhan and Pedersen, 2006) for the coordinate similarity task could be based on how context is defined when building context vectors.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D07-1061", 
    "citing_paper_authority": 32, 
    "citing_paper_authors": "Thad, Hughes | Daniel, Ramage", 
    "raw_text": "Other measures have been proposed that utilize the text in WordNet? s definitional glosses, such as Extended Lesk (Banerjee and Pedersen, 2003) and later the Gloss Vectors (Patwardhan and Pedersen, 2006) method", 
    "clean_text": "Other measures have been proposed that utilize the text in WordNet's definitional glosses, such as Extended Lesk (Banerjee and Pedersen, 2003) and later the Gloss Vectors (Patwardhan and Pedersen, 2006) method.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D07-1061", 
    "citing_paper_authority": 32, 
    "citing_paper_authors": "Thad, Hughes | Daniel, Ramage", 
    "raw_text": "It is worth noting that in their experiments, (Patwardhan and Pedersen, 2006) report that the Vector method has rank correlation coefficients of .91 and .90 for MC and RG, respectively, which are also top performing values", 
    "clean_text": "It is worth noting that in their experiments, (Patwardhan and Pedersen, 2006) report that the Vector method has rank correlation coefficients of .91 and .90 for MC and RG, respectively, which are also top performing values.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W11-0317", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Bridget T., McInnes | Ted, Pedersen | Ying, Liu | Serguei V., Pakhomov | Genevieve B., Melton", 
    "raw_text": "147 0 .3 0 0 0 0 0 0 dis phosphoric glucose fructose phosphoric esters changed effect 0 0 0 0 0glycolyte en zym es co m bined decreases intensity acid 0 metabolites FEATURES 0 0 0 0 .2 0 acid 0 0 0 .1 0 0 0 0 0 0 .5 0 0 esters 0 0 0 0 0 0 0 .1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 fructose 0 0 0 0 0 0 0 0 0 0 0 0 0diphosphate 0 0 0 0 0 0 isomer 0 0 0 0 0 0 0 prevalent 0 0 0 0 0 0 0 .1 0 .3 .5 .2 0 2nd order vector for Fructose Diphosphate 0 0 0 .1 0 0 Extend ed Def in iti on for Fru ct os e Diphosph at e Figure 1: 2nd Order Vector for Fructose Diphosphate (FDP) Patwardhan and Pedersen (2006) introduce a vector measure to determine the relatedness between pairs of concepts", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "S12-1097", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Luke, Stringer | Sam, Oakley | Shaabi, Mohammed | Sam, Biggins | Mark, Stevenson | Judita, Preiss", 
    "raw_text": "To take account of these similarities WordNet-based similarity measures are used (Patwardhan and Pedersen, 2006)", 
    "clean_text": "To take account of these similarities WordNet-based similarity measures are used (Patwardhan and Pedersen, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P08-3009", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Bridget T., McInnes", 
    "raw_text": "Patwardhan and Pedersen (2006) introduce a vector measure to determine the relatedness between pairs of concepts", 
    "clean_text": "Patwardhan and Pedersen (2006) introduce a vector measure to determine the relatedness between pairs of concepts.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "S12-1070", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ted, Pedersen", 
    "raw_text": "The system? generated rankings were compared with gold standard data created via Amazon Mechanical Turk.The Duluth systems relied on the Gloss Vec tor measure of semantic relatedness (Patwardhanand Pedersen, 2006) as implemented in WordNet: :Similarity (Pedersen et al, 2004) 1", 
    "clean_text": "The system generated rankings were compared with gold standard data created via Amazon Mechanical Turk.The Duluth systems relied on the Gloss Vec tor measure of semantic relatedness (Patwardhanand Pedersen, 2006) as implemented in WordNet: :Similarity (Pedersen et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W11-2502", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Alexander, Panchenko", 
    "raw_text": "(6) Extended Lesk (Banerjee and Pedersen, 2003 )mea sure is sij= ?ci? Ci ?cj? Cjsimg (ci ,cj), (7) where simg is a gloss-based similarity measure, and set Ci includes concept ci and all concepts which are directly related to it. Gloss Vectors measure (Patwardhan and Pedersen, 2006) is calculated as a cosine (9) between context vectors vi and vj of concepts ci and cj. A con text vector calculated as following: vi=?? j :cj? Gifj", 
    "clean_text": "Gloss Vectors measure (Patwardhan and Pedersen, 2006) is calculated as a cosine (9) between context vectors vi and vj of concepts ci and cj.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W11-2502", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Alexander, Panchenko", 
    "raw_text": "Patwardhan and Pedersen (2006 )evaluate six knowledge-based measures on the task of word sense disambiguation and report the same result", 
    "clean_text": "Patwardhan and Pedersen (2006) evaluate six knowledge-based measures on the task of word sense disambiguation and report the same result.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "D09-1081", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Yuval, Marton | Saif, Mohammad | Philip, Resnik", 
    "raw_text": "Mohammad and Hirst (2006) and Patwardhanand Pedersen (2006) argued that word sense ambiguity is a key reason for the poor performance of traditional distributional measures, and they pro posed hybrid approaches that are distributional in nature, but also make use of information in lexical resources such as published thesauri and WordNet", 
    "clean_text": "Mohammad and Hirst (2006) and Patwardhan and Pedersen (2006) argued that word sense ambiguity is a key reason for the poor performance of traditional distributional measures, and they proposed hybrid approaches that are distributional in nature, but also make use of information in lexical resources such as published thesauri and WordNet.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D11-1092", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ziqi, Zhang | Anna Lisa, Gentile | Fabio, Ciravegna", 
    "raw_text": "Effectively, this formalizes the notion that two concepts related to a third concept is also semantically related, which is similar to the hypothesis proposed by Patwardhan and Pedersen (2006) in their method based on second-order context vectors", 
    "clean_text": "Effectively, this formalizes the notion that two concepts related to a third concept is also semantically related, which is similar to the hypothesis proposed by Patwardhan and Pedersen (2006) in their method based on second-order context vectors.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W12-0502", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Olga, Morozova | Alexander, Panchenko", 
    "raw_text": "In addition to WktWiki, we operate with 2 baseline measures relying on WordNet glosses available in a WORDNET: :SIMILARITY package: Gloss Vectors (Patwardhan and Pedersen, 2006) 5We used JWKTL library (Zesch et al, 2008a), as an APItoWiktionary and DBpedia.org as a source of Wikipedia short abstracts (dumps were downloaded in October 2011)", 
    "clean_text": "In addition to WktWiki, we operate with 2 baseline measures relying on WordNet glosses available in a WORDNET::SIMILARITY package: Gloss Vectors (Patwardhan and Pedersen, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W07-2086", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Siddharth, Patwardhan | Satanjeev, Banerjee | Ted, Pedersen", 
    "raw_text": "For this work, we used the Context Vector measure (Patwardhan and Pedersen, 2006)", 
    "clean_text": "For this work, we used the Context Vector measure (Patwardhan and Pedersen, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W10-1308", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Xiaojuan, Ma | Christiane, Fellbaum | Perry, Cook", 
    "raw_text": "(Patwardhan and Pedersen, 2006)? cosine of the angle between the co occurrence vector computed from the definitions around the two synsets", 
    "clean_text": "(Patwardhan and Pedersen, 2006) cosine of the angle between the co-occurrence vector computed from the definitions around the two synsets.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P13-1100", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Anirban, Dasgupta | Ravi, Kumar | Sujith, Ravi", 
    "raw_text": "For each pair of nodes (u, v) in the graph, we compute the semantic similarity score (using WordNet) between every pair of dependency relation (rel: a, b) in u and v as: s (u, v)= ?reli? u ,relj? v reli=relj WN (ai ,aj)? WN (bi ,bj), where rel is a relation type (e.g. ,nsubj) and a, b are the two arguments present in the dependency relation (b does not exist for some relations) .WN (wi ,wj) is defined as the WordNet similarity score between words wi and wj .2 The edge weights are then normalized across all edges in the 2There exists various semantic relatedness measures based on WordNet (Patwardhan and Pedersen, 2006)", 
    "clean_text": "For each pair of nodes (u, v) in the graph, we compute the semantic similarity score (using WordNet) between every pair of dependency relation (rel: a, b) in u and v as: s (u, v)= reli u ,relj v reli=relj WN (ai ,aj) WN (bi ,bj), where rel is a relation type (e.g., nsubj) and a, b are the two arguments present in the dependency relation (b does not exist for some relations). WN (wi ,wj) is defined as the WordNet similarity score between words wi and wj. The edge weights are then normalized across all edges in the 2There exists various semantic relatedness measures based on WordNet (Patwardhan and Pedersen, 2006).", 
    "keep_for_gold": 0
  }
]