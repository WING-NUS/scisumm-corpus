[
  {
    "citance_No": 1, 
    "citing_paper_id": "P14-3009", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Ulukbek, Attokurov | Ulug, Bayazit", 
    "raw_text": "Term frequency (Luhn, 1958), lexical chains (Barzilay and Elhadad, 1997), location of the sentences (Edmundson, 1969) and the cue phrases (Teufel et al, 1997) are used to determine the important lexical units", 
    "clean_text": "Term frequency (Luhn, 1958), lexical chains (Barzilay and Elhadad, 1997), location of the sentences (Edmundson, 1969) and the cue phrases (Teufel et al, 1997) are used to determine the important lexical units.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P11-3014", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Charles, Greenbacker", 
    "raw_text": "Lexical chains, which capture relationships between related terms in a document, have shown promise as an intermediate representation for producing summaries (Barzilay and Elhadad, 1997)", 
    "clean_text": "Lexical chains, which capture relationships between related terms in a document, have shown promise as an intermediate representation for producing summaries (Barzilay and Elhadad, 1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W08-2206", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Irene, Cramer", 
    "raw_text": "Various applications in Natural Language Processing, such as Question Answering (Novischi and Moldovan, 2006), Topic Detection (Carthy, 2004), and Text Summarization (Barzilay and Elhadad, 1997), rely on semantic relatedness (similarity or distance) 1 measures either based on word nets and/or corpus statistics as a resource", 
    "clean_text": "Various applications in Natural Language Processing, such as Question Answering (Novischi and Moldovan, 2006), Topic Detection (Carthy, 2004), and Text Summarization (Barzilay and Elhadad, 1997), rely on semantic relatedness (similarity or distance) measures either based on word nets and/or corpus statistics as a resource.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "H05-1122", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Andrew, Olney | Zhiqiang, Cai", 
    "raw_text": "Ever since Morris and Hirst (1991)? s ground breaking paper, topic segmentation has been a steadily growing research area in computational linguistics, with applications in summarization (Barzilay and Elhadad, 1997), information retrieval (Salton and Allan, 1994), and text understanding (Kozima, 1993)", 
    "clean_text": "Ever since Morris and Hirst (1991)'s ground breaking paper, topic segmentation has been a steadily growing research area in computational linguistics, with applications in summarization (Barzilay and Elhadad, 1997), information retrieval (Salton and Allan, 1994), and text understanding (Kozima, 1993).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P07-3015", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Olena, Medelyan", 
    "raw_text": "For each top scored chain, Barzilay and Elhadad (1997) extract econometrics statistsical methods economic analysis case studies methods measurement evaluation statistical data data analysis cartography data collection surveys censures Figure 2", 
    "clean_text": "For each top scored chain, Barzilay and Elhadad (1997) extract econometrics statistsical methods economic analysis case studies methods measurement evaluation statistical data data analysis cartography data collection surveys censures Figure 2.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P06-3007", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Mingli, Wu", 
    "raw_text": "Barzilay and Elhadad (1997) segment the original text and construct lexical chains", 
    "clean_text": "Barzilay and Elhadad (1997) segment the original text and construct lexical chains that sentence which contains the first appearance of a chain member.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C04-1057", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Elena, Filatova | Vasileios, Hatzivassiloglou", 
    "raw_text": "Conceptualunits can also be defined out of more basic conceptual units, based on the co-occurrence of important concepts (Barzilay and Elhadad, 1997) or syntactic constraints between representations of concepts (Hatzivassiloglou et al, 2001)", 
    "clean_text": "Conceptual units can also be defined out of more basic conceptual units, based on the co-occurrence of important concepts (Barzilay and Elhadad, 1997) or syntactic constraints between representations of concepts (Hatzivassiloglou et al, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W03-0503", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Amardeep, Grewal | Timothy, Allison | Stanko, Dimitrov | Dragomir R., Radev", 
    "raw_text": "A number of techniques for choosing the right sentences to extract have been proposed in the literature, ranging from word counts (Luhn, 1958), key phrases (Edmundson, 1969), naive Bayesian classification (Kupiec et al, 1995), lexical chains (Barzilay and Elhadad, 1997), topic signatures (Hovy and Lin, 1999) and cluster centroids (Radev et al, 2000)", 
    "clean_text": "A number of techniques for choosing the right sentences to extract have been proposed in the literature, ranging from word counts (Luhn, 1958), key phrases (Edmundson, 1969), naive Bayesian classification (Kupiec et al, 1995), lexical chains (Barzilay and Elhadad, 1997), topic signatures (Hovy and Lin, 1999) and cluster centroids (Radev et al, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W10-1907", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Laura, Plaza | Mark, Stevenson | Alberto, D&iacute;az", 
    "raw_text": "In particular, in the biomedical domain Reeve et al (2007) adapt the lexical chaining approach (Barzilay and Elhadad, 1997) to work with UMLS concepts, using the MetaMap Transfer Tool to annotate these concepts", 
    "clean_text": "In particular, in the biomedical domain Reeve et al (2007) adapt the lexical chaining approach (Barzilay and Elhadad, 1997) to work with UMLS concepts, using the MetaMap Transfer Tool to annotate these concepts.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W06-0205", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ga&euml;l, Dias | Claudia, Santos | Guillaume, Cleuziou", 
    "raw_text": "In particular, they have successfully been used in the field of Automatic Text Summarization (Barzilay and Elhadad, 1997)", 
    "clean_text": "In particular, they have successfully been used in the field of Automatic Text Summarization (Barzilay and Elhadad, 1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W06-0205", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ga&euml;l, Dias | Claudia, Santos | Guillaume, Cleuziou", 
    "raw_text": "But, as Barzilay and Elhadad (1997) point at, the use of a part-of-speech tagger could eliminate wrong inclusions of words such as read, which has both noun and verb entries in WordNet", 
    "clean_text": "But, as Barzilay and Elhadad (1997) point at, the use of a part-of-speech tagger could eliminate wrong inclusions of words such as read, which has both noun and verb entries in WordNet.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W06-0205", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ga&euml;l, Dias | Claudia, Santos | Guillaume, Cleuziou", 
    "raw_text": "So, Barzilay and Elhadad (1997) propose the first dynamic method to compute Lexical Chains", 
    "clean_text": "So, Barzilay and Elhadad (1997) propose the first dynamic method to compute Lexical Chains.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W06-0205", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ga&euml;l, Dias | Claudia, Santos | Guillaume, Cleuziou", 
    "raw_text": "However, this method of retaining all possible interpretations until the end of the process, causes the exponential growth of the time and space complexity. As a consequence, Silber and McCoy (2002) pro pose a linear time version of (Barzilay and Elhadad,1997) lexical chaining algorithm", 
    "clean_text": "As a consequence, Silber and McCoy (2002) propose a linear time version of (Barzilay and Elhadad, 1997) lexical chaining algorithm.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W06-0205", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ga&euml;l, Dias | Claudia, Santos | Guillaume, Cleuziou", 
    "raw_text": "Their evaluation shows that their algorithm is more accurate than (Barzilay and Elhadad, 1997) and (Silber and Mc Coy, 2002) ones. One common point of all these works is that Lexical Chains are built using WordNet as the standard linguistic resource", 
    "clean_text": "Their evaluation shows that their algorithm is more accurate than (Barzilay and Elhadad, 1997) and (Silber and McCoy, 2002) ones.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W06-0205", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Ga&euml;l, Dias | Claudia, Santos | Guillaume, Cleuziou", 
    "raw_text": "Like in (Barzilay and Elhadad, 1997), we define a chain score which is defined in Equation 16 where |chain| is the number of words in the chain", 
    "clean_text": "Like in (Barzilay and Elhadad, 1997), we define a chain score which is defined in Equation 16 where |chain| is the number of words in the chain.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W12-4303", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Awais, Athar | Simone, Teufel", 
    "raw_text": "A more fine-grained model of coherence might include proper anaphora resolution (Lee et al, 2011), which is still an unsolved task for scientific texts, and also include models of lexical coherence such as lexical chains (Barzilay and Elhadad, 1997) and entity coherence (Barzilay and Lapata, 2008)", 
    "clean_text": "A more fine-grained model of coherence might include proper anaphora resolution (Lee et al, 2011), which is still an unsolved task for scientific texts, and also include models of lexical coherence such as lexical chains (Barzilay and Elhadad, 1997) and entity coherence (Barzilay and Lapata, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P08-1116", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Shiqi, Zhao | Cheng, Niu | Ming, Zhou | Ting, Liu | Sheng, Li", 
    "raw_text": "Some researchers extract synonyms as paraphrases (Kauchak and Barzilay, 2006), while some others use looser definitions, such as hypernyms and holonyms (Barzilay and Elhadad, 1997)", 
    "clean_text": "Some researchers extract synonyms as paraphrases (Kauchak and Barzilay, 2006), while some others use looser definitions, such as hypernyms and holonyms (Barzilay and Elhadad, 1997).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W03-1610", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Hua, Wu | Ming, Zhou", 
    "raw_text": "In automatic text summarization, synonymous words are employed to identify repetitive information in order to avoid redundant contents in a summary (Barzilay and Elhadad, 1997)", 
    "clean_text": "In automatic text summarization, synonymous words are employed to identify repetitive information in order to avoid redundant contents in a summary (Barzilay and Elhadad, 1997).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "C08-1009", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Samuel, Brody | Mirella, Lapata", 
    "raw_text": "Examples include summarization (Barzilay and Elhadad, 1997), question answering (Ramakrishnan et al, 2003) and machine translation (Chan and Ng, 2007) .WSD is commonly treated as a supervised classification task", 
    "clean_text": "Examples include summarization (Barzilay and Elhadad, 1997), question answering (Ramakrishnan et al, 2003) and machine translation (Chan and Ng, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W07-2106", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Yllias, Chali | Shafiq R., Joty", 
    "raw_text": "Cohesion is achieved through the use in the text of semantically related terms, reference, ellipse and conjunctions (Barzilay and Elhadad, 1997)", 
    "clean_text": "Cohesion is achieved through the use in the text of semantically related terms, reference, ellipse and conjunctions (Barzilay and Elhadad, 1997).", 
    "keep_for_gold": 1
  }
]