This paper examines how the differences in modelling between different data driven systems performing the same NLP task can be exploited to yield a higher accuracy than the best individual system.This paper is concerned with the question whether the differences between models can indeed be exploited to yield a data driven model with superior performance.the approach is known as ensemble, stacked, or combined classifiers.the approach is applied mopho-syntactic wordclass tagging.for this purpose a traditional trig-ram model,the Transformation Based Learning system,Memory-Based Learning and the MXPOST system are used.the tagged LOB corpus has been used for data.The pairwise voting system, using all four individual taggers, scores 97.92% correct on Test, a 19.1% reduction in error rate over the best individual system, viz. the Maximum Entropy tagger (97.43%).the writers believe that there is still some room for improvement and this approach can be extended to other NLP tasks.