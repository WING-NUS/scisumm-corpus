Named Entity Recognition With Character-Level Models
We discuss two named-entity recognition models which use characters and character n-grams either exclusively or as an important part of their data representation.
The first model is a character-level HMM with minimal context information, and the second model is a maximum-entropy conditional markov model with substantially richer context features.
Our best model achieves an overall F1 of 86.07% on the English test data (92.31% on the development data).
This number represents a 25% error reduction over the same model without word-internal (substring) features.
We find that the introduction of character n-gram features improved the overall F1 score by over 20%.
