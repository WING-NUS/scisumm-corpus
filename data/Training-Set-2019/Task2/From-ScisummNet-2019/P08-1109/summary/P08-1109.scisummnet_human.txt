Efficient Feature-based Conditional Random Field Parsing
Discriminative feature-based methods are widely used in natural language processing, but sentence parsing is still dominated by generative methods.
While prior feature-based dynamic programming parsers have restricted training and evaluation to artificially short sentences, we present the first general, feature rich discriminative parser, based on a conditional random field model, which has been successfully scaled to the full WSJ parsing data.
Our efficiency is primarily due to the use of stochastic optimization techniques, as well as parallelization and chart prefiltering.
On WSJ15, we attain a state-of-the-art F-score of 90.9%, a 14% relative reduction in error over previous models, while being two orders of magnitude faster.
On sentences of length 40, our system achieves an F-score of 89.0%, a 36% relative reduction in error over a generative baseline.
In our model, distributed online learning has been done in a synchronous setting, meaning that a mini-batch of data is divided among multiple CPUs, and the model is updated when they have all completed processing (Finkel et al, 2008).
