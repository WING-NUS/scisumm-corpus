[
  {
    "citance_No": 1, 
    "citing_paper_id": "P14-2081", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hao, Li | Wei, Liu | Heng, Ji", 
    "raw_text": "NNS is essential in dealing with many search related tasks, and also fundamental to a broad range of Natural Language Processing (NLP) downstream problems including person name spelling correction (Udupa and Ku mar, 2010), document translation pair acquisition (Krstovski and Smith, 2011), large-scale similar noun list generation (Ravichandran et al, 2005), lexical variants mining (Gouws et al, 2011), and large-scale first story detection (Petrovic et al, 2010)", 
    "clean_text": "NNS is essential in dealing with many search related tasks, and also fundamental to a broad range of Natural Language Processing (NLP) downstream problems including person name spelling correction (Udupa and Kumar, 2010), document translation pair acquisition (Krstovski and Smith, 2011), large-scale similar noun list generation (Ravichandran et al, 2005), lexical variants mining (Gouws et al, 2011), and large-scale first story detection (Petrovic et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W11-2504", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Tsz Ping, Chan | Chris, Callison-Burch | Benjamin, van Durme", 
    "raw_text": "In order to scale to this size of a collection, we relied on Locality Sensitive Hashing (LSH), as was done previously by Ravichandran et al (2005) and Bhagat and Ravichandran (2008)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P08-1077", 
    "citing_paper_authority": 22, 
    "citing_paper_authors": "Rahul, Bhagat | Deepak, Ravichandran", 
    "raw_text": "Ravichandran et al (2005) have shown that by using the LSH nearest neighbors calculation can be done in O (nd )time.1", 
    "clean_text": "Ravichandran et al (2005) have shown that by using the LSH nearest neighbors calculation can be done in O (nd) time.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P12-1041", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Mohit, Bansal | Dan, Klein", 
    "raw_text": "III and Marcu (2005), who use word class features derived from a Web-scale corpus via a process described in Ravichandran et al (2005)", 
    "clean_text": "III and Marcu (2005), who use word class features derived from a Web-scale corpus via a process described in Ravichandran et al (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P06-1101", 
    "citing_paper_authority": 69, 
    "citing_paper_authors": "Rion, Snow | Daniel, Jurafsky | Andrew Y., Ng", 
    "raw_text": "Our classifier for (m, n) -cousins is derived from the algorithm and corpus given in (Ravichandran et al, 2005)", 
    "clean_text": "Our classifier for (m, n)-cousins is derived from the algorithm and corpus given in (Ravichandran et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P07-1088", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Doug, Downey | Stefan, Schoenmackers | Oren, Etzioni", 
    "raw_text": "(Ravichandran et al, 2005))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P06-1046", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "Charikar (2002) proposed an approximation of the cosine measure using random hyperplanes Ravichandran et al (2005) used this co sine variant and showed it to produce over 70% accuracy in extracting synonyms when compared against Pantel and Lin (2002)", 
    "clean_text": "Ravichandran et al (2005) used this cosine variant and showed it to produce over 70% accuracy in extracting synonyms when compared against Pantel and Lin (2002).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P06-1046", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "It was used byRavichandran et al (2005) to improve the efficiency of distributional similarity calculations", 
    "clean_text": "It was used by Ravichandran et al (2005) to improve the efficiency of distributional similarity calculations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P06-1046", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "For LSH we chose d= 3, 000 (LSH3,000) and 10, 000 (LSH10,000), showing the effect of changing the dimensionality. The frequency statistics were weighted using mutual information, as in Ravichandran et al (2005): log (p (w, r, w?) p (w,?,?) p (?, r, w?)) (10) PLEB used the values q= 500 and B= 100", 
    "clean_text": "The frequency statistics were weighted using mutual information, as in Ravichandran et al (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P06-1046", 
    "citing_paper_authority": 18, 
    "citing_paper_authors": "James, Gorman | James R., Curran", 
    "raw_text": "When the cut-off was increased to 100, as used by Ravichandran et al (2005), the results improved significantly", 
    "clean_text": "When the cut-off was increased to 100, as used by Ravichandran et al (2005), the results improved significantly.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D11-1122", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Joel, Lang | Mirella, Lapata", 
    "raw_text": "We used randomized algorithms (Ravichandran et al, 2005) to build the semantic space efficiently. Comparison Models We compared our graph partitioning algorithm against three competitive approaches", 
    "clean_text": "We used randomized algorithms (Ravichandran et al, 2005) to build the semantic space efficiently.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "N10-1021", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Sa&scaron;a, Petrovi&#x107; | Miles, Osborne | Victor, Lavrenko", 
    "raw_text": "This scheme was used ,e.g., for creating similarity lists of nouns collected from a web corpus in Ravichandran et al (2005)", 
    "clean_text": "This scheme was used, e.g., for creating similarity lists of nouns collected from a web corpus in Ravichandran et al (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "C10-1096", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Naoaki, Okazaki | Jun'ichi, Tsujii", 
    "raw_text": "? Locality Sensitive Hashing (LSH) (Andoniand Indyk, 2008): This baseline system follows the design of previous work (Ravichandran et al, 2005)", 
    "clean_text": "This baseline system follows the design of previous work (Ravichandran et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C10-1096", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Naoaki, Okazaki | Jun'ichi, Tsujii", 
    "raw_text": "Weselected the parameter with the fastest response.3We followed the notation of the original pa per (Ravichandran et al, 2005) here", 
    "clean_text": "We followed the notation of the original paper (Ravichandran et al, 2005) here.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-1096", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Naoaki, Okazaki | Jun'ichi, Tsujii", 
    "raw_text": "Ravichandran et al (2005 )ap plied LSH to the task of noun clustering", 
    "clean_text": "Ravichandran et al (2005) applied LSH to the task of noun clustering.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D12-1098", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Raul, Guerra | Amit, Goyal | Hal, Daum&eacute; III", 
    "raw_text": "However, Ravichandran et al (2005) approach stored an enormous matrix of all unique words and their contexts in main memory, which is infeasible for very large data sets", 
    "clean_text": "However, Ravichandran et al (2005) approach stored an enormous matrix of all unique words and their contexts in main memory, which is infeasible for very large data sets.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D12-1098", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Raul, Guerra | Amit, Goyal | Hal, Daum&eacute; III", 
    "raw_text": "In practice p is generally large, Ravichandran et al (2005) used p= 1000 in their work", 
    "clean_text": "In practice p is generally large, Ravichandran et al (2005) used p= 1000 in their work.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "D12-1098", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Raul, Guerra | Amit, Goyal | Hal, Daum&eacute; III", 
    "raw_text": "Data sets: We use two data sets: Gigaword (Graff, 2003) and a copy of news web (Ravichandran et al., 2005)", 
    "clean_text": "Data sets: We use two data sets: Gigaword (Graff, 2003) and a copy of news web (Ravichandran et al., 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D12-1098", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Raul, Guerra | Amit, Goyal | Hal, Daum&eacute; III", 
    "raw_text": "LSH provides an upper boundon the performance of our approximate search representations (IRP, PLEB, and FAST-PLEB) for fast search from Section 3.3). We set the number of projections k= 3000 for all three methods and forPLEB and FAST-PLEB, we set number of permutations p= 1000 as used in large-scale noun clustering work (Ravichandran et al 2005) .Evaluation Metric: We use two kinds of measures, recall and Pearson? s correlation to measure the overlap in the approximate and exact similarity lists", 
    "clean_text": "We set the number of projections k= 3000 for all three methods and for PLEB and FAST-PLEB, we set number of permutations p= 1000 as used in large-scale noun clustering work (Ravichandran et al 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "N09-1058", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Amit, Goyal | Hal, Daum&eacute; III | Suresh, Venkatasubramanian", 
    "raw_text": "Language modeling (Chen and Goodman, 1996), noun-clustering (Ravichandran et al, 2005), constructing syntactic rules for SMT (Galley et al, 2004), and finding analogies (Turney, 2008) are examples of some of the problems where we need to compute relative frequencies", 
    "clean_text": "Language modeling (Chen and Goodman, 1996), noun-clustering (Ravichandran et al, 2005), constructing syntactic rules for SMT (Galley et al, 2004), and finding analogies (Turney, 2008) are examples of some of the problems where we need to compute relative frequencies.", 
    "keep_for_gold": 0
  }
]