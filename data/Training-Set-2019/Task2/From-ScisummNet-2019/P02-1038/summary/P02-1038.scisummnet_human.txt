Discriminative Training And Maximum Entropy Models For Statistical Machine Translation
We present a framework for statistical machine translation of natural languages based on direct maximum entropy models, which contains the widely used source-channel approach as a special case.
All knowledge sources are treated as feature functions, which depend on the source language sentence, the target language sentence and possible hidden variables.
This approach allows a baseline machine translation system to be extended easily by adding new feature functions.
We show that a baseline statistical machine translation system is significantly improved using this approach.
