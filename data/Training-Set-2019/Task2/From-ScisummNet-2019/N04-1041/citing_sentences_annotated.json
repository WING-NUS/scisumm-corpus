[
  {
    "citance_No": 1, 
    "citing_paper_id": "C04-1111", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Patrick, Pantel | Deepak, Ravichandran | Eduard, Hovy", 
    "raw_text": "We present an algorithm for extracting is-a relations, designed for the terascale, and compare it to a state of the art method that employs deep analysis of text (Pantel and Ravichandran 2004)", 
    "clean_text": "We present an algorithm for extracting is-a relations, designed for the terascale, and compare it to a state of the art method that employs deep analysis of text (Pantel and Ravichandran 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "C04-1111", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Patrick, Pantel | Deepak, Ravichandran | Eduard, Hovy", 
    "raw_text": "Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun", 
    "clean_text": "Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "C04-1111", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Patrick, Pantel | Deepak, Ravichandran | Eduard, Hovy", 
    "raw_text": "Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC", 
    "clean_text": "Our co-occurrence model (Pantel and Ravichandran 2004) makes use of semantic classes like those generated by CBC.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C04-1111", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Patrick, Pantel | Deepak, Ravichandran | Eduard, Hovy", 
    "raw_text": "These relationships, automatically learned in (Pantel and Ravichandran 2004), include appositions, nominal subjects, such as relationships, and like relationships", 
    "clean_text": "These relationships, automatically learned in (Pantel and Ravichandran 2004), include appositions, nominal subjects, such as relationships, and like relationships.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C04-1111", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Patrick, Pantel | Deepak, Ravichandran | Eduard, Hovy", 
    "raw_text": "The syntactical co-occurrence approach has worst-case time complexity O (n2k), where n is the number of words in the corpus and k is the feature space (Pantel and Ravichandran 2004)", 
    "clean_text": "The syntactical co-occurrence approach has worst-case time complexity O (n2k), where n is the number of words in the corpus and k is the feature space (Pantel and Ravichandran 2004).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P10-1160", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Matthew, Gerber | Joyce, Chai", 
    "raw_text": "Like Chambers and Jurafsky, we also used the discounting method suggested by Pantel and Ravichandran (2004) for low frequency observations", 
    "clean_text": "Like Chambers and Jurafsky, we also used the discounting method suggested by Pantel and Ravichandran (2004) for low frequency observations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P11-1154", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Jey Han, Lau | Karl, Grieser | David, Newman | Timothy, Baldwin", 
    "raw_text": "Pantel and Ravichandran (2004) addressed the more specific task of labelling a semantic class by applying Hearst-stylelexico-semantic patterns to each member of that class", 
    "clean_text": "Pantel and Ravichandran (2004) addressed the more specific task of labelling a semantic class by applying Hearst-style lexico-semantic patterns to each member of that class.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W08-1807", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Lonneke, van der Plas | J&ouml;rg, Tiedemann", 
    "raw_text": "Pantel and Ravichandran (2004) have used a method that is not related to query expansion, but yet very related to our work", 
    "clean_text": "Pantel and Ravichandran (2004) have used a method that is not related to query expansion, but yet very related to our work.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C10-1058", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Alpa, Jain | Marco, Pennacchiotti", 
    "raw_text": "We then compute the corrected point wise mutual information (cpmi) (Pan tel and Ravichandran, 2004) between each instance and each context c as :cpmi (e, c) =log2 f (e, c)? f (?,?) f (e)? f (c)? M (1) where f (e, c) is the number of times e and c occur in the same query; f (e) and f (c) is the count of the entity and the context in the query log; f (?,?) the overall count of all co-occurrences between contexts and entities; and M is the correction factor presented in (Pantel and Ravichandran, 2004), that eases the pmi? s bias towards infrequent entities/features", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "E09-3004", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Aur&eacute;lie, Herbelot", 
    "raw_text": "Lin et al (2003) and Pantel and Ravichandran (2004) have proposed to classify the output of systems based on feature vectors using lexico-syntactic patterns, respectively in order to remove antonyms from a related words list and to name clusters of related terms", 
    "clean_text": "Lin et al (2003) and Pantel and Ravichandran (2004) have proposed to classify the output of systems based on feature vectors using lexico-syntactic patterns, respectively in order to remove antonyms from a related words list and to name clusters of related terms.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P08-1090", 
    "citing_paper_authority": 37, 
    "citing_paper_authors": "Nathanael, Chambers | Daniel, Jurafsky", 
    "raw_text": "to penalize low occuring words (Pantel and Ravichandran, 2004) .Given the debate over appropriate metrics for distributional learning, we also experimented with the t-test", 
    "clean_text": "We also adopt the 'discount score' to penalize low occuring words (Pantel and Ravichandran, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P06-2075", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Shachar, Mirkin | Ido, Dagan | Maayan, Zhitomirsky-Geffet", 
    "raw_text": "Few recent attempts on related (though different) tasks were made to classify (Lin et al, 2003) and label (Pantel and Ravichandran, 2004) distributional similarity output using lexical-syntactic patterns, in a pipeline architecture", 
    "clean_text": "Few recent attempts on related (though different) tasks were made to classify (Lin et al, 2003) and label (Pantel and Ravichandran, 2004) distributional similarity output using lexical-syntactic patterns, in a pipeline architecture.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P08-1003", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Marius, Pa&scedil;ca | Benjamin, van Durme", 
    "raw_text": "First, instead of separately addressing the tasks of collecting unlabeled sets of instances (Lin, 1998), assigning appropriate class labels to a given set of instances (Pantel and Ravichandran, 2004), and identifying relevant attributes for a given set of classes (Pas? ca, 2007), our integrated method from Section 2 enables the simultaneous extraction of class instances, associated labels and attributes", 
    "clean_text": "First, instead of separately addressing the tasks of collecting unlabeled sets of instances (Lin, 1998), assigning appropriate class labels to a given set of instances (Pantel and Ravichandran, 2004), and identifying relevant attributes for a given set of classes (Pasca, 2007), our integrated method from Section 2 enables the simultaneous extraction of class instances, associated labels and attributes.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P08-1003", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Marius, Pa&scedil;ca | Benjamin, van Durme", 
    "raw_text": "Givenpre-existing sets of instances, (Pantel and Ravichandran, 2004) investigates the task of acquiring appropriate class labels to the sets from unstructured text", 
    "clean_text": "Given pre-existing sets of instances, (Pantel and Ravichandran, 2004) investigates the task of acquiring appropriate class labels to the sets from unstructured text.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-2110", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Marius, Pa&scedil;ca", 
    "raw_text": "In (Pantel and Ravichandran, 2004), given a collection of news articles that is both cleaner and smaller than Web document collections, a syn tactic parser is applied to document sentences in order to identify and exploit syntactic dependencies for the purpose of selecting candidate class labels", 
    "clean_text": "In (Pantel and Ravichandran, 2004), given a collection of news articles that is both cleaner and smaller than Web document collections, a syntactic parser is applied to document sentences in order to identify and exploit syntactic dependencies for the purpose of selecting candidate class labels.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P06-1015", 
    "citing_paper_authority": 74, 
    "citing_paper_authors": "Patrick, Pantel | Marco, Pennacchiotti", 
    "raw_text": "Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun", 
    "clean_text": "Recently, Pantel and Ravichandran (2004) extended this approach by making use of all syntactic dependency features for each noun.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P06-1015", 
    "citing_paper_authority": 74, 
    "citing_paper_authors": "Patrick, Pantel | Marco, Pennacchiotti", 
    "raw_text": "We thus multiply pmi (i, p) with the discounting factor suggested in (Pantel and Ravichandran 2004)", 
    "clean_text": "We thus multiply pmi (i, p) with the discounting factor suggested in (Pantel and Ravichandran 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P05-2025", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Anagha, Kulkarni", 
    "raw_text": "(Pantel and Ravichandran, 2004) have proposed an algorithm for labeling semantic classes, which can be viewed as a form of cluster", 
    "clean_text": "(Pantel and Ravichandran, 2004) have proposed an algorithm for labeling semantic classes, which can be viewed as a form of cluster.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W09-1116", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Shane, Bergsma | Dekang, Lin | Randy, Goebel", 
    "raw_text": "Pantel and Ravichandran (2004) note that the nouns computer and company both have a WordNet sense that is a hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she", 
    "clean_text": "Pantel and Ravichandran (2004) note that the nouns computer and company both have a WordNet sense that is a hyponym of person, falsely indicating these nouns would be compatible with pronouns like he or she.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "C10-1095", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Jong-Hoon, Oh | Ichiro, Yamada | Kentaro, Torisawa | Stijn, De Saeger", 
    "raw_text": "We use PMI (point-wise mutual information) of hyponymy relation candidate (hyper, hypo) as a collocation feature (Pantel and Ravichandran, 2004), where we assume that hyper and hypo in candidates would frequently co-occur in the same sentence if they hold a hyponymy relation", 
    "clean_text": "We use PMI (point-wise mutual information) of hyponymy relation candidate (hyper, hypo) as a collocation feature (Pantel and Ravichandran, 2004), where we assume that hyper and hypo in candidates would frequently co-occur in the same sentence if they hold a hyponymy relation.", 
    "keep_for_gold": 0
  }
]