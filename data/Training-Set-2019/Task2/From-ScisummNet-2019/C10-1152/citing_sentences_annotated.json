[
  {
    "citance_No": 1, 
    "citing_paper_id": "D11-1038", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Kristian, Woodsend | Mirella, Lapata", 
    "raw_text": "When compared against current state of-the-art methods (Zhu et al, 2010) our model yields significantly simpler output that is both grammatical and meaning preserving", 
    "clean_text": "When compared against current state of-the-art methods (Zhu et al, 2010) our model yields significantly simpler output that is both grammatical and meaning preserving.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "D11-1038", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Kristian, Woodsend | Mirella, Lapata", 
    "raw_text": "Zhu et al (2010) also use Wikipedia to learn a sentence simplification model which is able to perform four rewrite operations, namely substitution, reordering, splitting, and deletion", 
    "clean_text": "Zhu et al (2010) also use Wikipedia to learn a sentence simplification model which is able to perform four rewrite operations, namely substitution, reordering, splitting, and deletion.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D11-1038", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Kristian, Woodsend | Mirella, Lapata", 
    "raw_text": "In contrast to Yatskar et al (2010) and Zhuet al (2010), simplification operations (e.g., substitution or splitting) are not modeled explicitly; instead, we leave it up to our grammar extraction algorithm to learn appropriate rules that reflect the training data", 
    "clean_text": "In contrast to Yatskar et al (2010) and Zhu et al (2010), simplification operations (e.g., substitution or splitting) are not modeled explicitly; instead, we leave it up to our grammar extraction algorithm to learn appropriate rules that reflect the training data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D11-1038", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Kristian, Woodsend | Mirella, Lapata", 
    "raw_text": "Evaluation We evaluated our model on the same dataset used in Zhu et al (2010), an aligned corpus of MainEW and SimpleEW sentences", 
    "clean_text": "We evaluated our model on the same dataset used in Zhu et al (2010), an aligned corpus of MainEW and SimpleEW sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D11-1038", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Kristian, Woodsend | Mirella, Lapata", 
    "raw_text": "However, we refrained from doing so as Zhu et al (2010) show that Moses performs poorly, it can not model rewrite operations that split sentences or drop words and in most cases generates output identical 6We are grateful to Zhemin Zhu for providing us with his test set and the output of his system", 
    "clean_text": "However, we refrained from doing so as Zhu et al (2010) show that Moses performs poorly, it can not model rewrite operations that split sentences or drop words and in most cases generates output identical.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D11-1038", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Kristian, Woodsend | Mirella, Lapata", 
    "raw_text": "AlignILP is most different from the reference, followed by Zhu et al (2010) and RevILP", 
    "clean_text": "AlignILP is most different from the reference, followed by Zhu et al (2010) and RevILP.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D11-1038", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Kristian, Woodsend | Mirella, Lapata", 
    "raw_text": "Zhu et al (2010) is the least grammatical model. Finally, RevILP preserves the meaning of the tar get as well as SimpleEW, whereas Zhu et al yields the most distortions", 
    "clean_text": "Zhu et al (2010) is the least grammatical model. Finally, RevILP preserves the meaning of the target as well as SimpleEW, whereas Zhu et al yields the most distortions.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D11-1038", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Kristian, Woodsend | Mirella, Lapata", 
    "raw_text": "Our results also show that a more general model not restricted to specific rewrite operations like Zhu et al (2010) obtains superior results and has better coverage", 
    "clean_text": "Our results also show that a more general model not restricted to specific rewrite operations like Zhu et al (2010) obtains superior results and has better coverage.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W12-2910", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "David, Figueroa | Stefan, Bott | Horacio, Saggion", 
    "raw_text": "Zhu et al (2010), for example, use a tree-based simplification model which uses techniques from statistical ma chine translation (SMT) with this data set", 
    "clean_text": "Zhu et al (2010), for example, use a tree-based simplification model which uses techniques from statistical machine translation (SMT) with this data set.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W12-2910", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "David, Figueroa | Stefan, Bott | Horacio, Saggion", 
    "raw_text": "This system can handle sentence splitting operations and the authors use both automatic and human evaluation and show an improvement over the results of Zhu et al (2010) on the same data set, but they have to admit that learning from parallel bi-text is not as efficient as learning from revision histories of the Wiki-pages", 
    "clean_text": "This system can handle sentence splitting operations and the authors use both automatic and human evaluation and show an improvement over the results of Zhu et al (2010) on the same data set, but they have to admit that learning from parallel bi-text is not as efficient as learning from revision histories of the Wiki-pages.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W11-1601", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "William, Coster | David, Kauchak", 
    "raw_text": "Our work extends recent work by Zhu et al (2010) that also examines Wikipedia/Simple English Wikipedia as a data-driven, sentence simplification task", 
    "clean_text": "Our work extends recent work by Zhu et al (2010) that also examines Wikipedia/Simple English Wikipedia as a data-driven, sentence simplification task.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W11-1601", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "William, Coster | David, Kauchak", 
    "raw_text": "Our approach performs significantly better than two different text compression approaches, including T3, and better than previous approaches on a similar data set (Zhu et al, 2010)", 
    "clean_text": "Our approach performs significantly better than two different text compression approaches, including T3, and better than previous approaches on a similar data set (Zhu et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P12-1107", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Sander, Wubben | Antal, van den Bosch | Emiel, Krahmer", 
    "raw_text": "There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al, 2003) .Zhu et al (2010) examine the use of paired documents in English Wikipedia and Simple Wikipediafor a data-driven approach to the sentence simplification task", 
    "clean_text": "There has also been work on lexical substitution for simplification, where the aim is to substitute difficult words with simpler synonyms, derived from WordNet or dictionaries (Inui et al, 2003). Zhu et al (2010) examine the use of paired documents in English Wikipedia and Simple Wikipediafor a data-driven approach to the sentence simplification task.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P12-1107", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Sander, Wubben | Antal, van den Bosch | Emiel, Krahmer", 
    "raw_text": "We follow Zhu et al (2010) and CosterandKauchak (2011) in proposing that sentence simplification can be approached as a monolingual ma chine translation task, where the source and target languages are the same and where the output should be simpler in form from the input but similar in meaning", 
    "clean_text": "We follow Zhu et al (2010) and Coster and Kauchak (2011) in proposing that sentence simplification can be approached as a monolingual machine translation task, where the source and target languages are the same and where the output should be simpler in form from the input but similar in meaning.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P12-1107", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Sander, Wubben | Antal, van den Bosch | Emiel, Krahmer", 
    "raw_text": "Table 1.1 shows the average sentence length and the average 1http: //simple.wikipedia.org/wiki/Main_ Page/Introduction word length for Wikipedia and Simple Wikipedia sentences in the PWKP dataset used in this study (Zhu et al, 2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P12-1107", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Sander, Wubben | Antal, van den Bosch | Emiel, Krahmer", 
    "raw_text": "length Token length Simple Wikipedia 20.87 4.89 Wikipedia 25.01 5.06 Table 1: Sentence and token length statistics for the PWKP dataset (Zhu et al, 2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P12-1107", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Sander, Wubben | Antal, van den Bosch | Emiel, Krahmer", 
    "raw_text": "While Zhu et al (2010) have demonstrated that their approach outperforms a PBMT approach in terms of Flesch Reading Ease test scores, we arenot aware of any studies that evaluate PBMT for sentence simplification with human judgements", 
    "clean_text": "While Zhu et al (2010) have demonstrated that their approach outperforms a PBMT approach in terms of Flesch Reading Ease test scores, we are not aware of any studies that evaluate PBMT for sentence simplification with human judgements.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P12-1107", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Sander, Wubben | Antal, van den Bosch | Emiel, Krahmer", 
    "raw_text": "In this study we evaluate the output of Zhu et al (2010) (henceforth referred to as? Zhu?), Woodsend and Lapata (2011) (henceforth referred to as? RevILP?), our PBMT based system with dissimilarity-based re-ranking (henceforth referred to as? PBMT-R?), a word-substitution baseline, and, as a gold standard, the original Simple Wikipedia sentences", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P12-1107", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Sander, Wubben | Antal, van den Bosch | Emiel, Krahmer", 
    "raw_text": "2.2 Zhu et al. Zhu et al (2010) learn a sentence simplification model which is able to perform four rewrite operations on the parse trees of the input sentences, namely substitution, reordering, splitting, and deletion", 
    "clean_text": "Zhu et al (2010) learn a sentence simplification model which is able to perform four rewrite operations on the parse trees of the input sentences, namely substitution, reordering, splitting, and deletion.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P12-1107", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Sander, Wubben | Antal, van den Bosch | Emiel, Krahmer", 
    "raw_text": "Zhu et al (2010) evaluate their system usingBLEU and NIST scores, as well as various read ability scores that only take into account the output sentence, such as the Flesch Reading Ease test and n-gram language model perplexity", 
    "clean_text": "Zhu et al (2010) evaluate their system using BLEU and NIST scores, as well as various readability scores that only take into account the output sentence, such as the Flesch Reading Ease test and n-gram language model perplexity.", 
    "keep_for_gold": 0
  }
]