[
  {
    "citance_No": 1, 
    "citing_paper_id": "W09-1702", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Azniah, Ismail | Suresh, Manandhar", 
    "raw_text": "Haghighi et al (2008) mention one disadvantage of using edit distance, that is, precision quickly degrades with higher recall", 
    "clean_text": "Haghighi et al (2008) mention one disadvantage of using edit distance, that is, precision quickly degrades with higher recall.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W09-1702", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Azniah, Ismail | Suresh, Manandhar", 
    "raw_text": "Haghighi et al (2008), amongst a few others, propose using canonical correlation analysis to reduce the dimension", 
    "clean_text": "Haghighi et al (2008), amongst a few others, propose using canonical correlation analysis to reduce the dimension.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W09-1702", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Azniah, Ismail | Suresh, Manandhar", 
    "raw_text": "Haghighi et al (2008) only use a small-sized bilingual lexicon containing 100 word pairs as seed lexicon", 
    "clean_text": "Haghighi et al (2008) only use a small-sized bilingual lexicon containing 100 word pairs as seed lexicon.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W09-1702", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Azniah, Ismail | Suresh, Manandhar", 
    "raw_text": "Examples can be found in Fung and Cheung (2004), followed by Haghighi et al (2008)", 
    "clean_text": "Examples can be found in Fung and Cheung (2004), followed by Haghighi et al (2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W09-1702", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Azniah, Ismail | Suresh, Manandhar", 
    "raw_text": "Haghighi et al (2008) have reported that the most common errors detected in their analysis on top 100 errors were from semantically related words, which had strong context feature correlations", 
    "clean_text": "Haghighi et al (2008) have reported that the most common errors detected in their analysis on top 100 errors were from semantically related words, which had strong context feature correlations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P14-1006", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Karl Moritz, Hermann | Philip, Blunsom", 
    "raw_text": "Earlier work, Haghighi et al (2008), proposed a method for inducing bilingual lexica using monolingual feature rep re sentations and a small initial lexicon to bootstrap with", 
    "clean_text": "Earlier work, Haghighi et al (2008), proposed a method for inducing bilingual lexica using monolingual feature representations and a small initial lexicon to bootstrap with.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "N10-1073", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Raghavendra, Udupa | Mitesh M., Khapra", 
    "raw_text": "CCA has been used in bilingual lexicon extraction from comparable corpora (Gaussier et al, 2004) and monolingual corpora (Haghighi et al., 2008) .Nearest neighbor search is a fundamental problem where challenge is to preprocess a set of point sin some metric space into a geometric data structure so that given a query point, its k-nearest neighbors in the set can be reported as fast as possible", 
    "clean_text": "CCA has been used in bilingual lexicon extraction from comparable corpora (Gaussier et al, 2004) and monolingual corpora (Haghighi et al., 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-2070", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Florian, Laws | Lukas, Michelbacher | Beate, Dorow | Christian, Scheible | Ulrich, Heid | Hinrich, Sch&uuml;tze", 
    "raw_text": "Haghighi et al (2008) use a probabilistic mode lover word feature vectors containing co occur rence and orthographic features", 
    "clean_text": "Haghighi et al (2008) use a probabilistic model over word feature vectors containing co occurrence and orthographic features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C10-2070", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Florian, Laws | Lukas, Michelbacher | Beate, Dorow | Christian, Scheible | Ulrich, Heid | Hinrich, Sch&uuml;tze", 
    "raw_text": "Unlike the noun-only test sets used in other studies, (e.g., Koehn and Knight (2002), Haghighi et al (2008)), TS1000 also contains adjectives and verbs", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "C10-2070", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Florian, Laws | Lukas, Michelbacher | Beate, Dorow | Christian, Scheible | Ulrich, Heid | Hinrich, Sch&uuml;tze", 
    "raw_text": "The availability of parsers is a more stringent constraint, but our results suggest that more basic NLP methods may be sufficient for bilingual lexicon extraction. In this work, we have used a set of seed translations (unlike e.g., Haghighi et al (2008))", 
    "clean_text": "The availability of parsers is a more stringent constraint, but our results suggest that more basic NLP methods may be sufficient for bilingual lexicon extraction. In this work, we have used a set of seed translations (unlike e.g., Haghighi et al (2008)).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "C10-2070", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Florian, Laws | Lukas, Michelbacher | Beate, Dorow | Christian, Scheible | Ulrich, Heid | Hinrich, Sch&uuml;tze", 
    "raw_text": "For example, the paper by Haghighi et al (2008) (which demonstrates how orthography and contextual information can be successfully used) reports 61.7% ac curacy on the 186 most confident predictions of nouns", 
    "clean_text": "For example, the paper by Haghighi et al (2008) (which demonstrates how orthography and contextual information can be successfully used) reports 61.7% accuracy on the 186 most confident predictions of nouns.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P11-2071", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Hal, Daum&eacute; III | Jagadeesh, Jagarlamudi", 
    "raw_text": "Using an extension of a recent approach to mining translations from comparable corpora (Haghighi et al, 2008), we are able to find translations for otherwise OOV terms", 
    "clean_text": "Using an extension of a recent approach to mining translations from comparable corpora (Haghighi et al, 2008), we are able to find translations for otherwise OOV terms.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P11-2071", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Hal, Daum&eacute; III | Jagadeesh, Jagarlamudi", 
    "raw_text": "Our dictionary mining approach is based on Canonical Correlation Analysis, as used previously by (Haghighi et al, 2008)", 
    "clean_text": "Our dictionary mining approach is based on Canonical Correlation Analysis, as used previously by (Haghighi et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P11-2071", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Hal, Daum&eacute; III | Jagadeesh, Jagarlamudi", 
    "raw_text": "In general, using all the eigenvectors is sub optimal and thus retaining top eigenvectors leads to an improved gen eralizability. Here we describe the use of CCA to find the translations for the OOV German words (Haghighi et al, 2008)", 
    "clean_text": "Here we describe the use of CCA to find the translations for the OOV German words (Haghighi et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D09-1092", 
    "citing_paper_authority": 39, 
    "citing_paper_authors": "David, Mimno | Hanna M., Wallach | Jason, Naradowsky | David A., Smith | Andrew, McCallum", 
    "raw_text": "Wetherefore evaluate the ability of the PLTM to generate bilingual lexica, similar to other work in unsupervised translation modeling (Haghighi et al, 2008)", 
    "clean_text": "We therefore evaluate the ability of the PLTM to generate bilingual lexica, similar to other work in unsupervised translation modeling (Haghighi et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D09-1092", 
    "citing_paper_authority": 39, 
    "citing_paper_authors": "David, Mimno | Hanna M., Wallach | Jason, Naradowsky | David A., Smith | Andrew, McCallum", 
    "raw_text": "by comparing them to entries in human-constructed bilingual dictionaries, as done by Haghighi et al (2008)", 
    "clean_text": "We evaluate sets of high-probability words in each topic and multilingual \"synsets\" by comparing them to entries in human-constructed bilingual dictionaries, as done by Haghighi et al (2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "E12-1014", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Alexandre, Klementiev | Ann, Irvine | Chris, Callison-Burch | David, Yarowsky", 
    "raw_text": "nouns in Rapp (1995), 1,000 most frequent word sin Koehn and Knight (2002), or 2,000 most frequent nouns in Haghighi et al (2008))", 
    "clean_text": "Previous research on bilingual lexicon induction learned translations only for a small number of high frequency words (e.g. 100 nouns in Rapp (1995), 1,000 most frequent words in Koehn and Knight (2002), or 2,000 most frequent nouns in Haghighi et al (2008)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "E12-1014", 
    "citing_paper_authority": 17, 
    "citing_paper_authors": "Alexandre, Klementiev | Ann, Irvine | Chris, Callison-Burch | David, Yarowsky", 
    "raw_text": "Haghighi et al (2008) also used this method to show how well translations could be learned from monolingual corpora under ideal conditions, where the contextual and temporal distribution of words in the two monolingual corpora are nearly identical", 
    "clean_text": "Haghighi et al (2008) also used this method to show how well translations could be learned from monolingual corpora under ideal conditions, where the contextual and temporal distribution of words in the two monolingual corpora are nearly identical.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W09-1117", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Nikesh, Garera | Chris, Callison-Burch | David, Yarowsky", 
    "raw_text": "Haghighi et al, (2008) made use of contextual and orthographic clues for learning a generative model from monolingual corpora and a seed lexicon", 
    "clean_text": "Haghighi et al, (2008) made use of contextual and orthographic clues for learning a generative model from monolingual corpora and a seed lexicon.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "N09-1048", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Xianchao, Wu | Naoaki, Okazaki | Jun'ichi, Tsujii", 
    "raw_text": "Haghighi et al (2008) presented a generative model base don canonical correlation analysis, in which monolingual features such as the context and orthographic substrings of words were taken into account", 
    "clean_text": "Haghighi et al (2008) presented a generative model based on canonical correlation analysis, in which monolingual features such as the context and orthographic substrings of words were taken into account.", 
    "keep_for_gold": 1
  }
]