A Multi-Pass Sieve for Coreference Resolution
Most coreference resolution models determine if two mentions are coreferent using a single function over a set of constraints or features.
This approach can lead to incorrect decisions as lower precision features often overwhelm the smaller number of high precision ones.
To overcome this problem, we propose a simple coreference architecture based on a sieve that applies tiers of deterministic coreference models one at a time from highest to lowest precision.
Each tier builds on the previous tierâ€™s entity cluster output.
Further, our model propagates global information by sharing attributes (e.g., gender and number) across mentions in the same cluster.
This cautious sieve guarantees that stronger features are given precedence over weaker ones and that each decision is made using all of the information available at the time.
The framework is highly modular: new coreference modules can be plugged in without any change to the other modules.
In spite of its simplicity, our approach outperforms many state-of-the-art supervised and unsupervised models on several standard corpora.
This suggests that sieve-based approaches could be applied to other NLP tasks.
Our rule based model obtains competitive result with less time.
The candidate antecedents for the pronoun are ordered based on a notion of discourse salience that favors syntactic salience and document proximity.
We develop accurate unsupervised systems that exploit simple but robust linguistic principles.
