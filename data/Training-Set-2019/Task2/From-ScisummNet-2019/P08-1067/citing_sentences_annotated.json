[
  {
    "citance_No": 1, 
    "citing_paper_id": "D08-1091", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Slav, Petrov | Dan, Klein", 
    "raw_text": "873? 40 words all Parser F1 EX F1 EX ENGLISH-WSJ Petrov and Klein (2008) 88.8 35.7 88.3 33.1 Charniak et al (2005) 90.3 39.6 89.7 37.2 Petrov and Klein (2007) 90.6 39.1 90.1 37.1 This work w/o span features 89.7 39.6 89.2 37.2 This work w/ span features 90.0 40.1 89.4 37.7 ENGLISH-WSJ (re ranked) Huang (2008) 92.3 46.2 91.7 43.5 ENGLISH-BROWN Charniak et al (2005) 84.5 34.8 82.9 31.7 Petrov and Klein (2007) 84.9 34.5 83.7 31.2 This work w/o span features 85.3 35.6 84.3 32.1 This work w/ span features 85.6 35.8 84.5 32.3 ENGLISH-BROWN (re ranked) Charniak et al (2005) 86.8 39.9 85.2 37.8 FRENCH Arun and Keller (2005) 79.2 21.2 75.6 16.4 This Paper 80.1 24.2 77.2 19.2 GERMAN Petrov and Klein (2007) 80.8 40.8 80.1 39.1 This Paper 81.5 45.2 80.7 43.9 Table 2: Our final test set parsing accuracies compared to the best previous work on English, French and German", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "D08-1091", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Slav, Petrov | Dan, Klein", 
    "raw_text": "All those methods fall short of re ranking parsers like Charniak and Johnson (2005) and Huang (2008), which, however, have access to many additional features, that can not be used in our dynamic program. When trained on the French and German tree banks, our multi-scale grammars achieve the best figures we are aware of, without any language specific modifications", 
    "clean_text": "All those methods fall short of re ranking parsers like Charniak and Johnson (2005) and Huang (2008), which, however, have access to many additional features, that can not be used in our dynamic program.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W12-3412", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph, Le Roux | Benoit, Favre | Alexis, Nasr | Seyed Abolghasem, Mirroshandel", 
    "raw_text": "From the presented data, we can see that indirect re ranking on LAS may not seem as good as direct re ranking on phrase-structures compared to F-scores obtained in (Charniak and Johnson, 2005) and (Huang, 2008) with one parser or (Zhangetal., 2009) with several parsers", 
    "clean_text": "From the presented data, we can see that indirect re ranking on LAS may not seem as good as direct re ranking on phrase-structures compared to F-scores obtained in (Charniak and Johnson, 2005) and (Huang, 2008) with one parser or (Zhang et al., 2009) with several parsers.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W12-3412", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Joseph, Le Roux | Benoit, Favre | Alexis, Nasr | Seyed Abolghasem, Mirroshandel", 
    "raw_text": "The combination of n-best lists would not scale up and working on the ambiguous structure itself, the packed forest asin (Huang, 2008), might be necessary", 
    "clean_text": "The combination of n-best lists would not scale up and working on the ambiguous structure itself, the packed forest as in (Huang, 2008), might be necessary.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W10-2910", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Richard, Johansson | Alessandro, Moschitti", 
    "raw_text": "A common objection to re ranking is that the candidate set maynot be diverse enough to allow for much improvement unless it is very large; the candidates may be trivial variations that are all very similar to the top-scoring candidate (Huang, 2008)", 
    "clean_text": "A common objection to re ranking is that the candidate set may not be diverse enough to allow for much improvement unless it is very large; the candidates may be trivial variations that are all very similar to the top-scoring candidate (Huang, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P13-2108", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Coppola | Mark, Steedman", 
    "raw_text": "See Huang (2008) for more details", 
    "clean_text": "See Huang (2008) for more details.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P13-2108", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Coppola | Mark, Steedman", 
    "raw_text": "However, Huang (2008) shows that the use of non-local features does in fact contribute substantially to parser performance", 
    "clean_text": "However, Huang (2008) shows that the use of non-local features does in fact contribute substantially to parser performance.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P13-2108", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Coppola | Mark, Steedman", 
    "raw_text": "611 Huang (2008)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P13-2108", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Coppola | Mark, Steedman", 
    "raw_text": "With the ability to incorporate non-local phrase-structure parse features (Huang, 2008), we can recognize dependency features of arbitrary order (cf", 
    "clean_text": "With the ability to incorporate non-local phrase-structure parse features (Huang, 2008), we can recognize dependency features of arbitrary order.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P13-2108", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Coppola | Mark, Steedman", 
    "raw_text": "That is, not only is ?phrase+deps better at dependency recovery than its component parts, but ?phrase+deps+gen is also considerably bet 613ter on dependency recovery than ?phrase+gen, which represents the previous state-of-the-art in this vein of research (Huang, 2008)", 
    "clean_text": "That is, not only is phrase+deps better at dependency recovery than its component parts, but phrase+deps+gen is also considerably better on dependency recovery than phrase+gen, which represents the previous state-of-the-art in this vein of research (Huang, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P13-2108", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Coppola | Mark, Steedman", 
    "raw_text": "Note that our model ?phrase+gen uses essentially the same features as Huang (2008) ,sothe fact that our ?phrase+gen is noticeably more ac curate on F1 is presumably due to the benefits in reduced feature under-training achieved by the MERT combination strategy", 
    "clean_text": "Note that our model phrase+gen uses essentially the same features as Huang (2008), so the fact that our phrase+gen is noticeably more accurate on F1 is presumably due to the benefits in reduced feature under-training achieved by the MERT combination strategy.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P13-2108", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Coppola | Mark, Steedman", 
    "raw_text": "We test Type Model WSJ G+D Huang (2008) 91.7 Dphrase+deps 91.7 G+Dphrase+gen 92.1 G+Dphrase+deps+gen 92.4Table 3: Comparison of constituency parsing results in the cube decoding framework, on the WSJ test set", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "E09-1090", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Jun'ichi, Tsujii | Sophia, Ananiadou", 
    "raw_text": "Huang (2008) pro posed to use a parse forest to incorporate non-local features", 
    "clean_text": "Huang (2008) proposed to use a parse forest to incorporate non-local features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "E09-1090", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Jun'ichi, Tsujii | Sophia, Ananiadou", 
    "raw_text": "Our parser achieved an f-score of 88.4on the test data, which is comparable to the accuracy achieved by recent discriminative approaches such as Finkel et al (2008) and Petrov& amp; Klein (2008), but is not as high as the state-of-the-art accuracy achieved by the parsers that can incorporate global features such as Huang (2008) and Charniak& amp; Johnson (2005)", 
    "clean_text": "Our parser achieved an f-score of 88.4on the test data, which is comparable to the accuracy achieved by recent discriminative approaches such as Finkel et al (2008) and Petrov & Klein (2008), but is not as high as the state-of-the-art accuracy achieved by the parsers that can incorporate global features such as Huang (2008) and Charniak & Johnson (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "E09-1090", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Jun'ichi, Tsujii | Sophia, Ananiadou", 
    "raw_text": "796 Recall Precision F-score Time (min) This work (deterministic) 86.3 87.5 86.9 0.5 This work (search, beam width= 4) 88.2 88.7 88.4 1.7 Huang (2008) 91.7 Unk Finkel et al (2008) 87.8 88.2 88.0& gt; 250* Petrov& amp; Klein (2008) 88.3 3* Sagae& amp; Lavie (2006) 87.8 88.1 87.9 17 Charniak& amp; Johnson (2005) 90.6 91.3 91.0 Unk Tsuruoka& amp; Tsujii (2005) 85.0 86.8 85.9 2 Collins (1999) 88.1 88.3 88.2 39** Tjong Kim Sang (2001) 78.7 82.3 80.5 Unk Charniak (2000) 89.6 89.5 89.5 23** Ratnaparkhi (1997) 86.3 87.5 86.9 Unk Table 6: Parsing performance on section 23 (all sentences)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P13-1001", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Yang, Liu", 
    "raw_text": "3 In the second pass, we use the hyper graph re ranking algorithm (Huang, 2008) to find promising translations using additional dependency features (i.e., features 810 in the list)", 
    "clean_text": "In the second pass, we use the hyper graph reranking algorithm (Huang, 2008) to find promising translations using additional dependency features (i.e., features 810 in the list).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P09-1063", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Yang, Liu | Yajuan, L&uuml; | Qun, Liu", 
    "raw_text": "We follow Mi and Huang (2008) to estimate the fractional count of a rule extracted from an aligned forest pair", 
    "clean_text": "We follow Mi and Huang (2008) to estimate the fractional count of a rule extracted from an aligned forest pair.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P09-1063", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Yang, Liu | Yajuan, L&uuml; | Qun, Liu", 
    "raw_text": "Then, we ran the Python scripts (Huang, 2008) provided by Liang Huang to out put packed forests", 
    "clean_text": "Then, we ran the Python scripts (Huang, 2008) provided by Liang Huang to output packed forests.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P09-1063", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Yang, Liu | Yajuan, L&uuml; | Qun, Liu", 
    "raw_text": "To prune the packed forests, Huang (2008) uses inside and outside probabilities to compute the distance of the best derivation that traverses a hyper edge away from the glob ally best derivation", 
    "clean_text": "To prune the packed forests, Huang (2008) uses inside and outside probabilities to compute the distance of the best derivation that traverses a hyper edge away from the globally best derivation.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "E09-1037", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kevin, Gimpel | Noah A., Smith", 
    "raw_text": "features (Huang,2008) that score the string of terminals and nonterminals along the path from word j to word j+ 1when two constituents CY, i, j and CZ, j, k are combined", 
    "clean_text": "For example, consider the probabilistic CKY algorithm as above, but using the cube decoding semiring with the non-local feature functions collectively known as \"NGramTree\" features (Huang, 2008) that score the string of terminals and nonterminals along the path from word j to word j+1 when two constituents CY, i, j and CZ, j, k are combined.", 
    "keep_for_gold": 0
  }
]