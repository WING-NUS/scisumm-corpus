[
  {
    "citance_No": 1, 
    "citing_paper_id": "W06-0128", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Guo-Wei, Bian", 
    "raw_text": "In general, the word segmentation program utilizes the word entries, part-of-speech (POS) information (Chen and Liu, 1992) in a monolingual dictionary, segmentation rules (Palmer, 1997), and some statistical information (Sproat, et al, 1994)", 
    "clean_text": "In general, the word segmentation program utilizes the word entries, part-of-speech (POS) information (Chen and Liu, 1992) in a monolingual dictionary, segmentation rules (Palmer, 1997), and some statistical information (Sproat, et al, 1994).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2032", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Mengqiu, Wang | Rob, Voigt | Christopher D., Manning", 
    "raw_text": "Early word-based segmentation work employed simple heuristics like dictionary-lookup maximum matching (Chen and Liu, 1992)", 
    "clean_text": "Early word-based segmentation work employed simple heuristics like dictionary-lookup maximum matching (Chen and Liu, 1992).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P09-1098", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Long, Jiang | Shiquan, Yang | Ming, Zhou | Xiaohua, Liu | Qingsheng, Zhu", 
    "raw_text": "Here, the Forward Maximum Matching algorithm (Chen and Liu, 1992) based on a dictionary is adopted; c) Stop words filtering", 
    "clean_text": "Here, the Forward Maximum Matching algorithm (Chen and Liu, 1992) based on a dictionary is adopted; c) Stop words filtering.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W06-0118", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Dong, Song | Anoop, Sarkar", 
    "raw_text": "In our segmentation system, a hybrid strategy is applied (Figure 1): First, forward maximum matching (Chen and Liu, 1992), which is a dictionary-based method, is used to generate asegmentation result", 
    "clean_text": "In our segmentation system, a hybrid strategy is applied (Figure 1): First, forward maximum matching (Chen and Liu, 1992), which is a dictionary-based method, is used to generate asegmentation result.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W06-0118", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Dong, Song | Anoop, Sarkar", 
    "raw_text": "In our system, the well-known forward maximum matching algorithm (Chen and Liu, 1992) is implemented", 
    "clean_text": "In our system, the well-known forward maximum matching algorithm (Chen and Liu, 1992) is implemented.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P07-2018", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Chu-Ren, Huang | Petr, Simon | Shu-Kai, Hsieh | Laurent, Pr&eacute;vot", 
    "raw_text": "(Chen and Liu,1992) and many subsequent works), or uses the position of characters in a word as the basis for segmentation (Xue, 2003) .In terms of processing model, this is a contradiction since segmentation should be the pre-requisiteof dictionary lookup and should not presuppose lexical information", 
    "clean_text": "(Chen and Liu,1992) and many subsequent works), or uses the position of characters in a word as the basis for segmentation (Xue, 2003). In terms of processing model, this is a contradiction since segmentation should be the pre-requisite of dictionary lookup and should not presuppose lexical information.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P07-2018", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Chu-Ren, Huang | Petr, Simon | Shu-Kai, Hsieh | Laurent, Pr&eacute;vot", 
    "raw_text": "The classical model ,de scribed in (Chen and Liu, 1992) and still adopted in many recent works, considers text segmentation as a 69tokenization", 
    "clean_text": "The classical model, described in (Chen and Liu, 1992) and still adopted in many recent works, considers text segmentation as a tokenization.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-2139", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Weiwei, Sun", 
    "raw_text": "This word-by-word approach ranges from naive maximum matching (Chen and Liu, 1992) to complex solution based on semi-Markov conditional random fields (CRF) (Andrew, 2006)", 
    "clean_text": "This word-by-word approach ranges from naive maximum matching (Chen and Liu, 1992) to complex solution based on semi-Markov conditional random fields (CRF) (Andrew, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C10-2139", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Weiwei, Sun", 
    "raw_text": "Take for example maximum matching, which was a popular algorithm at the early stage of research (Chen and Liu, 1992)", 
    "clean_text": "Take for example maximum matching, which was a popular algorithm at the early stage of research (Chen and Liu, 1992).", 
    "keep_for_gold": 0
  }
]