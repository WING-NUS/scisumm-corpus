[
  {
    "citance_No": 1, 
    "citing_paper_id": "W11-2212", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "St&eacute;phane, Huet | Fabrice, Lef&egrave;vre", 
    "raw_text": "The experiments led on the alignment methods were evaluated on the development corpus using MGIZA++ (Gao and Vogel, 2008), a multi-thread version of GIZA++ (Och and Ney, 2003) which also allows previously trained IBM alignments models to be applied on the development and test corpora.1 The conceptual tagging process was evaluated on the test corpus, using WAPITI (Lavergne et al, 2010) to train the CRF models", 
    "clean_text": "The experiments led on the alignment methods were evaluated on the development corpus using MGIZA++ (Gao and Vogel, 2008), a multi-thread version of GIZA++ (Och and Ney, 2003) which also allows previously trained IBM alignments models to be applied on the development and test corpora.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W10-1709", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Greg, Hanneman | Jonathan H., Clark | Alon, Lavie", 
    "raw_text": "We word-aligned the corpus with MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of the standard word alignment tool GIZA++ (Och and Ney, 2003)", 
    "clean_text": "We word-aligned the corpus with MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of the standard word alignment tool GIZA++ (Och and Ney, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W12-3150", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Philip, Williams | Philipp, Koehn", 
    "raw_text": "The parallel corpus was then word-aligned using MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003)", 
    "clean_text": "The parallel corpus was then word-aligned using MGIZA++ (Gao and Vogel, 2008), a multi-threaded implementation of GIZA++ (Och and Ney, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W10-1701", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Qin, Gao | Nguyen, Bach | Stephan, Vogel", 
    "raw_text": "We extend the multi-thread GIZA++ (Gao and Vogel, 2008) to load the alignments from a modified corpus file", 
    "clean_text": "We extend the multi-thread GIZA++ (Gao and Vogel, 2008) to load the alignments from a modified corpus file.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W11-2158", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Holger, Schwenk | Patrik, Lambert | Lo&iuml;c, Barrault | Christophe, Servan | Sadaf, Abdul-Rauf | Haithem, Afli | Kashif, Shah", 
    "raw_text": "We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008) .1 This speeds up the process and corrects an error of GIZA++ that can appear with rare words", 
    "clean_text": "We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008). This speeds up the process and corrects an error of GIZA++ that can appear with rare words.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W10-1716", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Patrik, Lambert | Sadaf, Abdul-Rauf | Holger, Schwenk", 
    "raw_text": "We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008) .1 This speeds up the process and corrects an error of GIZA++ that can appear with rare words", 
    "clean_text": "We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008). This speeds up the process and corrects an error of GIZA++ that can appear with rare words.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P10-2067", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Vamshi, Ambati | Stephan, Vogel | Jaime G., Carbonnell", 
    "raw_text": "We use an extended version of MGIZA++ (Gaoand Vogel, 2008) to perform the constrained semi supervised word alignment", 
    "clean_text": "We use an extended version of MGIZA++ (Gaoand Vogel, 2008) to perform the constrained semi supervised word alignment.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W11-1217", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Radu, Ion | Alexandru, Ceau&scedil;u | Elena, Irimia", 
    "raw_text": "is the translation probability score (as the one given for instance by GIZA++ (Gao and Vogel, 2008))", 
    "clean_text": "is the translation probability score (as the one given for instance by GIZA++ (Gao and Vogel, 2008)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W11-1217", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Radu, Ion | Alexandru, Ceau&scedil;u | Elena, Irimia", 
    "raw_text": "Then, we applied a parallel version of GIZA++ (Gao and Vogel, 2008) that gave us the translation dictionaries of content words only (nouns, verbs, adjective and adverbs) at word form level", 
    "clean_text": "Then, we applied a parallel version of GIZA++ (Gao and Vogel, 2008) that gave us the translation dictionaries of content words only (nouns, verbs, adjective and adverbs) at word form level.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "C10-1040", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Qin, Gao | Francisco, Guzman | Stephan, Vogel", 
    "raw_text": "We will continue exploration on these directions. The extended GIZA++ is released to the re search community as a branch of MGIZA++ (Gao and Vogel, 2008), which is available online3", 
    "clean_text": "We will continue exploration on these directions. The extended GIZA++ is released to the research community as a branch of MGIZA++ (Gao and Vogel, 2008), which is available online.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P11-1044", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Hassan, Sajjad | Alexander, Fraser | Helmut, Schmid", 
    "raw_text": "In this section, we will explain how to builda transliteration module on the extracted trans liter ation pairs and how to integrate it into MGIZA++ (Gao and Vogel, 2008) by interpolating it with the t table probabilities of the IBM models and the HMM model", 
    "clean_text": "In this section, we will explain how to build a transliteration module on the extracted transliteration pairs and how to integrate it into MGIZA++ (Gao and Vogel, 2008) by interpolating it with the t table probabilities of the IBM models and the HMM model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W11-2143", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Greg, Hanneman | Alon, Lavie", 
    "raw_text": "Unidirectional word alignments were provided by MGIZA++ (Gao and Vogel, 2008), then symmetrized with the grow-diag-final-and heuristic (Koehn et al, 2005)", 
    "clean_text": "Unidirectional word alignments were provided by MGIZA++ (Gao and Vogel, 2008), then symmetrized with the grow-diag-final-and heuristic (Koehn et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W10-1714", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Michael, Jellinghaus | Alexandros, Poulis | David, Kolovratn&iacute;k", 
    "raw_text": "For the word alignments, we chose MGIZA (Gaoand Vogel, 2008), using seven threads per MGIZA instance, with the parallel option ,i.e. one MGIZA in stance per pair direction running in parallel", 
    "clean_text": "For the word alignments, we chose MGIZA (Gaoand Vogel, 2008), using seven threads per MGIZA instance, with the parallel option ,i.e. one MGIZA in stance per pair direction running in parallel.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W10-1715", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Philipp, Koehn | Barry, Haddow | Philip, Williams | Hieu, Hoang", 
    "raw_text": "This is largest publicly available parallel corpus, and it does strain computing resources, for instance forcing us to use multi-threaded GIZA++ (Gao and Vogel, 2008) .Table 7 shows the gains obtained from using this corpus in both the translation model and the language model opposed to a baseline system trained with otherwise the same settings", 
    "clean_text": "This is largest publicly available parallel corpus, and it does strain computing resources, for instance forcing us to use multi-threaded GIZA++ (Gao and Vogel, 2008). Table 7 shows the gains obtained from using this corpus in both the translation model and the language model opposed to a baseline system trained with otherwise the same settings.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W11-1012", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Qin, Gao | Stephan, Vogel", 
    "raw_text": "The parallel sentences are aligned using MGIZA++ (Gao and Vogel, 2008) and then the proposed rule extraction algorithm was used in extracting the SRL-aware SCFG rules", 
    "clean_text": "The parallel sentences are aligned using MGIZA++ (Gao and Vogel, 2008) and then the proposed rule extraction algorithm was used in extracting the SRL-aware SCFG rules.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W12-3147", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Anthony, Rousseau | Lo&iuml;c, Barrault | Christophe, Servan | Holger, Schwenk | Patrik, Lambert", 
    "raw_text": "We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008) .1 This speeds up the process and corrects an error of GIZA++ that can appear with rare words. Phrases and lexical reorderings are extracted using the default settings of the Moses toolkit", 
    "clean_text": "We used a multi-threaded version of the GIZA++ tool (Gao and Vogel, 2008). This speeds up the process and corrects an error of GIZA++ that can appear with rare words. Phrases and lexical reorderings are extracted using the default settings of the Moses toolkit.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W12-3131", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Michael, Denkowski | Greg, Hanneman | Alon, Lavie", 
    "raw_text": "Word alignment scores: source-target and target-source MGIZA++ (Gao and Vogel, 2008) force-alignment scores using IBM Model 4 (Och and Ney, 2003)", 
    "clean_text": "Word alignment scores: source-target and target-source MGIZA++ (Gao and Vogel, 2008) force-alignment scores using IBM Model 4 (Och and Ney, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W12-3131", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Michael, Denkowski | Greg, Hanneman | Alon, Lavie", 
    "raw_text": "The system translates from cased French to cased English; at no point do we lowercase data. The Parallel data is aligned in both directions using the MGIZA++ (Gao and Vogel, 2008 )implementation of IBM Model 4 and symmetrized with the grow-diag-final heuristic (Och and Ney, 2003)", 
    "clean_text": "The system translates from cased French to cased English; at no point do we lowercase data. The Parallel data is aligned in both directions using the MGIZA++ (Gao and Vogel, 2008) implementation of IBM Model 4 and symmetrized with the grow-diag-final heuristic (Och and Ney, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W10-0102", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Vamshi, Ambati | Stephan, Vogel | Jaime G., Carbonnell", 
    "raw_text": "We use an extended version of MGIZA++ (Gaoand Vogel, 2008) to perform the constrained semi supervised word alignment", 
    "clean_text": "We use an extended version of MGIZA++ (Gaoand Vogel, 2008) to perform the constrained semi supervised word alignment.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W11-2120", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Rico, Sennrich", 
    "raw_text": "For this, we create a parallel corpus consisting of n translation hypotheses and n copies of the corresponding source text, both lowercased and detokenized.2 We compute the word alignment with MGIZA++ (Gao and Vogel, 2008), based on the word alignment model from the primary corpus that we have previously saved to disk. After training a phrase table from the word aligned corpus with Moses, the lexical weights and translation probabilities are rescored, using the sufficient statistics (i.e. the word, phrase and word/phrase pair counts) of both the primary and the secondary corpus", 
    "clean_text": "For this, we create a parallel corpus consisting of n translation hypotheses and n copies of the corresponding source text, both lowercased and detokenized. We compute the word alignment with MGIZA++ (Gao and Vogel, 2008), based on the word alignment model from the primary corpus that we have previously saved to disk. After training a phrase table from the word aligned corpus with Moses, the lexical weights and translation probabilities are rescored, using the sufficient statistics (i.e. the word, phrase and word/phrase pair counts) of both the primary and the secondary corpus.", 
    "keep_for_gold": 0
  }
]