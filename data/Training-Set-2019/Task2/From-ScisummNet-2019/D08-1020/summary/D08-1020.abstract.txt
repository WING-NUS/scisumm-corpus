We combine lexical, syntactic, and discourse features to produce a highly predictive model
of human readers' judgments of text readability.
This is the first study to take into account such a variety of linguistic factors and
the first to empirically demonstrate that discourse relations are strongly associated with
the perceived quality of text.
We show that various surface metrics generally expected to be related to readability are not very good predictors of readability judgments in our Wall Street Journal corpus.
We also establish that readability predictors behave differently depending on the task: predicting text readability or ranking the readability.
Our experiments indicate that discourse relations are the one class of features that exhibits robustness across these two tasks.
