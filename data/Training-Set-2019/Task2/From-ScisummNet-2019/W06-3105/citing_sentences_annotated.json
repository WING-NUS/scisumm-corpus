[
  {
    "citance_No": 1, 
    "citing_paper_id": "W07-0715", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Robert C., Moore | Chris, Quirk", 
    "raw_text": "DeNero et al (2006 )trieda different generative phrase translation model analogous to IBM word-translation Model 3 (Brown et al., 1993), and again found that the standard model outperformed their generative model", 
    "clean_text": "DeNero et al (2006) tried a different generative phrase translation model analogous to IBM word-translation Model 3 (Brown et al., 1993), and again found that the standard model outperformed their generative model.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W07-0715", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Robert C., Moore | Chris, Quirk", 
    "raw_text": "DeNero et al (2006) attribute the inferiority of their model and the Marcu and Wong model to a hid den segmentation variable, which enables the EMalgorithm to maximize the probability of the training data without really improving the quality of the model", 
    "clean_text": "DeNero et al (2006) attribute the inferiority of their model and the Marcu and Wong model to a hidden segmentation variable, which enables the EM algorithm to maximize the probability of the training data without really improving the quality of the model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P11-1131", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Mohit, Bansal | Chris, Quirk | Robert C., Moore", 
    "raw_text": "This avoids segmentation problems encountered by DeNero et al (2006)", 
    "clean_text": "This avoids segmentation problems encountered by DeNero et al (2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D08-1066", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "140k sentences up to a certain length) .DeNero et al (2006) have explored estimation using EM of phrase pair probabilities under a conditional translation model based on the original source-channel formulation", 
    "clean_text": "140k sentences up to a certain length. DeNero et al (2006) have explored estimation using EM of phrase pair probabilities under a conditional translation model based on the original source-channel formulation.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D08-1066", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "This leads to the following probabilistic model: P (f| e; a)=?? I1?? (a) P (? I1)? ?fj ,ej??? I1 (f, e) P (fj |ej) (1) Where? (a) is the set of binarizable segmentations (defined next) that are eligible according to the word-alignments a between f and e. These segmentations into bilingual containers (where segmentations are taken inside the containers) are different from the monolingual segmentations used in earlier comparable conditional models (e.g., (DeNero et al, 2006)) which must generate the alignment on top of the segmentations", 
    "clean_text": "These segmentations into bilingual containers (where segmentations are taken inside the containers) are different from the monolingual segmentations used in earlier comparable conditional models (e.g., (DeNero et al, 2006)) which must generate the alignment on top of the segmentations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D08-1066", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "As it has been found out by (DeNero et al, 2006), it is not easy to come up with a simple, effective prior distribution over segmentations that al lows for improved phrase pair estimates", 
    "clean_text": "As it has been found out by (DeNero et al, 2006), it is not easy to come up with a simple, effective prior distribution over segmentations that allows for improved phrase pair estimates.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D08-1066", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "In contrast with the model of (DeNero et al, 2006), who define the segmentations over the source sentence f alone, our model employs bilingual containers thereby segmenting both source and target sides simultaneously", 
    "clean_text": "In contrast with the model of (DeNero et al, 2006), who define the segmentations over the source sentence f alone, our model employs bilingual containers thereby segmenting both source and target sides simultaneously.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D08-1066", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "Therefore, unlike (DeNeroet al, 2006), our model does not need to generate the word-alignments explicitly, as these are em bedded in the segmentations", 
    "clean_text": "Therefore, unlike (DeNeroet al, 2006), our model does not need to generate the word-alignments explicitly, as these are embedded in the segmentations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D08-1066", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "We did not explore mere EM without any smoothing or ITG prior, as we expect it will directly over fit the training data as reported by (DeNero et al, 2006)", 
    "clean_text": "We did not explore mere EM without any smoothing or ITG prior, as we expect it will directly over fit the training data as reported by (DeNero et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D08-1066", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "The most similar efforts to ours, mainly (DeNero et al, 2006), conclude that segmentation variable sin the generative translation model lead to over fitting while attaining higher likelihood of the training data than the heuristic estimator", 
    "clean_text": "The most similar efforts to ours, mainly (DeNero et al, 2006), conclude that segmentation variables in the generative translation model lead to overfitting while attaining higher likelihood of the training data than the heuristic estimator.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D09-1107", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Matti, K&auml;&auml;ri&auml;inen", 
    "raw_text": "Whiletheoretically sound, this approach is computationally challenging both in practice (DeNero et al, 2008) and in theory (DeNero and Klein, 2008), may suffer from reference reachability problems (DeNero et al, 2006), and in the end may lead to inferior translation quality (Koehn et al, 2003)", 
    "clean_text": "While theoretically sound, this approach is computationally challenging both in practice (DeNero et al, 2008) and in theory (DeNero and Klein, 2008), may suffer from reference reachability problems (DeNero et al, 2006), and in the end may lead to inferior translation quality (Koehn et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "D09-1107", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Matti, K&auml;&auml;ri&auml;inen", 
    "raw_text": "thus generates a number of potentially overlapping in (DeNero et al, 2006), the ambiguity in word alignment is less prevalent than in phrase segmentation", 
    "clean_text": "thus generates a number of potentially overlapping in (DeNero et al, 2006), the ambiguity in word alignment is less prevalent than in phrase segmentation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W10-1711", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Carmen, Heger | Joern, Wuebker | Matthias, Huck | Gregor, Leusch | Saab, Mansour | Daniel, Stein | Hermann, Ney", 
    "raw_text": "For the German? English, French? English and English? French language tasks we applied a forced alignment procedure to train the phrase translation model with the EM algorithm ,similar to the one described in (DeNero et al,2006)", 
    "clean_text": "For the German English, French English and English French language tasks we applied a forced alignment procedure to train the phrase translation model with the EM algorithm ,similar to the one described in (DeNero et al,2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P09-1088", 
    "citing_paper_authority": 37, 
    "citing_paper_authors": "Philip, Blunsom | Trevor, Cohn | Chris, Dyer | Miles, Osborne", 
    "raw_text": "Thisexplicitly avoids the degenerate solutions of maximum likelihood estimation (DeNero et al, 2006), without resort to the heuristic estimator of Koehn et al (2003)", 
    "clean_text": "This explicitly avoids the degenerate solutions of maximum likelihood estimation (DeNero et al, 2006), without resort to the heuristic estimator of Koehn et al (2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P09-1088", 
    "citing_paper_authority": 37, 
    "citing_paper_authors": "Philip, Blunsom | Trevor, Cohn | Chris, Dyer | Miles, Osborne", 
    "raw_text": "Phrasal SCFG models are subject to a degenerate maximum likelihood solution in which all probability mass is placed on long, or whole sentence, phrase translations (DeNero et al, 2006)", 
    "clean_text": "Phrasal SCFG models are subject to a degenerate maximum likelihood solution in which all probability mass is placed on long, or whole sentence, phrase translations (DeNero et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D08-1033", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "John, DeNero | Alexandre, Bouchard-C&ocirc;t&eacute; | Dan, Klein", 
    "raw_text": "DeNero et al (2006) instead proposed an exponential-time dynamic program pruned using word alignments", 
    "clean_text": "DeNero et al (2006) instead proposed an exponential-time dynamic program pruned using word alignments.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D09-1037", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Trevor, Cohn | Philip, Blunsom", 
    "raw_text": "The heuristic method is inconsistent in the limit (Johnson, 2002) while EM is degenerate, placing disproportionate probability mass on the largest rules in order to describe the data with as few a rules as possible (DeNero et al, 2006)", 
    "clean_text": "The heuristic method is inconsistent in the limit (Johnson, 2002) while EM is degenerate, placing disproportionate probability mass on the largest rules in order to describe the data with as few a rules as possible (DeNero et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W10-2915", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Markos, Mylonakis | Khalil, Sima'an", 
    "raw_text": "(DeNero et al, 2006))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D11-1081", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Xinyan, Xiao | Yang, Liu | Qun, Liu | Shouxun, Lin", 
    "raw_text": "If we only use the features as traditional SCFG systems, the bi parsing may end with a derivation consists of some giant rules or rules with rare source/target sides, which is called degenerate solution (DeNero et al, 2006)", 
    "clean_text": "If we only use the features as traditional SCFG systems, the bi parsing may end with a derivation consists of some giant rules or rules with rare source/target sides, which is called degenerate solution (DeNero et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P08-1024", 
    "citing_paper_authority": 46, 
    "citing_paper_authors": "Philip, Blunsom | Trevor, Cohn | Miles, Osborne", 
    "raw_text": "This is illustrated in Table 2, which shows the conditional probabilities for rules, obtained by locally normalising the rule feature weights for a simple grammar extracted from the ambiguous pair of sentences presented in DeNero et al (2006)", 
    "clean_text": "This is illustrated in Table 2, which shows the conditional probabilities for rules, obtained by locally normalising the rule feature weights for a simple grammar extracted from the ambiguous pair of sentences presented in DeNero et al (2006).", 
    "keep_for_gold": 0
  }
]