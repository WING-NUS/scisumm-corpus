[
  {
    "citance_No": 1, 
    "citing_paper_id": "D11-1139", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith | Mario, Figueiredo | Pedro, Aguiar", 
    "raw_text": "(5) Empirical comparison among these loss functions can be found in the literature (see ,e.g., Martins et al, 2010, who also consider interpolations of the losses above)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "D11-1139", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith | Mario, Figueiredo | Pedro, Aguiar", 
    "raw_text": "Elastic nets interpolate between L1 and L2, having been proposed by Zou and Hastie (2005) and used by Lavergne et al (2010) to regularize CRFs", 
    "clean_text": "Elastic nets interpolate between L1 and L2, having been proposed by Zou and Hastie (2005) and used by Lavergne et al (2010) to regularize CRFs.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D11-1139", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith | Mario, Figueiredo | Pedro, Aguiar", 
    "raw_text": "When G is tree-structured, it can still be efficiently computed by a recursive procedure (Jenatton et al, 2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D11-1139", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith | Mario, Figueiredo | Pedro, Aguiar", 
    "raw_text": "Schmidt and Murphy (2010) used to generative models, while our approach emphasizes discriminative learning", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D11-1139", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith | Mario, Figueiredo | Pedro, Aguiar", 
    "raw_text": "The tree structured case has been addressed by Kim and Xing (2010), Liu and Ye (2010) and Mairal et al (2010), along with L? ,1 and L2,1 regularization", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D11-1139", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Andre, Martins | Noah A., Smith | Mario, Figueiredo | Pedro, Aguiar", 
    "raw_text": "Graph structured groups are discussed in Jenatton et al (2010), along with a DAG representation", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P14-2111", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Grzegorz, Chrupa\u00c5\u201aa", 
    "raw_text": "As our sequence labeling model we use the Wapiti implementation of Conditional Random Fields (Lavergne et al, 2010) with the L-BFGS optimizer and elastic net regularization with default settings", 
    "clean_text": "As our sequence labeling model we use the Wapiti implementation of Conditional Random Fields (Lavergne et al, 2010) with the L-BFGS optimizer and elastic net regularization with default settings.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P14-2111", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Grzegorz, Chrupa\u00c5\u201aa", 
    "raw_text": "In addition to character n-gram features they use phoneme and syllable features, while we rely onthe SRN embeddings to provide generalized representations of input strings. Kaufmann and Kalita (2010) trained a phrase based statistical translation model on a parallel text message corpus and applied it to tweet normalization", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W12-0510", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Arnaud, Soulet | Damien, Nouvel | Jean-Yves, Antoine | Nathalie, Friburger", 
    "raw_text": "CRFs also have demonstrated their ability to merge symbolic and statistic processes in a machine learning framework (Zidouni et al, 2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W12-0510", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Arnaud, Soulet | Damien, Nouvel | Jean-Yves, Antoine | Nathalie, Friburger", 
    "raw_text": "We report results for the following hybridizations and CRF-based system using Wapiti (Lavergne et al., 2010)", 
    "clean_text": "We report results for the following hybridizations and CRF-based system using Wapiti (Lavergne et al., 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W12-0510", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Arnaud, Soulet | Damien, Nouvel | Jean-Yves, Antoine | Nathalie, Friburger", 
    "raw_text": "Although, manual corrections were done on half of the Test corpus (Nouvel et al, 2010) (Ester2-Test-corr in Table 2), to obtain agold standard that we will use to evaluate our approach", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W12-0510", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Arnaud, Soulet | Damien, Nouvel | Jean-Yves, Antoine | Nathalie, Friburger", 
    "raw_text": "(2010) reports 20.3% SER on Ester2 test corpus, but they leverage training corpus)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W11-0328", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Yusuke, Miyao | Jun'ichi, Kazama", 
    "raw_text": "In this experiment, we use the same set of feature templates as Huang and Sagae (2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W11-0328", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Yusuke, Miyao | Jun'ichi, Kazama", 
    "raw_text": "242 Training Time (sec) Test Time (sec) Accuracy CRF (L1 regularization& amp; SGD training) 847 3 97.11% No lookahead (depth= 0) 85 5 97.00% Lookahead (depth= 1) 294 9 97.19% Lookahead (depth= 2) 8,688 173 97.19% No lookahead (depth= 0)+ tag trigram features 88 5 97.11% Lookahead (depth= 1)+ tag trigram features 313 10 97.22% Lookahead (depth= 2)+ tag trigram features 10,034 209 97.28% Structuredperceptron (Collins, 2002 )n/an/a 97.11% Guided learning (Shen et al, 2007 )n/an/a 97.33% CRF with 4 billion features (Lavergne et al, 2010 )n/an/a 97.22% Table 1: Performance of English POS tagging (training times and accuracy scores on test data) Training time (sec) Test time (sec) F-measure CRF (L1 regularization& amp; SGD training) 74 1 93.66 No lookahead (depth= 0) 22 1 93.53 Lookahead (depth= 1) 73 1 93.77 Lookahead (depth= 2) 1,113 9 93.81 Voting of 8 SVMs (Kudo and Matsumoto, 2001 )n/an/a 93.91 Table 2: Performance of text chunking (training times and accuracy scores on test data)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W11-0328", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Yoshimasa, Tsuruoka | Yusuke, Miyao | Jun'ichi, Kazama", 
    "raw_text": "Training time (sec) Test time (sec) Accuracy No lookahead (depth= 0) 1,937 4 89.73 Lookahead (depth= 1) 4,907 13 91.00 Lookahead (depth= 2) 12,800 31 91.10 Lookahead (depth= 3) 31,684 79 91.24 Beam search (k= 64) (Zhang and Clark, 2008 )n/an/a 91.4 Deterministic (Huang et al, 2009 )n/an/a 90.2 Beam search (k= 16) (Huang et al, 2009 )n/an/a 91.3 Dynamic programming (Huang and Sagae, 2010 )n/an/a 92.1 Table 4: Performance of English dependency parsing (training times and accuracy scores on test data)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W12-1632", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Aoife, Cahill | Arndt, Riester", 
    "raw_text": "Thisclassification, which is described in Nissim et al (2004), has been used for annotating the Switchboard dialog corpus (Calhoun et al, 2010), on which both studies are based", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W12-1632", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Aoife, Cahill | Arndt, Riester", 
    "raw_text": "We (i) experiment with a different information status classification, derived from Riester et al (2010), (ii) use (morpho) syntactic and functional features automatically extracted from a deep linguistic parser in our CRF sequence model, (iii) test our approach on a different language (German), (iv) show that high accuracy can be achieved with a limited number of training examples, and (v) that the approach works on a different genre (transcribed radio news bulletins which contain complex embedded phrases like an offer to the minority Tamil population of Sri Lanka, not typically found in spoken dialog)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W12-1632", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Aoife, Cahill | Arndt, Riester", 
    "raw_text": "The annotation scheme by Riester et al (2010) divides referring items differently to Nissim et al (2004)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W12-1632", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Aoife, Cahill | Arndt, Riester", 
    "raw_text": "Reiter and Frank (2010) discuss thetask of identifying generic items in a manner similar to the learning tasks presented above, using aBayesian network", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W12-1632", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Aoife, Cahill | Arndt, Riester", 
    "raw_text": "We there fore treat the prediction of IS labels as a sequence labeling task.4 We train a CRF using wapiti (Lavergne et al, 2010), with the features outlined in Table 1", 
    "clean_text": "We therefore treat the prediction of IS labels as a sequence labeling task. We train a CRF using wapiti (Lavergne et al, 2010), with the features outlined in Table 1.", 
    "keep_for_gold": 0
  }
]