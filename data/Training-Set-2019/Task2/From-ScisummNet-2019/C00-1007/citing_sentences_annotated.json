[
  {
    "citance_No": 1, 
    "citing_paper_id": "W08-1112", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Yuqing, Guo | Haifeng, Wang | Josef, van Genabith", 
    "raw_text": "FERGUS (Bangalore and Rambow,2000) took dependency structures as inputs, and produced XTAG derivations by a stochastic tree model automatically acquired from an annotated corpus", 
    "clean_text": "FERGUS (Bangalore and Rambow,2000) took dependency structures as inputs, and produced XTAG derivations by a stochastic tree model automatically acquired from an annotated corpus.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W04-2208", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Kiyotaka, Uchimoto | Yujie, Zhang | Kiyoshi, Sudo | Masaki, Murata | Satoshi, Sekine | Hitoshi, Isahara", 
    "raw_text": "However, we can automatically estimate English word order by using a language model or an English surface sentence generator such as FERGUS (Bangalore and Rambow, 2000)", 
    "clean_text": "However, we can automatically estimate English word order by using a language model or an English surface sentence generator such as FERGUS (Bangalore and Rambow, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W11-2011", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Nina, Dethlefs | Heriberto, Cuay&#xE1;huitl | Jette, Viethen", 
    "raw_text": "More generally, the NLG problem of non-deterministic decision making has been addressed from many different angles, including PENMAN-style choosers (Mann and Matthiessen,1983), corpus-based statistical knowledge (Langkilde and Knight, 1998), tree-based stochastic models (Bangalore and Rambow, 2000), maximum entropy based ranking (Ratnaparkhi, 2000), combinatorial pattern discovery (Duboue and McKeown, 2001), instance-based ranking (Varges, 2003), chart generation (White, 2004), planning (Koller and Stone, 2007), or probabilistic generation spaces (Belz, 2008) to name just a few", 
    "clean_text": "More generally, the NLG problem of non-deterministic decision making has been addressed from many different angles, including PENMAN-style choosers (Mann and Matthiessen,1983), corpus-based statistical knowledge (Langkilde and Knight, 1998), tree-based stochastic models (Bangalore and Rambow, 2000), maximum entropy based ranking (Ratnaparkhi, 2000), combinatorial pattern discovery (Duboue and McKeown, 2001), instance-based ranking (Varges, 2003), chart generation (White, 2004), planning (Koller and Stone, 2007), or probabilistic generation spaces (Belz, 2008) to name just a few.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C04-1097", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Eric K., Ringger | Michael, Gamon | Robert C., Moore | David, Rojas | Martine, Smets | Simon H., Corston-Oliver", 
    "raw_text": "The Fergus system (Bangalore and Rambow, 2000) employs a statistical tree model to select probable trees and a word n-gram model to rank the string candidates generated from the best trees", 
    "clean_text": "The Fergus system (Bangalore and Rambow, 2000) employs a statistical tree model to select probable trees and a word n-gram model to rank the string candidates generated from the best trees.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P04-3009", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Charles B., Callaway", 
    "raw_text": "Fergus (Bangalore and Rambow, 2000) used the Penn TreeBank as a corpus, requiring a more substantial transformation algorithm since it requires a lexical predicate-argument structure instead of the TreeBank &apos; s representation", 
    "clean_text": "Fergus (Bangalore and Rambow, 2000) used the Penn TreeBank as a corpus, requiring a more substantial transformation algorithm since it requires a lexical predicate-argument structure instead of the TreeBank's representation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C02-1138", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "John, Chen | Srinivas, Bangalore | Owen, Rambow | Marilyn A., Walker", 
    "raw_text": "Stochastic methods for NLG may provide such auto maticity, but most previous work (Knight and Hatzivassiloglou, 1995), (Langkilde and Knight, 1998), (Oh and Rudnicky, 2000), (Uchimotoetal., 2000), (Bangalore and Rambow, 2000) con cent rate on the specifics of individual stochastic methods, ignoring other issues such as integrability, portability, and efficiency", 
    "clean_text": "Stochastic methods for NLG may provide such automaticity, but most previous work (Knight and Hatzivassiloglou, 1995), (Langkilde and Knight, 1998), (Oh and Rudnicky, 2000), (Uchimotoetal., 2000), (Bangalore and Rambow, 2000) concentrate on the specifics of individual stochastic methods, ignoring other issues such as integrability, portability, and efficiency.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C02-1138", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "John, Chen | Srinivas, Bangalore | Owen, Rambow | Marilyn A., Walker", 
    "raw_text": "We extend the work of (Walker et al., 2001) and (Bangalore and Rambow, 2000) in various ways", 
    "clean_text": "We extend the work of (Walker et al., 2001) and (Bangalore and Rambow, 2000) in various ways.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "N03-1013", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Nizar, Habash | Bonnie Jean, Dorr", 
    "raw_text": "WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SEN SUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al, 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000)", 
    "clean_text": "WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al, 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N09-3004", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Karthik, Gali | Sriram, Venkatapathy", 
    "raw_text": "These concepts are then realized into words resulting in a bag of words with syntactic relations (BangaloreandRambow, 2000)", 
    "clean_text": "These concepts are then realized into words resulting in a bag of words with syntactic relations (Bangalore and Rambow, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P08-1022", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Dominic, Espinosa | Michael, White | Dennis, Mehay", 
    "raw_text": "We have introduced a novel type of super tagger, which we have dubbed a hyper tagger, that assigns CCG category labels to elementary predications ina structured semantic representation with high accuracy at several levels of tagging ambiguity in a fashion reminiscent of (Bangalore and Rambow, 2000) .To our knowledge, we are the first to report tagging results in the semantic-to-syntactic direction. We have also shown that, by integrating this hyper tagger with a broad-coverage CCG chart realizer, considerably faster realization times are possible (approximately twice as fast as compared with a realizer that performs simple lexical look-ups) with higher BLEU, METEOR and exact string match scores", 
    "clean_text": "We have introduced a novel type of supertagger, which we have dubbed a hypertagger, that assigns CCG category labels to elementary predications in a structured semantic representation with high accuracy at several levels of tagging ambiguity in a fashion reminiscent of (Bangalore and Rambow, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "C02-1064", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Kiyotaka, Uchimoto | Satoshi, Sekine | Hitoshi, Isahara", 
    "raw_text": "Bangalore and Rambow proposed a method to generate candidate-text sentences in the form of trees (Bangalore and Rambow, 2000)", 
    "clean_text": "Bangalore and Rambow proposed a method to generate candidate-text sentences in the form of trees (Bangalore and Rambow, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W05-1601", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Anja, Belz", 
    "raw_text": "of a small number of alternative realisations, and a 3-gram model to select the best [Bangalore and Rambow, 2000b] .Humphreys et al [2001] reused a PCFG trained for NL parsing to build syntactic generation trees from candidate syntactic nodes. Recently, Habash [2004] reported work using structural 2grams for lexical/syntactic selection tasks (using joint prob ability of word and parent word in dependency structures, instead of probability of word given preceding word), as well as conventional n-grams for selection among surface strings", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "I05-5012", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Stephen, Wan | Mark, Dras | Robert, Dale | C&eacute;cile L., Paris", 
    "raw_text": "In recent years, there has been a steady stream of research in statistical text generation (see Langkilde and Knight (1998), and Bangalore and Rambow (2000))", 
    "clean_text": "In recent years, there has been a steady stream of research in statistical text generation (see Langkilde and Knight (1998), and Bangalore and Rambow (2000)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W04-2311", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Cassandre, Creswell | Elsi, Kaiser", 
    "raw_text": "(Bangalore and Rambow, 2000)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W04-2311", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Cassandre, Creswell | Elsi, Kaiser", 
    "raw_text": "In other words, in generating a form f to express an input, one wants to maximize the probability of the form, P (f), with respect to some gold-standard corpus, and thus express the in put in a way that resembles the realizations in the corpus most closely (Bangalore and Rambow, 2000)", 
    "clean_text": "In other words, in generating a form f to express an input, one wants to maximize the probability of the form, P (f), with respect to some gold-standard corpus, and thus express the in put in a way that resembles the realizations in the corpus most closely (Bangalore and Rambow, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P02-1004", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Michael, Gamon | Eric K., Ringger | Simon H., Corston-Oliver | Robert C., Moore", 
    "raw_text": "FERGUS (Bangalore and Rambow, 2000), on the other hand, employs a model of syntactic structure during sentence realization", 
    "clean_text": "FERGUS (Bangalore and Rambow, 2000), on the other hand, employs a model of syntactic structure during sentence realization.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W07-0408", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Keith, Hall | Petr, Nemec", 
    "raw_text": "Both the model of Amalgam and that presented here differ considerably from the n-gram models of Langkilde and Knight (1998), the TAG models of Bangalore and Rambow (2000), and the stochastic generation from semantic representation approach of Soricutand Marcu (2006)", 
    "clean_text": "Both the model of Amalgam and that presented here differ considerably from the n-gram models of Langkilde and Knight (1998), the TAG models of Bangalore and Rambow (2000), and the stochastic generation from semantic representation approach of Soricutand Marcu (2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P06-1130", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Aoife, Cahill | Josef, van Genabith", 
    "raw_text": "Bangalore and Rambow (2000) use n-gram word sequence statistics in a TAG-basedgeneration model to rank output strings and additional statistical and symbolic resources at intermediate generation stages", 
    "clean_text": "Bangalore and Rambow (2000) use n-gram word sequence statistics in a TAG-based generation model to rank output strings and additional statistical and symbolic resources at intermediate generation stages.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W05-1612", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Erwin, Marsi | Emiel, Krahmer", 
    "raw_text": "[Bangalore and Rambow, 2000] Srinivas Bangalore and Owen Rambow", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]