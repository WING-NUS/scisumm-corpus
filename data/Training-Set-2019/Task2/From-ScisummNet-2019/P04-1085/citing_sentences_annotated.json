[
  {
    "citance_No": 1, 
    "citing_paper_id": "P05-1037", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Liang, Zhou | Eduard, Hovy", 
    "raw_text": "Both systems use a corpus that, on average, contains 190 words and 3.25 messages per thread, much shorter than the ones in our collection. Galley et al (2004) describe a system that identifies agreement and disagreement occurring in human-to-human multi-party conversations", 
    "clean_text": "Galley et al (2004) describe a system that identifies agreement and disagreement occurring in human-to-human multi-party conversations.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P05-1037", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Liang, Zhou | Eduard, Hovy", 
    "raw_text": "An adjacent pair is said to consist of two parts that are ordered, adjacent, and produced by different speakers (Galley et al, 2004)", 
    "clean_text": "An adjacent pair is said to consist of two parts that are ordered, adjacent, and produced by different speakers (Galley et al, 2004).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P05-1037", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Liang, Zhou | Eduard, Hovy", 
    "raw_text": "Using them, Galley et al (2004) report an 8% increase in speaker identification", 
    "clean_text": "Using them, Galley et al (2004) report an 8% increase in speaker identification.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D12-1006", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Dragomir R., Radev | Ahmed, Hassan | Amjad, Abu-Jbara", 
    "raw_text": "Galley et al2004) show the value of using durational and structural features for identifying agreement and disagreement in spoken conversational speech", 
    "clean_text": "Galley et al 2004 show the value of using durational and structural features for identifying agreement and disagreement in spoken conversational speech.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W06-1639", 
    "citing_paper_authority": 46, 
    "citing_paper_authors": "Matt, Thomas | Bo, Pang | Lillian, Lee", 
    "raw_text": "More sophisticated approaches have been proposed (Hillard et al, 2003), including an extension that, in an interesting reversal of our problem, makes use of sentiment polarity indicators within speech segments (Galley et al, 2004)", 
    "clean_text": "More sophisticated approaches have been proposed (Hillard et al, 2003), including an extension that, in an interesting reversal of our problem, makes use of sentiment polarity indicators within speech segments (Galley et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C10-2100", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Akiko, Murakami | Rudy, Raymond", 
    "raw_text": "opinions (Murakami et al, 2007) .Classifyingagree/disagree opinions in conversational debates using Bayesian networks was presented in (Galley et al, 2004)", 
    "clean_text": "Classifying agree/disagree opinions in conversational debates using Bayesian networks was presented in (Galley et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "N07-1004", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Pei-Yun, Hsueh | Johanna D., Moore", 
    "raw_text": "Other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration, F0, speech rate) (Hillard et al, 2003) and structural information (e.g., the previous and following speaker) (Galley et al, 2004)", 
    "clean_text": "Other researchers have developed models for detecting agreement and disagreement in meetings, using models that combine lexical features with prosodic features (e.g., pause, duration, F0, speech rate) (Hillard et al, 2003) and structural information (e.g., the previous and following speaker) (Galley et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P10-2057", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Trung H., Bui | Stanley, Peters", 
    "raw_text": "This research has tackled is sues such as the automatic detection of agreement and disagreement (Galley et al, 2004), and of the level of involvement of conversational par tic ipants (Gatica-Perez et al, 2005)", 
    "clean_text": "This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al, 2004), and of the level of involvement of conversational participants (Gatica-Perez et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N06-2014", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Sangyun, Hahn | Richard, Ladner | Mari, Ostendorf", 
    "raw_text": "First, we performed the same experiment as in (Hillard et al, 2003) and (Galley et al, 2004), using the contrast classifier (CC) method. Among the four meetings, the data from one meeting was set aside for testing", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "N06-2014", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Sangyun, Hahn | Richard, Ladner | Mari, Ostendorf", 
    "raw_text": "Accuracy Hillard-lex 82 Galley-lex 85.0 SVM-lex 86.3 CC-lex 86.7 Galley-exp 86.9Table 2: Comparison of the classification performance Method 3-way A/D A/D Acc confusion recovery unsupervised 79 8 83 cc 81.4 4 82.4 cc-threshold 76.7 6 85.2 cc-meta 86.7 5 81.3cc-meta-thres 87.1 5 82.4tropy model in (Galley et al, 2004)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "N06-2014", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Sangyun, Hahn | Richard, Ladner | Mari, Ostendorf", 
    "raw_text": "The contrast classifier is also competitive with the best case result in (Galley et al, 2004) (last entry), which adds speaker change, segment duration, and adjacency pair sequence dependency features using a dynamic Bayesian network", 
    "clean_text": "The contrast classifier is also competitive with the best case result in (Galley et al, 2004) (last entry), which adds speaker change, segment duration, and adjacency pair sequence dependency features using a dynamic Bayesian network.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "N06-2014", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Sangyun, Hahn | Richard, Ladner | Mari, Ostendorf", 
    "raw_text": "The experiments here kept the feature set fixed, but results of (Galley et al, 2004) suggest that further gains can be achieved by augmenting the feature set", 
    "clean_text": "The experiments here kept the feature set fixed, but results of (Galley et al, 2004) suggest that further gains can be achieved by augmenting the feature set.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W12-3710", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Cecile, Paris | Paul, Thomas | Nalin, Narang | Jie, Yin", 
    "raw_text": "Galley et al (2004) proposed the use of Bayesian networks to model pragmatic dependencies of previous agreement or disagreement on the current utterance", 
    "clean_text": "Galley et al (2004) proposed the use of Bayesian networks to model pragmatic dependencies of previous agreement or disagreement on the current utterance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "E06-1022", 
    "citing_paper_authority": 7, 
    "citing_paper_authors": "Natasa, Jovanovic | Rieks, op den Akker | Anton, Nijholt", 
    "raw_text": "It is to be expected that the a-part provides a useful cue for identification of addressee of the b-part (Galley et al, 2004)", 
    "clean_text": "It is to be expected that the a-part provides a useful cue for identification of addressee of the b-part (Galley et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W12-1607", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Carolyn, Penstein Ros&Atilde;&copy; | Elijah, Mayfield | David, Adamson", 
    "raw_text": "This additional structure has been shown to improve performance of automated analysis (Poesio and Mikheev, 1998) .Identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (Galley et al, 2004), addressee detection (op den Akker and Traum,2009), and real-world applications, such as customer service conversations (Kim et al, 2010) .Higher-order structure has also been explored in dialogue, from complex graph-like relations (Wolf and Gibson, 2005) to simpler segmentation-based approaches (Malioutov and Barzilay, 2006)", 
    "clean_text": "Identification of this fine-grained structure of an interaction has been studied in prior work, with applications in agreement detection (Galley et al, 2004), addressee detection (op den Akker and Traum, 2009), and real-world applications, such as customer service conversations (Kim et al, 2010).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W06-1643", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Michel, Galley", 
    "raw_text": "To find these pairs automatically, we trained a non-sequential log-linear model that achieves a .902 accuracy (Galley et al, 2004)", 
    "clean_text": "To find these pairs automatically, we trained a non-sequential log-linear model that achieves a .902 accuracy (Galley et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "E09-1032", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Matthew, Frampton | Raquel, Fern&aacute;ndez | Patrick, Ehlen | C. Mario, Christoudias | Trevor, Darrell | Stanley, Peters", 
    "raw_text": "Our set of discourse features is a simplified version of those employed by Galley et al (2004) and Gupta et al (2007a)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]