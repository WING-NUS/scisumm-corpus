[
  {
    "citance_No": 1, 
    "citing_paper_id": "E12-2014", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Masud, Moshtaghi | Shanika, Karunasekera | Aaron, Harwood | Timothy, Baldwin | Paul, Cook | Bo, Han", 
    "raw_text": "We employ the method of Ritter et al (2011 )totokenise messages, and use token unigrams as features, including any hash tags, but ignoring twitter mentions, URLs and purely numeric tokens", 
    "clean_text": "We employ the method of Ritter et al (2011) to tokenise messages, and use token unigrams as features, including any hash tags, but ignoring twitter mentions, URLs and purely numeric tokens.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "E12-2014", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Masud, Moshtaghi | Shanika, Karunasekera | Aaron, Harwood | Timothy, Baldwin | Paul, Cook | Bo, Han", 
    "raw_text": "71 ll l l l l l l l l l l 10000 20000 30000 40000 0.15 0.20 0.25 0.30 0.35 0.40 Feature Number Predict ion Accurac y Figure 2: Accuracy of geolocation prediction, for varying numbers of features based on information gain also experimented with included the named entity predictions of the Ritter et al (2011) method into our system, but found that it had no impact on predictive accuracy", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P14-1118", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Aliaksei, Severyn | Alessandro, Moschitti | Olga, Uryupina | Barbara, Plank | Katja, Filippova", 
    "raw_text": "Our second component ?chunker? is taken from (Ritter et al, 2011), which also comes with a model trained on Twitter data 3and shown to per form better on noisy data such as user comments", 
    "clean_text": "Our second component - chunker - is taken from (Ritter et al, 2011), which also comes with a model trained on Twitter data and shown to perform better on noisy data such as user comments.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P14-1118", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Aliaksei, Severyn | Alessandro, Moschitti | Olga, Uryupina | Barbara, Plank | Katja, Filippova", 
    "raw_text": "Similarly, the nodes associated with words found in 3 Thechunker from (Ritter et al, 2011) relies on its ownPOS tagger, however, in our structural representations we favor the POS tags from the CMU Twitter tagger and take only the chunk tags from the chunker", 
    "clean_text": "The chunker from (Ritter et al., 2011) relies on its own POS tagger, however, in our structural representations we favor the POS tags from the CMU Twitter tagger and take only the chunk tags from the chunker.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P12-1055", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Zhongyang, Fu | Xiangyang, Zhou | Furu, Wei | Xiaohua, Liu | Ming, Zhou", 
    "raw_text": "As a result, the task of named entity recognition (NER) for tweets, which aims to identify mentions of rigid designators from tweets belonging to named-entity types such as persons, organizations and locations (2007), has attracted increasing research interest. For example, Ritter et al (2011) develop a system that exploits a CRF model to segment named 1http: //www.twitter.comentities and then uses a distantly supervised approach based on LabeledLDA to classify named entities", 
    "clean_text": "For example, Ritter et al (2011) develop a system that exploits a CRF model to segment named entities and then uses a distantly supervised approach based on LabeledLDA to classify named entities.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P14-2114", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Deyu, Zhou | Liangyu, Chen | Yulan, He", 
    "raw_text": "We have also used a named entity tagger trained specifically on the Twitter data 3 (Ritter et al, 2011) to directly extract named entities from tweets", 
    "clean_text": "We have also used a named entity tagger trained specifically on the Twitter data (Ritter et al, 2011) to directly extract named entities from tweets.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P14-2114", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Deyu, Zhou | Liangyu, Chen | Yulan, He", 
    "raw_text": "Firstly, a named entity recognizer (Ritter et al, 2011) is employed to identify named entities", 
    "clean_text": "Firstly, a named entity recognizer (Ritter et al, 2011) is employed to identify named entities.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P12-1109", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Xiao, Jiang | Fei, Liu | Fuliang, Weng", 
    "raw_text": "The social text serves as avery valuable information source for many NLPapplications, such as the information extraction (Ritter et al, 2011), retrieval (Subramaniam et al, 2009), summarization (Liu et al, 2011a), sentiment analysis (Celikyilmaz et al, 2010), etc. Yet existing systems often perform poorly in this domain due theto extensive use of the nonstandard tokens ,emoti cons, incomplete and ungrammatical sentences, etc. It is reported that the Stanford named entity re cog nizer (NER) experienced a performance drop from 90.8% to 45.8% on tweets (Liu et al, 2011c); the part-of-speech (POS) tagger and dependency parser degraded 12.2% and 20.65% respectively on tweets (Foster et al, 2011)", 
    "clean_text": "The social text serves as a very valuable information source for many NLP applications, such as the information extraction (Ritter et al, 2011), retrieval (Subramaniam et al, 2009), summarization (Liu et al, 2011a), sentiment analysis (Celikyilmaz et al, 2010), etc.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P13-1114", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Congle, Zhang | Tyler, Baldwin | Howard, Ho | Benny, Kimelfeld | Yunyao, Li", 
    "raw_text": "We generate part-of-speech information over the original raw text using a Twitter part-of-speech tagger (Ritter et al, 2011)", 
    "clean_text": "We generate part-of-speech information over the original raw text using a Twitter part-of-speech tagger (Ritter et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W12-2106", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Aobo, Wang | Tao, Chen | Min-Yen, Kan", 
    "raw_text": "6Using the UW Twitter NLP tools (Ritter et al, 2011)", 
    "clean_text": "Using the UW Twitter NLP tools (Ritter et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W12-2106", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Aobo, Wang | Tao, Chen | Min-Yen, Kan", 
    "raw_text": "To study the diversity of named entities (NEs) in re tweets, we used UW Twitter NLP Tools (Ritter et al., 2011) to extract NEs from RT-data", 
    "clean_text": "To study the diversity of named entities (NEs) in retweets, we used UW Twitter NLP Tools (Ritter et al., 2011) to extract NEs from RT-data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W12-2106", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Aobo, Wang | Tao, Chen | Min-Yen, Kan", 
    "raw_text": "as a variant of? Facebook?), and manually categorized them against the 10-class schema defined by Ritter et al (2011)", 
    "clean_text": "We then standardized variants (i.e. \"fb\" as a variant of \"Facebook\"), and manually categorized them against the 10-class schema defined by Ritter et al. (2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P14-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Dirk, Hovy | Barbara, Plank | Anders, S\u00c3\u00b8gaard", 
    "raw_text": "Leaving out the dedicated test set to avoid in-sample bias, we evaluate our mod els across three data sets: RITTER (the 10% test split of the data in Ritter et al (2011) used in Derczynski et al (2013)), the test set from Foster et al", 
    "clean_text": "Leaving out the dedicated test set to avoid in-sample bias, we evaluate our models across three data sets: RITTER (the 10% test split of the data in Ritter et al (2011) used in Derczynski et al (2013)), the test set from Foster et al.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P14-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Dirk, Hovy | Barbara, Plank | Anders, S\u00c3\u00b8gaard", 
    "raw_text": "For chunking, we use the test sets from Foster et al (2011) and Ritter et al (2011) (with the splits from Derczynski et al (2013))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P14-2062", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Dirk, Hovy | Barbara, Plank | Anders, S\u00c3\u00b8gaard", 
    "raw_text": "For NER, we use data from Finin et al (2010) and again Ritter et al (2011)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }
]