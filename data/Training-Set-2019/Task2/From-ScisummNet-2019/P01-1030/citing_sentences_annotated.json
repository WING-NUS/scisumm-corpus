[
  {
    "citance_No": 1, 
    "citing_paper_id": "P01-1050", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Daniel, Marcu", 
    "raw_text": "A The rest of the factors denote distorsionprobabilities (d), which capture the probability that words change their position when translated from one language into another; the probability of some French words being generated from an invisible English NULL element (p \u0006), etc. See (Brown et al, 1993) or (Germann et al, 2001) for a detailed discussion of this translation model and a description of its parameters", 
    "clean_text": "See (Brown et al, 1993) or (Germann et al, 2001) for a detailed discussion of this translation model and a description of its parameters.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P01-1050", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Daniel, Marcu", 
    "raw_text": "The decoding algorithm that we use is a greedy one? see (Germann et al, 2001) for details", 
    "clean_text": "The decoding algorithm that we use is a greedy one - see (Germann et al, 2001) for details.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P01-1050", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Daniel, Marcu", 
    "raw_text": "As discussed by Germann et al (2001), the word-for-word gloss is constructed by aligning each French word fL with its most likely English translation efk (efkmlargmax n t (e \u0000fL))", 
    "clean_text": "As discussed by Germann et al (2001), the word-for-word gloss is constructed by aligning each French word fL with its most likely English translation efk.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D12-1108", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "J&ouml;rg, Tiedemann | Christian, Hardmeier | Joakim, Nivre", 
    "raw_text": "Similarly to the work by Germannet al (2001), their decoder is deterministic and explores the entire neighbourhood of a state in order to identify the most promising step", 
    "clean_text": "Similarly to the work by Germann et al (2001), their decoder is deterministic and explores the entire neighbourhood of a state in order to identify the most promising step.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W06-1616", 
    "citing_paper_authority": 40, 
    "citing_paper_authors": "Sebastian, Riedel | James, Clarke", 
    "raw_text": "A similar problem also occurs in an ILP formulation for machine translation which treats decoding as the Travelling Sales man Problem (Germann et al, 2001)", 
    "clean_text": "A similar problem also occurs in an ILP formulation for machine translation which treats decoding as the Travelling Salesman Problem (Germann et al, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W06-1616", 
    "citing_paper_authority": 40, 
    "citing_paper_authors": "Sebastian, Riedel | James, Clarke", 
    "raw_text": "For instance, Germann et al (2001) present an ILP formulation of the Machine Translation (MT) decoding task in order to conduct ex act inference", 
    "clean_text": "For instance, Germann et al (2001) present an ILP formulation of the Machine Translation (MT) decoding task in order to conduct exact inference.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "N07-1056", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Pawan, Deshpande | Regina, Barzilay | David R., Karger", 
    "raw_text": "But our problem has an important feature: the length k of the path we want to find is small relative to the number of vertices n. This feature distinguishes our task from other decoding problems, such as decoding in machine translation (Germann et al, 2001), that aremodeled using a standard TSP formulation", 
    "clean_text": "This feature distinguishes our task from other decoding problems, such as decoding in machine translation (Germann et al, 2001), that are modeled using a standard TSP formulation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "N03-1017", 
    "citing_paper_authority": 624, 
    "citing_paper_authors": "Philipp, Koehn | Franz Josef, Och | Daniel, Marcu", 
    "raw_text": "We also include din the figure the performance of an IBM Model 4 word based translation system (M4), which uses a greedy decoder [Germann et al, 2001]", 
    "clean_text": "We also included in the figure the performance of an IBM Model 4 word based translation system (M4), which uses a greedy decoder [Germann et al, 2001].", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "N04-4003", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Michael, Paul | Eiichiro, Sumita | Seiichi, Yamamoto", 
    "raw_text": "(Germann et al, 2001) presents a greedy approach to search for the translation that is most likely according to previously learned statitistical models", 
    "clean_text": "(Germann et al, 2001) presents a greedy approach to search for the translation that is most likely according to previously learned statitistical models.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W04-2708", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Martin, Cmejrek | Jan, Curin | Jiri, Havelka", 
    "raw_text": "The system uses models GIZA++ and ISI ReWrite decoder (Germann et al., 2001)", 
    "clean_text": "The system uses models GIZA++ and ISI ReWrite decoder (Germann et al., 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "H05-1095", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "Michel, Simard | Nicola, Cancedda | Bruno, Cavestro | Marc, Dymetman | Eric, Gaussier | Cyril, Goutte | Kenji, Yamada | Philippe, Langlais | Arne, Mauser", 
    "raw_text": "As a point of comparison, we also trained an IBM-4 translation model with the GIZA++ toolkit (Och and Ney, 2000), using the combined bi-phrase building and training sets, and translated the test set using the ReWrite decoder (Germann et al, 2001) 5", 
    "clean_text": "As a point of comparison, we also trained an IBM-4 translation model with the GIZA++ toolkit (Och and Ney, 2000), using the combined bi-phrase building and training sets, and translated the test set using the ReWrite decoder (Germann et al, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "N03-1010", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Ulrich, Germann", 
    "raw_text": "Using the same evaluation metric (but different evaluation data), Wang and Waibel (1997) report search error rates of 7.9% and 9.3%, respectively, for their decoders. Och et al (2001) and Germann et al (2001) both implemented optimal decoders and benchmarked approximative algorithms against them", 
    "clean_text": "Och et al (2001) and Germann et al (2001) both implemented optimal decoders and benchmarked approximative algorithms against them.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "N03-1010", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Ulrich, Germann", 
    "raw_text": "Germann et al (2001) compare translations obtained by a multi-stack decoder and a greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as a variant of the traveling-salesman problem (cf", 
    "clean_text": "Germann et al (2001) compare translations obtained by a multi-stack decoder and a greedy hill-climbing algorithm against those produced by an optimal integer programming decoder that treats decoding as a variant of the traveling-salesman problem.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "N03-1010", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Ulrich, Germann", 
    "raw_text": "While acceptably fast for the kind of evaluation used in Germann et al (2001), namely sentences of up to 20 words, its speed becomes an issue for more realistic applications", 
    "clean_text": "While acceptably fast for the kind of evaluation used in Germann et al (2001), namely sentences of up to 20 words, its speed becomes an issue for more realistic applications.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "N03-1010", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Ulrich, Germann", 
    "raw_text": "In this subsection we recapitulate the greedy hill climbing algorithm presented in Germann et al (2001)", 
    "clean_text": "In this subsection we recapitulate the greedy hill climbing algorithm presented in Germann et al (2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "N03-1010", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Ulrich, Germann", 
    "raw_text": "Foradifferent approach that is based on dependency tree trans formations, see Alshawi et al (2000) .Thirdly, the results of our experiments with randomized searches show that greedy decoding does not per form as well on longer sentences as one might conclude from the findings in Germann et al (2001)", 
    "clean_text": "Thirdly, the results of our experiments with randomized searches show that greedy decoding does not perform as well on longer sentences as one might conclude from the findings in Germann et al (2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "N03-1010", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Ulrich, Germann", 
    "raw_text": "In this paper, we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al (2001) and presented improvements that drastically reduce the decoder? s complexity and speed to practically linear time", 
    "clean_text": "In this paper, we have analyzed the complexity of the greedy decoding algorithm originally presented in Germann et al (2001) and presented improvements that drastically reduce the decoder's complexity and speed to practically linear time.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "C02-1050", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Taro, Watanabe | Eiichiro, Sumita", 
    "raw_text": "Germann et al (2001) suggested greedy method and integer programming decoding, though the first method suffer from the similar problem as described above and the second is impractical for the real-world application", 
    "clean_text": "Germann et al (2001) suggested greedy method and integer programming decoding, though the first method suffer from the similar problem as described above and the second is impractical for the real-world application.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "C02-1050", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Taro, Watanabe | Eiichiro, Sumita", 
    "raw_text": "Under this constraint, many researchers had contributed algorithms and associated pruning strategies, such as Berger et al (1996), Och et al (2001), WangandWaibel (1997), Tillmann and Ney (2000) Garcia Varea and Casacuberta (2001) and Germann et al (2001), though they all based on almost linearly Translation Model Lexical Model? t (f j|ei) Fertility Model? n (? i |ei) Distortion Model Head ?d1 (j? c ?i|A (e? i) B (f j)) Non-Head ?d1& gt; (j? j? |B (f j)) NULL Translation Model (m?? 0? 0) pm? 2? 00 p? 0 1 Figure 2: Translation Model (IBM Model 4) aligned language pairs, and not suitable for language pairs with totally different alignment correspondence, such as Japanese and English", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "C02-1050", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Taro, Watanabe | Eiichiro, Sumita", 
    "raw_text": "The list of zero fertility words can be obtained from the viterbi alignment of training corpus (Germann et al, 2001) .The extension operator applied to an open hypo the sis (e, C) is:? align j to ei? this creates a new hypothesis by raising the fertility of ei by consuming the input word f j. The generated hypothesis can be treated as either closed or open, that means to stop raising the fertility or raise the fertility further more", 
    "clean_text": "The list of zero fertility words can be obtained from the viterbi alignment of training corpus (Germann et al, 2001).", 
    "keep_for_gold": 0
  }
]