[
  {
    "citance_No": 1, 
    "citing_paper_id": "W04-3213", 
    "citing_paper_authority": 48, 
    "citing_paper_authors": "Robert, Swier | Suzanne, Stevenson", 
    "raw_text": "Determining the appropriate level of generalization for a noun is an open problem (e.g., Clark and Weir, 2002)", 
    "clean_text": "Determining the appropriate level of generalization for a noun is an open problem (e.g., Clark and Weir, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "E12-1051", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Janara, Christensen | Marius A., Pasca", 
    "raw_text": "Clark and Weir (2002) investigate the task of generalizing a single relation concept pair", 
    "clean_text": "Clark and Weir (2002) investigate the task of generalizing a single relation concept pair.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W07-0606", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Afra, Alishahi | Suzanne, Stevenson", 
    "raw_text": "Clark and Weir (2002) also find an appropriate set of concept nodes to rep resent the selectional preferences for a verb, but do so using a? 2 test over corpus frequencies mapped to concepts to determine when to generalize from a node to its parent", 
    "clean_text": "Clark and Weir (2002) also find an appropriate set of concept nodes to represent the selectional preferences for a verb, but do so using a test over corpus frequencies mapped to concepts to determine when to generalize from a node to its parent.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D07-1042", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Sebastian, Pad&oacute; | Ulrike, Pado | Katrin, Erk", 
    "raw_text": "Other models also relying on the WordNet resource include Abe and Li (1996) and Clark and Weir (2002)", 
    "clean_text": "Other models also relying on the WordNet resource include Abe and Li (1996) and Clark and Weir (2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "E09-1092", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Benjamin, van Durme | Phillip, Michalak | Lenhart K., Schubert", 
    "raw_text": "Calling the generalization problem a case of engineering in the face of sparse data, Clark and Weir (2002) looked at a number of previous methods, one conclusion being that the approach of Li and Abe appears to over-generalize", 
    "clean_text": "Calling the generalization problem a case of engineering in the face of sparse data, Clark and Weir (2002) looked at a number of previous methods, one conclusion being that the approach of Li and Abe appears to over-generalize.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W06-3815", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Vivian, Tsang | Suzanne, Stevenson", 
    "raw_text": "Since we wish to evaluate the strength of our method alone without any additional NLP effort, we bypass the issue of approximating the true distribution of the concepts via word sense disambiguation or class based approximation methods, such as those by Li and Abe (1998) and Clark and Weir (2002)", 
    "clean_text": "Since we wish to evaluate the strength of our method alone without any additional NLP effort, we bypass the issue of approximating the true distribution of the concepts via word sense disambiguation or class based approximation methods, such as those by Li and Abe (1998) and Clark and Weir (2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W06-3815", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Vivian, Tsang | Suzanne, Stevenson", 
    "raw_text": "Finding a generalization of a profile is explored in the works of Clark and Weir (2002) and Li and Abe (1998)", 
    "clean_text": "Finding a generalization of a profile is explored in the works of Clark and Weir (2002) and Li and Abe (1998).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W05-0601", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Roberto, Basili | Marco, Cammisa | Alessandro, Moschitti", 
    "raw_text": "(Clark and Weir, 2002))", 
    "clean_text": "Methods for the induction of semantically inspired word clusters have been widely used in language modeling and lexical acquisition tasks (e.g. (Clark and Weir, 2002.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D07-1039", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Diana, McCarthy | Sriram, Venkatapathy | Aravind K., Joshi", 
    "raw_text": "There is scope for experimenting with other approaches such as (Clark and Weir, 2002), however, we feel a type-based approach is worthwhile to avoid the noise introduced from frequent but polysemous arguments and bias from highly frequent arguments which might be part of a multi word rather than a pro to typical argument of the predicate in question, for example eat hat", 
    "clean_text": "There is scope for experimenting with other approaches such as (Clark and Weir, 2002), however, we feel a type-based approach is worthwhile to avoid the noise introduced from frequent but polysemous arguments and bias from highly frequent arguments which might be part of a multiword rather than a prototypical argument of the predicate in question, for example eat hat.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D07-1039", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Diana, McCarthy | Sriram, Venkatapathy | Aravind K., Joshi", 
    "raw_text": "Further comparison of WNPROTOsandDSPROTOs to other WordNet models are war ranted to contrast the effect of our proposal for disambiguation using word types with iterative approaches, particularly those of Clark and Weir (2002)", 
    "clean_text": "Further comparison of WNPROTOs and DSPROTOs to other WordNet models are warranted to contrast the effect of our proposal for disambiguation using word types with iterative approaches, particularly those of Clark and Weir (2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "S12-1025", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Diarmuid, &Oacute; S&eacute;aghdha | Anna, Korhonen", 
    "raw_text": "Clark and Weir (2002) present a model that, while not explicitly described as cut-based, likewise seeks to find the right level of generalisation for an observation", 
    "clean_text": "Clark and Weir (2002) present a model that, while not explicitly described as cut-based, likewise seeks to find the right level of generalisation for an observation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "S12-1025", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Diarmuid, &Oacute; S&eacute;aghdha | Anna, Korhonen", 
    "raw_text": "In order to compare against previously proposed selectional preference approaches based on WordNet we also reimplemented the methods that per formed best in the evaluation of Brockmann and Lapata (2003): Resnik (1993) and Clark and Weir (2002)", 
    "clean_text": "In order to compare against previously proposed selectional preference approaches based on WordNet we also reimplemented the methods that performed best in the evaluation of Brockmann and Lapata (2003): Resnik (1993) and Clark and Weir (2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P05-1004", 
    "citing_paper_authority": 14, 
    "citing_paper_authors": "James R., Curran", 
    "raw_text": "Lexical-semantic resources have been applied successful to a wide range of Natural Language Processing (NLP) problems ranging from collocation extraction (Pearce, 2001) and class-based smoothing (Clark and Weir, 2002), to text classification (Baker and McCallum, 1998) and question answering (Pasca and Harabagiu, 2001)", 
    "clean_text": "Lexical-semantic resources have been applied successful to a wide range of Natural Language Processing (NLP) problems ranging from collocation extraction (Pearce, 2001) and class-based smoothing (Clark and Weir, 2002), to text classification (Baker and McCallum, 1998) and question answering (Pasca and Harabagiu, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "S12-1011", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Karl Moritz, Hermann | Chris, Dyer | Stephen G., Pulman | Philip, Blunsom", 
    "raw_text": "Pseudo-disambiguation was introduced by Clark and Weir (2002) to evaluate models of selectional preference", 
    "clean_text": "Pseudo-disambiguation was introduced by Clark and Weir (2002) to evaluate models of selectional preference.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "S12-1011", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Karl Moritz, Hermann | Chris, Dyer | Stephen G., Pulman | Philip, Blunsom", 
    "raw_text": "For us, this is to decide which adjective ,a1 or a2, is more likely to modify a noun n. We follow the approach by Clark and Weir (2002) to create the test data", 
    "clean_text": "We follow the approach by Clark and Weir (2002) to create the test data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W04-2411", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Vivian, Tsang | Suzanne, Stevenson", 
    "raw_text": "Briefly, Clark and Weir (2002) populate the WordNet hierarchy based on corpus frequencies (of all nouns for a verb/slot pair), and then determine the appropriate probability estimate at each node in the hierarchy by using \u0018 f to determine whether to generalize an estimate to a parent node in the hierarchy", 
    "clean_text": "Briefly, Clark and Weir (2002) populate the WordNet hierarchy based on corpus frequencies (of all nouns for a verb/slot pair), and then determine the appropriate probability estimate at each node in the hierarchy by using chi square to determine whether to generalize an estimate to a parent node in the hierarchy.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W04-2411", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Vivian, Tsang | Suzanne, Stevenson", 
    "raw_text": "It is worth noting that the method of Clark and Weir (2002) does not yield a tree cut, but instead generally populates the WordNet hierarchy with non-zero probabilities", 
    "clean_text": "It is worth noting that the method of Clark and Weir (2002) does not yield a tree cut, but instead generally populates the WordNet hierarchy with non-zero probabilities.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W04-2411", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Vivian, Tsang | Suzanne, Stevenson", 
    "raw_text": "We evaluate the SPD method on sense profiles created using the method of Clark and Weir (2002), with comparison to the other distance measures (skew and cos) as ex plained above", 
    "clean_text": "We evaluate the SPD method on sense profiles created using the method of Clark and Weir (2002), with comparison to the other distance measures (skew and cos) as explained above.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "I08-2105", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Vivi, Nastase", 
    "raw_text": "In an approach inspired by the works of Li and Abe (1998) and Clark and Weir (2002), McCarthy and Carroll use grammatically connected words from a corpus to induce a distribution of senses over subtrees in the WordNet hierarchy", 
    "clean_text": "In an approach inspired by the works of Li and Abe (1998) and Clark and Weir (2002), McCarthy and Carroll use grammatically connected words from a corpus to induce a distribution of senses over subtrees in the WordNet hierarchy.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D08-1007", 
    "citing_paper_authority": 23, 
    "citing_paper_authors": "Shane, Bergsma | Dekang, Lin | Randy, Goebel", 
    "raw_text": "SPs can help resolve syntactic, word sense, and reference ambiguity (Clark and Weir, 2002), and so gathering them has received a lot of attention in the NLP community", 
    "clean_text": "SPs can help resolve syntactic, word sense, and reference ambiguity (Clark and Weir, 2002), and so gathering them has received a lot of attention in the NLP community.", 
    "keep_for_gold": 0
  }
]