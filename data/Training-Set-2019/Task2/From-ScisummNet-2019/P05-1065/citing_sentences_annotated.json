[
  {
    "citance_No": 1, 
    "citing_paper_id": "N07-1058", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Michael, Heilman | Kevyn, Collins-Thompson | James, P., Callan | Maxine, Eskenazi", 
    "raw_text": "For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student? s lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005)", 
    "clean_text": "For first language (L1) learners (i.e., children learning their native tongue), reading level has been predicted using a variety of techniques, based on models of a student's lexicon, grammatical surface features such as sentence length (Flesch, 1948), or combinations of such features (Schwarm and Ostendorf, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "N07-1058", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Michael, Heilman | Kevyn, Collins-Thompson | James, P., Callan | Maxine, Eskenazi", 
    "raw_text": "Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases", 
    "clean_text": "Prior work on first language readability by Schwarm and Ostendorf (2005) incorporated grammatical surface features such as parse tree depth and average number of verb phrases.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P13-1010", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Camille, Guinaudeau | Michael, Strube", 
    "raw_text": "F S& amp; O 0.786 B& amp; L 0.509 B& amp; L+ S& amp; O 0.888wocoref w coref PU 0.589 0.589 0.374 0.374 PW 0.579 0.579 0.383 0.383 PAcc 0.645 0.645 0.421 0.421 PU, Dist 0.589 0.589 0.280 0.280 PW, Dist 0.570 0.570 0.290 0.290 PAcc, Dist 0.766 0.766 0.308 0.308Table 6: Readability, reported results from Barzi lay and Lapata (2008) vs. graph-based (S& amp; O: Schwarm and Ostendorf (2005)) 4.3.2 Results In order to compare our results with those reported by Barzilay and Lapata (2008), entities used forthe graph-based representation are discourse entities that head NPs.Table 6 shows that, for this task, syntactic information plays a dominant role (PAcc)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C10-1062", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Rohit J., Kate | Xiaoqiang, Luo | Siddharth, Patwardhan | Martin, Franz | Radu, Florian | Raymond J., Mooney | Salim, Roukos | Chris, Welty", 
    "raw_text": "In addition to language models, Heilman et al (2007) and Schwarm and Ostendorf (2005) also use some syntactic features to estimate the grade level of texts. Pitler and Nenkova (2008) consider a different task of predicting text quality for an educated adult audience", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "E09-3003", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Thomas, Fran&ccedil;ois", 
    "raw_text": "Schwarm and Ostendorf (2005) developed a SVMcategoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability", 
    "clean_text": "Schwarm and Ostendorf (2005) developed a SVM categoriser combining a classifier based on trigram language models (one for each level of difficulty), some parsing features such as average tree height, and variables traditionally used in readability.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "E09-3003", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Thomas, Fran&ccedil;ois", 
    "raw_text": "Sup port vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005)", 
    "clean_text": "Support vector machines have already been shown to be useful for readability purposes (Schwarm and Ostendorf, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "C10-2032", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Lijun, Feng | Martin, Jansche | Matt, Huenerfauth | No&eacute;mie, Elhadad", 
    "raw_text": "2A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005)", 
    "clean_text": "A corpus of Weekly Reader articles was previously used in work by Schwarm and Ostendorf (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "C10-2032", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Lijun, Feng | Martin, Jansche | Matt, Huenerfauth | No&eacute;mie, Elhadad", 
    "raw_text": "Schwarm and Ostendorf (2005) studied four parse tree features (average parse tree height, average number of SBARs, noun phrases, and verb phrases per sentences)", 
    "clean_text": "Schwarm and Ostendorf (2005) studied four parse tree features (average parse tree height, average number of SBARs, noun phrases, and verb phrases per sentences).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C10-2032", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Lijun, Feng | Martin, Jansche | Matt, Huenerfauth | No&eacute;mie, Elhadad", 
    "raw_text": "For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005)", 
    "clean_text": "For comparison, we replicated 6 out-of-vocabulary features described in Schwarm and Ostendorf (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "C10-2032", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Lijun, Feng | Martin, Jansche | Matt, Huenerfauth | No&eacute;mie, Elhadad", 
    "raw_text": "We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2)", 
    "clean_text": "We also replicated the 12 perplexity features implemented by Schwarm and Ostendorf (2005) (see Section 3.2).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "C10-2032", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Lijun, Feng | Martin, Jansche | Matt, Huenerfauth | No&eacute;mie, Elhadad", 
    "raw_text": "Table 8 compares a classifier trained on the four parse features of Schwarm and Ostendorf (2005 )toa classifier trained on our expanded set of parse features", 
    "clean_text": "Table 8 compares a classifier trained on the four parse features of Schwarm and Ostendorf (2005) to a classifier trained on our expanded set of parse features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "C10-2032", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Lijun, Feng | Martin, Jansche | Matt, Huenerfauth | No&eacute;mie, Elhadad", 
    "raw_text": "The most closely related previous study is the work of Schwarm and Ostendorf (2005)", 
    "clean_text": "The most closely related previous study is the work of Schwarm and Ostendorf (2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "E09-2013", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Eleni, Miltsakaki", 
    "raw_text": "Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5", 
    "clean_text": "Also, relatedly, (Schwarm and Ostendorf, 2005) use a statistical language model to train SVM classifiers to classify text for grade levels 2-5.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W08-0909", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Michael, Heilman | Kevyn, Collins-Thompson | Maxine, Eskenazi", 
    "raw_text": "A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features", 
    "clean_text": "A measure by Schwarmand Ostendorf (2005) incorporates syntactic analyses, among a variety of other types of features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W11-2308", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Felice, Dell'Orletta | Simonetta, Montemagni | Giulia, Venturi", 
    "raw_text": "The last few years have been characterised by approaches based on the com bi nation of features ranging over different linguistic levels, namely lexical, syntactic and discourse (see e.g. Pitler and Nenkova (2008), Kate (2010)) .Another important factor determining the typology of features to be considered for assessing read ability has to do with the intended audience of readers: it is commonly agreed that reading ease does not follow from intrinsic text properties alone, but it is also affected by the expected audience. Among the studies addressing readability with respect to specific audiences, it is worth mentioning here: Schwarm and Ostendorf (2005) and Heilman et al (2007) dealing with language learners, or Feng (2009 )focussing on people with mild intellectual disabilities", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W12-2019", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Sowmya, Vajjala | Detmar, Meurers", 
    "raw_text": "Schwarm and Ostendorf (2005) and PetersenandOstendorf (2009) report on classification experiments with WeeklyReader data, considering statistical language models, traditional formulae, as well ascertain basic parse tree features in building an SVM based statistical model", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W12-2019", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Sowmya, Vajjala | Detmar, Meurers", 
    "raw_text": "Schwarm and Ostendorf (2005) implemented four parse tree features (average parse tree height, aver age number of SBARs, NPs per sentence and VPs per sentence) in their work", 
    "clean_text": "Schwarm and Ostendorf (2005) implemented four parse tree features (average parse tree height, aver age number of SBARs, NPs per sentence and VPs per sentence) in their work.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W12-2019", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Sowmya, Vajjala | Detmar, Meurers", 
    "raw_text": "A summary of the results can be seen in Table accuracy on the WeeklyReader corpus, compared to 74.01% as the best previous WeeklyReader result, reported by Feng et al (2010) for their much larger feature set (122 features) .In order to verify the impact of our choice of features, we also did a replication of the parsed syntactic feature measures reported by (Schwarm and Ostendorf, 2005) on the WeeklyReader corpus and obtained essentially the same accuracy as the one pub 170lished (50.7% vs. 50.91%), supporting the comparability of the WeeklyReader data used", 
    "clean_text": "In order to verify the impact of our choice of features, we also did a replication of the parsed syntactic feature measures reported by (Schwarm and Ostendorf, 2005) on the WeeklyReader corpus and obtained essentially the same accuracy as the one published (50.7% vs. 50.91%), supporting the comparability of the WeeklyReader data used.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D08-1020", 
    "citing_paper_authority": 39, 
    "citing_paper_authors": "Emily, Pitler | Ani, Nenkova", 
    "raw_text": "(Si and Callan, 2001), (Collins-Thompson and Callan, 2004), (Schwarm and Ostendorf, 2005), and (Heilman et al, 2007) used language models to predict the suitability of texts for a given school grade level", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D08-1020", 
    "citing_paper_authority": 39, 
    "citing_paper_authors": "Emily, Pitler | Ani, Nenkova", 
    "raw_text": "Syntactic complexity is an obvious factor: indeed (Heilman et al, 2007) and (Schwarm and Ostendorf, 2005) also used syntactic features, such as parse tree height or the number of passive sentences, to predict reading grade levels", 
    "clean_text": "Syntactic complexity is an obvious factor: indeed (Heilman et al, 2007) and (Schwarm and Ostendorf, 2005) also used syntactic features, such as parse tree height or the number of passive sentences, to predict reading grade levels.", 
    "keep_for_gold": 1
  }
]