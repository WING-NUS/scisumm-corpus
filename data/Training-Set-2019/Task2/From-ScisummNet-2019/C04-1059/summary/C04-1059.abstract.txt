We explore unsupervised language model adaptation techniques for Statistical Machine Translation.
The hypotheses from the machine translation output are converted into queries at different levels of representation power and used to extract similar sentences from very large monolingual text collection.
Specific language models are then build from the retrieved data and interpolated with a general background model.
Experiments show significant improvements when translating with these adapted language models.
