[
  {
    "citance_No": 1, 
    "citing_paper_id": "P14-1005", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Anders, Bj\u00c3\u00b6rkelund | Jonas, Kuhn", 
    "raw_text": "Luo et al (2004) also apply beam search at test time, but use a static assignment of antecedents and learns log-linear model using batch learning", 
    "clean_text": "Luo et al (2004) also apply beam search at test time, but use a static assignment of antecedents and learns log-linear model using batch learning.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P08-2012", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Jenny Rose, Finkel | Christopher D., Manning", 
    "raw_text": "45 opposed to pairwise models) has included: Luo et al (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree; McCallum and Wellner (2004) who defined several conditional random field-based models; Ng (2005) who took a re ranking approach; and Culotta et al (2006) who use a probabilistic first-order logic model", 
    "clean_text": "Luo et al (2004) who used a Bell tree whose leaves represent possible partitionings of the mentions into entities and then trained a model for searching the tree.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P08-2012", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Jenny Rose, Finkel | Christopher D., Manning", 
    "raw_text": "As observed by Luo et al (2004), if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78.9% precision, and 88.2% F1 score? significantly higher than any published system", 
    "clean_text": "As observed by Luo et al (2004), if all mentions in each document are placed into a single entity, the results on the MUC-6 formal test set are 100% recall, 78.9% precision, and 88.2% F1 score - significantly higher than any published system.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "N09-1065", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Vincent, Ng", 
    "raw_text": "To cope with this computational complexity, Luo employs the algorithm pro posed in Luo et al (2004) to heuristically search for the most probable partition by performing a beam search through a Bell tree", 
    "clean_text": "To cope with this computational complexity, Luo employs the algorithm proposed in Luo et al (2004) to heuristically search for the most probable partition by performing a beam search through a Bell tree.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "N09-1065", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Vincent, Ng", 
    "raw_text": "Details of this process can be found in Luo et al (2004)", 
    "clean_text": "Details of this process can be found in Luo et al (2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D08-1068", 
    "citing_paper_authority": 38, 
    "citing_paper_authors": "Hoifung, Poon | Pedro, Domingos", 
    "raw_text": "The MLNs with learning (MLN-30 and MLN-HAN), on the 7As pointed out by Haghighi& amp; Klein (2007), Luo et al (2004) obtained a very high accuracy on MUC-6, but their system used gold NER features and is not directly comparable", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D08-1068", 
    "citing_paper_authority": 38, 
    "citing_paper_authors": "Hoifung, Poon | Pedro, Domingos", 
    "raw_text": "It tied with Denis& amp; Baldridge (2007) on NWIRE, and was somewhat less accurate on BNEWS and NPAPER.Luo et al (2004) pointed out that one can obtain a very high MUC score simply by lumping all mentions together", 
    "clean_text": "Luo et al (2004) pointed out that one can obtain a very high MUC score simply by lumping all mentions together.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W10-2301", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Zheng, Chen | Heng, Ji", 
    "raw_text": "Unfortunately, most of the proposed clustering algorithms ,e.g., closest-first clustering (Soon et al, 2001), best first clustering (Ng and Cardie, 2002), suffer from a drawback: an instant decision is made (in greedy style) when considering two mentions are co referent or not, therefore, the algorithm makes no attempt to search through the space of all possible clusterings, which results in a sub optimal clustering (Luo et al, 2004)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W10-2301", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Zheng, Chen | Heng, Ji", 
    "raw_text": "They compared BESTCUT algorithm with (Luo et al, 2004)? s Belltree and (Ng and Cardie, 2002)? s Link-Best algorithm and showed that using ground-truth entities, BESTCUT outperforms the other two with statistical significance (4.8% improvement over Belltree and Link Best algorithm in ECM F-measure)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "N06-1025", 
    "citing_paper_authority": 40, 
    "citing_paper_authors": "Simone Paolo, Ponzetto | Michael, Strube", 
    "raw_text": "This is in contrast to other related works in co reference resolution (e.g. Luo et al (2004), Kehler et al (2004))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P08-1096", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Xiaofeng, Yang | Jian, Su | Jun, Lang | Chew Lim, Tan | Ting, Liu | Sheng, Li", 
    "raw_text": "Luo et al (2004) propose a system that performs co reference resolution by doing search in a large space of entities", 
    "clean_text": "Luo et al (2004) propose a system that performs coreference resolution by doing search in a large space of entities.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P08-1096", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Xiaofeng, Yang | Jian, Su | Jun, Lang | Chew Lim, Tan | Ting, Liu | Sheng, Li", 
    "raw_text": "As a base line, we follow the solution proposed in (Luo et al,2004) to design a set of first-order features", 
    "clean_text": "As a base line, we follow the solution proposed in (Luo et al, 2004) to design a set of first-order features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P10-1142", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Vincent, Ng", 
    "raw_text": "For example, Luo et al (2004) apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model", 
    "clean_text": "For example, Luo et al (2004) apply the ANY predicate to generate cluster-level features for their entity-mention model, which does not perform as well as the mention-pair model.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P10-1142", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "Vincent, Ng", 
    "raw_text": "Memorization features have been used as binary-valued features indicating the presence or absence of their words (Luo et al, 2004) or as probabilistic features indicating the probability that the two heads are co referent according to the training data (Ng, 2007b)", 
    "clean_text": "Memorization features have been used as binary-valued features indicating the presence or absence of their words (Luo et al, 2004) or as probabilistic features indicating the probability that the two heads are coreferent according to the training data (Ng, 2007b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D11-1099", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Altaf, Rahman | Vincent, Ng", 
    "raw_text": "7.1.2 Cluster-Ranking Model The cluster-ranking (CR) model, proposed byRahman and Ng (2009), addresses the two weaknesses of the MP model by combining the strengths of the entity-mention model (e.g., Luo et al (2004), Yang et al (2008)) and the mention-ranking model (e.g., Denis and Baldridge (2008))", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P07-1131", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Hongyan, Jing | Nanda, Kambhatla | Salim, Roukos", 
    "raw_text": "This example shows that co-reference errors involving mentions that are relation arguments can lead to very bad performance in social network extraction. Our existing co-reference module is a state-of the-art system that produces very competitive results compared to other existing systems (Luo et al., 2004)", 
    "clean_text": "Our existing co-reference module is a state-of the-art system that produces very competitive results compared to other existing systems (Luo et al., 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D08-1031", 
    "citing_paper_authority": 41, 
    "citing_paper_authors": "Eric, Bengtson | Dan, Roth", 
    "raw_text": "Distances have been used in e.g. Luo et al (2004)", 
    "clean_text": "Distances have been used in e.g. Luo et al (2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "C10-1017", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Jie, Cai | Michael, Strube", 
    "raw_text": "The classification steps of most approaches vary in the choice of the classifier (e.g. decision tree classifiers (Soon et al, 2001), maximum entropy classification (Luo et al, 2004), SVMclassifiers (Rahman& amp; Ng, 2009)) and the number of features used (Soon et al (2001) employ a set of twelve simple but effective features while e.g., Ng& amp; Cardie (2002) and Bengtson& amp; Roth (2008 )de vise much richer feature sets) .The clustering step exhibits much more variation: Local variants utilize a closest-first decision (Soon et al, 2001), where a mention is resolved toits closest possible antecedent, or a best-first decision (Ng& amp; Cardie, 2002), where a mention is re solved to its most confident antecedent (based on the confidence value returned by step 1)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "C10-1017", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Jie, Cai | Michael, Strube", 
    "raw_text": "Luo et al (2004) perform the clustering step within a Bell tree representation", 
    "clean_text": "Luo et al (2004) perform the clustering step within a Bell tree representation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "C10-1017", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Jie, Cai | Michael, Strube", 
    "raw_text": "Theyreport considerable improvements over state-of the-art systems including Luo et al (2004)", 
    "clean_text": "They report considerable improvements over state-of the-art systems including Luo et al (2004).", 
    "keep_for_gold": 0
  }
]