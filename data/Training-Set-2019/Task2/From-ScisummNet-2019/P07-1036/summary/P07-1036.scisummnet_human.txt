Guiding Semi-Supervision with Constraint-Driven Learning
Over the last few years, two of the main research directions in machine learning of natural language processing have been the study of semi-supervised learning algorithms as a way to train classifiers when the labeled data is scarce, and the study of ways to exploit knowledge and global information in structured learning tasks.
In this paper, we suggest a method for incorporating domain knowledge in semi-supervised learning algorithms.
Our novel framework unifies and can exploit several kinds of task specific constraints.
The experimental results presented in the information extraction domain demonstrate that applying constraints helps the model to generate better feedback during learning, and hence the framework allows for high performance learning with significantly less training data than was possible before on these tasks.
We introduce constraint driven learning, CoDL.
We use constraints at multiple levels, such as sentence-level constraints to specify field boundaries and global constraints to ensure relation-level consistency.
