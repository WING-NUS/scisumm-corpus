[
  {
    "citance_No": 1, 
    "citing_paper_id": "W05-1504", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Jason M., Eisner | Noah A., Smith", 
    "raw_text": "of Klein and Manning (2004)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-1102", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Marten, van Schijndel | Micha, Elsner", 
    "raw_text": "How ever, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al, 2012), have not addressed filler-gap comprehension", 
    "clean_text": "However, previous computational models of grammar induction (Klein and Manning, 2004), including infant grammar induction (Kwiatkowski et al, 2012), have not addressed filler-gap comprehension.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W09-0103", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Mark, Johnson", 
    "raw_text": "In the field of language acquisition computational linguists such as Kleinand Manning (2004) have studied the unsupervised acquisition of syntactic structure, while linguists such as Boersma and Hayes (2001), Gold smith (2001), Pater (2008) and Albright and Hayes (2003) are developing probabilistic models of the acquisition of phonology and/or morphology, and Frank et al (2007) experimentally tests the predictions of a Bayesian model of lexical acquisition", 
    "clean_text": "In the field of language acquisition computational linguists such as Klein and Manning (2004) have studied the unsupervised acquisition of syntactic structure, while linguists such as Boersma and Hayes (2001), Gold smith (2001), Pater (2008) and Albright and Hayes (2003) are developing probabilistic models of the acquisition of phonology and/or morphology, and Frank et al (2007) experimentally tests the predictions of a Bayesian model of lexical acquisition.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P13-1028", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "David, Mare&#x10D;ek | Milan, Straka", 
    "raw_text": "It was introduced by Klein and Manning (2004) and further improved by Smith (2007) and Cohen et al (2008)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P13-1028", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "David, Mare&#x10D;ek | Milan, Straka", 
    "raw_text": "We use the standard generative Dependency Model with Valence (Klein and Manning, 2004)", 
    "clean_text": "We use the standard generative Dependency Model with Valence (Klein and Manning, 2004).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "Subsymbol refinement is an optional component of the full model and can be omitted by deterministically equating s and z. As we explain at the end of this section, without this aspect the generative story closely resembles the classic dependency model with valence (DMV) of Klein and Manning (2004)", 
    "clean_text": "As we explain at the end of this section, without this aspect the generative story closely resembles the classic dependency model with valence (DMV) of Klein and Manning (2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "We follow an approach similar to the widely-referenced DMV model (Klein and Manning, 2004), which forms the basis of the current state-of-the-art unsupervised grammar induction model (Headden III et al, 2009)", 
    "clean_text": "We follow an approach similar to the widely-referenced DMV model (Klein and Manning, 2004), which forms the basis of the current state-of-the-art unsupervised grammar induction model (Headden III et al, 2009).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "We encode more detailed valence information than Klein and Manning (2004) and condition child generation on parent valence", 
    "clean_text": "We encode more detailed valence information than Klein and Manning (2004) and condition child generation on parent valence.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "In particular, the HDPgener 1237ation of z is obviated and word x is drawn from aword distribution? s indexed solely by coarse symbol s. The resulting simplified model closely resembles DMV (Klein and Manning, 2004), except that it1) explicitly generate words x rather than only part of-speech tags s, 2) encodes richer context and valence information, and 3) imposes a Dirichlet prior on the symbol distribution?", 
    "clean_text": "The resulting simplified model closely resembles DMV (Klein and Manning, 2004), except that it 1) explicitly generate words x rather than only part of-speech tags s, 2) encodes richer context and valence information, and 3) imposes a Dirichlet prior on the symbol distribution.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "1240 DMV PGI No-Split HDP-DEP English 47.1 62.3 71.5 71.9 (0.3) Danish 33.5 41.6 48.8 51.9 (1.6) Portuguese 38.5 63.0 54.0 71.5 (0.5) Slovene 38.5 48.4 50.6 50.9 (5.5) Spanish 28.0 58.4 64.8 67.2 (0.4) Swedish 45.3 58.3 63.3 62.1 (0.5) Table 4: Directed dependency accuracy using our model with universal dependency rules (No-Split and HDP DEP), compared to DMV (Klein and Manning, 2004 )andPGI (Berg-Kirkpatrick and Klein, 2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "the dependency model with valence (DMV) (Klein and Manning, 2004) and the phylogenetic grammar induction (PGI) model (Berg-Kirkpatrick and Klein, 2010)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "D10-1120", 
    "citing_paper_authority": 29, 
    "citing_paper_authors": "Tahira, Naseem | Harr, Chen | Regina, Barzilay | Mark, Johnson", 
    "raw_text": "Note that we do not rely on rule-specific expectation informationas they do, instead requiring only a single expectation constraint parameter.4 Model Stability It is commonly acknowledge din the literature that unsupervised grammar induction methods exhibit sensitivity to initialization. As in the previous section, we find that the pres4As explained in Section 5, having a single expectation parameter is motivated by our focus on parsing with universal rules.ence of linguistic rules greatly reduces this sensitivity: for HDP-DEP, the standard deviation over five randomly initialized runs with the English-specificrules is 1.5%, compared to 4.5% for the parser developed by Headden III et al (2009) and 8.0% for DMV (Klein and Manning, 2004)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P09-1042", 
    "citing_paper_authority": 28, 
    "citing_paper_authors": "Kuzman, Ganchev | Jennifer, Gillenwater | Ben, Taskar", 
    "raw_text": "Finally, following (Klein and Manning, 2004) we strip out punctuation from the sentences", 
    "clean_text": "Finally, following (Klein and Manning, 2004) we strip out punctuation from the sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P09-1042", 
    "citing_paper_authority": 28, 
    "citing_paper_authors": "Kuzman, Ganchev | Jennifer, Gillenwater | Ben, Taskar", 
    "raw_text": "The maximum unsupervised accuracy it achieved on the Bulgarian data is 47.6% with initialization from Klein and Manning (2004) and this result is not stable", 
    "clean_text": "The maximum unsupervised accuracy it achieved on the Bulgarian data is 47.6% with initialization from Klein and Manning (2004) and this result is not stable.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D09-1086", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "David A., Smith | Jason M., Eisner", 
    "raw_text": "In the generative models of? 5, f has the form of adependency model with valence (Klein and Manning, 2004)", 
    "clean_text": "In the generative models of section 5, f has the form of a dependency model with valence (Klein and Manning, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D09-1086", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "David A., Smith | Jason M., Eisner", 
    "raw_text": "Although we could also try many random starting points, the initializer in Klein and Manning (2004) performs quite well", 
    "clean_text": "Although we could also try many random starting points, the initializer in Klein and Manning (2004) performs quite well.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "D09-1086", 
    "citing_paper_authority": 27, 
    "citing_paper_authors": "David A., Smith | Jason M., Eisner", 
    "raw_text": "We simply per form supervised training with this subset, which is still quite noisy (? 4), and performance quickly 6While these results are worse than those obtained previously for this model, the experiments in Klein and Manning (2004) and only used sentences of 10 words or fewer, without punctuation, and with gold-standard tags", 
    "clean_text": "While these results are worse than those obtained previously for this model, the experiments in Klein and Manning (2004) only used sentences of 10 words or fewer, without punctuation, and with gold-standard tags.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P13-2017", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Ryan, McDonald | Joakim, Nivre | Yvonne, Quirmbach-Brundage | Yoav, Goldberg | Dipanjan, Das | Kuzman, Ganchev | Keith, Hall | Slav, Petrov | Hao, Zhang | Oscar, T&auml;ckstr&ouml;m | Claudia, Bedini | N\u00c3\u00baria, Bertomeu Castell\u00c3\u00b3 | Jungmee, Lee", 
    "raw_text": "Second ,consis tent syntactic representations are desirable in the evaluation of unsupervised (Klein and Manning, 2004) or cross-lingual syntactic parsers (Hwa et al., 2005)", 
    "clean_text": "Second, consistent syntactic representations are desirable in the evaluation of unsupervised (Klein and Manning, 2004) or cross-lingual syntactic parsers (Hwa et al., 2005).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "D07-1042", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Sebastian, Pad&oacute; | Ulrike, Pado | Katrin, Erk", 
    "raw_text": "Fortunately, the state of the art in broad-coverage (Lin, 1993) and unsupervised (Klein and Manning, 2004) dependency parsing allows us to treat dependency parsing merely as a preprocessing step", 
    "clean_text": "Fortunately, the state of the art in broad-coverage (Lin, 1993) and unsupervised (Klein and Manning, 2004) dependency parsing allows us to treat dependency parsing merely as a preprocessing step.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W12-1911", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "David, Marecek | Zden&#x11B;k, &#x17D;abokrtsk&yacute;", 
    "raw_text": "5In DMV (Klein and Manning, 2004) and in the extended model EVG (Headden III et al, 2009), there is a STOP sign indicating that no more dependents in a given direction will begenerated", 
    "clean_text": "In DMV (Klein and Manning, 2004) and in the extended model EVG (Headden III et al, 2009), there is a STOP sign indicating that no more dependents in a given direction will be generated.", 
    "keep_for_gold": 0
  }
]