We describe a mixture-model approach to adapting a Statistical Machine Translation System for new domains, using weights that depend on text distances to mixture components. 
We investigate a number of variants on this approach, including cross-domainversus dynamic adaptation; linear versus loglinear mixtures; language and translation model adaptation; different methods of assigning weights; and granularity of the source unit being adapted to.
The best methods achieve gains of approximately one BLEU percentage point over a state-of-the art non-adapted baseline system.
