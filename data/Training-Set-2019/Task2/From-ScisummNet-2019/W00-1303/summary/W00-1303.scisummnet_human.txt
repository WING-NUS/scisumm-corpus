Japanese Dependency Structure Analysis Based On Support Vector Machines
This paper presents a method of Japanese dependency structure analysis based on Support Vector Machines (SVMs).
Conventional parsing techniques based on Machine Learning framework, such as Decision Trees and Maximum Entropy Models, have difficulty in selecting useful features as well as finding appropriate combination of selected features.
On the other hand, it is well-known that SVMs achieve high generalization performance even with input data of very high dimensional feature space.
Furthermore, by introducing the Kernel principle, SVMs can carry out the training in high-dimensional spaces with a smaller computational cost independent of their dimensionality.
We apply SVMs to Japanese dependency structure identification problem.
Experimental results on Kyoto University corpus show that our system achieves the accuracy of 89.09% even with small training data (7958 sentences).
We introduce a new type of feature called dynamic features which are created dynamically during the parsing process.
