[
  {
    "citance_No": 1, 
    "citing_paper_id": "W05-1205", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Dekai, Wu", 
    "raw_text": "In particular, for this study we employ the MSR Paraphrase Corpus (Quirk et al, 2004)", 
    "clean_text": "In particular, for this study we employ the MSR Paraphrase Corpus (Quirk et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P09-1094", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Shiqi, Zhao | Xiang, Lan | Ting, Liu | Sheng, Li", 
    "raw_text": "However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase pat terns are long or complicated (Quirk et al, 2004)", 
    "clean_text": "However, it has been shown that the coverage of the paraphrase patterns is not high enough, especially when the used paraphrase pat terns are long or complicated (Quirk et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P09-1094", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Shiqi, Zhao | Xiang, Lan | Ting, Liu | Sheng, Li", 
    "raw_text": "Researchers employ the existing SMT models for PG (Quirk et al, 2004)", 
    "clean_text": "Researchers employ the existing SMT models for PG (Quirk et al, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P09-1094", 
    "citing_paper_authority": 24, 
    "citing_paper_authors": "Shiqi, Zhao | Xiang, Lan | Ting, Liu | Sheng, Li", 
    "raw_text": "In our experiments, we implement two baseline methods for comparison: Baseline-1: Baseline-1 follows the method pro posed in (Quirk et al, 2004), which generates paraphrases using typical SMT tools", 
    "clean_text": "Baseline-1 follows the method pro posed in (Quirk et al, 2004), which generates paraphrases using typical SMT tools.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W07-0716", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Nitin, Madnani | Necip Fazil, Ayan | Philip, Resnik | Bonnie Jean, Dorr", 
    "raw_text": "They were able to generate paraphrases for 59 sentences (12%) out of a 484-sentence test set, generating no paraphrases at all for the remainder. Quirk et al (2004) also generate sentential para phrases using a monolingual corpus", 
    "clean_text": "Quirk et al (2004) also generate sentential paraphrases using a monolingual corpus.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P10-2070", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Josef, Steinberger | Marco, Turchi | Mijail, Alexandrov-Kabadjov | Ralf, Steinberger | Nello, Cristianini", 
    "raw_text": "Secondly, we directly exploit the resulting structures from the SVD making the last generation step fully aware of previous processing stages, as opposed to tackling the problem of sentence compression in isolation. A similar approach to our sentence reconstruction method has been developed by Quirk et al (2004) for paraphrase generation", 
    "clean_text": "A similar approach to our sentence reconstruction method has been developed by Quirk et al (2004) for paraphrase generation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W08-1911", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Aur&eacute;lien, Max | Michael, Zock", 
    "raw_text": "As sentential paraphrasing is more likely to alter meaning, Quirk et al (Quirk et al, 2004) approached paraphrasing as a monotonous decoding by a phrase-based SMT system", 
    "clean_text": "As sentential paraphrasing is more likely to alter meaning, Quirk et al (Quirk et al, 2004) approached paraphrasing as a monotonous decoding by a phrase-based SMT system.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P09-2063", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jonathan, Chevelu | Thomas, Lavergne | Yves, Lepage | Thierry, Moudenc", 
    "raw_text": "Most paraphrase generation tools use some standard SMT decoding algorithms (Quirk et al., 2004) or some off-the-shelf decoding tools like Moses (Koehn et al, 2007)", 
    "clean_text": "Most paraphrase generation tools use some standard SMT decoding algorithms (Quirk et al., 2004) or some off-the-shelf decoding tools like Moses (Koehn et al, 2007).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "C08-1029", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Atsushi, Fujita | Satoshi, Sato", 
    "raw_text": "Although a more frequent expression is more grammatical, the length bias should also be considered in the assessment. Quirk et al (2004) built a paraphrase generation model from a monolingual comparable corpus based on a statistical machine translation framework, where the language model assesses the grammaticality of the translations ,i.e., generated expressions", 
    "clean_text": "Quirk et al (2004) built a paraphrase generation model from a monolingual comparable corpus based on a statistical machine translation framework, where the language model assesses the grammaticality of the translations ,i.e., generated expressions.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "C10-2017", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Jonathan, Chevelu | Ghislain, Putois | Yves, Lepage", 
    "raw_text": "Most paraphrase generators use some standard SMT decoding algorithms (Quirk et al, 2004) or some off-the-shelf decoding tools like MOSES", 
    "clean_text": "Most paraphrase generators use some standard SMT decoding algorithms (Quirk et al, 2004) or some off-the-shelf decoding tools like MOSES.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P06-2096", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Siwei, Shen | Dragomir R., Radev | Agam, Patel | Gunes, Erkan", 
    "raw_text": "Another piece of related work, (Quirk et al, 2004), starts off with parallel inputs and uses monolingual Statistical Machine Translation techniques to align them and generate novel sentences", 
    "clean_text": "Another piece of related work, (Quirk et al, 2004), starts off with parallel inputs and uses monolingual Statistical Machine Translation techniques to align them and generate novel sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P11-2051", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Qin, Gao | Stephan, Vogel", 
    "raw_text": "Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data", 
    "clean_text": "Typical examples are paraphrasing using bilingual (Callison-Burch et al, 2006) or monolingual (Quirket al, 2004) data.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P12-2008", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hong, Sun | Ming, Zhou", 
    "raw_text": "Quirk et al (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events", 
    "clean_text": "Quirk et al (2004) build a monolingual translation system using a corpus of sentence pairs extracted from news articles describing same events.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C08-1018", 
    "citing_paper_authority": 28, 
    "citing_paper_authors": "Trevor, Cohn | Mirella, Lapata", 
    "raw_text": "Quirk et al (2004) present an end-to-end paraphrasing system inspired by phrase-based machine translation that can both ac quire paraphrases and use them to generate new strings", 
    "clean_text": "Quirk et al (2004) present an end-to-end paraphrasing system inspired by phrase-based machine translation that can both ac quire paraphrases and use them to generate new strings.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C08-1018", 
    "citing_paper_authority": 28, 
    "citing_paper_authors": "Trevor, Cohn | Mirella, Lapata", 
    "raw_text": "Al though there is a greater supply of paraphrasing corpora, such as the Multiple-Translation Chinese (MTC) corpus 1 and the Microsoft Research (MSR) Paraphrase Corpus (Quirk et al, 2004), they are also not ideal, since they have not been created 1 Available by the LDC, Catalog Number LDC2002T01, ISBN 1-58563-217-1", 
    "clean_text": "Although there is a greater supply of paraphrasing corpora, such as the Multiple-Translation Chinese (MTC) corpus 1 and the Microsoft Research (MSR) Paraphrase Corpus (Quirk et al, 2004),.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P11-2044", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Kapil, Thadani | Kathleen R., McKeown", 
    "raw_text": "Outside of NLI, prior research has also explored the task of monolingual word align 254ment using extensions of statistical MT (Quirk et al, 2004) and multi-sequence alignment (Barzilay and Lee, 2002)", 
    "clean_text": "Outside of NLI, prior research has also explored the task of monolingual word alignment using extensions of statistical MT (Quirk et al, 2004) and multi-sequence alignment (Barzilay and Lee, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P11-1109", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Chikara, Hashimoto | Kentaro, Torisawa | Stijn, De Saeger | Jun'ichi, Kazama | Sadao, Kurohashi", 
    "raw_text": "For other SMT methods, see Quirk et al (2004) and Bannard and Callison-Burch (2005) among others", 
    "clean_text": "For other SMT methods, see Quirk et al (2004) and Bannard and Callison-Burch (2005) among others.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P08-1116", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Shiqi, Zhao | Cheng, Niu | Ming, Zhou | Ting, Liu | Sheng, Li", 
    "raw_text": "? This research was finished while the first author worked as an intern in Microsoft Research Asia.Paraphrase generation can be viewed as monolingual machine translation (Quirk et al, 2004), which typically includes a translation model and a language model", 
    "clean_text": "Paraphrase generation can be viewed as monolingual machine translation (Quirk et al, 2004), which typically includes a translation model and a language model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P08-1116", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Shiqi, Zhao | Cheng, Niu | Ming, Zhou | Ting, Liu | Sheng, Li", 
    "raw_text": "However, the methods were demonstrated to be of limited generality (Quirk et al, 2004) .Quirk et al (2004) first recast paraphrase generation as monolingual SMT", 
    "clean_text": "Quirk et al (2004) first recast paraphrase generation as monolingual SMT.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P08-1116", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Shiqi, Zhao | Cheng, Niu | Ming, Zhou | Ting, Liu | Sheng, Li", 
    "raw_text": "The SMT-based paraphrasing model used by Quirk et al (2004) was the noisy channel model of Brown et al (1993), which identified the optimal paraphrase T? of a sentence S by finding: T? =argmax T{ P (T |S)} =argmax T{ P (S|T) P (T)} (1) In contrast, we adopt a log-linear model (Ochand Ney, 2002) in this work, since multiple paraphrase tables can be easily combined in the log linear model", 
    "clean_text": "The SMT-based paraphrasing model used by Quirk et al (2004) was the noisy channel model of Brown et al (1993), which identified the optimal paraphrase T of a sentence S by finding.", 
    "keep_for_gold": 0
  }
]