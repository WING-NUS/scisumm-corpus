[
  {
    "citance_No": 1, 
    "citing_paper_id": "W06-0121", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Xinhao, Wang | Xiaojun, Lin | Dianhai, Yu | Hao, Tian | Xihong, Wu", 
    "raw_text": "In ME model, the following features (Jin Kiat Low et al, 2005) are selected: a )cn (n=? 2,? 1, 0, 1, 2) b )cncn+1 (n=? 2,? 1, 0, 1) c) c? 1c+1 where cn indicates the character in the left or right position n relative to the current character c0", 
    "clean_text": "In ME model, the following features (Jin Kiat Low et al, 2005) are selected: a) cn (n=-2, -1, 0, 1, 2) b) cncn+1 (n=-2, -1, 0, 1) c) c-1c+1 where cn indicates the character in the left or right position n relative to the current character c0.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P06-2056", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Zhihui, Jin | Kumiko, Tanaka-Ishii", 
    "raw_text": "The current state-of-the-art segmentation software developed by (Low et al, 2005), which ranks as the best in the SIGHANbakeo (Emerson, 2005), attains word precision and recall of 96.9% and 96.8% ,respectively, on the PKU track", 
    "clean_text": "The current state-of-the-art segmentation software developed by (Low et al, 2005), which ranks as the best in the SIGHAN bakeoff (Emerson, 2005), attains word precision and recall of 96.9% and 96.8%, respectively, on the PKU track.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D10-1077", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Baobao, Chang | Dongxu, Han", 
    "raw_text": "(Low et al, 2005) Character tagging approaches require manually segmented training texts to learn models usually in a supervised way", 
    "clean_text": "3) New feature templates were added, such as the templates that were used in representing numbers, dates, letters etc. (Low et al., 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "I08-4017", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Hai, Zhao | Chunyu, Kitt", 
    "raw_text": "Those for the 4-tag set, adopted from (Xue, 2003) and (Low et al, 2005), include C? 2, C? 1, C0, C1, C2, C? 2C? 1, C? 1C0, C? 1C1, C0C1and C1C2.al., 2006b) about tag set selection for character tagging for word segmentation that the 6-tag set is more effective than others, each with its own best corresponding feature template set", 
    "clean_text": "Those for the 4-tag set, adopted from (Xue, 2003) and (Low et al., 2005), include C\u22122, C\u22121, C0, C1, C2, C\u22122C\u22121, C\u22121C0, C\u22121C1, C0C1 and C1C2.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W10-4141", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Huixing, Jiang | Zhe, Dong", 
    "raw_text": "Third, the post processing method (Low et al, 2005) is employed to enhance the unknown word segmentation", 
    "clean_text": "Third, the post processing method (Low et al, 2005) is employed to enhance the unknown word segmentation.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "I08-4015", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Zhenxing, Wang | Changning, Huang | Jingbo, Zhu", 
    "raw_text": "Since Chinese Word Segmentation was firstly treated as a character-based tagging task in (Xue and Converse, 2002), this method has been widely accepted and further developed by researchers (Peng et al, 2004), (Tseng et al, 2005), (Low et al., 2005), (Zhao et al, 2006)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "I08-4015", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Zhenxing, Wang | Changning, Huang | Jingbo, Zhu", 
    "raw_text": "We add a new feature, which also used in maximum entropy model for word segmentation task by (Low et al, 2005), to the feature templates for CRF model while keep the other features same as (Zhao et al, 2006)", 
    "clean_text": "We add a new feature, which also used in maximum entropy model for word segmentation task by (Low et al, 2005), to the feature templates for CRF model while keep the other features same as (Zhao et al, 2006).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W10-4136", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Baobao, Chang | Mansur, Mairgup", 
    "raw_text": "(Low et al, 2005) Usually, the performance of segmentation model is evaluated on a test set from the same domain as the training set", 
    "clean_text": "3) New feature templates were added, such as templates used in representing numbers, dates, letters etc. (Low et al., 2005).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W07-2054", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Yee Seng, Chan | Hwee Tou, Ng | Zhi, Zhong", 
    "raw_text": "Briefly ,after ensuring the corpora were sentence-aligned, we tokenized the English texts and performed word segmentation on the Chinese texts (Low et al, 2005)", 
    "clean_text": "Briefly, after ensuring the corpora were sentence-aligned, we tokenized the English texts and performed word segmentation on the Chinese texts (Low et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W07-2010", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Hwee Tou, Ng | Yee Seng, Chan", 
    "raw_text": "Briefly ,after ensuring the corpora were sentence-aligned, we tokenized the English texts and performed word segmentation on the Chinese texts (Low et al, 2005)", 
    "clean_text": "Briefly, after ensuring the corpora were sentence-aligned, we tokenized the English texts and performed word segmentation on the Chinese texts (Low et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "D10-1090", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Chang, Liu | Daniel, Dahlmeier | Hwee Tou, Ng", 
    "raw_text": "We use the maximum entropy segmenter of (Low et al, 2005) to segment the Chinese part of the FBIS corpus", 
    "clean_text": "We use the maximum entropy segmenter of (Low et al, 2005) to segment the Chinese part of the FBIS corpus.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "I08-4028", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Xihong, Wu | Xiaojun, Lin | Xinhao, Wang | Chunyao, Wu | Yaozhong, Zhang | Dianhai, Yu", 
    "raw_text": "Recently, Maximum Entropy model (ME) and CRFs (Low et al, 2005) (Tseng et al, 2005) (HaiZhao et al, 2006) turned out to be promising in natural language processing tracks, and obtain excellent performances on most of the test corpora of Bakeoff 2005 and Bakeoff 2006", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W06-0133", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Aaron J., Jacobs | Yuk Wah, Wong", 
    "raw_text": "Our Chinese word segmenter is a modification of the system described by Low et al (2005), which they entered in the 2005 Second International Chinese Word Segmentation Bakeoff", 
    "clean_text": "Our Chinese word segmenter is a modification of the system described by Low et al (2005), which they entered in the 2005 Second International Chinese Word Segmentation Bakeoff.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W06-0133", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Aaron J., Jacobs | Yuk Wah, Wong", 
    "raw_text": "Much of this can be attributed to the value of using an external dictionary and additional training data, as illustrated by the experiments run by Low et al (2005) with their model", 
    "clean_text": "Much of this can be attributed to the value of using an external dictionary and additional training data, as illustrated by the experiments run by Low et al (2005) with their model.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "W06-0133", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Aaron J., Jacobs | Yuk Wah, Wong", 
    "raw_text": "This is a surprising result, as in our testing the added features helped to improve the F scores and OOV recall rates of the system when dealing with the 2005bakeoff data, even if only by a small amount in some cases. It should be noted that in our testing during development, even when we strove to create a system which matched as closely as possible the one described by Low et al (2005), we were unable to achieve scores for the 2005bakeoff data as highas their system did", 
    "clean_text": "It should be noted that in our testing during development, even when we strove to create a system which matched as closely as possible the one described by Low et al (2005), we were unable to achieve scores for the 2005 bakeoff data as high as their system did.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "W10-4130", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Yu-Chieh, Wu | Jie-Chi, Yang | Yue-Shi, Lee", 
    "raw_text": "Especially, character-based tagging method which was proposed by Nianwen Xue (2003) achieves great success in the second International Chinese word segmentation Bakeoff in 2005 (Low et al, 2005)", 
    "clean_text": "Especially, character-based tagging method which was proposed by Nianwen Xue (2003) achieves great success in the second International Chinese word segmentation Bakeoff in 2005 (Low et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W06-0141", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Muhua, Zhu | Yilin, Wang | Zhenxing, Wang | Huizhen, Wang | Jingbo, Zhu", 
    "raw_text": "We utilized four of the five basic feature templates suggested in (Low et al, 2005), described as follows:? Cn (n=? 2,? 1, 0, 1, 2)? CnCn+ 1 (n=? 2,? 1, 0, 1)? Pu (C0)? T (C? 2) T (C? 1) T (C0) T (C1) T (C2) where C refers to a Chinese character", 
    "clean_text": "We utilized four of the five basic feature templates suggested in (Low et al, 2005), described as follows: Cn (n=-2, -1, 0, 1, 2), CnCn+ 1 (n=-2, -1, 0, 1), Pu (C0)? T (C-2) T (C-1) T (C0) T (C1) T (C2) where C refers to a Chinese character.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W06-0141", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Muhua, Zhu | Yilin, Wang | Zhenxing, Wang | Huizhen, Wang | Jingbo, Zhu", 
    "raw_text": "Seede tail description and the example in (Low et al, 2005)", 
    "clean_text": "See detail description and the example in (Low et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W10-4122", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chongyang, Zhang | Zhigang, Chen | Guoping, Hu", 
    "raw_text": "Especially, the character-based tagging method which was proposed by Nianwen Xue (2003) achieves great success in the second International Chinese word segmentation Bakeoff in 2005 (Low et al, 2005)", 
    "clean_text": "Especially, the character-based tagging method which was proposed by Nianwen Xue (2003) achieves great success in the second International Chinese word segmentation Bakeoff in 2005 (Low et al, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D11-1056", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Yugo, Murawaki | Sadao, Kurohashi", 
    "raw_text": "Low et al (2005) introduce an external dictionary as features of a discriminative model", 
    "clean_text": "Low et al (2005) introduce an external dictionary as features of a discriminative model.", 
    "keep_for_gold": 0
  }
]