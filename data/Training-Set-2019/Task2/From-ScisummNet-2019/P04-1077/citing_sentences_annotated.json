[
  {
    "citance_No": 1, 
    "citing_paper_id": "W04-1013", 
    "citing_paper_authority": 153, 
    "citing_paper_authors": "Chin-Yew, Lin", 
    "raw_text": "In a separate study (Lin and Och, 2004), Method CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP R-1 0.48 0.56 0.86 0.53 0.57 0.87 0.66 0.66 0.77 0.71 0.71 0.78 0.58 0.57 0.71 0.58 0.57 0.71 R-2 0.55 0.57 0.64 0.59 0.61 0.71 0.83 0.83 0.80 0.88 0.87 0.85 0.69 0.67 0.71 0.79 0.79 0.81 R-3 0.46 0.45 0.47 0.53 0.53 0.55 0.85 0.84 0.76 0.89 0.88 0.83 0.54 0.51 0.48 0.76 0.75 0.74 R-4 0.39 0.39 0.43 0.48 0.49 0.47 0.80 0.80 0.63 0.83 0.82 0.75 0.37 0.36 0.36 0.62 0.61 0.52 R-5 0.38 0.39 0.33 0.47 0.48 0.43 0.73 0.73 0.45 0.73 0.73 0.62 0.25 0.25 0.27 0.45 0.44 0.38 R-6 0.39 0.39 0.20 0.45 0.46 0.39 0.71 0.72 0.38 0.66 0.64 0.46 0.21 0.21 0.26 0.34 0.31 0.29 R-7 0.31 0.31 0.17 0.44 0.44 0.36 0.63 0.65 0.33 0.56 0.53 0.44 0.20 0.20 0.23 0.29 0.27 0.25 R-8 0.18 0.19 0.09 0.40 0.40 0.31 0.55 0.55 0.52 0.50 0.46 0.52 0.18 0.18 0.21 0.23 0.22 0.23 R-9 0.11 0.12 0.06 0.38 0.38 0.28 0.54 0.54 0.52 0.45 0.42 0.52 0.16 0.16 0.19 0.21 0.21 0.21 R-L 0.49 0.49 0.49 0.56 0.56 0.56 0.62 0.62 0.62 0.65 0.65 0.65 0.50 0.50 0.50 0.53 0.53 0.53 R-S* 0.45 0.52 0.84 0.51 0.54 0.86 0.69 0.69 0.77 0.73 0.73 0.79 0.60 0.60 0.67 0.61 0.60 0.70 R-S4 0.46 0.50 0.71 0.54 0.57 0.78 0.79 0.80 0.79 0.84 0.85 0.82 0.63 0.64 0.70 0.73 0.73 0.78 R-S9 0.42 0.49 0.77 0.53 0.56 0.81 0.79 0.80 0.78 0.83 0.84 0.81 0.65 0.65 0.70 0.70 0.70 0.76 R-SU* 0.45 0.52 0.84 0.51 0.54 0.87 0.69 0.69 0.77 0.73 0.73 0.79 0.60 0.59 0.67 0.60 0.60 0.70 R-SU4 0.47 0.53 0.80 0.55 0.58 0.83 0.76 0.76 0.79 0.80 0.81 0.81 0.64 0.64 0.74 0.68 0.68 0.76 R-SU9 0.44 0.50 0.80 0.53 0.57 0.84 0.77 0.78 0.78 0.81 0.82 0.81 0.65 0.65 0.72 0.68 0.68 0.75 R-W-1.2 0.52 0.52 0.52 0.60 0.60 0.60 0.67 0.67 0.67 0.69 0.69 0.69 0.53 0.53 0.53 0.58 0.58 0.58 Method CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP CASE STEM STOP R-1 0.71 0.68 0.49 0.49 0.49 0.73 0.44 0.48 0.80 0.81 0.81 0.90 0.84 0.84 0.91 0.74 0.73 0.90 R-2 0.82 0.85 0.80 0.43 0.45 0.59 0.47 0.49 0.62 0.84 0.85 0.86 0.93 0.93 0.94 0.88 0.88 0.87 R-3 0.59 0.74 0.75 0.32 0.33 0.39 0.36 0.36 0.45 0.80 0.80 0.81 0.90 0.91 0.91 0.84 0.84 0.82 R-4 0.25 0.36 0.16 0.28 0.26 0.36 0.28 0.28 0.39 0.77 0.78 0.78 0.87 0.88 0.88 0.80 0.80 0.75 R-5 -0.25 -0.25 -0.24 0.30 0.29 0.31 0.28 0.30 0.49 0.77 0.76 0.72 0.82 0.83 0.84 0.77 0.77 0.70 R-6 0.00 0.00 0.00 0.22 0.23 0.41 0.18 0.21 -0.17 0.75 0.75 0.67 0.78 0.79 0.77 0.74 0.74 0.63 R-7 0.00 0.00 0.00 0.26 0.23 0.50 0.11 0.16 0.00 0.72 0.72 0.62 0.72 0.73 0.74 0.70 0.70 0.58 R-8 0.00 0.00 0.00 0.32 0.32 0.34 -0.11 -0.11 0.00 0.68 0.68 0.54 0.71 0.71 0.70 0.66 0.66 0.52 R-9 0.00 0.00 0.00 0.30 0.30 0.34 -0.14 -0.14 0.00 0.64 0.64 0.48 0.70 0.69 0.59 0.63 0.62 0.46 R-L 0.78 0.78 0.78 0.56 0.56 0.56 0.50 0.50 0.50 0.81 0.81 0.81 0.88 0.88 0.88 0.82 0.82 0.82 R-S* 0.83 0.82 0.69 0.46 0.45 0.74 0.46 0.49 0.80 0.80 0.80 0.90 0.84 0.85 0.93 0.75 0.74 0.89 R-S4 0.85 0.86 0.76 0.40 0.41 0.69 0.42 0.44 0.73 0.82 0.82 0.87 0.91 0.91 0.93 0.85 0.85 0.85 R-S9 0.82 0.81 0.69 0.42 0.41 0.72 0.40 0.43 0.78 0.81 0.82 0.86 0.90 0.90 0.92 0.83 0.83 0.84 R-SU* 0.75 0.74 0.56 0.46 0.46 0.74 0.46 0.49 0.80 0.80 0.80 0.90 0.84 0.85 0.93 0.75 0.74 0.89 R-SU4 0.76 0.75 0.58 0.45 0.45 0.72 0.44 0.46 0.78 0.82 0.83 0.89 0.90 0.90 0.93 0.84 0.84 0.88 R-SU9 0.74 0.73 0.56 0.44 0.44 0.73 0.41 0.45 0.79 0.82 0.82 0.88 0.89 0.89 0.92 0.83 0.82 0.87 R-W-1.2 0.78 0.78 0.78 0.56 0.56 0.56 0.51 0.51 0.51 0.84 0.84 0.84 0.90 0.90 0.90 0.86 0.86 0.86 (A1) DUC 2001 100 WORDS MULTI (A2) DUC 2002 100 WORDS MULTI (A3) DUC 2003 100 WORDS MULTI 1 RFF 3 REFS 1 REF 2 REFS 1 REF 4 REFS", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W12-0103", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Cristina, Espa&Atilde;&plusmn;a-Bonet | Pere, Comas", 
    "raw_text": "A smoothed version is used to evaluate the pairs at sentence level yielding the score B. The other metric is ROUGE (Lin and Och, 2004), here named R. We use the skip-bigram overlap ping measure with a maximum skip distance of 4unigrams (ROUGE-S4)", 
    "clean_text": "The other metric is ROUGE (Lin and Och, 2004), here named R.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P09-1035", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Enrique, Amig&oacute; | Jes&uacute;s, Gim&eacute;nez | Julio, Gonzalo | M. Felisa, Verdejo", 
    "raw_text": "Melamed et al (2003) argued, at the time of introducing the GTM metric, that Pearson correlation coefficients can be affected by scale properties, and suggested, in order to avoid this effect, to use the non-parametric Spearmancorrelation coefficients instead. Lin and Och (2004) experimented, unlike previous works, with a wide set of metrics, including NIST, WER (Nie? en et al, 2000), PER (Tillmann et al, 1997), and variants of ROUGE, BLEU and GTM", 
    "clean_text": "Lin and Och (2004) experimented, unlike previous works, with a wide set of metrics, including NIST, WER (Nie\u00dfen et al, 2000), PER (Tillmann et al, 1997), and variants of ROUGE, BLEU and GTM.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P06-2070", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Ding, Liu | Daniel, Gildea", 
    "raw_text": "In order to improve sentence-level evaluation performance, several metrics have been pro posed, including ROUGE-W, ROUGE-S (Lin and Och, 2004) and METEOR (Banerjee and Lavie, 2005)", 
    "clean_text": "In order to improve sentence-level evaluation performance, several metrics have been proposed, including ROUGE-W, ROUGE-S (Lin and Och, 2004) and METEOR (Banerjee and Lavie, 2005).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P10-1012", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Hiroshi, Echizen-ya | Kenji, Araki", 
    "raw_text": "Methods based on word strings (e.g., BLEU (Papineni et al, 2002), NIST (NIST, 2002), METEOR (Banerjee and Lavie., 2005), ROUGE-L (Lin and Och, 2004), and IMPACT (Echizen-ya and Araki, 2007)) calculate matching scores using only common words between MT outputs and references from bilingual humans", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "H05-1019", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Tsutomu, Hirao | Manabu, Okumura | Hideki, Isozaki", 
    "raw_text": "Lin (2004a; 2004b) and Lin and Och (2004) proposed an LCS-basedautomatic evaluation measure called ROUGE-L", 
    "clean_text": "Lin and Och (2004) proposed an LCS-based automatic evaluation measure called ROUGE-L.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "H05-1019", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Tsutomu, Hirao | Manabu, Okumura | Hideki, Isozaki", 
    "raw_text": "Therefore, Lin and Och (2004) introduced skip-bigram statistics for the evaluation of machine translation", 
    "clean_text": "Therefore, Lin and Och (2004) introduced skip-bigram statistics for the evaluation of machine translation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "I08-1042", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Jes&uacute;s, Gim&eacute;nez | Llu&iacute;s, M&agrave;rquez", 
    "raw_text": "Other well-known metrics are WER (Nie? en et al, 2000), NIST (Doddington, 2002), GTM (Melamed et al, 2003), ROUGE (Lin and Och, 2004a), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al, 2006), just to namea few", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "I08-1042", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Jes&uacute;s, Gim&eacute;nez | Llu&iacute;s, M&agrave;rquez", 
    "raw_text": "The closest measure to KING is ORANGE (Lin and Och, 2004b), which is, however, not intended for the purpose of metric combination. Apart from being non-parametric, QARLA exhibits another important feature which differentiates it form other approaches; besides considering the similarity between automatic translations and human references, QARLA also takes into account the distribution of similarities among human references", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W06-1610", 
    "citing_paper_authority": 16, 
    "citing_paper_authors": "Liang, Zhou | Chin-Yew, Lin | Eduard, Hovy", 
    "raw_text": "(Lin and Och, 2004)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P06-2003", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Enrique, Amig&oacute; | Jes&uacute;s, Gim&eacute;nez | Julio, Gonzalo | Llu&iacute;s, M&agrave;rquez", 
    "raw_text": "Evaluation results have been computed by means of the IQMT5 Framework for Automatic MT Evaluation (Gime ?nez and Amigo?, 2006) .We have selected a representative set of 22 metric variants corresponding to six different families: BLEU (Papineni et al, 2001), NIST (Dodding ton, 2002), GTM (Melamed et al, 2003), m Per (Leusch et al, 2003) ,mWER (Nie? en et al, 2000) and ROUGE (Lin and Och, 2004a)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P06-2003", 
    "citing_paper_authority": 10, 
    "citing_paper_authors": "Enrique, Amig&oacute; | Jes&uacute;s, Gim&eacute;nez | Julio, Gonzalo | Llu&iacute;s, M&agrave;rquez", 
    "raw_text": "Let \u0005 and \u0006 be the sets of automatic and reference translations ,respectively, and \u0007 \b \u000e\u0006\u0010\u000f an evaluation metric which out puts the quality of an automatic translation \u0012\u0011\u0013\u0005by comparison to \u0006. ORANGE measures the descriptive power as the probability that a human reference \u0014 is more similar than an automatic translation to the rest of human references: \u0015 \u0006\u0016\u0005\u0018\u0017\u001a\u0019fiffffifl!& quot; \b# \u0007$ \u000f& amp;% &apos; \b# \u0014 (\u0011) \u0006* \u000e +\u0011) \u0005, .\u0007 \b# \u0014/ \u000e\u0006) 0213\u001454/\u000f768\u0007 \b \u000e\u0006) 0213\u001454/\u000f9\u000f ORANGE was introduced by Lin and Och (2004b) 6 for the meta-evaluation of MTevaluation metrics", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W07-0738", 
    "citing_paper_authority": 34, 
    "citing_paper_authors": "Jes&uacute;s, Gim&eacute;nez | Llu&iacute;s, M&agrave;rquez", 
    "raw_text": "Stemming is enabled (Lin and Och, 2004a)", 
    "clean_text": "Stemming is enabled (Lin and Och, 2004a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "W07-0719", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jes&uacute;s, Gim&eacute;nez | Llu&iacute;s, M&agrave;rquez", 
    "raw_text": "The optimal set is:{ METEORwnsyn, ROUGEw 1.2} which includes variants of METEOR, and ROUGE (Lin and Och, 2004)", 
    "clean_text": "The optimal set is: { METEOR wnsyn, ROUGE w 1.2} which includes variants of METEOR, and ROUGE (Lin and Och, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D09-1055", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Huihsin, Tseng | Longbin, Chen | Fan, Li | Ziming, Zhuang | Lei, Duan | Belle, Tseng", 
    "raw_text": "Furthermore, we attempt to achieve additional generalization by using skip n-grams (Lin and Och, 2004)", 
    "clean_text": "Furthermore, we attempt to achieve additional generalization by using skip n-grams (Lin and Och, 2004).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P07-1038", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Joshua, Albrecht | Rebecca, Hwa", 
    "raw_text": "ROUGE utilizes? skip n-grams?, which allow for matches of sequences of words that are not necessarily adjacent (Lin and Och, 2004a) .METEOR uses the Porterstemmer and synonym matching via WordNet to calculate recall and precision more accurately (Banerjee and Lavie, 2005) .The HWC metrics compare dependency and constituency trees for both reference and machine translations (Liu and Gildea, 2005)", 
    "clean_text": "ROUGE utilizes skip n-grams, which allow for matches of sequences of words that are not necessarily adjacent (Lin and Och, 2004a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P07-1038", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Joshua, Albrecht | Rebecca, Hwa", 
    "raw_text": "BLEU is smoothed (Lin and Och, 2004b), and it considers only matching up to bi grams because this has higher correlations with human judgments than when higher-ordered n-grams are included", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W09-0401", 
    "citing_paper_authority": 54, 
    "citing_paper_authors": "Chris, Callison-Burch | Philipp, Koehn | Christof, Monz | Josh, Schroeder", 
    "raw_text": "Leusch and Ney (2008) also submitted two contrastive metrics :bleusp4114, a modified version of BLEU-S (Lin and Och, 2004), with tuned n-gram weights, and bleusp, with constant weights", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "S12-1075", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Zhengzhong, Liu | Jian, Xu | Qin, Lu", 
    "raw_text": "Skip bi grams, generally speaking, are pairs of words in a sentence order with arbitrary gap (Lin and Och, 2004a)", 
    "clean_text": "Skip bigrams, generally speaking, are pairs of words in a sentence order with arbitrary gap (Lin and Och, 2004a).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "S12-1075", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Zhengzhong, Liu | Jian, Xu | Qin, Lu", 
    "raw_text": "Different from the previous skip bigram statistics which compare sentence similarities through overlapping skip bi grams (Lin and Och, 2004a), the skip bi grams we used are weighted by a decaying factor of the skipping gap in a sentence, giving higher scores to closer occurrences of skip bi grams", 
    "clean_text": "Different from the previous skip bigram statistics which compare sentence similarities through overlapping skip bigrams (Lin and Och, 2004a), the skip bigrams we used are weighted by a decaying factor of the skipping gap in a sentence, giving higher scores to closer occurrences of skip bigrams.", 
    "keep_for_gold": 0
  }
]