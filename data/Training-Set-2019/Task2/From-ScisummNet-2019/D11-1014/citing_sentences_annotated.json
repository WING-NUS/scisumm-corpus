[
  {
    "citance_No": 1, 
    "citing_paper_id": "D12-1050", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "William, Blacoe | Mirella, Lapata", 
    "raw_text": "Socher et al2011a) and Socher et al2011b) present a framework based on recursive neural net works that learns vector space representations for multi-word phrases and sentences", 
    "clean_text": "Socher et al (2011a) and Socher et al (2011b) present a framework based on recursive neural net works that learns vector space representations for multi-word phrases and sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "D12-1050", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "William, Blacoe | Mirella, Lapata", 
    "raw_text": "The second one is paraphrase detection ,i.e., the task of examining two sentences and determining whether they have the same meaning (Socher et al2011a)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D12-1050", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "William, Blacoe | Mirella, Lapata", 
    "raw_text": "[c? 1; c? 2]| 2 (16) Socher et al2011a) extend the standard re cursive auto encoder sketched above in two ways", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "D12-1050", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "William, Blacoe | Mirella, Lapata", 
    "raw_text": "Socher et al2011a) obtain best results with 100-dimensional vectors which we also used in our experiments", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D12-1050", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "William, Blacoe | Mirella, Lapata", 
    "raw_text": "Table 3: Correlation coefficients of model predictions with subject similarity ratings (Spearman? s?); columns show dimensionality: fixed or varying (see Section 2.1), composition method:+ is additive vector composition, is component-wise multiplicative vector composition, RAE is Socher et al2011a)? s recursive auto-encoder", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D12-1050", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "William, Blacoe | Mirella, Lapata", 
    "raw_text": "F1 Baseline 66.5 79.9 Mihalcea et al2006) 70.3 81.3 Rus et al2008) 70.6 80.5 Qiu et al2006) 72.0 81.6 Islam and Inkpen (2007) 72.6 81.3 Mitchell and Lapata (2010) () 73.0 82.3 Baroni and Lenci (2010) (+) 73.5 82.2 Fernando and Stevenson (2008) 74.1 82.4 Wan et al2006) 75.6 83.0 Das and Smith (2009) 76.1 82.7 Socher et al2011a) 76.8 83.6 Table 6: Overview of results on the MSRCP (test corpus)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D12-1050", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "William, Blacoe | Mirella, Lapata", 
    "raw_text": "Socher et al2011a) obtain an accuracy that is higher than previously published results", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D12-1050", 
    "citing_paper_authority": 25, 
    "citing_paper_authors": "William, Blacoe | Mirella, Lapata", 
    "raw_text": "With regard to F1, we are comparable with Das and Smith (2009) and Socher et al2011a) without using elaborate features, or any additional manipulations over and above the output of the composition functions 3Without dynamic pooling, their model yields an accuracy of 74.2", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P14-2008", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Charles, Jochim | Hinrich, Sch\u00c3\u00bctze", 
    "raw_text": "More specifically related to our work, deep learning neural networks have been successfully employed for sentiment analysis (Socher et al,2011) and for sentiment domain adaptation (Glo rot et al, 2011)", 
    "clean_text": "More specifically related to our work, deep learning neural networks have been successfully employed for sentiment analysis (Socher et al, 2011) and for sentiment domain adaptation (Glo rot et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P13-1095", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Takayuki, Hasegawa | Nobuhiro, Kaji | Naoki, Yoshinaga | Masashi, Toyoda", 
    "raw_text": "We should emphasize that the features induced from the addressee? s utterance are unique to this task and are hardly available in the related tasks that predicted the emotion of a reader of news articles (Lin and HsinYihn, 2008) or personal stories (Socher et al, 2011)", 
    "clean_text": "We should emphasize that the features induced from the addressee's utterance are unique to this task and are hardly available in the related tasks that predicted the emotion of a reader of news articles (Lin and HsinYihn, 2008) or personal stories (Socher et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P13-1095", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Takayuki, Hasegawa | Nobuhiro, Kaji | Naoki, Yoshinaga | Masashi, Toyoda", 
    "raw_text": "Unlike our prediction task, most of them have exclusively focused on estimating the emotion of a speaker (or writer) from her/his utterance (or writing) .Analogous to our prediction task, Lin and Hsin Yihn (2008) and Socher et al (2011) investigated predicting the emotion of a reader from the text that s/he reads", 
    "clean_text": "Analogous to our prediction task, Lin and Hsin Yihn (2008) and Socher et al (2011) investigated predicting the emotion of a reader from the text that s/he reads.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P14-1146", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Duyu, Tang | Furu, Wei | Nan, Yang | Ming, Zhou | Ting, Liu | Bing, Qin", 
    "raw_text": "Un like Socher et al (2011c) that utilize manually labeled texts to learn the meaning of phrase (or sentence) through compositionality, we focus onlearning the meaning of word, namely word em bedding, from massive distant-supervised tweets", 
    "clean_text": "Unlike Socher et al (2011c) that utilize manually labeled texts to learn the meaning of phrase (or sentence) through compositionality, we focus on learning the meaning of word, namely word embedding, from massive distant-supervised tweets.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P14-1146", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Duyu, Tang | Furu, Wei | Nan, Yang | Ming, Zhou | Ting, Liu | Bing, Qin", 
    "raw_text": "(4) RAE: Recursive Autoencoder (Socher et al,2011c) has been proven effective in many sentiment analysis tasks by learning compositionalityautomatically", 
    "clean_text": "Recursive Autoencoder (Socher et al, 2011c) has been proven effective in many sentiment analysis tasks by learning compositionality automatically.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P14-2126", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Feifei, Zhai | Jiajun, Zhang | Yu, Zhou | Chengqing, Zong", 
    "raw_text": "To our best knowledge, this is the first work on this issue in SMT community;? In current work, RNN has only been verified to be useful on monolingual structure learning (Socher et al, 2011a; Socher et al, 2013)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P14-2126", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Feifei, Zhai | Jiajun, Zhang | Yu, Zhou | Chengqing, Zong", 
    "raw_text": "To do this, we use two unsupervised recursive auto encoders (RAE) (Socher et al, 2011b), one for the source phrase and the other for the target phrase", 
    "clean_text": "To do this, we use two unsupervised recursive autoencoders (RAE) (Socher et al, 2011b), one for the source phrase and the other for the target phrase.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P14-2126", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Feifei, Zhai | Jiajun, Zhang | Yu, Zhou | Chengqing, Zong", 
    "raw_text": "More details can be found in (Socher et al, 2011b)", 
    "clean_text": "More details can be found in (Socher et al, 2011b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P14-1136", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Karl Moritz, Hermann | Dipanjan, Das | Jason, Weston | Kuzman, Ganchev", 
    "raw_text": "By providing richer representations of meaning than what can be encompassed in a discrete representation, such approaches have successfully been applied to tasks such as sentiment analysis (Socher et al, 2011), topic classification (Klementiev et al, 2012) or word-word similarity (Mitchell and Lapata, 2008)", 
    "clean_text": "By providing richer representations of meaning than what can be encompassed in a discrete representation, such approaches have successfully been applied to tasks such as sentiment analysis (Socher et al, 2011), topic classification (Klementiev et al, 2012) or word-word similarity (Mitchell and Lapata, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P12-2018", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Sida, Wang | Christopher D., Manning", 
    "raw_text": "Supporting this claim are examples such as not an inhumane monster6, or killing cancer that express an overall positive sentiment with negative words. Some previous work on classifying snippets include using pre-defined polarity reversing rules (Moilanen and Pulman, 2007), and learning complex models on parse trees such as in (Nakagawa et al., 2010) and (Socher et al, 2011)", 
    "clean_text": "Some previous work on classifying snippets include using pre-defined polarity reversing rules (Moilanen and Pulman, 2007), and learning complex models on parse trees such as in (Nakagawa et al., 2010) and (Socher et al, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P12-2018", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Sida, Wang | Christopher D., Manning", 
    "raw_text": "Tree-CRF: (Nakagawa et al, 2010) RAE: Recursive Autoen coders (Socher et al, 2011)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P14-1051", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Zhe, Zhang | Munindar P., Singh", 
    "raw_text": "Socher et al (2011) introduce a semi-supervised approach that uses recursive auto encoders to learn the hierarchical structure and sentiment distribution of a sentence", 
    "clean_text": "Socher et al (2011) introduce a semi-supervised approach that uses recursive autoencoders to learn the hierarchical structure and sentiment distribution of a sentence.", 
    "keep_for_gold": 1
  }
]