[
  {
    "citance_No": 1, 
    "citing_paper_id": "C04-1190", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Weifeng, Su | Marine, Carpuat | Dekai, Wu", 
    "raw_text": "Fornatural language problems in general, of course, it is widely recognized that significant accuracy gains can often be achieved by generalizing over relevant feature combinations (e.g., Kudo and Matsumoto (2003))", 
    "clean_text": "For natural language problems in general, of course, it is widely recognized that significant accuracy gains can often be achieved by generalizing over relevant feature combinations (e.g., Kudo and Matsumoto (2003)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-2040", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Yoshimi, Suzuki | Fumiyo, Fukumoto", 
    "raw_text": "and? short?, All series of documents were tagged by CaboCha (Kudo and Matsumoto, 2003)", 
    "clean_text": "There are two types of correct summary according to the character length, \"long\" and \"short\", All series of documents were tagged by CaboCha (Kudo and Matsumoto, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P14-2040", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Yoshimi, Suzuki | Fumiyo, Fukumoto", 
    "raw_text": "We used person name, organization, place and proper name extracted from NE recognition (Kudo and Matsumoto, 2003) for event detection, and noun words including named entities for topic detection", 
    "clean_text": "We used person name, organization, place and proper name extracted from NE recognition (Kudo and Matsumoto, 2003) for event detection, and noun words including named entities for topic detection.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "C10-1140", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Naoki, Yoshinaga | Masaru, Kitsuregawa", 
    "raw_text": "2.2.1 Kernel InvertedKudo and Matsumoto (2003) proposed polynomial kernel inverted (PKI), which builds inverted indices h (fj)?{ s| s? S ,fj? s} from each feature fj to support vector s? S to only con sider support vector s relevant to given x such that sTx 6= 0", 
    "clean_text": "Kudo and Matsumoto (2003) proposed polynomial kernel inverted (PKI), which builds inverted indices h(fj ) \u2261 {s | s \u2208 S, fj \u2208 s} from each feature fj to support vector s \u2208 S to only consider support vector s relevant to given x such that s Tx 6= 0.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "C10-1140", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Naoki, Yoshinaga | Masaru, Kitsuregawa", 
    "raw_text": "1Following Lemma 1 in Kudo and Matsumoto (2003) ,ckd=? d l=k `d l?`? k m=0 (? 1) k? m? ml` k m??", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "C10-1140", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Naoki, Yoshinaga | Masaru, Kitsuregawa", 
    "raw_text": "Following (Kudo and Matsumoto, 2003) ,weuse a trie (hereafter, weight trie) to maintain conjunctive features", 
    "clean_text": "Following (Kudo and Matsumoto, 2003), we use a trie (hereafter, weight trie) to maintain conjunctive features.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P08-2060", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoav, Goldberg | Michael, Elhadad", 
    "raw_text": "PKI? Inverted Indexing (Kudo and Matsumoto, 2003), stores for each feature the support vectors in which it appears", 
    "clean_text": "PKI - Inverted Indexing (Kudo and Matsumoto, 2003), stores for each feature the support vectors in which it appears.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P08-2060", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoav, Goldberg | Michael, Elhadad", 
    "raw_text": "However, even the sparse-representation version of w tends to be very large: (Isozaki and Kazawa, 2002) report that some of their second degree expanded NER models were more than 80 times slower to load than the original models (and 224 times faster to classify) .1 Thisapproach obviously does not scale well, both to tasks with more features and to larger degree kernels.PKE? Heuristic Kernel Expansion, was introduced by (Kudo and Matsumoto, 2003)", 
    "clean_text": "PKE - Heuristic Kernel Expansion, was introduced by (Kudo and Matsumoto, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P08-2060", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Yoav, Goldberg | Michael, Elhadad", 
    "raw_text": "Our approach is similar to the PKE approach (Kudo and Matsumoto, 2003), which used a basket mining approach to prune many features from the expansion", 
    "clean_text": "Our approach is similar to the PKE approach (Kudo and Matsumoto, 2003), which used a basket mining approach to prune many features from the expansion.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "E12-1069", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Sarah, Alkuhlani | Nizar, Habash", 
    "raw_text": "Yamcha Sequence Tagger We use Yamcha (Kudo and Matsumoto, 2003), a support-vector machine-based sequence tagger", 
    "clean_text": "We use Yamcha (Kudo and Matsumoto, 2003), a support-vector machine-based sequence tagger.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P05-1071", 
    "citing_paper_authority": 85, 
    "citing_paper_authors": "Nizar, Habash | Owen, Rambow", 
    "raw_text": "We use Yamcha (Kudo and Matsumoto, 2003), an implementation of support vector machines which includes Viterbidecoding.6 As training features, we use two sets", 
    "clean_text": "We use Yamcha (Kudo and Matsumoto, 2003), an implementation of support vector machines which includes Viterbi decoding.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "N07-2014", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Nizar, Habash | Owen, Rambow", 
    "raw_text": "Second, we replace the YAMCHA (Kudo and Matsumoto, 2003) implementation of Support Vec tor Machines (SVMs) with SVMTool (Gime ?nez and Ma`rquez, 2004) as our machine learning tool, for reasons of speed, at the cost of a slight decrease in accuracy", 
    "clean_text": "Second, we replace the YAMCHA (Kudo and Matsumoto, 2003) implementation of Support Vector Machines (SVMs) with SVMTool (Gimenez and Marquez, 2004) as our machine learning tool, for reasons of speed, at the cost of a slight decrease in accuracy.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "W07-2048", 
    "citing_paper_authority": 12, 
    "citing_paper_authors": "Richard, Johansson | Pierre, Nugues", 
    "raw_text": "We used YamCha (Kudo and Matsumoto, 2003) to detect named entities, and we trained it on the SemEval full-text training sets", 
    "clean_text": "We used YamCha (Kudo and Matsumoto, 2003) to detect named entities, and we trained it on the SemEval full-text training sets.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "D09-1160", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Naoki, Yoshinaga | Masaru, Kitsuregawa", 
    "raw_text": "readers may refer to Kudo and Matsumoto (2003) for the detailed computation for obtaining w. The time complexity of Eq", 
    "clean_text": "readers may refer to Kudo and Matsumoto (2003) for the detailed computation for obtaining w.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "D09-1160", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Naoki, Yoshinaga | Masaru, Kitsuregawa", 
    "raw_text": "The number of support vectors of SVMs was 71, 766? 9.2%, which is twice as many as those used by Kudo and Matsumoto (2003) (34,996) in their experiments on the same task. We could clearly observe that the number of active features |x d| increased dramatically according to the order d of feature combinations", 
    "clean_text": "The number of support vectors of SVMs was 71,766 \u00b1 9.2%, which is twice as many as those used by Kudo and Matsumoto (2003) (34,996) in their experiments on the same task.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "D09-1160", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Naoki, Yoshinaga | Masaru, Kitsuregawa", 
    "raw_text": "This result conforms to the results reported in (Kudo and Matsumoto, 2003)", 
    "clean_text": "This result conforms to the results reported in (Kudo and Matsumoto, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "W09-1106", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Daniele, Pighin | Alessandro, Moschitti", 
    "raw_text": "(Rakotomamonjy, 2003), (Weston et al, 2003) or (Kudo and Matsumoto, 2003)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "W09-1106", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Daniele, Pighin | Alessandro, Moschitti", 
    "raw_text": "In (Kudo and Matsumoto, 2003), an extension of thePrefixSpan algorithm (Pei et al, 2001) is used to efficiently mine the features in a low degree polynomial kernel space", 
    "clean_text": "In (Kudo and Matsumoto, 2003), an extension of the PrefixSpan algorithm (Pei et al, 2001) is used to efficiently mine the features in a low degree polynomial kernel space.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W10-2926", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "Daniele, Pighin | Alessandro, Moschitti", 
    "raw_text": "In (Kudo and Matsumoto,2003), an extension of the PrefixSpanalgorithm (Pei et al, 2001) is used to efficiently mine the features in a low degree polynomial kernel space", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "D12-1052", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Daniel, Dahlmeier | Hwee Tou, Ng", 
    "raw_text": "We use the following tools for syntactic processing: OpenNLP4 for POS tagging, YamCha (Kudo and Matsumoto, 2003) for constituent chunking, and the MALT parser (Nivre et al2007) for dependency parsing", 
    "clean_text": "We use the following tools for syntactic processing: OpenNLP4 for POS tagging, YamCha (Kudo and Matsumoto, 2003) for constituent chunking, and the MALT parser (Nivre et al, 2007) for dependency parsing.", 
    "keep_for_gold": 0
  }
]