[
  {
    "citance_No": 1, 
    "citing_paper_id": "P01-1067", 
    "citing_paper_authority": 183, 
    "citing_paper_authors": "Kenji, Yamada | Kevin, Knight", 
    "raw_text": "IBM Model 5 was sequentially bootstrapped with Model 1, an HMM Model, and Model 3 (Och and Ney, 2000)", 
    "clean_text": "IBM Model 5 was sequentially bootstrapped with Model 1, an HMM Model, and Model 3 (Och and Ney, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-1106", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Junhui, Li | Yuval, Marton | Philip, Resnik | Hal, Daum\u00c3\u00a9 III", 
    "raw_text": "The English data is lowercased, tokenized and aligned with GIZA++ (Och and Ney, 2000) to obtain bidirectional alignments, which are symmetrized using the grow-diag-final-and method (Koehn et al, 2003)", 
    "clean_text": "The English data is lowercased, tokenized and aligned with GIZA++ (Och and Ney, 2000) to obtain bidirectional alignments, which are symmetrized using the grow-diag-final-and method (Koehn et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P09-1067", 
    "citing_paper_authority": 15, 
    "citing_paper_authors": "Zhifei, Li | Jason M., Eisner | Sanjeev P., Khudanpur", 
    "raw_text": "We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) 17 to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively", 
    "clean_text": "We use GIZA++ (Och and Ney,2000), a suffix-array (Lopez, 2007), SRILM (Stolcke, 2002), and risk-based deterministic annealing (Smith and Eisner, 2006) to obtain word alignments, translation models, language models, and the optimal weights for combining these models, respectively.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "W02-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Shankar, Kumar | William, Byrne", 
    "raw_text": "The development of techniques in all these areas would be facilitated by automatic performance metrics, and alignment and translation quality metrics have been pro posed (Och and Ney, 2000b; Papineni et al, 2002)", 
    "clean_text": "The development of techniques in all these areas would be facilitated by automatic performance metrics, and alignment and translation quality metrics have been proposed (Och and Ney, 2000b; Papineni et al, 2002).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "W02-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Shankar, Kumar | William, Byrne", 
    "raw_text": "The Alignment Error Rate (AER) introduced by Och and Ney (2000b) measures the fraction of links by which the automatic alignment differs from the reference alignment", 
    "clean_text": "The Alignment Error Rate (AER) introduced by Och and Ney (2000b) measures the fraction of links by which the automatic alignment differs from the reference alignment.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "W02-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Shankar, Kumar | William, Byrne", 
    "raw_text": "The IBM-3 models were trained on a subset of the Canadian HansardsFrench-English data which consisted of 50,000 parallel sentences (Och and Ney, 2000b)", 
    "clean_text": "The IBM-3 models were trained on a subset of the Canadian Hansards French-English data which consisted of 50,000 parallel sentences (Och and Ney, 2000b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "W02-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Shankar, Kumar | William, Byrne", 
    "raw_text": "The GIZA++ toolkit (Och and Ney, 2000a) was used for training the IBM-3 models (as in (Och and Ney, 2000b))", 
    "clean_text": "The GIZA++ toolkit (Och and Ney, 2000a) was used for training the IBM-3 models (as in (Och and Ney, 2000b)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "W02-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Shankar, Kumar | William, Byrne", 
    "raw_text": "RatesOur unseen test data consisted of 207 FrenchEnglish sentence pairs from the Hansardscor pus (Och and Ney, 2000b)", 
    "clean_text": "Our unseen test data consisted of 207 French English sentence pairs from the Hansards corpus (Och and Ney, 2000b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "W02-1019", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Shankar, Kumar | William, Byrne", 
    "raw_text": "5.6.2 Evaluation MetricsThe performance of the four decoders was measured with respect to the alignments provided by human experts (Och and Ney, 2000b)", 
    "clean_text": "The performance of the four decoders was measured with respect to the alignments provided by human experts (Och and Ney, 2000b).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W05-0823", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Rafael E., Banches | Josep M., Crego | Adri&agrave; de, Gispert | Patrik, Lambert | Jos&eacute;e B., Mari&ntilde;o", 
    "raw_text": "and qu? .Once the training data was preprocessed, a word to-word alignment was performed in both directions, source-to-target and target-to-source, by using GIZA++ (Och and Ney, 2000)", 
    "clean_text": "Once the training data was preprocessed, a word-to-word alignment was performed in both directions, source-to-target and target-to-source, by using GIZA++ (Och and Ney, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W09-0435", 
    "citing_paper_authority": 20, 
    "citing_paper_authors": "Jan, Niehues | Muntsin, Kolss", 
    "raw_text": "The approach was first presented by Brown et al (1993) and has since been used in many translation systems (Wang and Waibel, 1998), (Och and Ney, 2000), (Yamadaand Knight, 2000), (Vogel et al, 2003)", 
    "clean_text": "The approach was first presented by Brown et al (1993) and has since been used in many translation systems (Wang and Waibel, 1998), (Och and Ney, 2000), (Yamadaand Knight, 2000), (Vogel et al, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P05-2012", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Adri&agrave; de, Gispert", 
    "raw_text": "In order to assess the quality of the word alignment, we randomly selected from the training corpus 350 sentences, and a manual gold standard alignment has been done with the criterion of Sure and Possible links, in order to compute Alignment Error Rate (AER) as described in (Och and Ney, 2000) and widely used in literature, together with appropriately redefined Recall and Precision measures", 
    "clean_text": "In order to assess the quality of the word alignment, we randomly selected from the training corpus 350 sentences, and a manual gold standard alignment has been done with the criterion of Sure and Possible links, in order to compute Alignment Error Rate (AER) as described in (Och and Ney, 2000) and widely used in literature, together with appropriately redefined Recall and Precision measures.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P10-2005", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Bing, Xiang | Yonggang, Deng | Bowen, Zhou", 
    "raw_text": "We use GIZA++ (Och and Ney, 2000) to generate the baseline alignment for each direction and then apply grow-diagonal-final (gdf)", 
    "clean_text": "We use GIZA++ (Och and Ney, 2000) to generate the baseline alignment for each direction and then apply grow-diagonal-final (gdf).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P03-1012", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Colin, Cherry | Dekang, Lin", 
    "raw_text": "We adopted the same evaluation methodology as in (Och and Ney, 2000), which compared alignment outputs with manually aligned sentences", 
    "clean_text": "We adopted the same evaluation methodology as in (Och and Ney, 2000), which compared alignment outputs with manually aligned sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P03-1012", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Colin, Cherry | Dekang, Lin", 
    "raw_text": "They defined the following metrics to evaluate an alignment A: recall= |A? S||S| precision= |A? P| |P| alignment error rate (AER)= |A? S|+|A? P ||S|+|P| We trained our alignment program with the same 50K pairs of sentences as (Och and Ney, 2000) and tested it on the same 500 manually aligned sentences", 
    "clean_text": "We trained our alignment program with the same 50K pairs of sentences as (Och and Ney, 2000) and tested it on the same 500 manually aligned sentences.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P03-1012", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Colin, Cherry | Dekang, Lin", 
    "raw_text": "We parsed the training Table 2: Comparison with (Och and Ney, 2000) Method Prec Rec AER Ours 95.7 86.4 8.7 IBM-4 F? E 80.5 91.2 15.6 IBM-4 E? F 80.0 90.8 16.0 IBM-4 Intersect 95.7 85.6 9.0 IBM-4 Refined 85.9 92.3 11.7 and testing corpora with Minipar.5 We then ran the training procedure in Section 4 for three iterations", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P03-1012", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Colin, Cherry | Dekang, Lin", 
    "raw_text": "Table 2 compares the results of our algorithm with the results in (Och and Ney, 2000), where an HMM model is used to bootstrap IBM Model 4", 
    "clean_text": "Table 2 compares the results of our algorithm with the results in (Och and Ney, 2000), where an HMM model is used to bootstrap IBM Model 4.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P03-1012", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Colin, Cherry | Dekang, Lin", 
    "raw_text": "This demonstrates that we are competitive with the methods described in (Och and Ney, 2000)", 
    "clean_text": "This demonstrates that we are competitive with the methods described in (Och and Ney, 2000).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W08-0402", 
    "citing_paper_authority": 21, 
    "citing_paper_authors": "Zhifei, Li | Sanjeev P., Khudanpur", 
    "raw_text": "We use the GIZA toolkit (Och and Ney, 2000), a suffix-array architecture (Lopez, 2007) ,theSRILM toolkit (Stolcke, 2002), and minimum error rate training (Och et al, 2003) to obtain word alignments, a translation model, language models, and the optimal weights for combining these mod els, respectively", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "P11-1090", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Jason, Naradowsky | Kristina, Toutanova", 
    "raw_text": "The first feature is the absolute difference between ai and ai? 1+ 1 and is similar to information used in other HMM word alignment models (Och and Ney, 2000) as well as phrase translation models (Koehn, 2004)", 
    "clean_text": "The first feature is the absolute difference between ai and ai-1 + 1 and is similar to information used in other HMM word alignment models (Och and Ney, 2000) as well as phrase translation models (Koehn, 2004).", 
    "keep_for_gold": 0
  }
]