[
  {
    "citance_No": 1, 
    "citing_paper_id": "E12-1024", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Tom, Kwiatkowski | Sharon, Goldwater | Luke, Zettlemoyer | Mark, Steedman", 
    "raw_text": "Semantic parser induction as addressed by Zettlemoyer and Collins (2005, 2007, 2009), Kate and Mooney (2007), Wong and Mooney (2006, 2007), Lu et al (2008), Chen et al (2010), Kwiatkowski et al (2010, 2011) and Bo ?rschinger et al (2011) has the same task definition as theone addressed by this paper", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P12-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Bevan K., Jones | Mark, Johnson | Sharon, Goldwater", 
    "raw_text": "Like the hybrid tree semantic parser (Lu et al, 2008) and the synchronous grammar based WASP (Wongand Mooney, 2006), our model simultaneously generates the input MR tree and the output NL string", 
    "clean_text": "Like the hybrid tree semantic parser (Lu et al, 2008) and the synchronous grammar based WASP (Wong and Mooney, 2006), our model simultaneously generates the input MR tree and the output NL string.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "P12-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Bevan K., Jones | Mark, Johnson | Sharon, Goldwater", 
    "raw_text": "The hybrid tree model (Lu et al, 2008) takes a trans formative perspective that is in some ways more similar to our model", 
    "clean_text": "The hybrid tree model (Lu et al, 2008) takes a transformative perspective that is in some ways more similar to our model.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P12-1051", 
    "citing_paper_authority": 6, 
    "citing_paper_authors": "Bevan K., Jones | Mark, Johnson | Sharon, Goldwater", 
    "raw_text": "WASP (Wong and Mooney, 2006) and the hybrid tree (Lu et al, 2008) are chosen to rep resent tree transformation based approaches, and, while this comparison is our primary focus, we also report UBL-S (Kwiatkowski et al, 2010) as a non tree based top-performing system.6 The hybrid treeis notable as the only other system based on a generative model, and uni-hybrid, a version that uses a unigram distribution over words, is very similar to our own model", 
    "clean_text": "WASP (Wong and Mooney, 2006) and the hybrid tree (Lu et al, 2008) are chosen to represent tree transformation based approaches, and, while this comparison is our primary focus, we also report UBL-S (Kwiatkowski et al, 2010) as a non tree based top-performing system.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "D11-1149", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Wei, Lu | Hwee Tou, Ng", 
    "raw_text": "A novel grammar induction algorithm: Toautomatically induce such synchronous grammar rules, we propose a novel generative model that establishes phrasal correspondences between logical sub-expressions and natural language word sequences, by extending a previous model proposed for parsing natural language into meaning representations (Lu et al, 2008) .To our best knowledge, this is the first probabilistic model for generating sentences from the lambda calculus encodings of their underlying formal meaning representations, that concerns both surface realization and lexical acquisition", 
    "clean_text": "A novel grammar induction algorithm: To automatically induce such synchronous grammar rules, we propose a novel generative model that establishes phrasal correspondences between logical sub-expressions and natural language word sequences, by extending a previous model proposed for parsing natural language into meaning representations (Lu et al, 2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "D11-1149", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Wei, Lu | Hwee Tou, Ng", 
    "raw_text": "Of particular interest is our prior work Lu et al (2008), in which we presented a joint generative process that produces a hybrid tree structure containing words, syntactic structures, and meaning representations, where the meaning representations are in a variable-free tree-structured form", 
    "clean_text": "Of particular interest is our prior work Lu et al (2008), in which we presented a joint generative process that produces a hybrid tree structure containing words, syntactic structures, and meaning representations, where the meaning representations are in a variable-free tree-structured form.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "D11-1149", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Wei, Lu | Hwee Tou, Ng", 
    "raw_text": "3? -Hybrid TreeIn Lu et al (2008), a generative model was presented to model the process that jointly generates both natural language sentences and their underlying meaning representations of a variable-free tree structured form", 
    "clean_text": "Hybrid Tree in Lu et al (2008), a generative model was presented to model the process that jointly generates both natural language sentences and their underlying meaning representations of a variable-free tree structured form.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "D11-1149", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Wei, Lu | Hwee Tou, Ng", 
    "raw_text": "In this section, we present a novel? -hybrid tree model that provides the following extensions over the model of Lu et al (2008): 1", 
    "clean_text": "In this section, we present a novel hybrid tree model that provides the following extensions over the model of Lu et al (2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "D11-1149", 
    "citing_paper_authority": 9, 
    "citing_paper_authors": "Wei, Lu | Hwee Tou, Ng", 
    "raw_text": "Since we allow a packed? -meaning forest representation rather than a fixed tree structure, the MR model parameters? in this work should be estimated with the inside-outside algorithm as well, rather than being estimated directly from the training data by simple counting, as was done in Lu et al (2008)", 
    "clean_text": "Since we allow a packed meaning forest representation rather than a fixed tree structure, the MR model parameters in this work should be estimated with the inside-outside algorithm as well, rather than being estimated directly from the training data by simple counting, as was done in Lu et al (2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "Inaddition, they use a combination of a simple Markov model and a bag-of-words model when generating natural language for MRs, therefore, they do not model context-free linguistic syntax. Motivated by the limitations of these previous methods, we propose a new generative alignment model that includes a full semantic parsing model proposed by Lu et al (2008)", 
    "clean_text": "Motivated by the limitations of these previous methods, we propose a new generative alignment model that includes a full semantic parsing model proposed by Lu et al (2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "Motivated by this prior research, our approach combines the generative alignment model of Liang et al (2009) with the generative semantic parsing model of Lu et al (2008) in order to fully exploit the NL syntax and its relationship to the MR semantics", 
    "clean_text": "Motivated by this prior research, our approach combines the generative alignment model of Liang et al (2009) with the generative semantic parsing model of Lu et al (2008) in order to fully exploit the NL syntax and its relationship to the MR semantics.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "Our model is built on top of the generative semantic parsing model developed by Lu et al (2008)", 
    "clean_text": "Our model is built on top of the generative semantic parsing model developed by Lu et al (2008).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "Lu et al (2008) introduced a generative semantic parsing model using a hybrid-tree framework", 
    "clean_text": "Lu et al (2008) introduced a generative semantic parsing model using a hybrid-tree framework.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "We use Lu et al (2008)? s generative model for this step, in which: P (w|e)=?? T over (w, m) P (T ,w|m) (2) where m is the MR logical form defined by event e and T is a hybrid tree defined over the NL? MR pair (w, m)", 
    "clean_text": "We use Lu et al (2008)'s generative model for this step, in which: P (w|e)=?? T over (w, m) P (T ,w|m) (2) where m is the MR logical form defined by event e and T is a hybrid tree defined over the NL? MR pair (w, m).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "Thus, it is unnecessary to separately model argument ordering in our approach.21Lu et al (2008) propose 3 models for generative semantic parsing :unigram ,bigram, and mix gram (interpolation between the two)", 
    "clean_text": "Lu et al (2008) propose 3 models for generative semantic parsing :unigram, bigram, and mix gram (interpolation between the two).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "Our model is built on top of Lu et al (2008)? s generative semantic parsing model, which is also trained in several steps in its best-performing ver sion.3 Thus, the overall model is vulnerable to getting stuck in local optima when running EM across these multiple steps", 
    "clean_text": "Our model is built on top of Lu et al (2008)'s generative semantic parsing model, which is also trained in several steps in its best-performing version.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "Since the corpus contains data for four separate games, each fold uses 3 games for training and the remaining game for 3Thebigram model of Lu et al (2008), which is the one used in this paper, must be trained using parameters previously learned for the IBM Model 1 and unigram model in order to exhibit the best performance", 
    "clean_text": "The bigram model of Lu et al (2008), which is the one used in this paper, must be trained using parameters previously learned for the IBM Model 1 and unigram model in order to exhibit the best performance.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "C10-2062", 
    "citing_paper_authority": 8, 
    "citing_paper_authors": "Joohyun, Kim | Raymond J., Mooney", 
    "raw_text": "In particular, our proposed model outperforms the generative alignment model of Liang et al (2009), indicating that the extra linguistic information and MR grammatical structure used by Lu et al (2008)? s generative language model make our overall model more effective than a simple Markov+ bag-of-words model for language generation", 
    "clean_text": "In particular, our proposed model outperforms the generative alignment model of Liang et al (2009), indicating that the extra linguistic information and MR grammatical structure used by Lu et al (2008)'s generative language model make our overall model more effective than a simple Markov + bag-of-words model for language generation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "W11-0105", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chitta, Baral | Juraj, Dzifcak | Marcos Alvarez, Gonzalez | Jiayu, Zhou", 
    "raw_text": "These include the following works: Zettlemoyer and Collins (2005), Kate and Mooney (2006), Wong and Mooney (2006), Wong and Mooney (2007), Lu et al (2008), Zettlemoyer and Collins (2007) and Ge and Mooney (2009)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W11-0105", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chitta, Baral | Juraj, Dzifcak | Marcos Alvarez, Gonzalez | Jiayu, Zhou", 
    "raw_text": "The systems that we compared with are: The SYN0, SYN20 and GOLDSYN systems by Ge and Mooney (2009), the system SCISSOR by Ge and Mooney (2005), an SVM based system KRIPS by Kate and Mooney (2006), a synchronous grammar based system WASP by Wong and Mooney (2007), the CCG based system by Zettlemoyer and Collins (2007) and the work by Lu et al (2008)", 
    "clean_text": "The systems that we compared with are: The SYN0, SYN20 and GOLDSYN systems by Ge and Mooney (2009), the system SCISSOR by Ge and Mooney (2005), an SVM based system KRIPS by Kate and Mooney (2006), a synchronous grammar based system WASP by Wong and Mooney (2007), the CCG based system by Zettlemoyer and Collins (2007) and the work by Lu et al (2008).", 
    "keep_for_gold": 0
  }
]