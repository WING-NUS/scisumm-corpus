Statistical Phrase-Based Translation
We propose a new phrase-based translation model and decoding algorithm that enables us to evaluate and compare several, previously proposed phrase-based translation models.
Within our framework, we carry out a large number of experiments to understand better and explain why phrase-based models outperform word-based models.
Our empirical results, which hold for all examined language pairs, suggest that the highest levels of performance can be obtained through relatively simple means: heuristic learning of phrase translations from word-based alignments and lexical weighting of phrase translations.
Surprisingly, learning phrases longer than three words and learning phrases from high-accuracy word-level alignment models does not have a strong impact on performance.
Learning only syntactically motivated phrases degrades the performance of our systems.
We propose STIR, as a pre-ordering step in a state of-the-art phrase-based translation system from English to Japanese.
