[
  {
    "citance_No": 1, 
    "citing_paper_id": "W02-1031", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Wen, Wang | Mary P., Harper", 
    "raw_text": "Additionally, we evaluate the performance of aconditional probability SuperARV LM (denoted cSu perARV) implemented following Equation (1) rather than Equation (3) to evaluate the importance of using joint probability estimations. For the WSJ PTB task, we compare the Super ARV LMs to the parser LMs developed by Chelba (2000), Roark (2001), and Charniak (2001)", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "W02-1031", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Wen, Wang | Mary P., Harper", 
    "raw_text": "To evaluate the perplexity of the LMs on the WSJ PTB task, we adopted the conventions of Chelba (2000), Roark (2001), and Charniak (2001) for preprocessing the data", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "W02-1031", 
    "citing_paper_authority": 13, 
    "citing_paper_authors": "Wen, Wang | Mary P., Harper", 
    "raw_text": "Perplexity LM 3gram Model Intp (Weight) r POS 167.14 142.55 142.55 (1.0) 0.95 SuperARV 167.14 118.35 118.35 (1.0) 0.92cSuperARV 167.14 150.01 143.83 (0.65) 0.68 Chelba (2000) 167.14 158.28 148.90 (0.64) N/A Roark (2001) 167.02 152.26 137.26 (0.64) N/A Charniak (2001) 167.89 130.20 126.07 (0.64) N/A Chelba 167.14 153.76 147.70 (0.64) 0.73 Charniak 167.14 130.20 126.03 (0.64) 0.69 Table 2: Comparing perplexity results for each LM on the WSJ PTB test set", 
    "clean_text": "", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "P14-2011", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Le, Sun | Xianpei, Han", 
    "raw_text": "That is, we parse all sentences using the Charniak? s parser (Charniak, 2001), relation instances are generated by iterating over all pairs of entity mentions occurring in the same sentence", 
    "clean_text": "That is, we parse all sentences using the Charniak's parser (Charniak, 2001), relation instances are generated by iterating over all pairs of entity mentions occurring in the same sentence.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "P04-1006", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Keith, Hall | Mark, Johnson", 
    "raw_text": "The model presented by Charniak (Charniak, 2001) identifies both syn tactic structural and lexical dependencies that aid in language modeling", 
    "clean_text": "The model presented by Charniak (Charniak, 2001) identifies both syntactic structural and lexical dependencies that aid in language modeling.", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "P04-1006", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Keith, Hall | Mark, Johnson", 
    "raw_text": "The first stage is a PCFG word-lattice parser that generates a set of candidate parses over strings in a word-lattice, while the second stage rescores these candidate edges using a lexicalized syntactic language model (Charniak, 2001)", 
    "clean_text": "The first stage is a PCFG word-lattice parser that generates a set of candidate parses over strings in a word-lattice, while the second stage rescores these candidate edges using a lexicalized syntactic language model (Charniak, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "P04-1006", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Keith, Hall | Mark, Johnson", 
    "raw_text": "These parses are then rescored using a lexicalized syntactic model (Charniak, 2001)", 
    "clean_text": "These parses are then rescored using a lexicalized syntactic model (Charniak, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P04-1006", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Keith, Hall | Mark, Johnson", 
    "raw_text": "These contexts include syntactic structure such as parent and grandparent category labels as well as lexical items such as the head of the parent or the head of a sibling constituent (Charniak, 2001)", 
    "clean_text": "These contexts include syntactic structure such as parent and grandparent category labels as well as lexical items such as the head of the parent or the head of a sibling constituent (Charniak, 2001).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P04-1006", 
    "citing_paper_authority": 5, 
    "citing_paper_authors": "Keith, Hall | Mark, Johnson", 
    "raw_text": "The parser continues to parse a until multiple of the number of edge pops required for the first parse are popped off the agenda. The second stage parser used is a modified version of the Charniak language modeling parser described in (Charniak, 2001)", 
    "clean_text": "The second stage parser used is a modified version of the Charniak language modeling parser described in (Charniak, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "W04-0307", 
    "citing_paper_authority": 11, 
    "citing_paper_authors": "Wen, Wang | Mary P., Harper", 
    "raw_text": "Charniak (Charniak, 2000) developed a state-of-the-art statistical CFG parser and then built an effective language model based on it (Charniak, 2001)", 
    "clean_text": "Charniak (Charniak, 2000) developed a state-of-the-art statistical CFG parser and then built an effective language model based on it (Charniak, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "W06-3122", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Marian, Olteanu | Pasin, Suriyentrakorn | Dan, Moldovan", 
    "raw_text": "We developed for the WMT 2006 shared task a system that is trained on a (a) word-aligned bilingual corpus, (b) a large monolingual (English) corpus and (c) an English tree bank and it is capable of translating from a source language (German, Spanish and French) into English.Our system embeds Phramer2 (used for mini mum error rate training, decoding, decoding tools), Pharaoh (Koehn, 2004) (decoding), Carmel 3 (helper for Pharaoh in n-best generation), Charniak? s parser (Charniak, 2001) (language model) and SRILM4 (n-gram LM construction)", 
    "clean_text": "Our system embeds Phramer2 (used for minimum error rate training, decoding, decoding tools), Pharaoh (Koehn, 2004) (decoding), Carmel 3 (helper for Pharaoh in n-best generation), Charniak's parser (Charniak, 2001) (language model) and SRILM4 (n-gram LM construction).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "W06-3122", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Marian, Olteanu | Pasin, Suriyentrakorn | Dan, Moldovan", 
    "raw_text": "catalogId=LDC2005T12 151 sentence probability n-gram hit/miss model model 1-grams 310 K 310 K 2-grams 45 M 45 M 3-grams 123 M 283 M 4-grams 235 M 675 M Table 2: Number of n-gram entries in the EGW LM 2.4.2 Charniak parsing We used Charniak? s parser as an additional LM (Charniak, 2001) in re ranking", 
    "clean_text": "We used Charniak's parser as an additional LM (Charniak, 2001) in reranking.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 13, 
    "citing_paper_id": "P04-1030", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Christopher, Collins | Bob, Carpenter | Gerald, Penn", 
    "raw_text": "Full acoustic and n-best lattices filtered by trigram scores have been parsed. Hall and Johnson (2003) use a best-first probabilistic context free grammar (PCFG) to parse the input lattice, pruning to a set of local trees (candidate partial parse trees), which are then passed to a version of the parser of Charniak (2001) for more refined parsing", 
    "clean_text": "Hall and Johnson (2003) use a best-first probabilistic context free grammar (PCFG) to parse the input lattice, pruning to a set of local trees (candidate partial parse trees), which are then passed to a version of the parser of Charniak (2001) for more refined parsing.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 14, 
    "citing_paper_id": "P04-1030", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Christopher, Collins | Bob, Carpenter | Gerald, Penn", 
    "raw_text": "of the BLLIP corpus (Charniak et al, 1999) [20 million words] The BLLIP corpus is a collection of Penn Treebank-style parses of the three-year (1987-1989) Wall Street Journal collection from the ACL/DCI corpus (approximately 30 million words) .6 The parses were automatically produced by the parser of Charniak (2001)", 
    "clean_text": "The parses were automatically produced by the parser of Charniak (2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 15, 
    "citing_paper_id": "P04-1030", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Christopher, Collins | Bob, Carpenter | Gerald, Penn", 
    "raw_text": "The current best-performing models, in terms of WER, for the HUB-1 corpus, are the models of Roark (2001), Charniak (2001) (applied to n-best lists by Hall and Johnson (2003)), and the SLM of Chelba and Jelinek (2000) (applied to n-best lists by Xu et al (2002))", 
    "clean_text": "The current best-performing models, in terms of WER, for the HUB-1 corpus, are the models of Roark (2001), Charniak (2001) (applied to n-best lists by Hall and Johnson (2003)), and the SLM of Chelba and Jelinek (2000) (applied to n-best lists by Xu et al (2002)).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 16, 
    "citing_paper_id": "P04-1030", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Christopher, Collins | Bob, Carpenter | Gerald, Penn", 
    "raw_text": "Hall (2003) is a lattice-parser related to Charniak (2001)", 
    "clean_text": "Hall (2003) is a lattice-parser related to Charniak (2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 17, 
    "citing_paper_id": "P04-1030", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Christopher, Collins | Bob, Carpenter | Gerald, Penn", 
    "raw_text": "The difference in WER between our parser and those of Charniak (2001) and Roark (2001) applied to word lists may be due in part to the lower PARSEVAL scores of our system", 
    "clean_text": "The difference in WER between our parser and those of Charniak (2001) and Roark (2001) applied to word lists may be due in part to the lower PARSEVAL scores of our system.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 18, 
    "citing_paper_id": "P04-1030", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Christopher, Collins | Bob, Carpenter | Gerald, Penn", 
    "raw_text": "Another contributing factor to the accuracy of Charniak (2001) is the size of the training set? 20M words larger than that used in this work", 
    "clean_text": "Another contributing factor to the accuracy of Charniak (2001) is the size of the training set: 20M words larger than that used in this work.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 19, 
    "citing_paper_id": "P05-2016", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Heidi J., Fox", 
    "raw_text": "We use a syntax-based language model which was originally developed for use in speech recognition (Charniak, 2001) and later adapted to work with a syntax-based machine translation system (Charniaket al, 2001)", 
    "clean_text": "We use a syntax-based language model which was originally developed for use in speech recognition (Charniak, 2001) and later adapted to work with a syntax-based machine translation system (Charniaket al, 2001).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 20, 
    "citing_paper_id": "W04-2609", 
    "citing_paper_authority": 33, 
    "citing_paper_authors": "Dan, Moldovan | Adriana, Badulescu | Marta, Tatu | Daniel, Antohe | Roxana, G&icirc;rju", 
    "raw_text": "Noun noun (adjective noun, respectively) sequences of words were extracted using the Lauer heuristic (Lauer 1995) which looks for consecutive pairs of nouns that are neither preceded nor succeeded by a noun after each sentence was syntactically parsed with Charniak parser (Charniak2001) (for XWN we used the gold parse trees)", 
    "clean_text": "Noun noun (adjective noun, respectively) sequences of words were extracted using the Lauer heuristic (Lauer 1995) which looks for consecutive pairs of nouns that are neither preceded nor succeeded by a noun after each sentence was syntactically parsed with Charniak parser (Charniak, 2001) (for XWN we used the gold parse trees).", 
    "keep_for_gold": 0
  }
]