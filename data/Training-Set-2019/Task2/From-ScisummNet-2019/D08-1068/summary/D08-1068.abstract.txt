Machine learning approaches to coreference resolution are typically supervised, and require expensive labeled data.
Some unsupervised approaches have been proposed (e.g., Haghighi and Klein (2007)), but they are less accurate.
In this paper, we present the first unsupervised approach that is competitive with supervised ones.
This is made possible by performing joint inference across mentions, in contrast to the pairwise classification typically used in supervised methods, and by using Markov logic as a representation language, which enables us to easily express relations like apposition and predicate nominals.
On MUC and ACE datasets, our model outperforms Haghigi and Kleinâ€™s one using only a fraction of the training data, and often matches or exceeds the accuracy of state-of-the-art supervised models.