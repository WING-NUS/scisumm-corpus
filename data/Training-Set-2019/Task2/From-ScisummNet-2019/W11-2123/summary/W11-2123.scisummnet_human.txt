KenLM: Faster and Smaller Language Model Queries
We present KenLM, a library that implements two data structures for efficient language model queries, reducing both time and memory costs.
The PROBING data structure uses linear probing hash tables and is designed for speed.
Compared with the widely-used SRILM, our PROBING model is 2.4 times as fast while using 57% of the memory.
The TRIE data structure is a trie with bit-level packing, sorted records, interpolation search, and optional quantization aimed at lower memory consumption.
TRIE simultaneously uses less memory than the smallest lossless baseline and less CPU than the fastest baseline.
Our code is open-source, thread-safe, and integrated into the Moses, cdec, and Joshua translation systems.
This paper describes the several performance techniques used and presents benchmarks against alternative implementations.
We describe a language modeling library.
