[
  {
    "citance_No": 1, 
    "citing_paper_id": "D12-1066", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Aur&eacute;lien, Max | Houda, Bouamor | Anne, Vilnat", 
    "raw_text": "SCENE We used the Multiple Video DescriptionCorpus (Chen and Dolan, 2011) obtained from multiple descriptions of short videos", 
    "clean_text": "We used the Multiple Video Description Corpus (Chen and Dolan, 2011) obtained from multiple descriptions of short videos.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 2, 
    "citing_paper_id": "P14-1114", 
    "citing_paper_authority": 1, 
    "citing_paper_authors": "Islam, Beltagy | Katrin, Erk | Raymond J., Mooney", 
    "raw_text": "The dataset consists of 1,500 pairs of short video descriptions collected using crowd sourcing (Chen and Dolan, 2011) and subsequently annotated for the STS task (Agirre et al, 2012)", 
    "clean_text": "The dataset consists of 1,500 pairs of short video descriptions collected using crowd sourcing (Chen and Dolan, 2011) and subsequently annotated for the STS task (Agirre et al, 2012).", 
    "keep_for_gold": 1
  }, 
  {
    "citance_No": 3, 
    "citing_paper_id": "D12-1058", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Atsushi, Fujita | Pierre, Isabelle | Roland, Kuhn", 
    "raw_text": "Such corpora have also been created manually through crowd sourcing (Chen and Dolan, 2011)", 
    "clean_text": "Such corpora have also been created manually through crowd sourcing (Chen and Dolan, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 4, 
    "citing_paper_id": "S12-1051", 
    "citing_paper_authority": 83, 
    "citing_paper_authors": "Aitor, Gonzalez-Agirre | Eneko, Agirre | Daniel, Cer | Mona, Diab", 
    "raw_text": "The authors showed brief video segments to Annotators from Amazon Mechanical Turk (AMT) and were asked 1http: //search.cpan.org/ ?mlehmann/ String-Similarity-1.04/Similarity.pm 386 Figure 1: Video and corresponding descriptions from MSRvid Figure 2: Definition and instructions for annotation to provide a one-sentence description of the main action or event in the video (Chen and Dolan, 2011)", 
    "clean_text": "Figure 2: Definition and instructions for annotation to provide a one-sentence description of the main action or event in the video (Chen and Dolan, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 5, 
    "citing_paper_id": "E12-1073", 
    "citing_paper_authority": 2, 
    "citing_paper_authors": "Aur&eacute;lien, Max | Houda, Bouamor | Anne, Vilnat", 
    "raw_text": "video descriptions Descriptions of short YouTube videos obtained via Mechanical Turk (Chen and Dolan, 2011) .4", 
    "clean_text": "3. video descriptions Descriptions of short YouTube videos obtained via Mechanical Turk (Chen and Dolan, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 6, 
    "citing_paper_id": "S12-1076", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Michael, Heilman | Nitin, Madnani", 
    "raw_text": "The STS task data includes five subtasks with text pairs from different sources: the Microsoft Research Paraphrase Corpus (Dolan et al, 2004) (MSRpar), The Microsoft Research Video corpus (ChenandDolan, 2011) (MSRvid), statistical machine translation output of parliament proceedings (Koehn, 2005) (SMT-eur)", 
    "clean_text": "The STS task data includes five subtasks with text pairs from different sources: the Microsoft Research Paraphrase Corpus (Dolan et al, 2004) (MSRpar), The Microsoft Research Video corpus (Chen and Dolan, 2011) (MSRvid), statistical machine translation output of parliament proceedings (Koehn, 2005) (SMT-eur).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 7, 
    "citing_paper_id": "S12-1086", 
    "citing_paper_authority": 4, 
    "citing_paper_authors": "Weiwei, Guo | Mona, Diab", 
    "raw_text": "MSR video data (Chen and Dolan, 2011), 3", 
    "clean_text": "MSR video data (Chen and Dolan, 2011).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 8, 
    "citing_paper_id": "P12-1045", 
    "citing_paper_authority": 3, 
    "citing_paper_authors": "David, Chen", 
    "raw_text": "To encourage quality contributions, we use a tiered payment structure (Chen and Dolan, 2011) that rewards the good workers", 
    "clean_text": "To encourage quality contributions, we use a tiered payment structure (Chen and Dolan, 2011) that rewards the good workers.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 9, 
    "citing_paper_id": "P12-2008", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Hong, Sun | Ming, Zhou", 
    "raw_text": "However, as pointed out by (Chenand Dolan, 2011), there is the lack of automatic metric that is capable to measure all the three criteria in paraphrase generation", 
    "clean_text": "However, as pointed out by (Chenand Dolan, 2011), there is the lack of automatic metric that is capable to measure all the three criteria in paraphrase generation.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 10, 
    "citing_paper_id": "P13-2040", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chris, Quirk | Pallavi, Choudhury", 
    "raw_text": "Examples of groundings include pictures (Rashtchianetal., 2010), videos (Chen and Dolan, 2011) ,translations of a sentence from another language (Dreyer and Marcu, 2012), or even paraphrases of the same sentence (Barzilay and Lee, 2003)", 
    "clean_text": "Examples of groundings include pictures (Rashtchianu et al., 2010), videos (Chen and Dolan, 2011), translations of a sentence from another language (Dreyer and Marcu, 2012), or even paraphrases of the same sentence (Barzilay and Lee, 2003).", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 11, 
    "citing_paper_id": "P13-2040", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chris, Quirk | Pallavi, Choudhury", 
    "raw_text": "Consider the following excerpts from a video description corpus (Chen and Dolan, 2011):? A man is sliding a cat on the floor", 
    "clean_text": "Consider the following excerpts from a video description corpus (Chen and Dolan, 2011): A man is sliding a cat on the floor.", 
    "keep_for_gold": 0
  }, 
  {
    "citance_No": 12, 
    "citing_paper_id": "P13-2040", 
    "citing_paper_authority": 0, 
    "citing_paper_authors": "Chris, Quirk | Pallavi, Choudhury", 
    "raw_text": "We explore a task in description recognition. Given a large set of videos and a number of descriptions for each video (Chen and Dolan, 2011), we build a system that can recognize fluent and accurate descriptions of videos", 
    "clean_text": "Given a large set of videos and a number of descriptions for each video (Chen and Dolan, 2011), we build a system that can recognize fluent and accurate descriptions of videos.", 
    "keep_for_gold": 0
  }
]