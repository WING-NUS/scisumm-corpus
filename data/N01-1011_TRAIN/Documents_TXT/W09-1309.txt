Disambiguation of Biomedical Abbreviations
Proceedings of the Workshop on BioNLP, pages 71–79,Boulder, Colorado, June 2009. c©2009 Association for Computational Linguistics
Disambiguation of Biomedical Abbreviations
Mark Stevenson1, Yikun Guo2, Abdulaziz Al Amri3 and Robert Gaizauskas4Department of Computer Science
University of SheffieldRegent Court, 211 Portobello
Sheffield, S1 4DPUnited Kingdom
1,2,4{initial.surname}@dcs.shef.ac.uk, 3abdulazizmail@gmail.com
Abstract
Abbreviations are common in biomedical doc-uments and many are ambiguous in the sensethat they have several potential expansions.Identifying the correct expansion is necessaryfor language understanding and important forapplications such as document retrieval. Iden-tifying the correct expansion can be viewed asa Word Sense Disambiguation (WSD) prob-lem. A WSD system that uses a variety ofknowledge sources, including two types of in-formation specific to the biomedical domain,is also described. This system was tested on acorpus of ambiguous abbreviations, created byautomatically identifying the correct expan-sion in Medline abstracts, and found to iden-tify the correct expansion with up to 99% ac-curacy.
1 Introduction
Many abbreviations are ambiguous in the sense thatthey have more than one possible expansion. Forexample, expansions for “NLP” include “Neuro-linguistic Programming” as well as “Natural Lan-guage Processing”. Ambiguous abbreviations forma challenge to language understanding since iden-tification of the correct expansion is often impor-tant. The query “NLP”, for example, returns pageswhich refer to “Neuro-linguistic programming” formost web search engines, pages which are of lim-ited value to those interested in Natural LanguageProcessing. In some cases this problem could beobviated by altering the query terms, for exampleincluding “Natural”, “Language” and “Processing”.
However, this will not help when the abbreviation’sexpansion does not occur within the document. Fredand Cheng (1999) point out that this is often the casein biomedical documents, in this domain ubiquitousabbreviations (such as DNA and mRNA) often ap-pear without an expansion.
It has been reported that misinterpretation of ab-breviations in biomedical documents has lead tomedical practitioners making fatal errors (Fred andCheng, 1999). However, identifying the correct ex-pansion is not a straightforward task since an ab-breviation may have several possible expansions.Chang et al. (2002) reported that abbreviations inbiomedical journal articles consisting of six charac-ters or less have an average of 4.61 possible mean-ings and Pustejovsky et al. (2002) mention that thesimple abbreviation “AC” is associated with at least10 strings in different biomedical documents includ-ing “atrioventricular connection”, “anterior colpor-rhaphy procedure”, “auditory cortex” and “atypicalcarcinoid”.
The problem of identifying the correct expansionof an ambiguous abbreviation can be viewed as aWord Sense Disambiguation (WSD) task where thevarious expansions are the “senses” of the abbrevia-tion. In this paper we approach the problem in thisway by applying a WSD system which has previ-ously been applied to biomedical text (Stevenson etal., 2008). The WSD system uses a variety of infor-mation sources, including those traditionally appliedto the WSD problem in addition to two knowledgesources that are specific to the biomedical domain.
Evaluation of systems for disambiguating am-biguous abbreviations has been hindered by the fact
71
that there is no freely available benchmark corpusagainst which approaches can be compared. We de-scribe a process whereby such a corpus can be cre-ated by automatically mining abstracts from Med-line. This corpus is being made publicly availableto encourage comparative research in this area. Ourabbreviation disambiguation system was evaluatedagainst this corpus and found to identify the correctabbreviation with up to 99% accuracy.
The remainder of this paper is organised as fol-lows. The next section describes relevant previouswork on disambiguation of abbreviations. Section3 describes a supervised learning WSD system tai-lored specifically to the biomedical domain. Section4 describes the automatic creation of a corpus of am-biguous abbreviations designed specifically for thetraining and evaluation of abbreviation disambigua-tion systems. Section 5 describes the evaluation ofour system on this corpus. Our conclusions are pre-sented in Section 6.
2 Previous Work
Gaudan et al. (2005) distinguish two types of abbre-viations: global and local. Global abbreviations arethose found in documents without the expansion ex-plicitly stated, while local abbreviations are definedin the same document in which the abbreviation oc-curs. Our work is concerned with the problem ofdisambiguating global abbreviations. Gaudan et al.(2005) point out that global abbreviations are oftenambiguous.
Various researchers have explored the problemof disambiguating global abbreviations in biomed-ical documents. Liu et al. (2001)(2002) used sev-eral domain-specific knowledge sources to identifyterms which are semantically related to each possi-ble expansion but which have only one sense them-selves. Instances of these terms were identified ina corpus of biomedical journal abstracts and usedas training data. Their learning algorithm uses avariety of features including all words in the ab-stract and collocations of the ambiguous abbrevia-tion. They report an accuracy of 97% on a small setof abbreviations. Liu et al. (2004) present a fullysupervised approach. They compared a variety ofsupervised machine learning algorithms and foundthat the best performance over a set of 15 ambigu-
ous abbreviations, 98.6%, was obtained using NaiveBayes. Gaudan et al. (2005) use a Support VectorMachine trained on a bag-of-words model and re-port an accuracy of 98.5%. Yu et al. (2006) exper-imented with two supervised learning algorithms:Naive Bayes and Support Vector Machines. Theyextracted a corpus containing examples of 60 ab-breviations from a set of biomedical journal articleswhich was split so that abstracts in which the abbre-viations were defined were used as training data andthose in which no definition is found as test data.Abbreviations in the test portion were manually dis-ambiguated. They report 79% coverage and 80%precision using a Naive Bayes classifier. Pakho-mov (2002) applied a maximum entropy model toidentify the meanings of ambiguous abbreviations in10,000 rheumatology notes with around 89% accu-racy. Joshi et al. (2006) disambiguated abbreviationsin clinical notes using three supervised learning al-gorithms (Naive Bayes, decision trees and SupportVector Machines). They used a range of features andfound that the best performance was obtained whenthese were combined. Unfortunately direct compari-son of these methods is made difficult by the fact thatvarious researchers have evaluated their approacheson different data sets.
A variety of approaches have also been proposedfor the problem of disambiguating local abbrevia-tions in biomedical documents. This task is equiv-alent to identifying the abbreviation’s expansion inthe document. The problem is relatively straight-forward for abbreviations which are created by se-lecting the first character from each word in the ex-pansion, such as “angiotensin converting enzyme(ACE)”, but is more difficult when this conventionis not followed, for example “acetylchlinesterase(ACE)”, “antisocial personality (ASP)” and “cata-lase (CAT)”. Okazaki et al. (2008) recently pro-posed an approach to this problem based on dis-criminative alignment that has been shown to per-form well. However, the most common solutionsare based on heuristic approaches, for exampleAdar (2004) and Zhou et al. (2006). Pustejovskyet al. (2002) used hand-built regular expressions.Schwartz and Hearst (2003) describe an approachwhich starts by identifying the set of candidate ex-pansions in the same sentence as an abbreviation.The most likely one is identified by searching for the
72
shortest candidate which contains all the charactersin the abbreviation in the correct order.
3 Abbreviation Disambiguation System
Our abbreviation disambiguation system is based ona state-of-the-art WSD system that has been adaptedto the biomedical domain by augmenting it with ad-ditional knowledge sources. The system on whichour approach is based (Agirre and Marti´nez, 2004)participated in the Senseval-3 challenge (Mihalceaet al., 2004) with a performance close to the bestsystem for the lexical sample tasks in two languageswhile the version adapted to the biomedical domainhas achieved the best recorded results (Stevenson etal., 2008) on a standard test set consisting of am-biguous terms (Weeber et al., 2001).
This system is based on a supervised learning ap-proach with features derived from text around theambiguous word that are domain independent. Werefer to these as general features. This feature sethas been adapted for the disambiguation of biomed-ical text by adding further linguistic features and twodifferent types of domain-specific features: CUIs (asused by McInnes et al. (2007)) and Medical Sub-ject Heading (MeSH) terms. This set of features ismore diverse than have been explored by previousapproaches to abbreviation disambiguation.
3.1 FeaturesOur feature set contains a number of parameters(e.g. thresholds for unigram and CUI frequencies).These parameters were set to the same values thatwere used when the system was applied to gen-eral biomedical terms (Stevenson et al., 2008) sincethese were found to perform well. We also use theentire abstract as the context of the ambiguous termfor relevant features rather than just the sentencecontaining the term. Effects of altering these vari-ables are consistent with previous results (Liu et al.,2004; Joshi et al., 2005; McInnes et al., 2007) andare not reported here.
General features: The system uses a wide rangeof domain-independent features that are commonlyemployed for WSD.
• Local collocations: A total of 41 features whichextensively describe the context of the am-biguous word and fall into two main types:
(1) bigrams and trigrams containing the am-biguous word constructed from lemmas, wordforms or PoS tags and (2) preceding/followinglemma/word-form of the content words (adjec-tive, adverb, noun and verb) in the same sen-tence as the ambiguous abbreviation. For ex-ample, consider the sentence below with thetarget abreviation BSA.
“Lean BSA was obtained from heightand lean body weight ...”
The features would include the following:left-content-word-lemma “lean BSA”, right-function-word-lemma “BSA be”, left-POS “JJNNP”, right-POS “NNP VBD”, left-content-word-form “Lean BSA”, right-function-word-form “BSA was”, etc.
• Salient bigrams: Salient bigrams within the ab-stract with high log-likelihood scores, as de-scribed by Pedersen (2001).
• Unigrams: Lemmas of all content words in theabstract and words within a ±4-word windowaround the target word, excluding those in a listof stopwords. In addition, the lemmas of anyunigrams appearing at least twice in the entirecorpus and which are found in the abstract arealso included as features.
Concept Unique Identifiers (CUIs): We followthe approach presented by McInnes et al. (2007) togenerate features based on UMLS Concept UniqueIdentifiers (CUIs). The MetaMap program (Aron-son, 2001) identifies all words and terms in atext which could be mapped onto a UMLS CUI.MetaMap does not disambiguate the senses of theconcepts, instead it enumerates likely candidate con-cepts. For example, MetaMap will segment thephrase “Lean BSA was obtained from height andlean body weight ...” into four chunks: “LeanBSA”, “obtained”, “from height” and “lean bodyweight”. The first chunk will be mapped ontothree CUIs: “C1261466: BSA (Body surface area)”,“C1511233: BSA (NCI Board of Scientific Ad-visors)” and “C0036774: BSA (Serum Albumin,Bovine)”. The chunk “lean body weight” is mappedonto two concepts: “C0005910: Body Weight”
73
and “C1305866: Body Weight (Weighing patient)”1.CUIs occurring more than twice in an abstract are in-cluded as features. CUIs have been used for variousdisambiguation tasks in the biomedical domain, in-cluding disambiguation of ambiguous general terms(McInnes et al., 2007) and gene symbol disambigua-tion (Xu et al., 2007), but not, to our knowledge, forabbreviation disambiguation.
Medical Subject Headings (MeSH): The fi-nal feature is also specific to the biomedical do-main. Medical Subject Headings (MeSH) (Nelsonet al., 2002) is a controlled vocabulary for index-ing biomedical and health-related information anddocuments. MeSH terms are manually assigned toabstracts by human indexers. The latest version ofMeSH (2009) contains over 25,000 terms organisedinto an 11 level hierarchy.
The MeSH terms assigned to the abstract in whicheach ambiguous word occurs are used as features.For example, the abstract containing our examplephrase has been assigned 16 terms including “BodySurface Area”, “Body Weight”, “Humans” and “Or-gan Size” . MeSH terms have previously been usedfor abbreviation disambiguation by Yu et al. (2006).
3.2 Learning Algorithms
We compared three machine leaning algorithmswhich have previously been shown to be effectivefor WSD tasks.
The Vector Space Model (VSM) is a memory-based learning algorithm which was used by Agirreand Marti´nez (2004). Each occurrence of anambiguous word is represented as a binary vec-tor in which each position indicates the occur-rence/absence of a feature. A single centroid vectoris generated for each sense during training. Thesecentroids are compared with the vectors that repre-sent new examples using the cosine metric to com-pute similarity. The sense assigned to a new exampleis that of the closest centroid.
The Naive Bayes (NB) classifier is based on aprobabilistic model which assumes conditional in-dependence of features given the target classifica-tion. It calculates the posterior probability that an
1The first of these, C0005910, refers to the weight ofa patient as a property of that individual while the second,C1305866, refers to the process of weighing a patient as partof a diagnostic procedure.
instance belongs to a particular class given the priorprobabilities of the class and the conditional proba-bility of each feature given the target class.
Support Vector Machines (SVM) have beenwidely used in classification tasks. SVMs mapfeature vectors onto a high dimensional space andconstruct a classifier by searching for the hyper-plane that gives the greatest separation between theclasses.
We used our own implementation of the VectorSpace Model and Weka implementations (Wittenand Frank, 2005) of the other two algorithms.
4 Evaluation Corpus
The most common method for generating corporato train and test WSD systems is to manually an-notate instances of ambiguous terms found in textwith the appropriate meaning. However, this processis both time-consuming and difficult (Artstein andPoesio, 2008). An alternative to manual tagging isto find a way of automatically creating sense taggedcorpora. For the translation of ambiguous Englishwords Ng et al. (2003) made use of the fact that thevarious senses are often translated differently. Forexample when “bank” is used in the ‘financial insti-tution’ sense it is translated to French as “banque”and “bord” when it is used to mean ‘edge of river’.However, a disadvantage of this approach is that itrelies on the existence of parallel text which maynot be available. In the biomedical domain Liu et al.(2001)(2002) created a corpus using unambiguousrelated terms (see Section 2) although they foundthat it was not always possible to identify suitablerelated terms.
4.1 Corpus Creation
Liu et al. (2001) also made use of the fact thatwhen abbreviations are introduced they are often ac-companied by their expansion, for example “BSA(bovine serum albumin)”. This phenomenon wasexploited to automatically generate a corpus of ab-breviations and associated definitions by replacingthe abbreviation and expansion with the abbrevia-tion alone. For example, the sentence “The adsorp-tion behavior of bovine serum albumin (BSA) ona Sepharose based hydrophobic interaction supporthas been studied.” becomes “The adsorption behav-
74
“BSA” AND “body surface area” NOT “bovine serum albumin”“BSA” AND “bovine serum albumin” NOT “body surface area”
Figure 1: Example queries for abbreviation “BSA”
ior of BSA on a Sepharose based hydrophobic inter-action support has been studied.”
We used this approach to create a corpus of sensetagged abbreviations in biomedical documents usinga set of 21 three letter abbreviations used in previ-ous research on abbreviation disambiguation (Liu etal., 2001; Liu et al., 2002; Liu et al., 2004). Pos-sible expansions for the majority of these abbrevi-ations were listed in these papers. For the few re-maining ones possible expansions were taken fromthe Medstract database (Pustejovsky et al., 2002).We searched for instances of these abbreviations inMedline, a database containing more than 18 mil-lion abstracts from publications in biomedicine andthe life sciences. For each abbreviation we queriedMedline, using the Entrez interface, to identify doc-uments containing one of its meanings. For exam-ple the abbreviation “BSA” has two possible expan-sions: “body surface area” and “bovine serum alu-min”. Medline is searched to identify documentsthat contain each possible expansion of the abbre-viation using the queries shown in Figure 1. Eachquery matches documents containing the abbrevia-tion and relevant expansion and no mentions of theother possible expansion(s).
The retrieved documents are then processed toremove the expansions of each abbreviation. TheSchwartz and Hearst (2003) algorithm for identi-fying abbreviations and the relevant expansion (seeSection 2) is then run over each of the retrieved ab-stracts to identify the correct expansion. The expan-sion is removed from the document and stored sep-arately, effectively creating a sense tagged corpus.For convenience the abstracts are converted into aformat similar to the one used for the NLM-WSDcorpus (Weeber et al., 2001).
The resulting corpus consists of 55,655 docu-ments. For each abbreviation Table 1 shows thenumber of abstracts retrieved from Medline (in thecolumn labeled “Abstracts”) and the number of ex-pansions (“Count” column). The column labelled“Rare” lists the number of expansions that account
for fewer than 1% of the occurrences of an abbre-viation and “Frequent” lists the percentage of occu-rances represented by the most frequent expansion.It can be seen that there is a wide variation betweenthe number of abstracts retrieved for each abbrevi-ation. CSF occurs in 14,871 abstracts and ASP injust 71. There is also a wide variation between thefrequency of the most common expansion with over99% of the occurrences of “CSF” representing oneexpansion (“cerebrospinal fluid”) while for “ASP”two of the five possible expansions (“antisocial per-sonality” and “aspartate”) each account for almost34% of the documents. In addition, several abbrevi-ations have expansions which occur only rarely. Forexample, two of the expansions of “APC” (“atrialpressure complexes” and “aphidicholin”) each haveonly a single document and account for just 0.03%of the instances of that abbreviation.
4.2 Corpus Reduction
Given the diversity of the abbreviations which weredownloaded from Medline, both in terms of num-ber of documents and distribution of senses, sub-sets of this corpus that are more suitable for WSDexperiments were created. Corpora containing 100,200 and 300 randomly selected examples of each ab-breviation were generated and these are referred toas Corpus.100, Corpus.200 and Corpus.300 respec-tively.
Some of the 21 abbreviations were not suitablefor inclusion in these corpora. Abbreviations werenot included in the relevant corpus if an insufficientnumber of examples were retrieved from Medline.For example, only 71 abstracts containing “ASP”were retrieved and it is is not included in any of thethree corpora. Similarly, “ANA” and “FDP” are notincluded in Corpus.200 or Corpus.300 and “DIP”not included in Corpus.300. In addition, rare senses,those which represent fewer than 1% of the occur-rences of an abbreviation in all retrieved abstracts,were discarded. Finally, two abbreviations (“ACE”and “CSF”) have only one sense that is not “Rare”
75
ExpansionsAbstracts Count Rare Frequent
ACE 3105 3 2 98.7ANA 100 3 0 58.0APC 3146 5 2 39.4ASP 71 5 0 33.8BPD 1841 3 0 46.7BSA 5373 2 0 86.4CAT 4636 3 1 55.2CML 2234 4 2 91.7CMV 7665 2 0 96.7CSF 14871 3 2 99.1DIP 209 2 0 75.1
EMG 2052 2 0 88.4FDP 130 4 0 78.5LAM 325 4 1 48.3MAC 955 5 1 64.3MCP 815 5 1 50.2PCA 2442 5 1 68.9PCP 1642 2 0 57.8PEG 607 2 0 94.1PVC 234 2 2 78.2RSV 3202 2 0 76.7
Average 2650 3.2 0.6 70.8
Table 1: Properties of abbreviations corpus retrievedfrom Medline
(see Table 1) and these were also excluded from thereduced corpora.
Consequently, Corpus.100 contains 18 abbrevia-tions (“ACE”, “ASP” and “CSF” are excluded), Cor-pus.200 contains 16 (“ANA” and “FDP” are alsoexcluded) and Corpus.300 contains 14 (“DIP” and“PVC” also excluded). Where an abbreviation is in-cluded in more than one corpus, all the examples inthe smaller corpus are included in the larger one(s).For example, the 100 examples of “APC” in Cor-pus.100 are also included in Corpus.200 and Cor-pus.300.
5 Experiments
Various combinations of learning algorithms andfeatures were applied to the three reduced corporadescribed in Section 4.2. Performance of the WSDsystem is measured in terms of the proportion of ab-breviation instances for which the correct expansion
is identified. 10-fold cross validation was used forall experiments and all quoted results refer to the av-erage performance across the 10 folds. Results areshown in Table 2. The baseline figures, based onselecting the most frequent expansion for each ab-breviation, are shown for each corpus. Note thatthese figures vary slightly across the three corporabecause of the different abbreviations each contains(see Section 4.2).
A first observation is that performance of theWSD system is consistently better than the base-line for the relevant corpus and, with a few excep-tions, above 90%. As might be expected, perfor-mance improves as additional training examples areadded. However, even when the number of exam-ples is relatively low, just 100, performance of thebest configuration (VSM learning algorithm with allthree types of feature) is 97.4%.
The best result, 99% (300 training examples,VSM learning algorithm with all feature types), ex-ceeds reported performance of previous abbreviationdisambiguation systems (see Section 2). Althoughthese results are not directly comparable, since thesestudies used different evaluation corpora, the setof ambiguous abbreviations used in this study andmethodology for corpus creation are similar to thoseused by Liu et al. (2001)(2002)(2004).
The best performance for each learning algorithmis obtained when all three types of features are com-bined. The difference between performance ob-tained using all three feature types and using onlythe MeSH or CUI features is statistically significant(Wilcoxon Signed Ranks test, p < 0.01) althoughthe difference between this and performance usingjust the linguistic features is not.
The VSM learning algorithm generally performsbetter than either the SVM or Naive Bayes learningalgorithms. The difference between performance ofVSM and the other algorithms is statistically signif-icant for Corpus.100 but not for the other two, sug-gesting that this learning algorithm is better able tocope with small number of training examples thanNaive Bayes and Support Vector Machines. Strongperformance of the VSM algorithm is consistentwith previous work which has shown that this algo-rithm performs well on the disambiguation of am-biguous terms in both biomedical and general text(Agirre and Marti´nez, 2004; Stevenson et al., 2008).
76
FeaturesAlgorithm Linguistic Linguistic CUI+ Linguistic+Linguistic CUI MeSH
+CUI +MeSH MeSH MeSH+CUICorpus.100 (Baseline = 69.0%)
SVM 0.934 0.900 0.949 0.947 0.946 0.938 0.954NB 0.940 0.917 0.949 0.951 0.947 0.944 0.958
VSM 0.968 0.937 0.888 0.970 0.971 0.939 0.974Corpus.200 (Baseline = 69.1%)
SVM 0.957 0.911 0.964 0.964 0.964 0.947 0.965NB 0.966 0.926 0.962 0.969 0.971 0.955 0.972
VSM 0.979 0.930 0.894 0.982 0.981 0.947 0.984Corpus.300 (Baseline = 68.7%)
SVM 0.966 0.914 0.970 0.968 0.974 0.954 0.975NB 0.971 0.933 0.960 0.971 0.976 0.960 0.978
VSM 0.981 0.938 0.894 0.987 0.985 0.957 0.990
Table 2: Performance of WSD system using various combinations of learning algorithms and features.
Performance of our system on this task is higherthan would be expected for most WSD tasks sug-gesting that the problem of abbreviation disam-biguation is simpler than the disambiguation of gen-eral terms. The most probable reason for this is thatthe various expansions of abbreviations in our cor-pus are more distinct and better defined than sensesfor general terms. For example, the three possi-ble expansions for “ANA” in our corpus are a pro-fessional body (“American Nurses Association”), atype of medical test (“antinuclear”) and a neuro-transmitter (“Anandamide”). It is likely that thesediverse meanings will tend to occur in very differ-ent contexts and in documents with different topics.On the other hand it is widely accepted that distinc-tions between possible meanings of words in natu-ral language are often vague (Kilgarriff, 1993). Itis likely that clearer distinctions between possibleexpansions of abbreviations make the task of iden-tifying the correct one more straightforward thanidentifying meanings of ambiguous words. In ad-dition, the creation of annotated data for WSD is of-ten hampered by the difficulty in obtaining sufficientagreement between annotators (Artstein and Poesio,2008; Weeber et al., 2001) and this problem does notapply to our automatically-generated corpus.
Results in Table 2 indicate that CUIs are use-ful features in the disambiguation of abbreviations.This is in contrast with previous experiments on am-
biguous terms in biomedical documents (Stevensonet al., 2008) in which it was found that the bestperformance as obtained using only linguistic andMeSH features. It is likely that the clear distinctionbetween expansions of abbreviations is the reasonbehind this difference. CUIs are assigned automat-ically by the MetaMap program (Aronson, 2001).However, this assignment is very noisy. It is likelythat the various expansions of abbreviations are dis-tinct enough for this noise to be tolerated by thelearning algorithms while it causes problems whenthe meanings are closer together, such as in the caseof ambiguous terms.
5.1 Performance of Individual Abbreviations
Table 3 shows the performance of the best WSD sys-tem (VSM learning algorithm with all features) foreach abbreviation in the three subsets of our corpus.Our system performs well for all abbreviations. Ac-curacy is no lower than 92% for any abbreviationusing Corpus.100 and no lower than 97% for Cor-pus.300, demonstrating that the approach is robust.In fact, the approach still performs well for abbre-viations with low baseline scores, such as “APC”,“BPD” and “LAM”.
It is interesting to note that the abbreviations withthe lowest performance tend to have expansions thatare closely related. For example, the two expansionsof “EMG” are ‘electromyography’ and ‘electromyo-
77
Corpus100 200 300
ANA 0.980 - -APC 0.980 1.000 1.000BPD 1.000 1.000 1.000BSA 0.970 0.970 0.982CAT 0.990 0.990 1.000
CML 0.960 0.963 0.978CMV 0.970 0.970 0.970
DIP 1.000 1.000 -EMG 0.920 0.960 0.980FDP 0.970 - -
LAM 0.960 0.980 0.980MAC 0.970 0.990 0.989MCP 0.980 0.978 1.000PCA 0.960 0.987 0.992PCP 0.990 1.000 1.000PEG 0.980 0.982 1.000PVC 0.990 1.000 -RSV 0.960 0.972 0.978
Overall 0.974 0.984 0.990
Table 3: Performance of WSD system over individual ab-breviations in three reduced corpora
gram’ while for “LAM” one expansion (‘Lymphan-gioleiomyomatosis’) is a rare lung disease and theother (‘Lipoarabinomannan’) a molecule associatedwith another lung disease (tuberculosis). On theother hand, abbreviations that are more accuratelydisambiguated tend to have expansions with moredistinct meanings. For example, “BPD” can be anacronym for ‘borderline personality disorder’ (a psy-chiatric diagnosis), ‘bronchopulmonary dysplasia’(a lung disease) or ‘biparietal diameter’ (diameter ofa foetus’ head in an ultrasound) and the expansionsof “DIP” are ‘desquamative interstitial pneumonia’(a lung disease) and ‘distal interphalangeal joints’(types of joints in the human hand and foot).
6 Conclusions
This paper has presented an approach to the disam-biguation of ambiguous abbreviations in biomedi-cal documents. We treat this problem as a formof WSD and apply a system that combines a widerrange of features than have been previously applied,including those which are commonly used within
WSD systems in addition to information from twodomain-specific knowledge sources. The approachis evaluated using a corpus of abbreviations auto-matically mined from Medline and found to iden-tify the correct expansion with accuracy of up to99%. This figure is higher than previously reportedresults for abbreviation disambiguation systems, al-though direct comparison is difficult due to the useof different data sets. It was also found that best per-formance could be obtained using a simple machinelearning algorithm and a diverse range of knowledgesources. Performance of our system is higher than isnormally achieved by WSD systems when appliedto general terms and we suggest that the reason forthis is that the various expansions of abbreviationsare better defined and more distinct than the sensesof ambiguous words.
This study has been limited to the disambiguationof abbreviations consisting of exactly three letters.Possibilities for future work include experimentingwith abbreviations of various lengths.
Data
The corpus described in Section 4 has beenmade freely available for research and maybe obtained from http://nlp.shef.ac.uk/BioWSD/downloads/abbreviationdata/.
Acknowledgments
We are grateful to the anonymous reviewers of thispaper for their valuable feedback.
ReferencesE. Adar. 2004. SaRAD: A simple and robust abbrevia-
tion dictionary. Bioinformatics, 20(4):527–533.E. Agirre and D. Marti´nez. 2004. The Basque Coun-
try University system: English and Basque tasks. InRada Mihalcea and Phil Edmonds, editors, Senseval-3: Third International Workshop on the Evaluation ofSystems for the Semantic Analysis of Text, pages 44–48, Barcelona, Spain, July.
A. Aronson. 2001. Effective mapping of biomedical textto the UMLS Metathesaurus: the MetaMap program.In Proceedings of the American Medical InformaticsAssociation (AMIA), pages 17–21.
R. Artstein and M. Poesio. 2008. Inter-coder agreementfor computational linguistics. Computational Linguis-tics, 34(4):555–596.
78
J. Chang, H. Schu¨tze, and R. Altman. 2002. Creating anOnline Dictionary of Abbreviations from MEDLINE.The Journal of the American Medical Informatics As-sociation, 9(6):612–620.
H. Fred and T. Cheng. 1999. Acronymesis: the explod-ing misuse of acronyms. Texas Heart Institute Jour-nal, 30:255–257.
S. Gaudan, H. Kirsch, and D. Rebholz-Schuhmann.2005. Resolving abbreviations to their senses in Med-line. Bioinformatics, 21(18):3658–3664.
M. Joshi, T. Pedersen, and R. Maclin. 2005. A Compara-tive Study of Support Vector Machines Applied to theWord Sense Disambiguation Problem for the MedicalDomain. In Proceedings of the Second Indian Confer-ence on Artificial Intelligence (IICAI-05), pages 3449–3468, Pune, India.
M. Joshi, S. Pakhomov, T. Pedersen, and C. Chute. 2006.A comparative study of supervised learning as appliedto acronym expansion in clinical reports. In Proceed-ings of the Annual Symposium of the American Medi-cal Informatics Association, pages 399–403, Washing-ton, DC.
A. Kilgarriff. 1993. Dictionary word sense distinctions:An enquiry into their nature. Computers and the Hu-manities, 26:356–387.
H. Liu, Y. Lussier, and C. Friedman. 2001. Disam-biguating ambiguous biomedical terms in biomedicalnarrative text: An unsupervised method. Journal ofBiomedical Informatics, 34:249–261.
H. Liu, S. Johnson, and C. Friedman. 2002. Au-tomatic Resolution of Ambiguous Terms Based onMachine Learning and Conceptual Relations in theUMLS. Journal of the American Medical InformaticsAssociation, 9(6):621–636.
H. Liu, V. Teller, and C. Friedman. 2004. A Multi-aspectComparison Study of Supervised Word Sense Disam-biguation. Journal of the American Medical Informat-ics Association, 11(4):320–331.
B. McInnes, T. Pedersen, and J. Carlis. 2007. UsingUMLS Concept Unique Identifiers (CUIs) for WordSense Disambiguation in the Biomedical Domain. InProceedings of the Annual Symposium of the Ameri-can Medical Informatics Association, pages 533–537,Chicago, IL.
R. Mihalcea, T. Chklovski, and A. Kilgarriff. 2004. TheSenseval-3 English lexical sample task. In Proceed-ings of Senseval-3: The Third International Workshopon the Evaluation of Systems for the Semantic Analysisof Text, Barcelona, Spain.
S. Nelson, T. Powell, and B. Humphreys. 2002. TheUnified Medical Language System (UMLS) Project.In Allen Kent and Carolyn M. Hall, editors, Ency-clopedia of Library and Information Science. MarcelDekker, Inc.
H. Ng, B. Wang, and S. Chan. 2003. Exploiting ParallelTexts for Word Sense Disambiguation: an EmpiricalStudy. In Proceedings of the 41st Annual Meeting ofthe Association for Computational Linguistics (ACL-03), pages 455–462, Sapporo, Japan.
N. Okazaki, S. Ananiadou, and J. Tsujii. 2008. A dis-criminative alignment model for abbreviation recogni-tion. In Proceedings of the 22nd International Con-ference on Computational Linguistics (Coling 2008),pages 657–664, Manchester, UK.
S. Pakhomov. 2002. Semi-supervised maximum entropybased approach to acronym and abbreviation normal-ization in medical texts. In Proceedings of the 40thAnnual Meeting of the Association for ComputationalLinguistics, pages 160–167, Philadelphia, PA.
T. Pedersen. 2001. A Decision Tree of Bigrams is anAccurate Predictor of Word Sense. In Proceedingsof the Second Meeting of the North American Chap-ter of the Association for Computational Linguistics(NAACL-01), pages 79–86, Pittsburgh, PA.
J. Pustejovsky, J. Castano, R. Saur, A. Rumshisky,J. Zhang, and W. Luo. 2002. Medstract: CreatingLarge-scale Information Servers for Biomedical Li-braries. In ACL 2002 Workshop on Natural LanguageProcessing in the Biomedical Domain.
A. Schwartz and M. Hearst. 2003. A simple algorithmfor identifying abbreviation definitions in biomedicaltext. In Proceedings of the Pacific Symposium on Bio-computing, Kauai.
M. Stevenson, Y. Guo, R. Gaizauskas, and D. Martinez.2008. Disambiguation of biomedical text using di-verse sources of information. BMC Bioinformatics,9(Suppl 11):S7.
M. Weeber, J. Mork, and A. Aronson. 2001. Developinga Test Collection for Biomedical Word Sense Disam-biguation. In Proceedings of AMAI Symposium, pages746–50, Washington, DC.
I. Witten and E. Frank. 2005. Data Mining: Practicalmachine learning tools and techniques. Morgan Kauf-mann, San Francisco.
H. Xu, J. Fan, G. Hripcsak, E. Mendonc¸a, Markatou M.,and Friedman C. 2007. Gene symbol disambigua-tion using knowledge-based profiles. Bioinformatics,23(8):1015–22.
H. Yu, W. Kim, V. Hatzivassiloglou, and J. Wilbur. 2006.A large scale, corpus-based approach for automati-cally disambigutaing biomedical abbreviations. ACMTransactions on Information Systems, 24(3):380–404.
W. Zhou, I. Vetle, and N. Smalheiser. 2006. ADAM: an-other database of abbreviations in MEDLINE. Bioin-formatics, 22(22):2813–2818.
79
