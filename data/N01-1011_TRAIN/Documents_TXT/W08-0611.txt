Knowledge Sources for Word Sense Disambiguation of Biomedical Text
BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 80–87,Columbus, Ohio, USA, June 2008. c©2008 Association for Computational Linguistics
Knowledge Sources for Word SenseDisambiguation of Biomedical Text
Mark Stevenson, Yikun Guoand Robert Gaizauskas
Department of Computer ScienceUniversity of Sheffield
Regent Court, 211 Portobello StreetSheffield, S1 4DPUnited Kingdom
{inital.surname}@dcs.shef.ac.uk
David MartinezDepartment of Computer Science
& Software EngineeringUniversity of Melbourne
Victoria 3010Australia
davidm@csse.unimelb.edu.au
Abstract
Like text in other domains, biomedical doc-uments contain a range of terms with morethan one possible meaning. These ambigu-ities form a significant obstacle to the auto-matic processing of biomedical texts. Previ-ous approaches to resolving this problem havemade use of a variety of knowledge sources in-cluding linguistic information (from the con-text in which the ambiguous term is used) anddomain-specific resources (such as UMLS). Inthis paper we compare a range of knowledgesources which have been previously used andintroduce a novel one: MeSH terms. The bestperformance is obtained using linguistic fea-tures in combination with MeSH terms. Re-sults from our system outperform publishedresults for previously reported systems on astandard test set (the NLM-WSD corpus).
1 Introduction
The number of documents discussing biomedicalscience is growing at an ever increasing rate, makingit difficult to keep track of recent developments. Au-tomated methods for cataloging, searching and nav-igating these documents would be of great benefitto researchers working in this area, as well as hav-ing potential benefits to medicine and other branchesof science. Lexical ambiguity, the linguistic phe-nomena where a word or phrase has more thanone potential meaning, makes the automatic pro-cessing of text difficult. For example, “cold” hassix possible meanings in the Unified Medical Lan-guage System (UMLS) Metathesaurus (Humphreys
et al., 1998) including “common cold”, “cold sen-sation” and “Chronic Obstructive Airway Disease(COLD)”. The NLM Indexing Initiative (Aronson etal., 2000) attempted to automatically index biomedi-cal journals with concepts from the UMLS Metathe-saurus and concluded that lexical ambiguity was thebiggest challenge in the automation of the indexingprocess. Weeber et al. (2001) analysed MEDLINEabstracts and found that 11.7% of phrases were am-biguous relative to the UMLS Metathesaurus.
Word Sense Disambiguation (WSD) is the pro-cess of resolving lexical ambiguities. Previous re-searchers have used a variety of approaches forWSD of biomedical text. Some of them have takentechniques proven to be effective for WSD of gen-eral text and applied them to ambiguities in thebiomedical domain, while others have created sys-tems using domain-specific biomedical resources.However, there has been no direct comparison ofwhich knowledge sources are the most useful orwhether combining a variety of knowledge sources,a strategy which has been shown to be successful forWSD in the general domain (Stevenson and Wilks,2001), improves results.
This paper compares the effectiveness of a vari-ety of knowledge sources for WSD in the biomed-ical domain. These include features which havebeen commonly used for WSD of general text aswell as information derived from domain-specificresources. One of these features is MeSH terms,which we find to be particularly effective when com-bined with generic features.
The next section provides an overview of variousapproaches to WSD in the biomedical domain. Sec-
80
tion 3 outlines our approach, paying particular atten-tion to the range of knowledge sources used by oursystem. An evaluation of this system is presentedin Section 4. Section 5 summarises this paper andprovides suggestions for future work.
2 Previous Work
WSD has been actively researched since the 1950sand is regarded as an important part of the processof understanding natural language texts.
2.1 The NLM-WSD data set
Research on WSD for general text in the last decadehas been driven by the SemEval evaluation frame-works1 which provide a set of standard evaluationmaterials for a variety of semantic evaluation tasks.At this point there is no specific collection for thebiomedical domain in SemEval, but a test collectionfor WSD in biomedicine was developed by Wee-ber et al. (2001), and has been used as a benchmarkby many independent groups. The UMLS Metathe-saurus was used to provide a set of possible mean-ings for terms in biomedical text. 50 ambiguousterms which occur frequently in MEDLINE werechosen for inclusion in the test set. 100 instancesof each term were selected from citations added tothe MEDLINE database in 1998 and manually dis-ambiguated by 11 annotators. Twelve terms wereflagged as “problematic” due to substantial disagree-ment between the annotators. There are an averageof 2.64 possible meanings per ambiguous term andthe most ambiguous term, “cold” has five possiblemeanings. In addition to the meanings defined inUMLS, annotators had the option of assigning a spe-cial tag (“none”) when none of the UMLS meaningsseemed appropriate.
Various researchers have chosen to evaluate theirsystems against subsets of this data set. Liu et al.(2004) excluded the 12 terms identified as problem-atic by Weeber et al. (2001) in addition to 16 forwhich the majority (most frequent) sense accountedfor more than 90% of the instances, leaving 22 termsagainst which their system was evaluated. Leroy andRindflesch (2005) used a set of 15 terms for whichthe majority sense accounted for less than 65% ofthe instances. Joshi et al. (2005) evaluated against
1http://www.senseval.org
the set union of those two sets, providing 28 am-biguous terms. McInnes et al. (2007) used the setintersection of the two sets (dubbed the “commonsubset”) which contained 9 terms. The terms whichform these various subsets are shown in Figure 1.
The 50 terms which form the NLM-WSD data setrepresent a range of challenges for WSD systems.The Most Frequent Sense (MFS) heuristic has be-come a standard baseline in WSD (McCarthy et al.,2004) and is simply the accuracy which would beobtained by assigning the most common meaning ofa term to all of its instances in a corpus. Despite itssimplicity, the MFS heuristic is a hard baseline tobeat, particularly for unsupervised systems, becauseit uses hand-tagged data to determine which senseis the most frequent. Analysis of the NLM-WSDdata set showed that the MFS over all 50 ambigu-ous terms is 78%. The different subsets have lowerMFS, indicating that the terms they contain are moredifficult to disambiguate. The 22 terms used by (Liuet al., 2004) have a MFS of 69.9% while the setused by (Leroy and Rindflesch, 2005) has an MFSof 55.3%. The union and intersection of these setshave MFS of 66.9% and 54.9% respectively.
adjustmentblood pressureevaluationimmunosuppressionradiationsensitivity
degreegrowthmanmosaicnutrition
colddepressiondischargeextractionfatimplantation
associationconditionculturedeterminationenergy
failurefitfluidfrequencyganglion
glucoseinhibition pressure resistancesecretion
singlestrainssupportsurgerytransient
transportvariation
repairscaleweightwhite
japaneseleadmolepathologyreductionsexultrasound
NLM-WSD data set
Liu et. al. (2004) Leroy and Rindflesch (2005)
Figure 1: The NLM-WSD test set and some of its sub-sets. Note that the test set used by (Joshi et al., 2005)comprises the set union of the terms used by (Liu et al.,2004) and (Leroy and Rindflesch, 2005) while the “com-mon subset” is formed from their intersection.
2.2 WSD of Biomedical Text
A standard approach to WSD is to make use ofsupervised machine learning systems which aretrained on examples of ambiguous words in con-text along with the correct sense for that usage. The
81
models created are then applied to new examples ofthat word to determine the sense being used.
Approaches which are adapted from WSD of gen-eral text include Liu et al. (2004). Their techniqueuses a supervised learning algorithm with a vari-ety of features consisting of a range of collocationsof the ambiguous word and all words in the ab-stract. They compared a variety of supervised ma-chine learning algorithms and found that a decisionlist worked best. Their best system correctly dis-ambiguated 78% the occurrences of 22 ambiguousterms in the NLM-WSD data set (see Section 2.1).
Joshi et al. (2005) also use collocations as featuresand experimented with five supervised learning al-gorithms: Support Vector Machines, Naive Bayes,decision trees, decision lists and boosting. The Sup-port Vector Machine performed scoring 82.5% ona set of 28 words (see Section 2.1) and 84.9% onthe 22 terms used by Liu et al. (2004). Performanceof the Naive Bayes classifier was comparable to theSupport Vector Machine, while the other algorithmswere hampered by the large number of features.
Examples of approaches which have made use ofknowledge sources specific to the biomedical do-main include Leroy and Rindflesch (2005), who re-lied on information from the UMLS Metathesaurusassigned by MetaMap (Aronson, 2001). Their sys-tem used information about whether the ambigu-ous word is the head word of a phrase identified byMetaMap, the ambiguous word’s part of speech, se-mantic relations between the ambiguous words andsurrounding words from UMLS as well as semantictypes of the ambiguous word and surrounding word.Naive Bayes was used as a learning algorithm. Thisapproach correctly disambiguated 65.6% of word in-stances from a set of 15 terms (see Section 2.1).Humphrey et al. (2006) presented an unsupervisedsystem that also used semantic types. They con-structed semantic type vectors for each word froma large collection of MEDLINE abstracts. This al-lowed their method to perform disambiguation at acoarser level, without the need for labeled trainingexamples. In most cases the semantic types can bemapped to the UMLS concepts but not for five of theterms in the NLM-WSD data set. Humphrey et al.(2006) reported 78.6% accuracy over the remaining45. However, their approach could not be appliedto all instances of ambiguous terms and, in particu-
lar, is unable to model the “none” tag. Their systemcould only assign senses to an average of 54% of theinstances of each ambiguous term.
McInnes et al. (2007) made use of ConceptUnique Identifiers (CUIs) from UMLS which arealso assigned by MetaMap. The information con-tained in CUIs is more specific than in the semantictypes applied by Leroy and Rindflesch (2005). Forexample, there are two CUIs for the term “culture”in UMLS: “C0010453: Anthropological Culture”and “C0430400: Laboratory Culture”. The seman-tic type for the first of these is “Idea or Concept” and“Laboratory Procedure” for the second. McInnes etal. (2007) were interested in exploring whether themore specific information contained in CUIs wasmore effective than UMLS semantic types. Theirbest result was reported for a system which repre-sented each sense by all CUIs which occurred atleast twice in the abstract surrounding the ambigu-ous word. They used a Naive Bayes classifier as thelearning algorithm. McInnes et al. (2007) reportedan accuracy of 74.5% on the set of ambiguous termstested by Leroy and Rindflesch (2005) and 80.0% onthe set used by Joshi et al. (2005). They concludedthat CUIs are more useful for WSD than UMLS se-mantic types but that they are not as robust as fea-tures which are known to work in general English,such as unigrams and bigrams.
3 Approach
Our approach is to adapt a state-of-the-art WSD sys-tem to the biomedical domain by augmenting it withadditional domain-specific and domain-independentknowledge sources. Our basic system (Agirre andMarti´nez, 2004) participated in the Senseval-3 chal-lenge (Mihalcea et al., 2004) with a performanceclose to the best system for the English and Basquelexical sample tasks. The system is based on a su-pervised learning approach. The features used byAgirre and Marti´nez (2004) are derived from textaround the ambiguous word and are domain inde-pendent. We refer to these as linguistic features.This feature set has been adapted for the disam-biguation of biomedical text by adding further lin-guistic features and two different types of domain-specific features: CUIs (as used by (McInnes et al.,2007)) and Medical Subject Heading (MeSH) terms.
82
3.1 FeaturesOur feature set contains a number of parameterswhich were set empirically (e.g. threshold for un-igram frequency in the linguistic features). In addi-tion, we use the entire abstract as the context of theambiguous term for relevant features rather than justthe sentence containing the term. Effects of varyingthese parameters are consistent with previous results(Liu et al., 2004; Joshi et al., 2005; McInnes et al.,2007) and are not reported in this paper.
Linguistic features: The system uses a widerange of domain-independent features which arecommonly used for WSD.
• Local collocations: A total of 41 features whichextensively describe the context of the am-biguous word and fall into two main types:(1) bigrams and trigrams containing the am-biguous word constructed from lemmas, wordforms or PoS tags2 and (2) preceding/followinglemma/word-form of the content words (adjec-tive, adverb, noun and verb) in the same sen-tence with the target word. For example, con-sider the sentence below with the target wordadjustment.
“Body surface area adjustments ofinitial heparin dosing...”
The features would include the following: left-content-word-lemma “area adjustment”, right-function-word-lemma “adjustment of ”, left-POS “NN NNS”, right-POS “NNS IN”, left-content-word-form “area adjustments”, right-function-word-form “adjustment of ”, etc.
• Syntactic Dependencies: These features modellonger-distance dependencies of the ambigu-ous words than can be represented by the lo-cal collocations. Five relations are extracted:object, subject, noun-modifier, preposition andsibling. These are identified using heuristic pat-terns and regular expressions applied to PoS tagsequences around the ambiguous word. In theabove example, “heparin” is noun-modifier fea-ture of “adjustment”.
2A maximum-entropy-based part of speech tagger was used(Ratnaparkhi, 1996) without the adaptation to the biomedicaldomain.
• Salient bigrams: Salient bigrams within the ab-stract with high log-likelihood scores, as de-scribed by Pedersen (2001).
• Unigrams: Lemmas of unigrams which appearmore frequently than a predefined threshold inthe entire corpus, excluding those in a list ofstopwords. We empirically set the thresholdto 1. This feature was not used by Agirre andMarti´nez (2004), but Joshi et al. (2005) foundthem to be useful for this task.
Concept Unique Identifiers (CUIs): We followthe approach presented by McInnes et al. (2007) togenerate features based on UMLS Concept UniqueIdentifiers (CUIs). The MetaMap program (Aron-son, 2001) identifies all words and terms in atext which could be mapped onto a UMLS CUI.MetaMap does not disambiguate the senses of theconcepts, instead it enumerates all the possible com-binations of the concept names found. For exam-ple, MetaMap will segment the phrase “Body sur-face area adjustments of initial heparin dosing ...”into two chunks: “Body surface area adjustments”and “of initial heparin dosing”. The first chunkwill be mapped onto four CUIs with the conceptname “Body Surface Area”: “C0005902: Diag-nostic Procedure” and “C1261466: Organism At-tribute” and a further pair with the name “Adjust-ments”: “C0456081: Health Care Activity” and“C0871291: Individual Adjustment”. The final re-sults from MetaMap for the first chunk will be eightcombinations of those concept names, e.g. first fourby second two concept names. CUIs which occurmore than three times in the abstract containing theambiguous word are included as features.
Medical Subject Headings (MeSH): The fi-nal feature is also specific to the biomedical do-main. Medical Subject Headings (MeSH) (Nelsonet al., 2002) is a controlled vocabulary for index-ing biomedical and health-related information anddocuments. MeSH terms are manually assigned toabstracts by human indexers. The latest version ofMeSH contains over 24,000 terms organised into an11 level hierarchy.
The terms assigned to the abstract in whicheach ambiguous word occurs are used as fea-tures. For example, the abstract containing ourexample phrase has been assigned 16 MeSH
83
terms including “M01.060.116.100: Aged”,“M01.060.116.100.080: Aged, 80 and over”,“D27.505.954.502.119: Anticoagulants” and“G09.188.261.560.150: Blood Coagulation”. Toour knowledge MeSH terms have not been pre-viously used as a feature for WSD of biomedicaldocuments.
3.2 Learning Algorithms
We compared three machine leaning algorithmswhich have previously been shown to be effectivefor WSD tasks.
The Vector Space Model is a memory-basedlearning algorithm which was used by (Agirre andMarti´nez, 2004). Each occurrence of an ambiguousword is represented as a binary vector in which eachposition indicates the occurrence/absence of a fea-ture. A single centroid vector is generated for eachsense during training. These centroids are comparedwith the vectors that represent new examples usingthe cosine metric to compute similarity. The senseassigned to a new example is that of the closest cen-troid.
The Naive Bayes classifier is based on a proba-bilistic model which assumes conditional indepen-dence of features given the target classification. Itcalculates the posterior probability that an instancebelongs to a particular class given the prior proba-bilities of the class and the conditional probabilityof each feature given the target class.
Support Vector Machines have been widelyused in classification tasks. SVMs map feature vec-tors onto a high dimensional space and construct aclassifier by searching for the hyperplane that givesthe greatest separation between the classes.
We used our own implementation of the VectorSpace Model and Weka implementations (Wittenand Frank, 2005) of the other two algorithms.
4 Results
This system was applied to the NLM-WSD data set.Experiments were carried out using each of the threetypes of features (linguistic, CUI and MeSH) bothalone and in combination. Ten-fold cross valida-tion was used, and the figures we report are averagedacross all ten runs.
Results from this experiment are shown in Table
1 which lists the performance using combinations oflearning algorithm and features. The figure shownfor each configuration represents the percentage ofinstances of ambiguous terms which are correctlydisambiguated.
These results show that each of the three typesof knowledge (linguistic, CUIs and MeSH) can beused to create a classifier which achieves a reason-able level of disambiguation since performance ex-ceeds the relevant baseline score. This suggests thateach of the knowledge sources can contribute to thedisambiguation of ambiguous terms in biomedicaltext.
The best performance is obtained using a combi-nation of the linguistic and MeSH features, a patternobserved across all test sets and machine learningalgorithms. Although the increase in performancegained from using both the linguistic and MeSHfeatures compared to only the linguistic features ismodest it is statistically significant, as is the differ-ence between using both linguistic and MeSH fea-tures compared with using the MeSH features alone(Wilcoxon Signed Ranks Test, p < 0.01).
Combining MeSH terms with other features gen-erally improves performance, suggesting that theinformation contained in MeSH terms is distinctfrom the other knowledge sources. However, theinclusion of CUIs as features does not always im-prove performance and, in several cases, causes it tofall. This is consistent with McInnes et al. (2007)who concluded that CUIs were a useful informa-tion source for disambiguation of biomedical textbut that they were not as robust as a linguistic knowl-edge source (unigrams) which they had used for aprevious system. The most likely reason for this isthat our approach relies on automatically assignedCUIs, provided by MetaMap, while the MeSH termsare assigned manually. We do not have access to areliable assignment of CUIs to text; if we had WSDwould not be necessary. On the other hand, reli-ably assigned MeSH terms are readily available inMedline. The CUIs assigned by MetaMap are noisywhile the MeSH terms are more reliable and proveto be a more useful knowledge source for WSD.
The Vector Space Model learning algorithm per-forms significantly better than both Support VectorMachine and Naive Bayes (Wilcoxon Signed RanksTest, p < 0.01). This pattern is observed regardless
84
FeaturesCUI+ Linguistic Linguistic Linguistic+Data sets Linguistic CUI MeSHMeSH +MeSH +CUI MeSH+CUI
Vector space modelAll words 87.2 85.8 81.9 86.9 87.8 87.3 87.6
Joshi subset 82.3 79.6 76.6 81.4 83.3 82.4 82.6Leroy subset 77.8 74.4 70.4 75.8 79.0 78.0 77.8
Liu subset 84.3 81.3 78.3 83.4 85.1 84.3 84.5Common subset 79.6 75.1 70.4 76.9 80.8 79.6 79.2
Naive BayesAll words 86.2 81.2 85.7 81.1 86.4 81.4 81.5
Joshi subset 80.6 73.4 80.1 73.3 80.9 73.7 73.8Leroy subset 76.4 66.1 74.6 65.9 76.8 66.3 66.3
Liu subset 81.9 75.4 81.7 75.3 82.2 75.5 75.6Common subset 76.7 66.1 74.7 65.8 77.2 65.9 65.9
Support Vector MachineAll words 85.6 83.5 85.3 84.5 86.1 85.3 85.6
Joshi subset 79.8 76.4 79.5 78.0 80.6 79.1 79.8Leroy subset 75.1 69.7 72.6 72.0 76.3 74.2 74.9
Liu subset 81.3 78.2 81.0 80.0 82.0 80.6 81.2Common subset 75.7 69.8 71.6 73.0 76.8 74.7 75.2
Previous ApproachesMFS Liu et. al. Leroy and Joshi et. McInnes et.
baseline (2004) Rindflesch (2005) al. (2005) al. (2007)All words 78.0 – – – 85.3
Joshi subset 66.9 – – 82.5 80.0Leroy subset 55.3 – 65.5 77.4 74.5
Liu subset 69.9 78.0 – 84.9 82.0Common subset 54.9 – 68.8 79.8 75.7
Table 1: Results from WSD system applied to various sections of the NLM-WSD data set using a variety of fea-tures and machine learning algorithms. Results from baseline and previously published approaches are included forcomparison.
of which set of features are used, and it is consis-tent of the results in Senseval data from (Agirre andMarti´nez, 2004).
4.1 Per-Word Analysis
Table 2 shows the results of our best performing sys-tem (combination of linguistic and MeSH featuresusing the Vector Space Model learning algorithm).Comparable results for previous supervised systemsare also reported where available.3 The MFS base-line for each term is shown in the leftmost column.
The performance of Leroy and Rindflesch’s sys-
3It is not possible to directly compare our results with Liuet al. (2004) or Humphrey et al. (2006). The first report onlyoptimal configuration for each term (combination of feature setsand learning algorithm) while the second do not assign sensesto all of the instances of each ambiguous term (see Section 2).
tem is always lower than the best result for eachword. The systems reported by Joshi et al. (2005)and McInnes et al. (2007) are better than, or thesame as, all other systems for 14 and 12 words re-spectively. The system reported here achieves re-sults equal to or better than previously reported sys-tems for 33 terms.
There are seven terms for which the performanceof our approach is actually lower than the MFS base-line (shown in italics) in Table 2. (In fact, the base-line outperforms all systems for four of these terms.)The performance of our system is within 1% of thebaseline for five of these terms. The remaining pair,“blood pressure” and “failure”, are included in theset of problematic words identified by (Weeber etal., 2001). Examination of the possible senses showthat they include pairs with similar meanings. For
85
MFS Leroy and Joshi et. McInnes et. Reportedbaseline Rindflesch (2005) al. (2005) al. (2007) system
adjustment 62 57 71 70 74association 100 - - 97 100
blood pressure 54 46 53 46 46cold 86 - 90 89 88
condition 90 - - 89 89culture 89 - - 94 95degree 63 68 89 79 95
depression 85 - 86 81 88determination 79 - - 81 87
discharge 74 - 95 96 95energy 99 - - 99 98
evaluation 50 57 69 73 81extraction 82 - 84 86 85
failure 71 - - 73 67fat 71 - 84 77 84fit 82 - - 87 88
fluid 100 - - 99 100frequency 94 - - 94 94ganglion 93 - - 94 96glucose 91 - - 90 91growth 63 62 71 69 68
immunosuppression 59 61 80 75 80implantation 81 - 94 92 93
inhibition 98 - - 98 98japanese 73 - 77 76 75
lead 71 - 89 90 94man 58 80 89 80 90
mole 83 - 95 87 93mosaic 52 66 87 75 87
nutrition 45 48 52 49 54pathology 85 - 85 84 85
pressure 96 - - 93 95radiation 61 72 82 81 84reduction 89 - 91 92 89
repair 52 81 87 93 88resistance 97 - - 96 98
scale 65 84 81 83 88secretion 99 - - 99 99
sensitivity 49 70 88 92 93sex 80 - 88 87 87
single 99 - - 98 99strains 92 - - 92 93
support 90 - - 91 89surgery 98 - - 94 97
transient 99 - - 98 99transport 93 - - 93 93
ultrasound 84 - 92 85 90variation 80 - - 91 95
weight 47 68 83 79 81white 49 62 79 74 76
Table 2: Per-word performance of best reported systems.
example, the two senses which account for 98% ofthe instances of “blood pressure”, which refer to theblood pressure within an organism and the result ob-tained from measuring this quantity, are very closelyrelated semantically.
5 Conclusion
This paper has compared a variety of knowledgesources for WSD of ambiguous biomedical termsand reported results which exceed the performanceof previously published approaches. We found thataccurate results can be achieved using a combina-tion of linguistic features commonly used for WSD
86
of general text and manually assigned MeSH terms.While CUIs are a useful source of information fordisambiguation, they do not improve the perfor-mance of other features when used in combinationwith them. Our approach uses manually assignedMeSH terms while the CUIs are obtained automati-cally using MetaMap.
The linguistic knowledge sources used in this pa-per comprise a wide variety of features includingn-grams and syntactic dependencies. We have notexplored the effectiveness of these individually andthis is a topic for further work.
In addition, our approach does not make use ofthe fact that MeSH terms are organised into a hierar-chy. It would be interesting to discover whether thisinformation could be used to improve WSD perfor-mance. Others have developed techniques to makeuse of hierarchical information in WordNet for WSD(see Budanitsky and Hirst (2006)) which could beadapted to MeSH.
References
E. Agirre and D. Marti´nez. 2004. The Basque Coun-try University system: English and Basque tasks. InRada Mihalcea and Phil Edmonds, editors, Senseval-3: Third International Workshop on the Evaluation ofSystems for the Semantic Analysis of Text, pages 44–48, Barcelona, Spain, July.
A. Aronson, O. Bodenreider, H. Chang, S. Humphrey,J. Mork, S. Nelson, T. Rindflesch, and W. Wilbur.2000. The NLM Indexing Initiative. In Proceedingsof the AMIA Symposium.
A. Aronson. 2001. Effective mapping of biomedical textto the UMLS Metathesaurus: the MetaMap program.In Proceedings of the American Medical InformaticsAssociation (AMIA), pages 17–21.
A. Budanitsky and G. Hirst. 2006. Evaluating WordNet-based measures of semantic distance. ComputationalLinguistics, 32(1):13–47.
S. Humphrey, W. Rogers, H. Kilicoglu, D. Demner-Fushman, and T. Rindflesch. 2006. Word Sense Dis-ambiguation by selecting the best semantic type basedon Journal Descriptor Indexing: Preliminary experi-ment. Journal of the American Society for InformationScience and Technology, 57(5):96–113.
L. Humphreys, D. Lindberg, H. Schoolman, and G. Bar-nett. 1998. The Unified Medical Language System:An Informatics Research Collaboration. Journal of theAmerican Medical Informatics Association, 1(5):1–11.
M. Joshi, T. Pedersen, and R. Maclin. 2005. A Compara-tive Study of Support Vector Machines Applied to theWord Sense Disambiguation Problem for the MedicalDomain. In Proceedings of the Second Indian Confer-ence on Artificial Intelligence (IICAI-05), pages 3449–3468, Pune, India.
G. Leroy and T. Rindflesch. 2005. Effects of Informationand Machine Learning algorithms on Word Sense Dis-ambiguation with small datasets. International Jour-nal of Medical Informatics, 74(7-8):573–585.
H. Liu, V. Teller, and C. Friedman. 2004. A Multi-aspectComparison Study of Supervised Word Sense Disam-biguation. Journal of the American Medical Informat-ics Association, 11(4):320–331.
D. McCarthy, R. Koeling, J. Weeds, and J. Carroll. 2004.Finding predominant senses in untagged text. In Pro-ceedings of the 42nd Annual Meeting of the Associa-tion for Computational Lingusitics (ACL-2004), pages280–287, Barcelona, Spain.
B. McInnes, T. Pedersen, and J. Carlis. 2007. UsingUMLS Concept Unique Identifiers (CUIs) for WordSense Disambiguation in the Biomedical Domain. InProceedings of the Annual Symposium of the Ameri-can Medical Informatics Association, pages 533–537,Chicago, IL.
R. Mihalcea, T. Chklovski, and A. Kilgarriff. 2004. TheSenseval-3 English lexical sample task. In Proceed-ings of Senseval-3: The Third International Workshopon the Evaluation of Systems for the Semantic Analysisof Text, Barcelona, Spain.
S. Nelson, T. Powell, and B. Humphreys. 2002. TheUnified Medical Language System (UMLS) Project.In Allen Kent and Carolyn M. Hall, editors, Ency-clopedia of Library and Information Science. MarcelDekker, Inc.
T. Pedersen. 2001. A Decision Tree of Bigrams is anAccurate Predictor of Word Sense. In Proceedingsof the Second Meeting of the North American Chap-ter of the Association for Computational Linguistics(NAACL-01), pages 79–86, Pittsburgh, PA., June.
A. Ratnaparkhi. 1996. A Maximum Entropy Model forPart-of-Speech Tagging. In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing, pages 133–142.
M. Stevenson and Y. Wilks. 2001. The Interaction ofKnowledge Sources in Word Sense Disambiguation.Computational Linguistics, 27(3):321–350.
M. Weeber, J. Mork, and A. Aronson. 2001. Developinga Test Collection for Biomedical Word Sense Disam-biguation. In Proceedings of AMAI Symposium, pages746–50, Washington, DC.
I. Witten and E. Frank. 2005. Data Mining: Practicalmachine learning tools and techniques. Morgan Kauf-mann, San Francisco.
87
