The Expectation Maximization (EM) algorithm (Dempster  Laird and Rubin 77) is a common approach for unsupervised training; in this section we describe its application to the named entity problem.This modification brings the method closer to the DL-CoTrain algorithm described earlier  and is motivated by the intuition that all three labels should be kept healthily populated in the unlabeled examples  preventing one label from dominating — this deserves more theoretical investigation.For example  in ..  says Mr. Cooper  a vice president of.. both a spelling feature (that the string contains Mr.) and a contextual feature (that president modifies the string) are strong indications that Mr. Cooper is of type Person.A spelling rule might be a simple look-up for the string (e.g.  a rule that Honduras is a location) or a rule that looks at words within a string (e.g.  a rule that any string containing Mr. is a person).The algorithm  called CoBoost  has the advantage of being more general than the decision-list learning alInput: (xi   yi)    (xim  ) ; x  E 2x  yi = +1 Initialize Di (i) = 1/m.(Berland and Charniak 99) describe a method for extracting parts of objects from wholes (e.g.  &quot;speedometer&quot; from &quot;car&quot;) from a large corpus using hand-crafted patterns.(Riloff and Shepherd 97) describe a bootstrapping approach for acquiring nouns in particular categories (such as &quot;vehicle&quot; or &quot;weapon&quot; categories).Following the convention presented in earlier sections  we assume that each example is an instance pair of the from (xi  i  x2 ) where xj   E 2x3   j E 2}.(Blum and Mitchell 98) describe learning in the following situation: X = X1 X X2 where X1 and X2 correspond to two different &quot;views&quot; of an example.The only supervision is in the form of 7 seed rules (namely  that New York  California and U.S. are locations; that any name containing Mr is a person; that any name containing Incorporated is an organization; and that I.B.M. and Microsoft are organizations).(We would like to note though that unlike previous boosting algorithms  the CoBoost algorithm presented here is not a boosting algorithm under Valiant's (Valiant 84) Probably Approximately Correct (PAC) model.)The first method uses a similar algorithm to that of (Yarowsky 95)  with modifications motivated by (Blum and Mitchell 98).Our first algorithm is similar to Yarowsky's  but with some important modifications motivated by (Blum and Mitchell 98).The input to AdaBoost is a set of training examples ((xi   yi)    (x„.„ yrn)).(Brin 98)  describes a system for extracting (author  book-title) pairs from the World Wide Web using an approach that bootstraps from an initial seed set of examples.The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98).(Yarowsky 95) describes an algorithm for word-sense disambiguation that exploits redundancy in contextual features  and gives impressive performance.(Blum and Mitchell 98) offer a promising formulation of redundancy  also prove some results about how the use of unlabeled examples can help classification  and suggest an objective function when training with unlabeled examples.The task can be considered to be one component of the MUC (MUC-6  1995) named entity task (the other task is that of segmentation  i.e.  pulling possible people  places and locations from text before sending them to the classifier).When this feature type was included  CoBoost chose this default feature at an early iteration  thereby giving non-abstaining pseudo-labels for all examples  with eventual convergence to the two classifiers agreeing by assigning the same label to almost all examples.In addition to a heuristic based on decision list learning  we also presented a boosting-like framework that builds on ideas from (Blum and Mitchell 98).(Blum and Mitchell 98) go on to give PAC results for learning in the cotraining case.AdaBoost finds a weighted combination of simple (weak) classifiers  where the weights are chosen to minimize a function that bounds the classification error on a set of training examples.More recently  (Riloff and Jones 99) describe a method they term &quot;mutual bootstrapping&quot; for simultaneously constructing a lexicon and contextual extraction patterns.For example  the independence assumptions mean that the model fails to capture the dependence between specific and more general features (for example the fact that the feature full.-string=New_York is always seen with the features contains (New) and The baseline method tags all entities as the most frequent class type (organization). contains (York) and is never seen with a feature such as contains (Group) ).The model was parameterized such that the joint probability of a (label  feature-set) pair P(yi  xi) is written as The model assumes that (y  x) pairs are generated by an underlying process where the label is first chosen with some prior probability P(yi); the number of features mi is then chosen with some probability P(mi); finally the features are independently generated with probabilities P(xulyi).Using the virtual distribution Di (i) and pseudo-labels&quot;y. „ values for Wo  W± and W_ can be calculated for each possible weak hypothesis (i.e.  for each feature x E Xi); the weak hypothesis with minimal value for Wo + 2/WW _ can be chosen as before; and the weight for this weak hypothesis at = ln ww+411:) can be calculated.