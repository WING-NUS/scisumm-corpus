Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
2,W06-2932,W06-2920,nan,"McDonald et al, 2006",0,"Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)","Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)","['96', '102', '22', '43', '37']","<S sid =""96"" ssid = ""18"">Each stage by itself is relatively accurate (unlabeled accuracy is 79% and labeling accuracy3 is also 79%)  but since there is very little overlap in the kinds of errors each makes  overall labeled accuracy drops to 67%.</S><S sid =""102"" ssid = ""24"">Clearly adding more data is improving performance.</S><S sid =""22"" ssid = ""4"">An exact projective and an approximate non-projective parsing algorithm are presented  since it is shown that nonprojective dependency parsing becomes NP-hard when features are extended beyond a single edge.</S><S sid =""43"" ssid = ""12"">For score functions  we use simple dot products between high dimensional feature representations and a weight vector Assuming we have an appropriate feature representation  we can find the highest scoring label sequence with Viterbi’s algorithm.</S><S sid =""37"" ssid = ""6"">The simplest labeler would be to take as input an edge (i  j) E y for sentence x and find the label with highest score  Doing this for each edge in the tree would produce the final output.</S>",['Method_Citation']
3,W06-2932,W06-2920,0,2006,0,Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),"['96', '68', '56', '51', '93']","<S sid =""96"" ssid = ""18"">Each stage by itself is relatively accurate (unlabeled accuracy is 79% and labeling accuracy3 is also 79%)  but since there is very little overlap in the kinds of errors each makes  overall labeled accuracy drops to 67%.</S><S sid =""68"" ssid = ""6"">Table 2 shows that each component of our system does not change performance significantly (rows 24 versus row 1).</S><S sid =""56"" ssid = ""4"">Results on the test set are given in Table 1.</S><S sid =""51"" ssid = ""20"">Note that many of these features are beyond the scope of the edge based factorizations of the unlabeled parser.</S><S sid =""93"" ssid = ""15"">A quick look at unlabeled attachment accuracies indicate that errors in Arabic parsing are the most common across all languages: prepositions (62%)  conjunctions (69%) and to a lesser extent verbs (73%).</S>",['Method_Citation']
4,W06-2932,W06-2920,0,2006,0,"Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences","Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences","['25', '7', '45', '20', '55']","<S sid =""25"" ssid = ""7"">For instance  the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.</S><S sid =""7"" ssid = ""3"">However  recently their has been a revived interest in parsing models that produce dependency graph representations of sentences  which model words and their arguments through directed edges (Hudson  1984; Mel'ˇcuk  1988).</S><S sid =""45"" ssid = ""14"">Furthermore  it made the system homogeneous in terms of learning algorithms since that is what is used to train our unlabeled parser (McDonald and Pereira  2006).</S><S sid =""20"" ssid = ""2"">This system is primarily based on the parsing models described by McDonald and Pereira (2006).</S><S sid =""55"" ssid = ""3"">Furthermore  for Arabic and Spanish  we used lemmas instead of inflected word forms  again based on performance on held-out data1.</S>",['Method_Citation']
5,W06-2932,W08-1007,0,2006,0,"The high est score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)","The highest score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (and a different policy regarding the inclusion of punctuation). The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)","['18', '41', '13', '54', '76']","<S sid =""18"" ssid = ""14"">We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X)  pages 216–220  New York City  June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective  both of which are true in the data sets we use.</S><S sid =""41"" ssid = ""10"">To model this we treat the labeling of the edges (i  j1)  ...   (i  jM) as a sequence labeling problem  We use a first-order Markov factorization of the score s(l(i jm)  l(i jm�1)  i  y  x) in which each factor is the score of labeling the adjacent edges (i  jm) and (i  jm−1) in the tree y.</S><S sid =""13"" ssid = ""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al.  2006; Hajiˇc et al.  2004; Simov et al.  2005; Simov and Osenova  2003; Chen et al.  2003; B¨ohmov´a et al.  2003; Kromann  2003; van der Beek et al.  2002; Brants et al.  2002; Kawata and Bartels  2000; Afonso et al.  2002; Dˇzeroski et al.  2006; Civit Torruella and MartiAntonin  2002; Nilsson et al.  2005; Oflazer et al.  2003; Atalay et al.  2003).</S><S sid =""54"" ssid = ""2"">Based on performance from a held-out section of the training data  we used non-projective parsing algorithms for Czech  Danish  Dutch  German  Japanese  Portuguese and Slovene  and projective parsing algorithms for Arabic  Bulgarian  Chinese  Spanish  Swedish and Turkish.</S><S sid =""76"" ssid = ""14"">For instance  sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S>",['Method_Citation']
6,W06-2932,W09-1210,0,2006,nan,McDonald et al (2006) use an additional algorithm,McDonald et al (2006) use an additional algorithm,"['9', '20', '45', '60', '42']","<S sid =""9"" ssid = ""5"">Nivre (2005) gives an introduction to dependency representations of sentences and recent developments in dependency parsing strategies.</S><S sid =""20"" ssid = ""2"">This system is primarily based on the parsing models described by McDonald and Pereira (2006).</S><S sid =""45"" ssid = ""14"">Furthermore  it made the system homogeneous in terms of learning algorithms since that is what is used to train our unlabeled parser (McDonald and Pereira  2006).</S><S sid =""60"" ssid = ""8"">Furthermore  these results show that a twostage system can achieve a relatively high performance.</S><S sid =""42"" ssid = ""11"">We attempted higher-order Markov factorizations but they did not improve performance uniformly across languages and training became significantly slower.</S>",['Method_Citation']
7,W06-2932,W12-3407,0,"McDonald et al, 2006",0,"Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)","Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)","['18', '13', '54', '41', '76']","<S sid =""18"" ssid = ""14"">We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X)  pages 216–220  New York City  June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective  both of which are true in the data sets we use.</S><S sid =""13"" ssid = ""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al.  2006; Hajiˇc et al.  2004; Simov et al.  2005; Simov and Osenova  2003; Chen et al.  2003; B¨ohmov´a et al.  2003; Kromann  2003; van der Beek et al.  2002; Brants et al.  2002; Kawata and Bartels  2000; Afonso et al.  2002; Dˇzeroski et al.  2006; Civit Torruella and MartiAntonin  2002; Nilsson et al.  2005; Oflazer et al.  2003; Atalay et al.  2003).</S><S sid =""54"" ssid = ""2"">Based on performance from a held-out section of the training data  we used non-projective parsing algorithms for Czech  Danish  Dutch  German  Japanese  Portuguese and Slovene  and projective parsing algorithms for Arabic  Bulgarian  Chinese  Spanish  Swedish and Turkish.</S><S sid =""41"" ssid = ""10"">To model this we treat the labeling of the edges (i  j1)  ...   (i  jM) as a sequence labeling problem  We use a first-order Markov factorization of the score s(l(i jm)  l(i jm�1)  i  y  x) in which each factor is the score of labeling the adjacent edges (i  jm) and (i  jm−1) in the tree y.</S><S sid =""76"" ssid = ""14"">For instance  sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S>",['Method_Citation']
8,W06-2932,I08-1012,0,"McDonald et al, 2006",0,"In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)? s parser, (McDonald et al., 2006)? s parser, and so on","In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)'s parser, (McDonald et al., 2006)'s parser, and so on","['25', '61', '75', '92', '12']","<S sid =""25"" ssid = ""7"">For instance  the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.</S><S sid =""61"" ssid = ""9"">In fact  for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).</S><S sid =""75"" ssid = ""13"">This is not surprising since these edge labels typically are the most correlated (i.e.  if you already know which noun dependent is the subject  then it should be easy to find the object).</S><S sid =""92"" ssid = ""14"">For example  in the test sentence Lo que decia Mae West de si misma podriamos decirlo tambi´en los hombres:...  decia’s head is given as decirlo  although the main verbs of relative clauses are normally dependent on what the relative modifies  in this case the article Lo.</S><S sid =""12"" ssid = ""8"">In this paper we describe a two-stage discriminative parsing approach consisting of an unlabeled parser and a subsequent edge labeler.</S>",['Method_Citation']
11,W06-2932,N07-1050,0,"McDonald et al, 2006",0,"We have shown that, for languages with a7McDonald et al (2006) use post-processing for non projective dependencies and for labeling",McDonald et al (2006) use post-processing for non-projective dependencies and for labeling,"['20', '9', '7', '25', '42']","<S sid =""20"" ssid = ""2"">This system is primarily based on the parsing models described by McDonald and Pereira (2006).</S><S sid =""9"" ssid = ""5"">Nivre (2005) gives an introduction to dependency representations of sentences and recent developments in dependency parsing strategies.</S><S sid =""7"" ssid = ""3"">However  recently their has been a revived interest in parsing models that produce dependency graph representations of sentences  which model words and their arguments through directed edges (Hudson  1984; Mel'ˇcuk  1988).</S><S sid =""25"" ssid = ""7"">For instance  the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.</S><S sid =""42"" ssid = ""11"">We attempted higher-order Markov factorizations but they did not improve performance uniformly across languages and training became significantly slower.</S>",['Method_Citation']
12,W06-2932,D07-1122,0,"McDonald et al, 2006",0,"As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem","As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem","['25', '40', '51', '20', '45']","<S sid =""25"" ssid = ""7"">For instance  the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.</S><S sid =""40"" ssid = ""9"">For instance  if we consider a head xi with dependents xj1  ...   xjM  it is often the case that many of these dependencies will have correlated labels.</S><S sid =""51"" ssid = ""20"">Note that many of these features are beyond the scope of the edge based factorizations of the unlabeled parser.</S><S sid =""20"" ssid = ""2"">This system is primarily based on the parsing models described by McDonald and Pereira (2006).</S><S sid =""45"" ssid = ""14"">Furthermore  it made the system homogeneous in terms of learning algorithms since that is what is used to train our unlabeled parser (McDonald and Pereira  2006).</S>",['Results_Citation']
14,W06-2932,D07-1015,0,2006,0,5It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,"['25', '20', '45', '55', '75']","<S sid =""25"" ssid = ""7"">For instance  the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.</S><S sid =""20"" ssid = ""2"">This system is primarily based on the parsing models described by McDonald and Pereira (2006).</S><S sid =""45"" ssid = ""14"">Furthermore  it made the system homogeneous in terms of learning algorithms since that is what is used to train our unlabeled parser (McDonald and Pereira  2006).</S><S sid =""55"" ssid = ""3"">Furthermore  for Arabic and Spanish  we used lemmas instead of inflected word forms  again based on performance on held-out data1.</S><S sid =""75"" ssid = ""13"">This is not surprising since these edge labels typically are the most correlated (i.e.  if you already know which noun dependent is the subject  then it should be easy to find the object).</S>",['Method_Citation']
18,W06-2932,D10-1004,0,2006,0,"Entries marked with? are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)","Entries marked with are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)","['13', '18', '54', '41', '76']","<S sid =""13"" ssid = ""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al.  2006; Hajiˇc et al.  2004; Simov et al.  2005; Simov and Osenova  2003; Chen et al.  2003; B¨ohmov´a et al.  2003; Kromann  2003; van der Beek et al.  2002; Brants et al.  2002; Kawata and Bartels  2000; Afonso et al.  2002; Dˇzeroski et al.  2006; Civit Torruella and MartiAntonin  2002; Nilsson et al.  2005; Oflazer et al.  2003; Atalay et al.  2003).</S><S sid =""18"" ssid = ""14"">We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X)  pages 216–220  New York City  June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective  both of which are true in the data sets we use.</S><S sid =""54"" ssid = ""2"">Based on performance from a held-out section of the training data  we used non-projective parsing algorithms for Czech  Danish  Dutch  German  Japanese  Portuguese and Slovene  and projective parsing algorithms for Arabic  Bulgarian  Chinese  Spanish  Swedish and Turkish.</S><S sid =""41"" ssid = ""10"">To model this we treat the labeling of the edges (i  j1)  ...   (i  jM) as a sequence labeling problem  We use a first-order Markov factorization of the score s(l(i jm)  l(i jm�1)  i  y  x) in which each factor is the score of labeling the adjacent edges (i  jm) and (i  jm−1) in the tree y.</S><S sid =""76"" ssid = ""14"">For instance  sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S>",['Method_Citation']
19,W06-2932,P08-1108,0,"McDonald et al, 2006",0,"The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.2 2.3 Transition-Based Models","The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.","['18', '41', '76', '54', '92']","<S sid =""18"" ssid = ""14"">We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X)  pages 216–220  New York City  June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective  both of which are true in the data sets we use.</S><S sid =""41"" ssid = ""10"">To model this we treat the labeling of the edges (i  j1)  ...   (i  jM) as a sequence labeling problem  We use a first-order Markov factorization of the score s(l(i jm)  l(i jm�1)  i  y  x) in which each factor is the score of labeling the adjacent edges (i  jm) and (i  jm−1) in the tree y.</S><S sid =""76"" ssid = ""14"">For instance  sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S><S sid =""54"" ssid = ""2"">Based on performance from a held-out section of the training data  we used non-projective parsing algorithms for Czech  Danish  Dutch  German  Japanese  Portuguese and Slovene  and projective parsing algorithms for Arabic  Bulgarian  Chinese  Spanish  Swedish and Turkish.</S><S sid =""92"" ssid = ""14"">For example  in the test sentence Lo que decia Mae West de si misma podriamos decirlo tambi´en los hombres:...  decia’s head is given as decirlo  although the main verbs of relative clauses are normally dependent on what the relative modifies  in this case the article Lo.</S>",['Method_Citation']
20,W06-2932,P08-1108,0,"McDonald et al, 2006",0,"More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? Rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)","More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l) Rk, where f is typically a binary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)","['76', '92', '25', '104', '40']","<S sid =""76"" ssid = ""14"">For instance  sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.</S><S sid =""92"" ssid = ""14"">For example  in the test sentence Lo que decia Mae West de si misma podriamos decirlo tambi´en los hombres:...  decia’s head is given as decirlo  although the main verbs of relative clauses are normally dependent on what the relative modifies  in this case the article Lo.</S><S sid =""25"" ssid = ""7"">For instance  the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.</S><S sid =""104"" ssid = ""1"">We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al.  2005b; McDonald and Pereira  2006) generalizes well to languages other than English.</S><S sid =""40"" ssid = ""9"">For instance  if we consider a head xi with dependents xj1  ...   xjM  it is often the case that many of these dependencies will have correlated labels.</S>",['Method_Citation']
