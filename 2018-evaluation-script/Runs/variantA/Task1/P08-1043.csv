Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P08-1043,C10-1045,0,2008,0,"Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew","Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew","['65', '173', '94', '97', '14']","<S sid =""65"" ssid = ""12"">A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad  2006) and Arabic (Smith et al.  2005) present similar models.</S><S sid =""173"" ssid = ""11"">The addition of vertical markovization enables non-pruned models to outperform all previously reported re12Cohen and Smith (2007) make use of a parameter (α) which is tuned separately for each of the tasks.</S><S sid =""94"" ssid = ""26"">Our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the PCFG derivations.</S><S sid =""97"" ssid = ""29"">Thus our proposed model is a proper model assigning probability mass to all (7r  L) pairs  where 7r is a parse tree and L is the one and only lattice that a sequence of characters (and spaces) W over our alpha-beth gives rise to.</S><S sid =""14"" ssid = ""10"">The input for the segmentation task is however highly ambiguous for Semitic languages  and surface forms (tokens) may admit multiple possible analyses as in (BarHaim et al.  2007; Adler and Elhadad  2006).</S>",['Method_Citation']
2,P08-1043,P11-1141,0,2008,0,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,"['18', '52', '49', '47', '53']","<S sid =""18"" ssid = ""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid =""52"" ssid = ""10"">Cohen and Smith (2007) later on based a system for joint inference on factored  independent  morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid =""49"" ssid = ""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid =""47"" ssid = ""5"">Sima’an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid =""53"" ssid = ""11"">Both (Tsarfaty  2006; Cohen and Smith  2007) have shown that a single integrated framework outperforms a completely streamlined implementation  yet neither has shown a single generative model which handles both tasks.</S>",['Method_Citation']
3,P08-1043,P10-1074,0,2008,0,"Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMMbased approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of He brew, based on lattice parsing","Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMM-based approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of Hebrew, based on lattice parsing","['45', '156', '95', '21', '146']","<S sid =""45"" ssid = ""3"">Morphological disambiguators that consider a token in context (an utterance) and propose the most likely morphological analysis of an utterance (including segmentation) were presented by Bar-Haim et al. (2005)  Adler and Elhadad (2006)  Shacham and Wintner (2007)  and achieved good results (the best segmentation result so far is around 98%).</S><S sid =""156"" ssid = ""34"">To evaluate the performance on the segmentation task  we report SEG  the standard harmonic means for segmentation Precision and Recall F1 (as defined in Bar-Haim et al. (2005); Tsarfaty (2006)) as well as the segmentation accuracy SEGTok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by Cohen and Smith (2007)).</S><S sid =""95"" ssid = ""27"">A compatible view is presented by Charniak et al. (1996) who consider the kind of probabilities a generative parser should get from a PoS tagger  and concludes that these should be P(w|t) “and nothing fancier”.3 In our setting  therefore  the Lattice is not used to induce a probability distribution on a linear context  but rather  it is used as a common-denominator of state-indexation of all segmentations possibilities of a surface form.</S><S sid =""21"" ssid = ""17"">Morphological segmentation decisions in our model are delegated to a lexeme-based PCFG and we show that using a simple treebank grammar  a data-driven lexicon  and a linguistically motivated unknown-tokens handling our model outperforms (Tsarfaty  2006) and (Cohen and Smith  2007) on the joint task and achieves state-of-the-art results on a par with current respective standalone models.2</S><S sid =""146"" ssid = ""24"">Given a PCFG grammar G and a lattice L with nodes n1 ... nk  we construct the weighted grammar GL as follows: for every arc (lexeme) l E L from node ni to node nj  we add to GL the rule [l --+ tni  tni+1  ...   tnj_1] with a probability of 1 (this indicates the lexeme l spans from node ni to node nj).</S>",['Method_Citation']
4,P08-1043,P11-1089,0,2008,0,Goldberg and Tsarfaty (2008) pro pose a generative joint model,Goldberg and Tsarfaty (2008) propose a generative joint model,"['18', '52', '49', '48', '47']","<S sid =""18"" ssid = ""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid =""52"" ssid = ""10"">Cohen and Smith (2007) later on based a system for joint inference on factored  independent  morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid =""49"" ssid = ""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid =""48"" ssid = ""6"">Tsarfaty (2006) was the first to demonstrate that fully automatic Hebrew parsing is feasible using the newly available 5000 sentences treebank.</S><S sid =""47"" ssid = ""5"">Sima’an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S>",['Method_Citation']
5,P08-1043,W10-1404,0,2008,0,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,"['18', '47', '17', '52', '49']","<S sid =""18"" ssid = ""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid =""47"" ssid = ""5"">Sima’an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid =""17"" ssid = ""13"">Tsarfaty (2006) argues that for Semitic languages determining the correct morphological segmentation is dependent on syntactic context and shows that increasing information sharing between the morphological and the syntactic components leads to improved performance on the joint task.</S><S sid =""52"" ssid = ""10"">Cohen and Smith (2007) later on based a system for joint inference on factored  independent  morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid =""49"" ssid = ""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S>",['Method_Citation']
6,P08-1043,P11-2124,0,2008,0,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrewtext,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrew text,"['18', '52', '47', '48', '53']","<S sid =""18"" ssid = ""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid =""52"" ssid = ""10"">Cohen and Smith (2007) later on based a system for joint inference on factored  independent  morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid =""47"" ssid = ""5"">Sima’an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid =""48"" ssid = ""6"">Tsarfaty (2006) was the first to demonstrate that fully automatic Hebrew parsing is feasible using the newly available 5000 sentences treebank.</S><S sid =""53"" ssid = ""11"">Both (Tsarfaty  2006; Cohen and Smith  2007) have shown that a single integrated framework outperforms a completely streamlined implementation  yet neither has shown a single generative model which handles both tasks.</S>",['Method_Citation']
7,P08-1043,P11-2124,0,"Goldberg and Tsarfaty, 2008",0,"Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","['144', '136', '7', '14', '153']","<S sid =""144"" ssid = ""22"">In our second model GTvpi we also distinguished finite and non-finite verbs and VPs as 10Lattice parsing can be performed by special initialization of the chart in a CKY parser (Chappelier et al.  1999).</S><S sid =""136"" ssid = ""14"">Lexicon and OOV Handling Our data-driven morphological-analyzer proposes analyses for unknown tokens as described in Section 5.</S><S sid =""7"" ssid = ""3"">In Modern Hebrew (Hebrew)  a Semitic language with very rich morphology  particles marking conjunctions  prepositions  complementizers and relativizers are bound elements prefixed to the word (Glinert  1989).</S><S sid =""14"" ssid = ""10"">The input for the segmentation task is however highly ambiguous for Semitic languages  and surface forms (tokens) may admit multiple possible analyses as in (BarHaim et al.  2007; Adler and Elhadad  2006).</S><S sid =""153"" ssid = ""31"">Finally  model GTv = 2 includes parent annotation on top of the various state-splits  as is done also in (Tsarfaty and Sima’an  2007; Cohen and Smith  2007).</S>",['Method_Citation']
8,P08-1043,P12-2002,0,2008,0,2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),"['92', '65', '14', '190', '126']","<S sid =""92"" ssid = ""24"">This is akin to PoS tags sequences induced by different parses in the setup familiar from English and explored in e.g.</S><S sid =""65"" ssid = ""12"">A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad  2006) and Arabic (Smith et al.  2005) present similar models.</S><S sid =""14"" ssid = ""10"">The input for the segmentation task is however highly ambiguous for Semitic languages  and surface forms (tokens) may admit multiple possible analyses as in (BarHaim et al.  2007; Adler and Elhadad  2006).</S><S sid =""190"" ssid = ""4"">We conjecture that this trend may continue by incorporating additional information  e.g.  three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S><S sid =""126"" ssid = ""4"">When a comparison against previous results requires additional pre-processing  we state it explicitly to allow for the reader to replicate the reported results.</S>",['Method_Citation']
9,P08-1043,D12-1046,0,"Goldberg and Tsarfaty, 2008",0,"A study that is closely related toours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","A study that is closely related to ours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","['65', '14', '33', '17', '190']","<S sid =""65"" ssid = ""12"">A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad  2006) and Arabic (Smith et al.  2005) present similar models.</S><S sid =""14"" ssid = ""10"">The input for the segmentation task is however highly ambiguous for Semitic languages  and surface forms (tokens) may admit multiple possible analyses as in (BarHaim et al.  2007; Adler and Elhadad  2006).</S><S sid =""33"" ssid = ""12"">The current work treats both segmental and super-segmental phenomena  yet we note that there may be more adequate ways to treat supersegmental phenomena assuming Word-Based morphology as we explore in (Tsarfaty and Goldberg  2008).</S><S sid =""17"" ssid = ""13"">Tsarfaty (2006) argues that for Semitic languages determining the correct morphological segmentation is dependent on syntactic context and shows that increasing information sharing between the morphological and the syntactic components leads to improved performance on the joint task.</S><S sid =""190"" ssid = ""4"">We conjecture that this trend may continue by incorporating additional information  e.g.  three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S>",['Results_Citation']
10,P08-1043,D12-1133,0,2008,0,"Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","['43', '71', '65', '134', '127']","<S sid =""43"" ssid = ""1"">Morphological analyzers for Hebrew that analyze a surface form in isolation have been proposed by Segal (2000)  Yona and Wintner (2005)  and recently by the knowledge center for processing Hebrew (Itai et al.  2006).</S><S sid =""71"" ssid = ""3"">This is by now a fairly standard representation for multiple morphological segmentation of Hebrew utterances (Adler  2001; Bar-Haim et al.  2005; Smith et al.  2005; Cohen and Smith  2007; Adler  2007).</S><S sid =""65"" ssid = ""12"">A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad  2006) and Arabic (Smith et al.  2005) present similar models.</S><S sid =""134"" ssid = ""12"">Such resources exist for Hebrew (Itai et al.  2006)  but unfortunately use a tagging scheme which is incompatible with the one of the Hebrew Treebank.s For this reason  we use a data-driven morphological analyzer derived from the training data similar to (Cohen and Smith  2007).</S><S sid =""127"" ssid = ""5"">Data We use the Hebrew Treebank  (Sima’an et al.  2001)  provided by the knowledge center for processing Hebrew  in which sentences from the daily newspaper “Ha’aretz” are morphologically segmented and syntactically annotated.</S>",['Method_Citation']
11,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008) (Sec","Parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008)","['92', '25', '111', '179', '140']","<S sid =""92"" ssid = ""24"">This is akin to PoS tags sequences induced by different parses in the setup familiar from English and explored in e.g.</S><S sid =""25"" ssid = ""4"">While the linear precedence of segmental morphemes within a token is subject to constraints  the dominance relations among their mother and sister constituents is rather free.</S><S sid =""111"" ssid = ""43"">Our smoothing procedure takes into account all the aforementioned aspects and works as follows.</S><S sid =""179"" ssid = ""17"">On the surface  our model may seem as a special case of Cohen and Smith in which α = 0.</S><S sid =""140"" ssid = ""18"">For these models we limit the options provided for OOV words by not considering the entire token as a valid segmentation in case at least some prefix segmentation exists.</S>",['Method_Citation']
12,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","['92', '179', '65', '190', '14']","<S sid =""92"" ssid = ""24"">This is akin to PoS tags sequences induced by different parses in the setup familiar from English and explored in e.g.</S><S sid =""179"" ssid = ""17"">On the surface  our model may seem as a special case of Cohen and Smith in which α = 0.</S><S sid =""65"" ssid = ""12"">A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad  2006) and Arabic (Smith et al.  2005) present similar models.</S><S sid =""190"" ssid = ""4"">We conjecture that this trend may continue by incorporating additional information  e.g.  three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S><S sid =""14"" ssid = ""10"">The input for the segmentation task is however highly ambiguous for Semitic languages  and surface forms (tokens) may admit multiple possible analyses as in (BarHaim et al.  2007; Adler and Elhadad  2006).</S>",['Method_Citation']
14,P08-1043,E09-1038,0,2008,0,"Several studies followed this line, (Cohen and Smith, 2007) the most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","The most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","['160', '52', '33', '190', '14']","<S sid =""160"" ssid = ""38"">We further report SYNCS  the parsing metric of Cohen and Smith (2007)  to facilitate the comparison.</S><S sid =""52"" ssid = ""10"">Cohen and Smith (2007) later on based a system for joint inference on factored  independent  morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid =""33"" ssid = ""12"">The current work treats both segmental and super-segmental phenomena  yet we note that there may be more adequate ways to treat supersegmental phenomena assuming Word-Based morphology as we explore in (Tsarfaty and Goldberg  2008).</S><S sid =""190"" ssid = ""4"">We conjecture that this trend may continue by incorporating additional information  e.g.  three-dimensional models as proposed by Tsarfaty and Sima’an (2007).</S><S sid =""14"" ssid = ""10"">The input for the segmentation task is however highly ambiguous for Semitic languages  and surface forms (tokens) may admit multiple possible analyses as in (BarHaim et al.  2007; Adler and Elhadad  2006).</S>",['Method_Citation']
15,P08-1043,E09-1038,0,2008,0,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,"['18', '52', '47', '49', '183']","<S sid =""18"" ssid = ""14"">Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.</S><S sid =""52"" ssid = ""10"">Cohen and Smith (2007) later on based a system for joint inference on factored  independent  morphological and syntactic components of which scores are combined to cater for the joint inference task.</S><S sid =""47"" ssid = ""5"">Sima’an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.</S><S sid =""49"" ssid = ""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid =""183"" ssid = ""21"">Cohen and Smith approach this by introducing the α hyperparameter  which performs best when optimized independently for each sentence (cf.</S>",['Method_Citation']
16,P08-1043,E09-1038,0,2008,0,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,"['136', '160', '191', '83', '43']","<S sid =""136"" ssid = ""14"">Lexicon and OOV Handling Our data-driven morphological-analyzer proposes analyses for unknown tokens as described in Section 5.</S><S sid =""160"" ssid = ""38"">We further report SYNCS  the parsing metric of Cohen and Smith (2007)  to facilitate the comparison.</S><S sid =""191"" ssid = ""5"">In the current work morphological analyses and lexical probabilities are derived from a small Treebank  which is by no means the best way to go.</S><S sid =""83"" ssid = ""15"">Each token may admit multiple analyses  each of which a sequence of one or more lexemes (we use li to denote a lexeme) belonging a presupposed Hebrew lexicon LEX.</S><S sid =""43"" ssid = ""1"">Morphological analyzers for Hebrew that analyze a surface form in isolation have been proposed by Segal (2000)  Yona and Wintner (2005)  and recently by the knowledge center for processing Hebrew (Itai et al.  2006).</S>",['Method_Citation']
17,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units","Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parseval to use characters instead of space-delimited tokens as its basic units","['97', '144', '65', '164', '173']","<S sid =""97"" ssid = ""29"">Thus our proposed model is a proper model assigning probability mass to all (7r  L) pairs  where 7r is a parse tree and L is the one and only lattice that a sequence of characters (and spaces) W over our alpha-beth gives rise to.</S><S sid =""144"" ssid = ""22"">In our second model GTvpi we also distinguished finite and non-finite verbs and VPs as 10Lattice parsing can be performed by special initialization of the chart in a CKY parser (Chappelier et al.  1999).</S><S sid =""65"" ssid = ""12"">A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad  2006) and Arabic (Smith et al.  2005) present similar models.</S><S sid =""164"" ssid = ""2"">In addition we report for each model its performance on goldsegmented input (GS) to indicate the upper bound 11Overt definiteness errors may be seen as a wrong feature rather than as wrong constituent and it is by now an accepted standard to report accuracy with and without such errors. for the grammars’ performance on the parsing task.</S><S sid =""173"" ssid = ""11"">The addition of vertical markovization enables non-pruned models to outperform all previously reported re12Cohen and Smith (2007) make use of a parameter (α) which is tuned separately for each of the tasks.</S>",['Method_Citation']
