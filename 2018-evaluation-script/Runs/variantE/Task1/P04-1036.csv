Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)","['8', '123', '14', '115', '12']","<S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid =""123"" ssid = ""21"">This demonstrates that our method of providing a first sense from raw text will help when sense-tagged data is not available.</S><S sid =""14"" ssid = ""7"">Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al.  2001).</S><S sid =""115"" ssid = ""13"">Our automatically acquired predominant sense performs nearly as well as the first sense provided by SemCor  which is very encouraging given that our method only uses raw text  with no manual labelling.</S><S sid =""12"" ssid = ""5"">The figure distinguishes systems which make use of hand-tagged data (using HTD) such as SemCor  from those that do not (without HTD).</S>",['Results_Citation']
2,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available","['15', '105', '165', '145', '155']","<S sid =""15"" ssid = ""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful  there is a strong case for obtaining a first  or predominant  sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid =""105"" ssid = ""3"">We use an allwords task because the predominant senses will reflect the sense distributions of all nouns within the documents  rather than a lexical sample task  where the target words are manually determined and the results will depend on the skew of the words in the sample.</S><S sid =""165"" ssid = ""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus  whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid =""145"" ssid = ""22"">It is not always intuitively clear which of the senses to expect as predominant sense for either a particular domain or for the BNC  but the first senses of words like division and goal shift towards the more specific senses (league and score respectively).</S><S sid =""155"" ssid = ""3"">A major benefit of our work  rather than reliance on hand-tagged training data such as SemCor  is that this method permits us to produce predominant senses for the domain and text type required.</S>",['Method_Citation']
3,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The method is described in (McCarthy et al, 2004), which we summarise here","The method is described in (McCarthy et al, 2004), which we summarise here","['100', '174', '34', '133', '7']","<S sid =""100"" ssid = ""29"">In the English all-words SENSEVAL-2  25% of the noun data was monosemous.</S><S sid =""174"" ssid = ""22"">We have restricted ourselves to nouns in this work  since this PoS is perhaps most affected by domain.</S><S sid =""34"" ssid = ""27"">In these each target word is entered with an ordered list of “nearest neighbours”.</S><S sid =""133"" ssid = ""10"">We acquired thesauruses for these corpora using the procedure described in section 2.1.</S><S sid =""7"" ssid = ""7"">Furthermore  we demonstrate that our method discovers appropriate predominant senses for words from two domainspecific corpora.</S>",['Method_Citation']
5,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges",McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD,"['44', '50', '70', '61', '71']","<S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S><S sid =""50"" ssid = ""6"">For input we used grammatical relation data extracted using an automatic where: .</S><S sid =""70"" ssid = ""26"">Jiang and Conrath specify a distance measure:   where the third class ( ) is the most informative  or most specific  superordinate synset of the two senses and .</S><S sid =""61"" ssid = ""17"">We use the WordNet Similarity Package 0.05 and WordNet version 1.6.</S><S sid =""71"" ssid = ""27"">This is transformed from a distance measure in the WN-Similarity package by taking the reciprocal:</S>",['Method_Citation']
6,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","['30', '72', '91', '10', '45']","<S sid =""30"" ssid = ""23"">Sections 3 and 4 concern experiments using predominant senses from the BNC evaluated against the data in SemCor and the SENSEVAL-2 English all-words task respectively.</S><S sid =""72"" ssid = ""1"">In order to evaluate our method we use the data in SemCor as a gold-standard.</S><S sid =""91"" ssid = ""20"">This is to be expected regardless of any inherent shortcomings of the ranking technique since the senses within SemCor will differ compared to those of the BNC.</S><S sid =""10"" ssid = ""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al.  1993).</S><S sid =""45"" ssid = ""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S>",['Method_Citation']
7,P04-1036,I08-2105,0,2004,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","['69', '50', '82', '81', '44']","<S sid =""69"" ssid = ""25"">The frequency data is used to calculate the “information content” (IC) of a class .</S><S sid =""50"" ssid = ""6"">For input we used grammatical relation data extracted using an automatic where: .</S><S sid =""82"" ssid = ""11"">We also calculate the WSD accuracy that would be obtained on SemCor  when using our first sense in all contexts ( ).</S><S sid =""81"" ssid = ""10"">4 We calculate the accuracy of finding the predominant sense  when there is indeed one sense with a higher frequency than the others for this word in SemCor ( ).</S><S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S>",['Method_Citation']
8,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","['55', '58', '45', '56', '7']","<S sid =""55"" ssid = ""11"">For the experiments in sections 3 and 4 we used the 90 million words of written English from the BNC.</S><S sid =""58"" ssid = ""14"">A noun    is thus described by a set of co-occurrence triples and associated frequencies  where is a grammatical relation and is a possible cooccurrence with in that relation.</S><S sid =""45"" ssid = ""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S><S sid =""56"" ssid = ""12"">For each noun we considered the co-occurring verbs in the direct object and subject relation  the modifying nouns in noun-noun relations and the modifying adjectives in adjective-noun relations.</S><S sid =""7"" ssid = ""7"">Furthermore  we demonstrate that our method discovers appropriate predominant senses for words from two domainspecific corpora.</S>",['Method_Citation']
9,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense","['30', '136', '53', '52', '82']","<S sid =""30"" ssid = ""23"">Sections 3 and 4 concern experiments using predominant senses from the BNC evaluated against the data in SemCor and the SENSEVAL-2 English all-words task respectively.</S><S sid =""136"" ssid = ""13"">The words included in this experiment are not a random sample  since we anticipated different predominant senses in the SPORTS and FINANCE domains for these words.</S><S sid =""53"" ssid = ""9"">This weight is the WordNet similarity score ( ) between the target sense ( ) and the sense of ( ) that maximises this score  divided by the sum of all such WordNet similarity scores for and .</S><S sid =""52"" ssid = ""8"">For each sense of ( ) we obtain a ranking score by summing over the of each neighbour ( ) multiplied by a weight.</S><S sid =""82"" ssid = ""11"">We also calculate the WSD accuracy that would be obtained on SemCor  when using our first sense in all contexts ( ).</S>",['Method_Citation']
11,P04-1036,P10-1155,0,2004,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)","['135', '179', '111', '54', '6']","<S sid =""135"" ssid = ""12"">We therefore decided to select a limited number of words and to evaluate these words qualitatively.</S><S sid =""179"" ssid = ""2"">We use an automatically acquired thesaurus and a WordNet Similarity measure.</S><S sid =""111"" ssid = ""9"">We give the results for this WSD task in table 2.</S><S sid =""54"" ssid = ""10"">Thus we rank each sense using: parser (Briscoe and Carroll  2002).</S><S sid =""6"" ssid = ""6"">This is a very promising result given that our method does not require any hand-tagged text  such as SemCor.</S>",['Method_Citation']
12,P04-1036,W12-3401,0,2004,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","['137', '156', '61', '65', '142']","<S sid =""137"" ssid = ""14"">Additionally  we evaluated our method quantitatively using the Subject Field Codes (SFC) resource (Magnini and Cavagli`a  2000) which annotates WordNet synsets with domain labels.</S><S sid =""156"" ssid = ""4"">Buitelaar and Sacaleanu (2001) have previously explored ranking and selection of synsets in GermaNet for specific domains using the words in a given synset  and those related by hyponymy  and a term relevance measure taken from information retrieval.</S><S sid =""61"" ssid = ""17"">We use the WordNet Similarity Package 0.05 and WordNet version 1.6.</S><S sid =""65"" ssid = ""21"">The measures provide a similarity score between two WordNet senses ( and )  these being synsets within WordNet. lesk (Banerjee and Pedersen  2002) This score maximises the number of overlapping words in the gloss  or definition  of the senses.</S><S sid =""142"" ssid = ""19"">The results for 10 of the words from the qualitative experiment are summarized in table 3 with the WordNet sense number for each word supplied alongside synonyms or hypernyms from WordNet for readability.</S>",['Method_Citation']
13,P04-1036,W12-3401,0,2004,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)","['50', '69', '44', '71', '30']","<S sid =""50"" ssid = ""6"">For input we used grammatical relation data extracted using an automatic where: .</S><S sid =""69"" ssid = ""25"">The frequency data is used to calculate the “information content” (IC) of a class .</S><S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S><S sid =""71"" ssid = ""27"">This is transformed from a distance measure in the WN-Similarity package by taking the reciprocal:</S><S sid =""30"" ssid = ""23"">Sections 3 and 4 concern experiments using predominant senses from the BNC evaluated against the data in SemCor and the SENSEVAL-2 English all-words task respectively.</S>",['Method_Citation']
14,P04-1036,W12-3401,0,2004,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","['50', '70', '137', '69', '44']","<S sid =""50"" ssid = ""6"">For input we used grammatical relation data extracted using an automatic where: .</S><S sid =""70"" ssid = ""26"">Jiang and Conrath specify a distance measure:   where the third class ( ) is the most informative  or most specific  superordinate synset of the two senses and .</S><S sid =""137"" ssid = ""14"">Additionally  we evaluated our method quantitatively using the Subject Field Codes (SFC) resource (Magnini and Cavagli`a  2000) which annotates WordNet synsets with domain labels.</S><S sid =""69"" ssid = ""25"">The frequency data is used to calculate the “information content” (IC) of a class .</S><S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S>",['Method_Citation']
16,P04-1036,S12-1097,0,"McCarthy et al, 2004",0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","['16', '161', '29', '6', '34']","<S sid =""16"" ssid = ""9"">SemCor comprises a relatively small sample of 250 000 words.</S><S sid =""161"" ssid = ""9"">Our approach is complementary to this.</S><S sid =""29"" ssid = ""22"">We discuss our method in the following section.</S><S sid =""6"" ssid = ""6"">This is a very promising result given that our method does not require any hand-tagged text  such as SemCor.</S><S sid =""34"" ssid = ""27"">In these each target word is entered with an ordered list of “nearest neighbours”.</S>",['Results_Citation']
17,P04-1036,W10-2803,0,"McCarthy et al, 2004",0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","['157', '185', '193', '39', '128']","<S sid =""157"" ssid = ""5"">Buitelaar and Sacaleanu have evaluated their method on identifying domain specific concepts using human judgements on 100 items.</S><S sid =""185"" ssid = ""8"">In the future  we will perform a large scale evaluation on domain specific corpora.</S><S sid =""193"" ssid = ""2"">This work was funded by EU-2001-34460 project MEANING: Developing Multilingual Web-scale Language Technologies  UK EPSRC project Robust Accurate Statistical Parsing (RASP) and a UK EPSRC studentship.</S><S sid =""39"" ssid = ""32"">We expect that the quantity and similarity of the neighbours pertaining to different senses will reflect the dominance of the sense to which they pertain.</S><S sid =""128"" ssid = ""5"">The Reuters corpus (Rose et al.  2002) is a collection of about 810 000 Reuters  English Language News stories.</S>",['Method_Citation']
18,P04-1036,W08-2107,0,2004,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","['68', '50', '65', '44', '82']","<S sid =""68"" ssid = ""24"">We are of course able to apply the method to other versions of WordNet. synset  is incremented with the frequency counts from the corpus of all words belonging to that synset  directly or via the hyponymy relation.</S><S sid =""50"" ssid = ""6"">For input we used grammatical relation data extracted using an automatic where: .</S><S sid =""65"" ssid = ""21"">The measures provide a similarity score between two WordNet senses ( and )  these being synsets within WordNet. lesk (Banerjee and Pedersen  2002) This score maximises the number of overlapping words in the gloss  or definition  of the senses.</S><S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S><S sid =""82"" ssid = ""11"">We also calculate the WSD accuracy that would be obtained on SemCor  when using our first sense in all contexts ( ).</S>",['Method_Citation']
19,P04-1036,D07-1026,0,"McCarthy et al, 2004",0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","['90', '175', '8', '2', '1']","<S sid =""90"" ssid = ""19"">From manual analysis  there are cases where the acquired first sense disagrees with SemCor  yet is intuitively plausible.</S><S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid =""2"" ssid = ""2"">The problem with using the predominant  or first sense heuristic  aside from the fact that it does not take surrounding context into account  is that it assumes some quantity of handtagged data.</S><S sid =""1"" ssid = ""1"">word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.</S>",['Method_Citation']
20,P04-1036,W12-2429,0,"McCarthy et al, 2004",0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","['69', '10', '0', '50', '30']","<S sid =""69"" ssid = ""25"">The frequency data is used to calculate the “information content” (IC) of a class .</S><S sid =""10"" ssid = ""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al.  1993).</S><S sid =""0"" ssid = ""0"">Finding Predominant Word Senses in Untagged Text</S><S sid =""50"" ssid = ""6"">For input we used grammatical relation data extracted using an automatic where: .</S><S sid =""30"" ssid = ""23"">Sections 3 and 4 concern experiments using predominant senses from the BNC evaluated against the data in SemCor and the SENSEVAL-2 English all-words task respectively.</S>",['Method_Citation']
