Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,D10-1044,P11-2074,0,"Foster et al, 2010",0,"Another popular task in SMT is domain adaptation (Foster et al, 2010)","Another popular task in SMT is domain adaptation (Foster et al, 2010)","['128', '140', '10', '4', '136']","<S sid =""128"" ssid = ""32"">Clearly  retaining the original frequencies is important for good performance  and globally smoothing the final weighted frequencies is crucial.</S><S sid =""140"" ssid = ""9"">Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem.</S><S sid =""10"" ssid = ""7"">This is a standard adaptation problem for SMT.</S><S sid =""4"" ssid = ""1"">Domain adaptation is a common concern when optimizing empirical NLP applications.</S><S sid =""136"" ssid = ""5"">It is also worth pointing out a connection with Daum´e’s (2007) work that splits each feature into domain-specific and general copies.</S>",['Results_Citation']
2,D10-1044,P12-1048,0,"Foster et al, 2010",0,"In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)","In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)","['143', '38', '82', '142', '130']","<S sid =""143"" ssid = ""12"">Other work includes transferring latent topic distributions from source to target language for LM adaptation  (Tam et al.  2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita  2008).</S><S sid =""38"" ssid = ""2"">The toplevel weights are trained to maximize a metric such as BLEU on a small development set of approximately 1000 sentence pairs.</S><S sid =""82"" ssid = ""19"">This is not unreasonable given the application to phrase pairs from OUT  but it suggests that an interesting alternative might be to use a plain log-linear weighting function exp(Ei Aifi(s  t))  with outputs in [0  oo].</S><S sid =""142"" ssid = ""11"">There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan  2007; Wu et al.  2005)  and on dynamically choosing a dev set (Xu et al.  2007).</S><S sid =""130"" ssid = ""34"">The final block in table 2 shows models trained on feature subsets and on the SVM feature described in 3.4.</S>",['Method_Citation']
3,D10-1044,D12-1129,0,"Foster et al., 2010",0,"Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010) .Research in Word Sense Disambiguation (Navigli, 2009, WSD), the task aimed at the automatic labeling of text with word senses, has been oriented towards domain text understanding for several years now","Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010)","['140', '7', '31', '128', '78']","<S sid =""140"" ssid = ""9"">Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem.</S><S sid =""7"" ssid = ""4"">For developers of Statistical Machine Translation (SMT) systems  an additional complication is the heterogeneous nature of SMT components (word-alignment model  language model  translation model  etc.</S><S sid =""31"" ssid = ""28"">For comparison to information-retrieval inspired baselines  eg (L¨u et al.  2007)  we select sentences from OUT using language model perplexities from IN.</S><S sid =""128"" ssid = ""32"">Clearly  retaining the original frequencies is important for good performance  and globally smoothing the final weighted frequencies is crucial.</S><S sid =""78"" ssid = ""15"">This has solutions: where pI(s|t) is derived from the IN corpus using relative-frequency estimates  and po(s|t) is an instance-weighted model derived from the OUT corpus.</S>",['Method_Citation']
4,D10-1044,P14-2093,0,2010,0,"Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models","Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models","['130', '127', '143', '65', '102']","<S sid =""130"" ssid = ""34"">The final block in table 2 shows models trained on feature subsets and on the SVM feature described in 3.4.</S><S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S><S sid =""143"" ssid = ""12"">Other work includes transferring latent topic distributions from source to target language for LM adaptation  (Tam et al.  2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita  2008).</S><S sid =""65"" ssid = ""2"">Matsoukas et al (2009) generalize it by learning weights on sentence pairs that are used when estimating relative-frequency phrase-pair probabilities.</S><S sid =""102"" ssid = ""6"">The dev corpus was taken from the NIST05 evaluation set  augmented with some randomly-selected material reserved from the training set.</S>",['Method_Citation']
5,D10-1044,E12-1055,0,2010,0,"However, such confounding factors do not affect the optimization algorithm, which works with a fixed set of phrase pairs, and merely varies? .Our main technical contributions are as fol lows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation. Also, we independently perform perplexity minimization for all four features of the standard SMTtranslation model: the phrase translation probabilities p (t|s) and p (s|t), and the lexical weights lex (t|s) and lex (s|t)","Our main technical contributions are as follows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation","['75', '21', '49', '55', '127']","<S sid =""75"" ssid = ""12"">However  it is robust  efficient  and easy to implement.4 To perform the maximization in (7)  we used the popular L-BFGS algorithm (Liu and Nocedal  1989)  which requires gradient information.</S><S sid =""21"" ssid = ""18"">This highly effective approach is not directly applicable to the multinomial models used for core SMT components  which have no natural method for combining split features  so we rely on an instance-weighting approach (Jiang and Zhai  2007) to downweight domain-specific examples in OUT.</S><S sid =""49"" ssid = ""13"">This leads to a linear combination of domain-specific probabilities  with weights in [0  1]  normalized to sum to 1.</S><S sid =""55"" ssid = ""19"">This suggests a direct parallel to (1): where ˜p(s  t) is a joint empirical distribution extracted from the IN dev set using the standard procedure.2 An alternative form of linear combination is a maximum a posteriori (MAP) combination (Bacchiani et al.  2004).</S><S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S>",['Method_Citation']
6,D10-1044,E12-1055,0,2010,0,"Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) ex tend this approach by weighting individual phrase pairs","Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) extend this approach by weighting individual phrase pairs","['127', '130', '49', '38', '143']","<S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S><S sid =""130"" ssid = ""34"">The final block in table 2 shows models trained on feature subsets and on the SVM feature described in 3.4.</S><S sid =""49"" ssid = ""13"">This leads to a linear combination of domain-specific probabilities  with weights in [0  1]  normalized to sum to 1.</S><S sid =""38"" ssid = ""2"">The toplevel weights are trained to maximize a metric such as BLEU on a small development set of approximately 1000 sentence pairs.</S><S sid =""143"" ssid = ""12"">Other work includes transferring latent topic distributions from source to target language for LM adaptation  (Tam et al.  2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita  2008).</S>",['Method_Citation']
7,D10-1044,E12-1055,0,2010,0,"These more fine-grained methods need not be seen as alternatives to coarse-grained ones. Foster et al (2010) combine the two, applying linear interpolation to combine the instance 542 weighted out-of-domain model with an in-domain model","Foster et al (2010) combine the two, applying linear interpolation to combine the instance weighted out-of-domain model with an in-domain model","['127', '20', '38', '130', '49']","<S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S><S sid =""20"" ssid = ""17"">Daum´e (2007) applies a related idea in a simpler way  by splitting features into general and domain-specific versions.</S><S sid =""38"" ssid = ""2"">The toplevel weights are trained to maximize a metric such as BLEU on a small development set of approximately 1000 sentence pairs.</S><S sid =""130"" ssid = ""34"">The final block in table 2 shows models trained on feature subsets and on the SVM feature described in 3.4.</S><S sid =""49"" ssid = ""13"">This leads to a linear combination of domain-specific probabilities  with weights in [0  1]  normalized to sum to 1.</S>",['Method_Citation']
8,D10-1044,E12-1055,0,Foster et al 2010,0,Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN) Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011),Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN); Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011),"['127', '49', '111', '37', '21']","<S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S><S sid =""49"" ssid = ""13"">This leads to a linear combination of domain-specific probabilities  with weights in [0  1]  normalized to sum to 1.</S><S sid =""111"" ssid = ""15"">We used a standard one-pass phrase-based system (Koehn et al.  2003)  with the following features: relative-frequency TM probabilities in both directions; a 4-gram LM with Kneser-Ney smoothing; word-displacement distortion model; and word count.</S><S sid =""37"" ssid = ""1"">Standard SMT systems have a hierarchical parameter structure: top-level log-linear weights are used to combine a small set of complex features  interpreted as log probabilities  many of which have their own internal parameters and objectives.</S><S sid =""21"" ssid = ""18"">This highly effective approach is not directly applicable to the multinomial models used for core SMT components  which have no natural method for combining split features  so we rely on an instance-weighting approach (Jiang and Zhai  2007) to downweight domain-specific examples in OUT.</S>",['Method_Citation']
9,D10-1044,E12-1055,0,Foster et al 2010,0,"We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translationmodels.15 We demonstrate perplexity optimization for weighted counts, which are a natural extension of unadapted MLE training, but are of little prominence in domain adaptation research",We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translation models,"['7', '81', '151', '75', '143']","<S sid =""7"" ssid = ""4"">For developers of Statistical Machine Translation (SMT) systems  an additional complication is the heterogeneous nature of SMT components (word-alignment model  language model  translation model  etc.</S><S sid =""81"" ssid = ""18"">The logistic function  whose outputs are in [0  1]  forces pp(s  t) <_ po(s  t).</S><S sid =""151"" ssid = ""8"">In future work we plan to try this approach with more competitive SMT systems  and to extend instance weighting to other standard SMT components such as the LM  lexical phrase weights  and lexicalized distortion.</S><S sid =""75"" ssid = ""12"">However  it is robust  efficient  and easy to implement.4 To perform the maximization in (7)  we used the popular L-BFGS algorithm (Liu and Nocedal  1989)  which requires gradient information.</S><S sid =""143"" ssid = ""12"">Other work includes transferring latent topic distributions from source to target language for LM adaptation  (Tam et al.  2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita  2008).</S>",['Method_Citation']
10,D10-1044,P12-1099,0,"Foster et al, 2010",0,"In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) 940 as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT","In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT","['21', '75', '127', '151', '143']","<S sid =""21"" ssid = ""18"">This highly effective approach is not directly applicable to the multinomial models used for core SMT components  which have no natural method for combining split features  so we rely on an instance-weighting approach (Jiang and Zhai  2007) to downweight domain-specific examples in OUT.</S><S sid =""75"" ssid = ""12"">However  it is robust  efficient  and easy to implement.4 To perform the maximization in (7)  we used the popular L-BFGS algorithm (Liu and Nocedal  1989)  which requires gradient information.</S><S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S><S sid =""151"" ssid = ""8"">In future work we plan to try this approach with more competitive SMT systems  and to extend instance weighting to other standard SMT components such as the LM  lexical phrase weights  and lexicalized distortion.</S><S sid =""143"" ssid = ""12"">Other work includes transferring latent topic distributions from source to target language for LM adaptation  (Tam et al.  2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita  2008).</S>",['Method_Citation']
11,D10-1044,P12-1099,0,2010,0,m ?mpm (e? |f?) Our technique for setting? m is similar to that outlined in Foster et al (2010),Our technique for setting ? m is similar to that outlined in Foster et al (2010),"['97', '53', '106', '81', '26']","<S sid =""97"" ssid = ""1"">We carried out translation experiments in two different settings.</S><S sid =""53"" ssid = ""17"">This has led previous workers to adopt ad hoc linear weighting schemes (Finch and Sumita  2008; Foster and Kuhn  2007; L¨u et al.  2007).</S><S sid =""106"" ssid = ""10"">The corpora for both settings are summarized in table 1.</S><S sid =""81"" ssid = ""18"">The logistic function  whose outputs are in [0  1]  forces pp(s  t) <_ po(s  t).</S><S sid =""26"" ssid = ""23"">Phrase-level granularity distinguishes our work from previous work by Matsoukas et al (2009)  who weight sentences according to sub-corpus and genre membership.</S>",['Method_Citation']
12,D10-1044,P12-1099,0,"Foster et al., 2010",0,"m ?mpm (e? |f?) For efficiency and stability, we use the EMalgorithm to find??, rather than L-BFGS as in (Foster et al., 2010)","For efficiency and stability, we use the EM algorithm to find ?, rather than L-BFGS as in (Foster et al., 2010)","['7', '81', '31', '78', '140']","<S sid =""7"" ssid = ""4"">For developers of Statistical Machine Translation (SMT) systems  an additional complication is the heterogeneous nature of SMT components (word-alignment model  language model  translation model  etc.</S><S sid =""81"" ssid = ""18"">The logistic function  whose outputs are in [0  1]  forces pp(s  t) <_ po(s  t).</S><S sid =""31"" ssid = ""28"">For comparison to information-retrieval inspired baselines  eg (L¨u et al.  2007)  we select sentences from OUT using language model perplexities from IN.</S><S sid =""78"" ssid = ""15"">This has solutions: where pI(s|t) is derived from the IN corpus using relative-frequency estimates  and po(s|t) is an instance-weighted model derived from the OUT corpus.</S><S sid =""140"" ssid = ""9"">Recent work by Finkel and Manning (2009) which re-casts Daum´e’s approach in a hierarchical MAP framework may be applicable to this problem.</S>",['Method_Citation']
13,D10-1044,P12-1099,0,2010,0,"Foster et al (2010), however, uses a different approach to select related sentences from OUT","Foster et al (2010), however, uses a different approach to select related sentences from OUT","['60', '30', '24', '65', '145']","<S sid =""60"" ssid = ""24"">The matching sentence pairs are then added to the IN corpus  and the system is re-trained.</S><S sid =""30"" ssid = ""27"">A similar maximumlikelihood approach was used by Foster and Kuhn (2007)  but for language models only.</S><S sid =""24"" ssid = ""21"">Sentence pairs are the natural instances for SMT  but sentences often contain a mix of domain-specific and general language.</S><S sid =""65"" ssid = ""2"">Matsoukas et al (2009) generalize it by learning weights on sentence pairs that are used when estimating relative-frequency phrase-pair probabilities.</S><S sid =""145"" ssid = ""2"">Each out-of-domain phrase pair is characterized by a set of simple features intended to reflect how useful it will be.</S>",['Results_Citation']
14,D10-1044,P12-1099,0,2010,0,Foster et al (2010) propose asimilar method for machine translation that uses features to capture degrees of generality,Foster et al (2010) propose a similar method for machine translation that uses features to capture degrees of generality,"['127', '20', '130', '49', '22']","<S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S><S sid =""20"" ssid = ""17"">Daum´e (2007) applies a related idea in a simpler way  by splitting features into general and domain-specific versions.</S><S sid =""130"" ssid = ""34"">The final block in table 2 shows models trained on feature subsets and on the SVM feature described in 3.4.</S><S sid =""49"" ssid = ""13"">This leads to a linear combination of domain-specific probabilities  with weights in [0  1]  normalized to sum to 1.</S><S sid =""22"" ssid = ""19"">Within this framework  we use features intended to capture degree of generality  including the output from an SVM classifier that uses the intersection between IN and OUT as positive examples.</S>",['Method_Citation']
15,D10-1044,P13-1126,0,"Foster et al, 2010",0,"As in (Foster et al, 2010), this approach works at the level of phrase pairs","As in (Foster et al, 2010), this approach works at the level of phrase pairs","['127', '130', '20', '49', '119']","<S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S><S sid =""130"" ssid = ""34"">The final block in table 2 shows models trained on feature subsets and on the SVM feature described in 3.4.</S><S sid =""20"" ssid = ""17"">Daum´e (2007) applies a related idea in a simpler way  by splitting features into general and domain-specific versions.</S><S sid =""49"" ssid = ""13"">This leads to a linear combination of domain-specific probabilities  with weights in [0  1]  normalized to sum to 1.</S><S sid =""119"" ssid = ""23"">The 2nd block contains the IR system  which was tuned by selecting text in multiples of the size of the EMEA training corpus  according to dev set performance.</S>",['Method_Citation']
16,D10-1044,D11-1033,0,2010,0,"The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)","The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)","['143', '66', '75', '113', '102']","<S sid =""143"" ssid = ""12"">Other work includes transferring latent topic distributions from source to target language for LM adaptation  (Tam et al.  2007) and adapting features at the sentence level to different categories of sentence (Finch and Sumita  2008).</S><S sid =""66"" ssid = ""3"">The weight on each sentence is a value in [0  1] computed by a perceptron with Boolean features that indicate collection and genre membership.</S><S sid =""75"" ssid = ""12"">However  it is robust  efficient  and easy to implement.4 To perform the maximization in (7)  we used the popular L-BFGS algorithm (Liu and Nocedal  1989)  which requires gradient information.</S><S sid =""113"" ssid = ""17"">The corpus was wordaligned using both HMM and IBM2 models  and the phrase table was the union of phrases extracted from these separate alignments  with a length limit of 7.</S><S sid =""102"" ssid = ""6"">The dev corpus was taken from the NIST05 evaluation set  augmented with some randomly-selected material reserved from the training set.</S>",['Method_Citation']
17,D10-1044,D11-1033,0,2010,0,"Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and re port a decrease in performance","Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and report a decrease in performance","['44', '79', '62', '115', '13']","<S sid =""44"" ssid = ""8"">When OUT is large and distinct  its contribution can be controlled by training separate IN and OUT models  and weighting their combination.</S><S sid =""79"" ssid = ""16"">This combination generalizes (2) and (3): we use either at = a to obtain a fixed-weight linear combination  or at = cI(t)/(cI(t) + 0) to obtain a MAP combination.</S><S sid =""62"" ssid = ""26"">To approximate these baselines  we implemented a very simple sentence selection algorithm in which parallel sentence pairs from OUT are ranked by the perplexity of their target half according to the IN language model.</S><S sid =""115"" ssid = ""19"">Table 2 shows results for both settings and all methods described in sections 2 and 3.</S><S sid =""13"" ssid = ""10"">The techniques we develop can be extended in a relatively straightforward manner to the more general case when OUT consists of multiple sub-domains.</S>",['Method_Citation']
18,D10-1044,D11-1033,0,2010,0,"Foster et al (2010) further perform this on extracted phrase pairs, not just sentences","Foster et al (2010) further perform this on extracted phrase pairs, not just sentences","['106', '60', '81', '38', '53']","<S sid =""106"" ssid = ""10"">The corpora for both settings are summarized in table 1.</S><S sid =""60"" ssid = ""24"">The matching sentence pairs are then added to the IN corpus  and the system is re-trained.</S><S sid =""81"" ssid = ""18"">The logistic function  whose outputs are in [0  1]  forces pp(s  t) <_ po(s  t).</S><S sid =""38"" ssid = ""2"">The toplevel weights are trained to maximize a metric such as BLEU on a small development set of approximately 1000 sentence pairs.</S><S sid =""53"" ssid = ""17"">This has led previous workers to adopt ad hoc linear weighting schemes (Finch and Sumita  2008; Foster and Kuhn  2007; L¨u et al.  2007).</S>",['Method_Citation']
19,D10-1044,P14-1012,0,"Foster et al, 2010",0,"To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments","To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments","['95', '50', '21', '59', '51']","<S sid =""95"" ssid = ""32"">Phrase tables were extracted from the IN and OUT training corpora (not the dev as was used for instance weighting models)  and phrase pairs in the intersection of the IN and OUT phrase tables were used as positive examples  with two alternate definitions of negative examples: The classifier trained using the 2nd definition had higher accuracy on a development set.</S><S sid =""50"" ssid = ""14"">Linear weights are difficult to incorporate into the standard MERT procedure because they are “hidden” within a top-level probability that represents the linear combination.1 Following previous work (Foster and Kuhn  2007)  we circumvent this problem by choosing weights to optimize corpus loglikelihood  which is roughly speaking the training criterion used by the LM and TM themselves.</S><S sid =""21"" ssid = ""18"">This highly effective approach is not directly applicable to the multinomial models used for core SMT components  which have no natural method for combining split features  so we rely on an instance-weighting approach (Jiang and Zhai  2007) to downweight domain-specific examples in OUT.</S><S sid =""59"" ssid = ""23"">To set β  we used the same criterion as for α  over a dev corpus: The MAP combination was used for TM probabilities only  in part due to a technical difficulty in formulating coherent counts when using standard LM smoothing techniques (Kneser and Ney  1995).3 Motivated by information retrieval  a number of approaches choose “relevant” sentence pairs from OUT by matching individual source sentences from IN (Hildebrand et al.  2005; L¨u et al.  2007)  or individual target hypotheses (Zhao et al.  2004).</S><S sid =""51"" ssid = ""15"">For the LM  adaptive weights are set as follows: where α is a weight vector containing an element αi for each domain (just IN and OUT in our case)  pi are the corresponding domain-specific models  and ˜p(w  h) is an empirical distribution from a targetlanguage training corpus—we used the IN dev set for this.</S>","['Aim_Citation', 'Results_Citation']"
