Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P05-1013,W05-1505,0,"Nivre and Nilsson, 2005",0,"Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","['50', '75', '48', '21', '36']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S>",['Results_Citation']
2,P05-1013,P08-1006,0,"Nivre and Nilsson, 2005",0,"1http: //sourceforge.net/projects/mstparser Figure 1: CoNLL-X dependency tree Figure 2: Penn Treebank-style phrase structure tree KSDEP Sagae and Tsujii (2007)? s dependencyparser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","Sagae and Tsujii (2007)'s dependency parser, based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","['48', '75', '62', '21', '91']","<S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""62"" ssid = ""1"">In the experiments below  we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs 3 previously tested on Swedish (Nivre et al.  2004) and English (Nivre and Scholz  2004).</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""91"" ssid = ""2"">Table 5 shows the overall parsing accuracy attained with the three different encoding schemes  compared to the baseline (no special arc labels) and to training directly on non-projective dependency graphs.</S>",['Method_Citation']
3,P05-1013,W10-1401,0,"Nivre and Nilsson, 2005",0,"Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","['50', '75', '77', '48', '21']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""77"" ssid = ""4"">The Danish Dependency Treebank (DDT) comprises about 100K words of text selected from the Danish PAROLE corpus  with annotation of primary and secondary dependencies (Kromann  2003).</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S>",['Method_Citation']
4,P05-1013,P12-3029,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees weuse the pseudo-projective parsing technique to trans form the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","['50', '75', '71', '21', '45']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""71"" ssid = ""10"">For robustness reasons  the parser may output a set of dependency trees instead of a single tree. most dependent of the next input token  dependency type features are limited to tokens on the stack.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""45"" ssid = ""16"">In order to facilitate this task  we extend the set of arc labels to encode information about lifting operations.</S>",['Method_Citation']
5,P05-1013,W10-1403,0,"Nivre and Nilsson, 2005",0,"It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","['75', '50', '48', '45', '21']","<S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""45"" ssid = ""16"">In order to facilitate this task  we extend the set of arc labels to encode information about lifting operations.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S>",['Method_Citation']
6,P05-1013,D08-1008,0,"Nivre and Nilsson, 2005",0,"To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson,2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson, 2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","['50', '51', '36', '21', '48']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""51"" ssid = ""22"">In the second scheme  Head+Path  we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S>",['Method_Citation']
7,P05-1013,D07-1013,0,2005,0,",wn in O (n) time, producing a projective dependency graph satisfying conditions 1? 4 in section 2.1, possibly after adding arcs (0, i ,lr) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers) .Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to pre process training data and post-process parser output, so-called pseudo-projective parsing. To learn transition scores, these systems use discriminative learning methods ,e.g., memory-based learning or support vector machines","Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing","['50', '48', '21', '36', '75']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S>",['Method_Citation']
8,P05-1013,D07-1119,0,2005,0,"For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","['50', '21', '51', '48', '75']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""51"" ssid = ""22"">In the second scheme  Head+Path  we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S>",['Method_Citation']
9,P05-1013,N07-1050,0,"Nivre and Nilsson, 2005",0,"Whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","['36', '51', '21', '48', '23']","<S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid =""51"" ssid = ""22"">In the second scheme  Head+Path  we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""23"" ssid = ""19"">By applying an inverse transformation to the output of the parser  arcs with non-standard labels can be lowered to their proper place in the dependency graph  giving rise 1The dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.</S>",['Method_Citation']
10,P05-1013,W09-1207,0,"Nivre and Nilsson, 2005",0,"troduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","['50', '75', '48', '21', '45']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""45"" ssid = ""16"">In order to facilitate this task  we extend the set of arc labels to encode information about lifting operations.</S>",['Method_Citation']
11,P05-1013,E09-1034,0,"Nivre and Nilsson, 2005",0,"non projective (Nivre and Nilsson, 2005), we char ac terise a sense in which the structures appearing in tree banks can be viewed as being only? slightly? ill-nested","However, just as it has been noted that most non-projective structures appearing in practice are only 'slightly' non projective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in tree banks can be viewed as being only 'slightly' ill-nested","['2', '83', '7', '6', '35']","<S sid =""2"" ssid = ""2"">We show how a datadriven deterministic dependency parser  in itself restricted to projective structures  can be combined with graph transformation techniques to produce non-projective structures.</S><S sid =""83"" ssid = ""10"">It is worth noting that  although nonprojective constructions are less frequent in DDT than in PDT  they seem to be more deeply nested  since only about 80% can be projectivized with a single lift  while almost 95% of the non-projective arcs in PDT only require a single lift.</S><S sid =""7"" ssid = ""3"">From the point of view of computational implementation this can be problematic  since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.</S><S sid =""6"" ssid = ""2"">However  this argument is only plausible if the formal framework allows non-projective dependency structures  i.e. structures where a head and its dependents may correspond to a discontinuous constituent.</S><S sid =""35"" ssid = ""6"">The dependency graph in Figure 1 satisfies all the defining conditions above  but it fails to satisfy the condition ofprojectivity (Kahane et al.  1998): The arc connecting the head jedna (one) to the dependent Z (out-of) spans the token je (is)  which is not dominated by jedna.</S>",['Method_Citation']
12,P05-1013,W09-1218,0,"Nivre and Nilsson, 2005",0,"In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","['48', '75', '45', '21', '20']","<S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""45"" ssid = ""16"">In order to facilitate this task  we extend the set of arc labels to encode information about lifting operations.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""20"" ssid = ""16"">In this paper  we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.</S>",['Method_Citation']
13,P05-1013,C08-1081,0,"Nivre and Nilsson, 2005",0,"Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","['48', '45', '73', '20', '106']","<S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""45"" ssid = ""16"">In order to facilitate this task  we extend the set of arc labels to encode information about lifting operations.</S><S sid =""73"" ssid = ""12"">More details on the memory-based prediction can be found in Nivre et al. (2004) and Nivre and Scholz (2004).</S><S sid =""20"" ssid = ""16"">In this paper  we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.</S><S sid =""106"" ssid = ""17"">However  the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech  with a best performance of 73% UAS (Holan  2004).</S>",['Results_Citation']
14,P05-1013,C08-1081,0,2005,0,"Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","['50', '48', '75', '36', '52']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid =""52"" ssid = ""23"">Thus  the arc from je to jedna will be labeled 5b↓ (to indicate that there is a syntactic head below it).</S>",['Method_Citation']
15,P05-1013,C08-1081,0,2005,0,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,"['50', '48', '21', '84', '79']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""84"" ssid = ""11"">In the second part of the experiment  we applied the inverse transformation based on breadth-first search under the three different encoding schemes.</S><S sid =""79"" ssid = ""6"">In the first part of the experiment  dependency graphs from the treebanks were projectivized using the algorithm described in section 2.</S>",['Method_Citation']
16,P05-1013,C08-1081,0,2005,0,"Weprojectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","['69', '23', '64', '59', '46']","<S sid =""69"" ssid = ""8"">For each token  three types of features may be taken into account: the word form; the part-of-speech assigned by an automatic tagger; and labels on previously assigned dependency arcs involving the token – the arc from its head and the arcs to its leftmost and rightmost dependent  respectively.</S><S sid =""23"" ssid = ""19"">By applying an inverse transformation to the output of the parser  arcs with non-standard labels can be lowered to their proper place in the dependency graph  giving rise 1The dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.</S><S sid =""64"" ssid = ""3"">At each point during the derivation  the parser has a choice between pushing the next input token onto the stack – with or without adding an arc from the token on top of the stack to the token pushed – and popping a token from the stack – with or without adding an arc from the next input token to the token popped.</S><S sid =""59"" ssid = ""30"">The details of the transformation procedure are slightly different depending on the encoding schemes: d↑h let the linear head be the syntactic head). target arc must have the form wl −→ wm; if no target arc is found  Head is used as backoff. must have the form wl −→ wm and no outgoing arcs of the form wm p'↓ −→ wo; no backoff.</S><S sid =""46"" ssid = ""17"">In principle  it would be possible to encode the exact position of the syntactic head in the label of the arc from the linear head  but this would give a potentially infinite set of arc labels and would make the training of the parser very hard.</S>",['Method_Citation']
17,P05-1013,D11-1006,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","['50', '75', '71', '21', '45']","<S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""71"" ssid = ""10"">For robustness reasons  the parser may output a set of dependency trees instead of a single tree. most dependent of the next input token  dependency type features are limited to tokens on the stack.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""45"" ssid = ""16"">In order to facilitate this task  we extend the set of arc labels to encode information about lifting operations.</S>",['Method_Citation']
18,P05-1013,P11-2121,0,"Nivre and Nilsson, 2005",0,"Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","['107', '14', '101', '89', '87']","<S sid =""107"" ssid = ""18"">Compared to related work on the recovery of long-distance dependencies in constituency-based parsing  our approach is similar to that of Dienes and Dubey (2003) in that the processing of non-local dependencies is partly integrated in the parsing process  via an extension of the set of syntactic categories  whereas most other approaches rely on postprocessing only.</S><S sid =""14"" ssid = ""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%  the total proportion of non-projective arcs is normally only 1–2%.</S><S sid =""101"" ssid = ""12"">However  if we consider precision  recall and Fmeasure on non-projective dependencies only  as shown in Table 6  some differences begin to emerge.</S><S sid =""89"" ssid = ""16"">The increase is generally higher for PDT than for DDT  which indicates a greater diversity in non-projective constructions.</S><S sid =""87"" ssid = ""14"">However  it can be noted that the results for the least informative encoding  Path  are almost comparable  while the third encoding  Head  gives substantially worse results for both data sets.</S>",['Method_Citation']
19,P05-1013,E06-1010,0,"Nivre and Nilsson, 2005",0,"Itshould be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in them selves (Nivre and Nilsson, 2005)","It should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves (Nivre and Nilsson, 2005)","['89', '14', '88', '28', '103']","<S sid =""89"" ssid = ""16"">The increase is generally higher for PDT than for DDT  which indicates a greater diversity in non-projective constructions.</S><S sid =""14"" ssid = ""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%  the total proportion of non-projective arcs is normally only 1–2%.</S><S sid =""88"" ssid = ""15"">We also see that the increase in the size of the label sets for Head and Head+Path is far below the theoretical upper bounds given in Table 1.</S><S sid =""28"" ssid = ""24"">First  in section 4  we evaluate the graph transformation techniques in themselves  with data from the Prague Dependency Treebank and the Danish Dependency Treebank.</S><S sid =""103"" ssid = ""14"">On the other hand  given that all schemes have similar parsing accuracy overall  this means that the Path scheme is the least likely to introduce errors on projective arcs.</S>","['Aim_Citation', 'Results_Citation']"
20,P05-1013,D07-1111,0,"Nivre and Nilsson, 2005",0,"The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective trans formations as described in (Nivre and Nilsson, 2005)","The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective transformations as described in (Nivre and Nilsson, 2005)","['48', '50', '75', '21', '36']","<S sid =""48"" ssid = ""19"">To explore this tradeoff  we have performed experiments with three different encoding schemes (plus a baseline)  which are described schematically in Table 1.</S><S sid =""50"" ssid = ""21"">Using this encoding scheme  the arc from je to Z in Figure 2 would be assigned the label AuxP↑Sb (signifying an AuxP that has been lifted from a Sb).</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S>",['Method_Citation']
