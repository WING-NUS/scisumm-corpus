Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Reference Citation
1,W99-0623,A00-2005,0,1999,0,1 Introduct ion Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,"['142', '141', '18', '81', '57']","<S sid =""142"" ssid = ""4"">Both of the switching techniques  as well as the parametric hybridization technique were also shown to be robust when a poor parser was introduced into the experiments.</S><S sid =""141"" ssid = ""3"">All four of the techniques studied result in parsing systems that perform better than any previously reported.</S><S sid =""18"" ssid = ""4"">These two principles guide experimentation in this framework  and together with the evaluation measures help us decide which specific type of substructure to combine.</S><S sid =""81"" ssid = ""10"">F-measure is the harmonic mean of precision and recall  2PR/(P + R).</S><S sid =""57"" ssid = ""43"">The combining technique must act as a multi-position switch indicating which parser should be trusted for the particular sentence.</S>",['Results_Citation']
2,W99-0623,A00-2005,0,1999,0,the collection of hypotheses ti =fi (Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999),"Given a novel sentence Stest E Ctest, combine the collection of hypotheses ti = fi(Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999)","['112', '61', '81', '78', '139']","<S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid =""81"" ssid = ""10"">F-measure is the harmonic mean of precision and recall  2PR/(P + R).</S><S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S>",['Method_Citation']
4,W99-0623,N10-1091,0,"Henderson and Brill, 1999",0,"5 (Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","(Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","['62', '88', '27', '115', '22']","<S sid =""62"" ssid = ""48"">This is the parse that is closest to the centroid of the observed parses under the similarity metric.</S><S sid =""88"" ssid = ""17"">For example  one parser could be more accurate at predicting noun phrases than the other parsers.</S><S sid =""27"" ssid = ""13"">Another technique for parse hybridization is to use a naïve Bayes classifier to determine which constituents to include in the parse.</S><S sid =""115"" ssid = ""44"">It is the performance we could achieve if an omniscient observer told us which parser to pick for each of the sentences.</S><S sid =""22"" ssid = ""8"">If enough parsers suggest that a particular constituent belongs in the parse  we include it.</S>",['Method_Citation']
5,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","['38', '21', '125', '41', '44']","<S sid =""38"" ssid = ""24"">Under certain conditions the constituent voting and naïve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S><S sid =""21"" ssid = ""7"">One hybridization strategy is to let the parsers vote on constituents' membership in the hypothesized set.</S><S sid =""125"" ssid = ""54"">The constituent voting and naïve Bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers.</S><S sid =""41"" ssid = ""27"">IL+-1Proof: Assume a pair of crossing constituents appears in the output of the constituent voting technique using k parsers.</S><S sid =""44"" ssid = ""30"">Each of the constituents must have received at least 1 votes from the k parsers  so a > I1 and 2 — 2k±-1 b > ri-5-111.</S>",['Method_Citation']
6,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"This approach roughly corresponds to (Henderson and Brill, 1999)? s Na ?ve Bayes parse hybridization","This approach roughly corresponds to (Henderson and Brill, 1999)'s Naive Bayes parse hybridization","['112', '81', '15', '78', '139']","<S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""81"" ssid = ""10"">F-measure is the harmonic mean of precision and recall  2PR/(P + R).</S><S sid =""15"" ssid = ""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S><S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S>",['Method_Citation']
7,W99-0623,W05-1518,0,1999,0,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,"['21', '136', '131', '103', '132']","<S sid =""21"" ssid = ""7"">One hybridization strategy is to let the parsers vote on constituents' membership in the hypothesized set.</S><S sid =""136"" ssid = ""65"">The Bayes models were able to achieve significantly higher precision than their non-parametric counterparts.</S><S sid =""131"" ssid = ""60"">It was then tested on section 22 of the Treebank in conjunction with the other parsers.</S><S sid =""103"" ssid = ""32"">The counts represent portions of the approximately 44000 constituents hypothesized by the parsers in the development set.</S><S sid =""132"" ssid = ""61"">The results of this experiment can be seen in Table 5.</S>",['Method_Citation']
8,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) improved their best parser? s F-measure of 89.7 to 91.3, using their na ?ve Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","(Henderson and Brill, 1999) improved their best parser's F-measure of 89.7 to 91.3, using their naive Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","['112', '78', '81', '61', '130']","<S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid =""81"" ssid = ""10"">F-measure is the harmonic mean of precision and recall  2PR/(P + R).</S><S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid =""130"" ssid = ""59"">The PCFG was trained from the same sections of the Penn Treebank as the other three parsers.</S>",['Method_Citation']
10,W99-0623,P01-1005,0,"Henderson and Brill, 1999",0,"Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","['125', '27', '21', '1', '38']","<S sid =""125"" ssid = ""54"">The constituent voting and naïve Bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers.</S><S sid =""27"" ssid = ""13"">Another technique for parse hybridization is to use a naïve Bayes classifier to determine which constituents to include in the parse.</S><S sid =""21"" ssid = ""7"">One hybridization strategy is to let the parsers vote on constituents' membership in the hypothesized set.</S><S sid =""1"" ssid = ""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses  as well as new bounds on achievable Treebank parsing accuracy.</S><S sid =""38"" ssid = ""24"">Under certain conditions the constituent voting and naïve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S>",['Method_Citation']
11,W99-0623,D09-1161,0,1999,0,"Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","['55', '12', '51', '18', '57']","<S sid =""55"" ssid = ""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid =""12"" ssid = ""8"">The corpus-based statistical parsing community has many fast and accurate automated parsing systems  including systems produced by Collins (1997)  Charniak (1997) and Ratnaparkhi (1997).</S><S sid =""51"" ssid = ""37"">One can trivially create situations in which strictly binary-branching trees are combined to create a tree with only the root node and the terminal nodes  a completely flat structure.</S><S sid =""18"" ssid = ""4"">These two principles guide experimentation in this framework  and together with the evaluation measures help us decide which specific type of substructure to combine.</S><S sid =""57"" ssid = ""43"">The combining technique must act as a multi-position switch indicating which parser should be trusted for the particular sentence.</S>",['Method_Citation']
12,W99-0623,D09-1161,0,1999,0,"Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","['142', '127', '141', '12', '140']","<S sid =""142"" ssid = ""4"">Both of the switching techniques  as well as the parametric hybridization technique were also shown to be robust when a poor parser was introduced into the experiments.</S><S sid =""127"" ssid = ""56"">Parser 3  the most accurate parser  was chosen 71% of the time  and Parser 1  the least accurate parser was chosen 16% of the time.</S><S sid =""141"" ssid = ""3"">All four of the techniques studied result in parsing systems that perform better than any previously reported.</S><S sid =""12"" ssid = ""8"">The corpus-based statistical parsing community has many fast and accurate automated parsing systems  including systems produced by Collins (1997)  Charniak (1997) and Ratnaparkhi (1997).</S><S sid =""140"" ssid = ""2"">For each experiment we gave an nonparametric and a parametric technique for combining parsers.</S>",['Method_Citation']
13,W99-0623,D09-1161,0,"Henderson and Brill, 1999",0,"Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","['112', '78', '61', '130', '15']","<S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid =""130"" ssid = ""59"">The PCFG was trained from the same sections of the Penn Treebank as the other three parsers.</S><S sid =""15"" ssid = ""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S>",['Method_Citation']
14,W99-0623,N06-2033,0,"Henderson and Brill, 1999",0,"Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","['55', '51', '52', '50', '26']","<S sid =""55"" ssid = ""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid =""51"" ssid = ""37"">One can trivially create situations in which strictly binary-branching trees are combined to create a tree with only the root node and the terminal nodes  a completely flat structure.</S><S sid =""52"" ssid = ""38"">This drastic tree manipulation is not appropriate for situations in which we want to assign particular structures to sentences.</S><S sid =""50"" ssid = ""36"">There is a guarantee of no crossing brackets but there is no guarantee that a constituent in the tree has the same children as it had in any of the three original parses.</S><S sid =""26"" ssid = ""12"">This technique has the advantage of requiring no training  but it has the disadvantage of treating all parsers equally even though they may have differing accuracies or may specialize in modeling different phenomena.</S>",['Method_Citation']
15,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","['112', '81', '78', '61', '114']","<S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""81"" ssid = ""10"">F-measure is the harmonic mean of precision and recall  2PR/(P + R).</S><S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid =""114"" ssid = ""43"">The parser switching oracle is the upper bound on the accuracy that can be achieved on this set in the parser switching framework.</S>",['Results_Citation']
16,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","['112', '81', '12', '15', '130']","<S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""81"" ssid = ""10"">F-measure is the harmonic mean of precision and recall  2PR/(P + R).</S><S sid =""12"" ssid = ""8"">The corpus-based statistical parsing community has many fast and accurate automated parsing systems  including systems produced by Collins (1997)  Charniak (1997) and Ratnaparkhi (1997).</S><S sid =""15"" ssid = ""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S><S sid =""130"" ssid = ""59"">The PCFG was trained from the same sections of the Penn Treebank as the other three parsers.</S>",['Method_Citation']
17,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"output (Figure 3) .Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework. Third, we extend these parser combination methods from 1-best outputs to n-best outputs","Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework","['78', '61', '114', '112', '81']","<S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid =""114"" ssid = ""43"">The parser switching oracle is the upper bound on the accuracy that can be achieved on this set in the parser switching framework.</S><S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""81"" ssid = ""10"">F-measure is the harmonic mean of precision and recall  2PR/(P + R).</S>",['Method_Citation']
18,W99-0623,P09-1065,0,"Henderson and Brill, 1999",0,"System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","['129', '11', '130', '15', '9']","<S sid =""129"" ssid = ""58"">In the interest of testing the robustness of these combining techniques  we added a fourth  simple nonlexicalized PCFG parser.</S><S sid =""11"" ssid = ""7"">Similar advances have been made in machine translation (Frederking and Nirenburg  1994)  speech recognition (Fiscus  1997) and named entity recognition (Borthwick et al.  1998).</S><S sid =""130"" ssid = ""59"">The PCFG was trained from the same sections of the Penn Treebank as the other three parsers.</S><S sid =""15"" ssid = ""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S><S sid =""9"" ssid = ""5"">Recently  combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al.  1998; Brill and Wu  1998).</S>",['Method_Citation']
20,W99-0623,C10-1151,0,1999,0,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,"['81', '57', '114', '112', '78']","<S sid =""81"" ssid = ""10"">F-measure is the harmonic mean of precision and recall  2PR/(P + R).</S><S sid =""57"" ssid = ""43"">The combining technique must act as a multi-position switch indicating which parser should be trusted for the particular sentence.</S><S sid =""114"" ssid = ""43"">The parser switching oracle is the upper bound on the accuracy that can be achieved on this set in the parser switching framework.</S><S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""78"" ssid = ""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S>",['Method_Citation']
