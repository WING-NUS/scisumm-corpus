Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,A00-2030,W01-0510,0,"Miller et al., 2000",0,"Section 5 compares our approach tooth ers in the literature, in particular that of (Miller et al., 2000)","Section 5 compares our approach too thiers in the literature, in particular that of (Miller et al., 2000)","['28', '49', '68', '70', '73']","<S sid =""28"" ssid = ""11"">Finally  our newly constructed parser  like that of (Collins 1997)  was based on a generative statistical model.</S><S sid =""49"" ssid = ""9"">By necessity  we adopted the strategy of hand marking only the semantics.</S><S sid =""68"" ssid = ""9"">The next steps are to generate in order: In this case  there are none.</S><S sid =""70"" ssid = ""11"">Post-modifier constituents for the PER/NP.</S><S sid =""73"" ssid = ""14"">We now briefly summarize the probability structure of the model.</S>",['Results_Citation']
2,A00-2030,W01-0510,0,"Miller et al, 2000",0,"The basic approach we described is very similar to the one presented in (Miller et al, 2000) however there are a few major di erences:  in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. The approach in (Miller","The basic approach we described is very similar to the one presented in (Miller et al, 2000) however there are a few major differences:  in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. The approach in (Miller","['61', '101', '76', '39', '30']","<S sid =""61"" ssid = ""2"">The detailed probability structure differs  however  in that it was designed to jointly perform part-of-speech tagging  name finding  syntactic parsing  and relation finding in a single process.</S><S sid =""101"" ssid = ""6"">We evaluated part-of-speech tagging and parsing accuracy on the Wall Street Journal using a now standard procedure (see Collins 97)  and evaluated name finding accuracy on the MUC7 named entity test.</S><S sid =""76"" ssid = ""17"">Finally  word features  fm  for modifiers are predicted based on the modifier  cm  the partof-speech tag of the modifier word   tâ€žâ€ž the part-of-speech tag of the head word th  the head word itself  wh  and whether or not the modifier head word  wâ€žâ€ž is known or unknown.</S><S sid =""39"" ssid = ""7"">For example  the coreference relation between &quot;Nance&quot; and &quot;a paid consultant to ABC News&quot; is indicated by &quot;per-desc-of.&quot; In this case  because the argument does not connect directly to the relation  the intervening nodes are labeled with semantics &quot;-ptr&quot; to indicate the connection.</S><S sid =""30"" ssid = ""13"">Although each model differed in its detailed probability structure  we believed that the essential elements of all three models could be generalized in a single probability model.</S>",['Method_Citation']
3,A00-2030,W01-0510,0,"Miller et al, 2000",0,"The semantic annotation required by our task is much simpler than that employed by (Miller et al, 2000)","The semantic annotation required by our task is much simpler than that employed by (Miller et al, 2000)","['33', '41', '64', '2', '23']","<S sid =""33"" ssid = ""1"">Our integrated model represents syntax and semantics jointly using augmented parse trees.</S><S sid =""41"" ssid = ""1"">To train our integrated model  we required a large corpus of augmented parse trees.</S><S sid =""64"" ssid = ""5"">Word features are introduced primarily to help with unknown words  as in (Weischedel et al. 1993).</S><S sid =""2"" ssid = ""2"">In this paper we report adapting a lexic al ized  probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.</S><S sid =""23"" ssid = ""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S>",['Method_Citation']
4,A00-2030,W01-0510,0,"Miller et al, 2000",0,"One possibly bene cial extension of our work suggested by (Miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level","One possibly beneficial extension of our work suggested by (Miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level","['61', '101', '81', '74', '0']","<S sid =""61"" ssid = ""2"">The detailed probability structure differs  however  in that it was designed to jointly perform part-of-speech tagging  name finding  syntactic parsing  and relation finding in a single process.</S><S sid =""101"" ssid = ""6"">We evaluated part-of-speech tagging and parsing accuracy on the Wall Street Journal using a now standard procedure (see Collins 97)  and evaluated name finding accuracy on the MUC7 named entity test.</S><S sid =""81"" ssid = ""3"">For modifier constituents  the mixture components are: For part-of-speech tags  the mixture components are: Finally  for word features  the mixture components are:</S><S sid =""74"" ssid = ""15"">The categories for head constituents  clâ€ž are predicted based solely on the category of the parent node  cp: Modifier constituent categories  cm  are predicted based on their parent node  cp  the head constituent of their parent node  chp  the previously generated modifier  câ€ž _1  and the head word of their parent  wp.</S><S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S>",['Method_Citation']
5,A00-2030,W01-0510,0,"Miller et al, 2000",0,"Similar to the approach in (Miller et al, 2000 )weinitialized the SLM statistics from the UPenn Tree bank parse trees (about 1Mwds of training data) at the rst training stage, see Section 3","Similar to the approach in (Miller et al, 2000) we initialized the SLM statistics from the UPenn Tree bank parse trees","['60', '72', '77', '88', '28']","<S sid =""60"" ssid = ""1"">In our statistical model  trees are generated according to a process similar to that described in (Collins 1996  1997).</S><S sid =""72"" ssid = ""13"">This generation process is continued until the entire tree has been produced.</S><S sid =""77"" ssid = ""18"">The probability of a complete tree is the product of the probabilities of generating each element in the tree.</S><S sid =""88"" ssid = ""7"">For purposes of pruning  and only for purposes of pruning  the prior probability of each constituent category is multiplied by the generative probability of that constituent (Goodman  1997).</S><S sid =""28"" ssid = ""11"">Finally  our newly constructed parser  like that of (Collins 1997)  was based on a generative statistical model.</S>",['Method_Citation']
6,A00-2030,P14-1078,0,"Miller et al, 2000",0,"Rule-based methods (Miller et al, 2000) employ a number of linguistic rules to capture relation patterns","Rule-based methods (Miller et al, 2000) employ a number of linguistic rules to capture relation patterns","['0', '46', '57', '54', '106']","<S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S><S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S><S sid =""54"" ssid = ""3"">These steps are given below:</S><S sid =""106"" ssid = ""3"">We were able to use the Penn TREEBANK to estimate the syntactic parameters; no additional syntactic training was required.</S>",['Method_Citation']
7,A00-2030,P05-1061,0,2000,0,"One interesting system that does not belong to the above class is that of Miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations","One interesting system that does not belong to the above class is that of Miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations","['61', '94', '30', '60', '39']","<S sid =""61"" ssid = ""2"">The detailed probability structure differs  however  in that it was designed to jointly perform part-of-speech tagging  name finding  syntactic parsing  and relation finding in a single process.</S><S sid =""94"" ssid = ""13"">Given a new sentence  the outcome of this search process is a tree structure that encodes both the syntactic and semantic structure of the sentence.</S><S sid =""30"" ssid = ""13"">Although each model differed in its detailed probability structure  we believed that the essential elements of all three models could be generalized in a single probability model.</S><S sid =""60"" ssid = ""1"">In our statistical model  trees are generated according to a process similar to that described in (Collins 1996  1997).</S><S sid =""39"" ssid = ""7"">For example  the coreference relation between &quot;Nance&quot; and &quot;a paid consultant to ABC News&quot; is indicated by &quot;per-desc-of.&quot; In this case  because the argument does not connect directly to the relation  the intervening nodes are labeled with semantics &quot;-ptr&quot; to indicate the connection.</S>",['Method_Citation']
8,A00-2030,P05-1053,0,2000,0,"Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees","Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees","['110', '41', '57', '51', '46']","<S sid =""110"" ssid = ""2"">Technical agents for part of this work were Fort Huachucha and AFRL under contract numbers DABT63-94-C-0062  F30602-97-C-0096  and 4132-BBN-001.</S><S sid =""41"" ssid = ""1"">To train our integrated model  we required a large corpus of augmented parse trees.</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S><S sid =""51"" ssid = ""11"">To produce a corpus of augmented parse trees  we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus  now annotated with complete augmented trees like that in Figure 3.</S><S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S>",['Method_Citation']
9,A00-2030,P05-1053,0,2000,0,"Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model","Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model","['51', '81', '0', '61', '74']","<S sid =""51"" ssid = ""11"">To produce a corpus of augmented parse trees  we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus  now annotated with complete augmented trees like that in Figure 3.</S><S sid =""81"" ssid = ""3"">For modifier constituents  the mixture components are: For part-of-speech tags  the mixture components are: Finally  for word features  the mixture components are:</S><S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S><S sid =""61"" ssid = ""2"">The detailed probability structure differs  however  in that it was designed to jointly perform part-of-speech tagging  name finding  syntactic parsing  and relation finding in a single process.</S><S sid =""74"" ssid = ""15"">The categories for head constituents  clâ€ž are predicted based solely on the category of the parent node  cp: Modifier constituent categories  cm  are predicted based on their parent node  cp  the head constituent of their parent node  chp  the previously generated modifier  câ€ž _1  and the head word of their parent  wp.</S>",['Method_Citation']
10,A00-2030,H05-1094,0,2000,0,"(Miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. Part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable","(Miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. Part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable","['32', '61', '19', '101', '51']","<S sid =""32"" ssid = ""15"">Because generative statistical models had already proven successful for each of the first three stages  we were optimistic that some of their properties â€” especially their ability to learn from large amounts of data  and their robustness when presented with unexpected inputs â€” would also benefit semantic analysis.</S><S sid =""61"" ssid = ""2"">The detailed probability structure differs  however  in that it was designed to jointly perform part-of-speech tagging  name finding  syntactic parsing  and relation finding in a single process.</S><S sid =""19"" ssid = ""2"">Currently  the prevailing architecture for dividing sentential processing is a four-stage pipeline consisting of: Since we were interested in exploiting recent advances in parsing  replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility.</S><S sid =""101"" ssid = ""6"">We evaluated part-of-speech tagging and parsing accuracy on the Wall Street Journal using a now standard procedure (see Collins 97)  and evaluated name finding accuracy on the MUC7 named entity test.</S><S sid =""51"" ssid = ""11"">To produce a corpus of augmented parse trees  we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus  now annotated with complete augmented trees like that in Figure 3.</S>",['Method_Citation']
11,A00-2030,P04-1054,0,2000,0,Miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,Miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,"['0', '54', '81', '57', '46']","<S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S><S sid =""54"" ssid = ""3"">These steps are given below:</S><S sid =""81"" ssid = ""3"">For modifier constituents  the mixture components are: For part-of-speech tags  the mixture components are: Finally  for word features  the mixture components are:</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S><S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S>",['Method_Citation']
12,A00-2030,P04-1054,0,2000,0,"WhereasMiller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance","Whereas Miller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance","['30', '46', '105', '106', '11']","<S sid =""30"" ssid = ""13"">Although each model differed in its detailed probability structure  we believed that the essential elements of all three models could be generalized in a single probability model.</S><S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S><S sid =""105"" ssid = ""2"">A single model proved capable of performing all necessary sentential processing  both syntactic and semantic.</S><S sid =""106"" ssid = ""3"">We were able to use the Penn TREEBANK to estimate the syntactic parameters; no additional syntactic training was required.</S><S sid =""11"" ssid = ""1"">We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh  1998).</S>",['Method_Citation']
13,A00-2030,W05-0602,0,"Miller et al, 2000",0,"The syntactic model in (Miller et al, 2000) is similar to Collins?, but doesnot use features like sub cat frames and distance measures","The syntactic model in (Miller et al, 2000) is similar to Collins', but does not use features like subcat frames and distance measures","['105', '0', '46', '57', '54']","<S sid =""105"" ssid = ""2"">A single model proved capable of performing all necessary sentential processing  both syntactic and semantic.</S><S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S><S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S><S sid =""54"" ssid = ""3"">These steps are given below:</S>",['Results_Citation']
14,A00-2030,N07-2041,0,"Miller et al, 2000",0,"Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2","Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2","['46', '0', '57', '51', '105']","<S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S><S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S><S sid =""51"" ssid = ""11"">To produce a corpus of augmented parse trees  we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus  now annotated with complete augmented trees like that in Figure 3.</S><S sid =""105"" ssid = ""2"">A single model proved capable of performing all necessary sentential processing  both syntactic and semantic.</S>",['Method_Citation']
15,A00-2030,W10-2924,0,2000,0,Miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,Miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,"['0', '57', '46', '51', '81']","<S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S><S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S><S sid =""51"" ssid = ""11"">To produce a corpus of augmented parse trees  we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus  now annotated with complete augmented trees like that in Figure 3.</S><S sid =""81"" ssid = ""3"">For modifier constituents  the mixture components are: For part-of-speech tags  the mixture components are: Finally  for word features  the mixture components are:</S>",['Method_Citation']
16,A00-2030,W06-0508,0,"Miller et al, 2000",0,"Most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as SVO, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (Miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (Gamallo et al, 2002)","Most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as SVO, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (Miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (Gamallo et al, 2002)","['51', '32', '61', '11', '26']","<S sid =""51"" ssid = ""11"">To produce a corpus of augmented parse trees  we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus  now annotated with complete augmented trees like that in Figure 3.</S><S sid =""32"" ssid = ""15"">Because generative statistical models had already proven successful for each of the first three stages  we were optimistic that some of their properties â€” especially their ability to learn from large amounts of data  and their robustness when presented with unexpected inputs â€” would also benefit semantic analysis.</S><S sid =""61"" ssid = ""2"">The detailed probability structure differs  however  in that it was designed to jointly perform part-of-speech tagging  name finding  syntactic parsing  and relation finding in a single process.</S><S sid =""11"" ssid = ""1"">We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh  1998).</S><S sid =""26"" ssid = ""9"">We were already using a generative statistical model for part-of-speech tagging (Weischedel et al. 1993)  and more recently  had begun using a generative statistical model for name finding (Bikel et al.</S>",['Method_Citation']
17,A00-2030,P07-1055,0,"Miller et al, 2000",0,"This includes parsing and relation extraction (Miller et al, 2000), entity labeling and relation extraction (Roth and Yih, 2004), and part-of-speech tagging and chunking (Sutton et al, 2004)","This includes parsing and relation extraction (Miller et al, 2000), entity labeling and relation extraction (Roth and Yih, 2004), and part-of-speech tagging and chunking (Sutton et al, 2004)","['110', '106', '46', '57', '105']","<S sid =""110"" ssid = ""2"">Technical agents for part of this work were Fort Huachucha and AFRL under contract numbers DABT63-94-C-0062  F30602-97-C-0096  and 4132-BBN-001.</S><S sid =""106"" ssid = ""3"">We were able to use the Penn TREEBANK to estimate the syntactic parameters; no additional syntactic training was required.</S><S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S><S sid =""105"" ssid = ""2"">A single model proved capable of performing all necessary sentential processing  both syntactic and semantic.</S>",['Method_Citation']
18,A00-2030,W05-0636,0,2000,0,"For example, Miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks","For example, Miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks","['54', '55', '0', '62', '7']","<S sid =""54"" ssid = ""3"">These steps are given below:</S><S sid =""55"" ssid = ""1"">syntactic modifier of the other  the inserted node serves to indicate the relation as well as the argument.</S><S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S><S sid =""62"" ssid = ""3"">For each constituent  the head is generated first  followed by the modifiers  which are generated from the head outward.</S><S sid =""7"" ssid = ""5"">The technique was benchmarked in the Seventh Message Understanding Conference (MUC-7) in 1998.</S>",['Method_Citation']
19,A00-2030,N06-1037,0,2000,0,Miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,Miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,"['106', '110', '46', '105', '57']","<S sid =""106"" ssid = ""3"">We were able to use the Penn TREEBANK to estimate the syntactic parameters; no additional syntactic training was required.</S><S sid =""110"" ssid = ""2"">Technical agents for part of this work were Fort Huachucha and AFRL under contract numbers DABT63-94-C-0062  F30602-97-C-0096  and 4132-BBN-001.</S><S sid =""46"" ssid = ""6"">Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.</S><S sid =""105"" ssid = ""2"">A single model proved capable of performing all necessary sentential processing  both syntactic and semantic.</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S>","['Aim_Citation', 'Results_Citation']"
