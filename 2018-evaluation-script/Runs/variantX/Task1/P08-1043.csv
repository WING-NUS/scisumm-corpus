Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P08-1043,C10-1045,0,2008,0,"Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew","Finally, we note that simple weighting gives nearly a 2% F1 improvement, whereas Goldberg and Tsarfaty (2008) found that unweighted lattices were more effective for Hebrew","['54', '89', '179', '183', '148']","<S sid =""54"" ssid = ""1"">A Hebrew surface token may have several readings  each of which corresponding to a sequence of segments and their corresponding PoS tags.</S><S sid =""89"" ssid = ""21"">Each connected path (l1 ... lk) E L corresponds to one morphological segmentation possibility of W. The Parser Given a sequence of input tokens W = w1 ... wn and a morphological analyzer  we look for the most probable parse tree π s.t.</S><S sid =""179"" ssid = ""17"">On the surface  our model may seem as a special case of Cohen and Smith in which α = 0.</S><S sid =""183"" ssid = ""21"">Cohen and Smith approach this by introducing the α hyperparameter  which performs best when optimized independently for each sentence (cf.</S><S sid =""148"" ssid = ""26"">Removing the leaves from the resulting tree yields a parse for L under G  with the desired probabilities.</S>",['Implication_Citation']
2,P08-1043,P11-1141,0,2008,0,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,Goldberg and Tsarfaty (2008) showed that a single model for morphological segmentation and syntactic parsing of Hebrew yielded an error reduction of 12% over the best pipelined models,"['80', '33', '156', '169', '188']","<S sid =""80"" ssid = ""12"">In speech recognition the arcs of the lattice are typically weighted in order to indicate the probability of specific transitions.</S><S sid =""33"" ssid = ""12"">The current work treats both segmental and super-segmental phenomena  yet we note that there may be more adequate ways to treat supersegmental phenomena assuming Word-Based morphology as we explore in (Tsarfaty and Goldberg  2008).</S><S sid =""156"" ssid = ""34"">To evaluate the performance on the segmentation task  we report SEG  the standard harmonic means for segmentation Precision and Recall F1 (as defined in Bar-Haim et al. (2005); Tsarfaty (2006)) as well as the segmentation accuracy SEGTok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by Cohen and Smith (2007)).</S><S sid =""169"" ssid = ""7"">Table 2 compares the performance of our system on the setup of Cohen and Smith (2007) to the best results reported by them for the same tasks.</S><S sid =""188"" ssid = ""2"">The overall performance of our joint framework demonstrates that a probability distribution obtained over mere syntactic contexts using a Treebank grammar and a data-driven lexicon outperforms upper bounds proposed by previous joint disambiguation systems and achieves segmentation and parsing results on a par with state-of-the-art standalone applications results.</S>",['Implication_Citation']
3,P08-1043,P10-1074,0,2008,0,"Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMMbased approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of He brew, based on lattice parsing","Zhang and Clark (2008) built a perceptron-based joint segmenter and part-of-speech (POS) tagger for Chinese, and Toutanova and Cherry (2009) learned a joint model of lemmatization and POS tagging which outperformed a pipelined model. Adler and Elhadad (2006) presented an HMM-based approach for unsupervised joint morphological segmentation and tagging of Hebrew, and Goldberg and Tsarfaty (2008) developed a joint model of segmentation, tagging and parsing of Hebrew, based on lattice parsing","['130', '80', '48', '176', '97']","<S sid =""130"" ssid = ""8"">To facilitate the comparison of our results to those reported by (Cohen and Smith  2007) we use their data set in which 177 empty and “malformed”7 were removed.</S><S sid =""80"" ssid = ""12"">In speech recognition the arcs of the lattice are typically weighted in order to indicate the probability of specific transitions.</S><S sid =""48"" ssid = ""6"">Tsarfaty (2006) was the first to demonstrate that fully automatic Hebrew parsing is feasible using the newly available 5000 sentences treebank.</S><S sid =""176"" ssid = ""14"">Furthermore  the combination of pruning and vertical markovization of the grammar outperforms the Oracle results reported by Cohen and Smith.</S><S sid =""97"" ssid = ""29"">Thus our proposed model is a proper model assigning probability mass to all (7r  L) pairs  where 7r is a parse tree and L is the one and only lattice that a sequence of characters (and spaces) W over our alpha-beth gives rise to.</S>",['Results_Citation']
4,P08-1043,P11-1089,0,2008,0,Goldberg and Tsarfaty (2008) pro pose a generative joint model,Goldberg and Tsarfaty (2008) propose a generative joint model,"['49', '163', '71', '33', '148']","<S sid =""49"" ssid = ""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid =""163"" ssid = ""1"">The accuracy results for segmentation  tagging and parsing using our different models and our standard data split are summarized in Table 1.</S><S sid =""71"" ssid = ""3"">This is by now a fairly standard representation for multiple morphological segmentation of Hebrew utterances (Adler  2001; Bar-Haim et al.  2005; Smith et al.  2005; Cohen and Smith  2007; Adler  2007).</S><S sid =""33"" ssid = ""12"">The current work treats both segmental and super-segmental phenomena  yet we note that there may be more adequate ways to treat supersegmental phenomena assuming Word-Based morphology as we explore in (Tsarfaty and Goldberg  2008).</S><S sid =""148"" ssid = ""26"">Removing the leaves from the resulting tree yields a parse for L under G  with the desired probabilities.</S>",['Method_Citation']
5,P08-1043,W10-1404,0,2008,0,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,Goldberg and Tsarfaty (2008) concluded that an integrated model of morphological disambiguation and syntactic parsing in Hebrew Treebank parsing improves the results of a pipelined approach,"['180', '156', '45', '157', '169']","<S sid =""180"" ssid = ""18"">However  there is a crucial difference: the morphological probabilities in their model come from discriminative models based on linear context.</S><S sid =""156"" ssid = ""34"">To evaluate the performance on the segmentation task  we report SEG  the standard harmonic means for segmentation Precision and Recall F1 (as defined in Bar-Haim et al. (2005); Tsarfaty (2006)) as well as the segmentation accuracy SEGTok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by Cohen and Smith (2007)).</S><S sid =""45"" ssid = ""3"">Morphological disambiguators that consider a token in context (an utterance) and propose the most likely morphological analysis of an utterance (including segmentation) were presented by Bar-Haim et al. (2005)  Adler and Elhadad (2006)  Shacham and Wintner (2007)  and achieved good results (the best segmentation result so far is around 98%).</S><S sid =""157"" ssid = ""35"">SEGTok(noH) is the segmentation accuracy ignoring mistakes involving the implicit definite article h.11 To evaluate our performance on the tagging task we report CPOS and FPOS corresponding to coarse- and fine-grained PoS tagging results (F1) measure.</S><S sid =""169"" ssid = ""7"">Table 2 compares the performance of our system on the setup of Cohen and Smith (2007) to the best results reported by them for the same tasks.</S>",['Method_Citation']
6,P08-1043,P11-2124,0,2008,0,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrewtext,Goldberg and Tsarfaty (2008) demonstrated the effectiveness of lattice parsing for jointly performing segmentation and parsing of Hebrew text,"['169', '156', '80', '161', '67']","<S sid =""169"" ssid = ""7"">Table 2 compares the performance of our system on the setup of Cohen and Smith (2007) to the best results reported by them for the same tasks.</S><S sid =""156"" ssid = ""34"">To evaluate the performance on the segmentation task  we report SEG  the standard harmonic means for segmentation Precision and Recall F1 (as defined in Bar-Haim et al. (2005); Tsarfaty (2006)) as well as the segmentation accuracy SEGTok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by Cohen and Smith (2007)).</S><S sid =""80"" ssid = ""12"">In speech recognition the arcs of the lattice are typically weighted in order to indicate the probability of specific transitions.</S><S sid =""161"" ssid = ""39"">We report the F1 value of both measures.</S><S sid =""67"" ssid = ""14"">Hence  we take the probability of the event fmnh analyzed as REL VB to be This means that we generate f and mnh independently depending on their corresponding PoS tags  and the context (as well as the syntactic relation between the two) is modeled via the derivation resulting in a sequence REL VB spanning the form fmnh. based on linear context.</S>",['Method_Citation']
7,P08-1043,P11-2124,0,"Goldberg and Tsarfaty, 2008",0,"Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","Following (Goldberg and Tsarfaty, 2008) we deal with the ambiguous affixation patterns in Hebrew by encoding the input sentence as a segmentation lattice","['88', '156', '36', '26', '73']","<S sid =""88"" ssid = ""20"">M(wi) = Li).</S><S sid =""156"" ssid = ""34"">To evaluate the performance on the segmentation task  we report SEG  the standard harmonic means for segmentation Precision and Recall F1 (as defined in Bar-Haim et al. (2005); Tsarfaty (2006)) as well as the segmentation accuracy SEGTok measure indicating the percentage of input tokens assigned the correct exact segmentation (as reported by Cohen and Smith (2007)).</S><S sid =""36"" ssid = ""15"">Furthermore  the systematic way in which particles are prefixed to one another and onto an open-class category gives rise to a distinct sort of morphological ambiguity: space-delimited tokens may be ambiguous between several different segmentation possibilities.</S><S sid =""26"" ssid = ""5"">The relativizer f(“that”) for example  may attach to an arbitrarily long relative clause that goes beyond token boundaries.</S><S sid =""73"" ssid = ""5"">We use double-circles to indicate the space-delimited token boundaries.</S>",['Method_Citation']
8,P08-1043,P12-2002,0,2008,0,2The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),The complete set of analyses for this word is provided in Goldberg and Tsarfaty (2008),"['80', '38', '108', '49', '158']","<S sid =""80"" ssid = ""12"">In speech recognition the arcs of the lattice are typically weighted in order to indicate the probability of specific transitions.</S><S sid =""38"" ssid = ""17"">The form mnh itself can be read as at least three different verbs (“counted”  “appointed”  “was appointed”)  a noun (“a portion”)  and a possessed noun (“her kind”).</S><S sid =""108"" ssid = ""40"">Secondly  some segments in a proposed segment sequence may in fact be seen lexical events  i.e.  for some p tag Prf(p —* (s  p)) > 0  while other segments have never been observed as a lexical event before.</S><S sid =""49"" ssid = ""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S><S sid =""158"" ssid = ""36"">Evaluating parsing results in our joint framework  as argued by Tsarfaty (2006)  is not trivial under the joint disambiguation task  as the hypothesized yield need not coincide with the correct one.</S>",['Method_Citation']
9,P08-1043,D12-1046,0,"Goldberg and Tsarfaty, 2008",0,"A study that is closely related toours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","A study that is closely related to ours is (Goldberg and Tsarfaty, 2008), where a single generative model was proposed for joint morphological segmentation and syntactic parsing for Hebrew","['182', '101', '163', '58', '44']","<S sid =""182"" ssid = ""20"">In addition  as the CRF and PCFG look at similar sorts of information from within two inherently different models  they are far from independent and optimizing their product is meaningless.</S><S sid =""101"" ssid = ""33"">The possible analyses of a surface token pose constraints on the analyses of specific segments.</S><S sid =""163"" ssid = ""1"">The accuracy results for segmentation  tagging and parsing using our different models and our standard data split are summarized in Table 1.</S><S sid =""58"" ssid = ""5"">Such tag sequences are often treated as “complex tags” (e.g.</S><S sid =""44"" ssid = ""2"">Such analyzers propose multiple segmentation possibilities and their corresponding analyses for a token in isolation but have no means to determine the most likely ones.</S>",['Method_Citation']
10,P08-1043,D12-1133,0,2008,0,"Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing","['180', '195', '80', '98', '191']","<S sid =""180"" ssid = ""18"">However  there is a crucial difference: the morphological probabilities in their model come from discriminative models based on linear context.</S><S sid =""195"" ssid = ""9"">We further thank Khalil Simaan (ILLCUvA) for his careful advise concerning the formal details of the proposal.</S><S sid =""80"" ssid = ""12"">In speech recognition the arcs of the lattice are typically weighted in order to indicate the probability of specific transitions.</S><S sid =""98"" ssid = ""30"">The Grammar Our parser looks for the most likely tree spanning a single path through the lattice of which the yield is a sequence of lexemes.</S><S sid =""191"" ssid = ""5"">In the current work morphological analyses and lexical probabilities are derived from a small Treebank  which is by no means the best way to go.</S>",['Implication_Citation']
11,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"4), and in a more realistic one in which parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008) (Sec","Parsing and segmentation are handled jointly by the parser (Goldberg and Tsarfaty, 2008)","['120', '180', '158', '157', '49']","<S sid =""120"" ssid = ""52"">From now on all lattice arcs are tagged segments and the assignment of probability P(p —* (s  p)) to lattice arcs proceeds as usual.4 A rather pathological case is when our lexical heuristics prune away all segmentation possibilities and we remain with an empty lattice.</S><S sid =""180"" ssid = ""18"">However  there is a crucial difference: the morphological probabilities in their model come from discriminative models based on linear context.</S><S sid =""158"" ssid = ""36"">Evaluating parsing results in our joint framework  as argued by Tsarfaty (2006)  is not trivial under the joint disambiguation task  as the hypothesized yield need not coincide with the correct one.</S><S sid =""157"" ssid = ""35"">SEGTok(noH) is the segmentation accuracy ignoring mistakes involving the implicit definite article h.11 To evaluate our performance on the tagging task we report CPOS and FPOS corresponding to coarse- and fine-grained PoS tagging results (F1) measure.</S><S sid =""49"" ssid = ""7"">Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.</S>",['Method_Citation']
12,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","It is the same grammar as described in (Goldberg and Tsarfaty, 2008)","['14', '26', '54', '130', '80']","<S sid =""14"" ssid = ""10"">The input for the segmentation task is however highly ambiguous for Semitic languages  and surface forms (tokens) may admit multiple possible analyses as in (BarHaim et al.  2007; Adler and Elhadad  2006).</S><S sid =""26"" ssid = ""5"">The relativizer f(“that”) for example  may attach to an arbitrarily long relative clause that goes beyond token boundaries.</S><S sid =""54"" ssid = ""1"">A Hebrew surface token may have several readings  each of which corresponding to a sequence of segments and their corresponding PoS tags.</S><S sid =""130"" ssid = ""8"">To facilitate the comparison of our results to those reported by (Cohen and Smith  2007) we use their data set in which 177 empty and “malformed”7 were removed.</S><S sid =""80"" ssid = ""12"">In speech recognition the arcs of the lattice are typically weighted in order to indicate the probability of specific transitions.</S>",['Method_Citation']
14,P08-1043,E09-1038,0,2008,0,"Several studies followed this line, (Cohen and Smith, 2007) the most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","The most recent of which is Goldberg and Tsarfaty (2008), who presented a model based on unweighted lattice parsing for performing the joint task","['154', '194', '97', '130', '149']","<S sid =""154"" ssid = ""32"">For all grammars  we use fine-grained PoS tags indicating various morphological features annotated therein.</S><S sid =""194"" ssid = ""8"">Acknowledgments We thank Meni Adler and Michael Elhadad (BGU) for helpful comments and discussion.</S><S sid =""97"" ssid = ""29"">Thus our proposed model is a proper model assigning probability mass to all (7r  L) pairs  where 7r is a parse tree and L is the one and only lattice that a sequence of characters (and spaces) W over our alpha-beth gives rise to.</S><S sid =""130"" ssid = ""8"">To facilitate the comparison of our results to those reported by (Cohen and Smith  2007) we use their data set in which 177 empty and “malformed”7 were removed.</S><S sid =""149"" ssid = ""27"">We use a patched version of BitPar allowing for direct input of probabilities instead of counts.</S>",['Method_Citation']
15,P08-1043,E09-1038,0,2008,0,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,Goldberg and Tsarfaty (2008) use a data-driven morphological analyzer derived from the tree bank,"['5', '76', '180', '108', '133']","<S sid =""5"" ssid = ""1"">Current state-of-the-art broad-coverage parsers assume a direct correspondence between the lexical items ingrained in the proposed syntactic analyses (the yields of syntactic parse-trees) and the spacedelimited tokens (henceforth  ‘tokens’) that constitute the unanalyzed surface forms (utterances).</S><S sid =""76"" ssid = ""8"">Furthermore  some of the arcs represent lexemes not present in the input tokens (e.g. h/DT  fl/POS)  however these are parts of valid analyses of the token (cf. super-segmental morphology section 2).</S><S sid =""180"" ssid = ""18"">However  there is a crucial difference: the morphological probabilities in their model come from discriminative models based on linear context.</S><S sid =""108"" ssid = ""40"">Secondly  some segments in a proposed segment sequence may in fact be seen lexical events  i.e.  for some p tag Prf(p —* (s  p)) > 0  while other segments have never been observed as a lexical event before.</S><S sid =""133"" ssid = ""11"">Morphological Analyzer Ideally  we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses.</S>",['Results_Citation']
16,P08-1043,E09-1038,0,2008,0,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,The model of Goldberg and Tsarfaty (2008) uses a morphological analyzer to constructs a lattice for each input token,"['80', '48', '181', '95', '54']","<S sid =""80"" ssid = ""12"">In speech recognition the arcs of the lattice are typically weighted in order to indicate the probability of specific transitions.</S><S sid =""48"" ssid = ""6"">Tsarfaty (2006) was the first to demonstrate that fully automatic Hebrew parsing is feasible using the newly available 5000 sentences treebank.</S><S sid =""181"" ssid = ""19"">Many morphological decisions are based on long distance dependencies  and when the global syntactic evidence disagrees with evidence based on local linear context  the two models compete with one another  despite the fact that the PCFG takes also local context into account.</S><S sid =""95"" ssid = ""27"">A compatible view is presented by Charniak et al. (1996) who consider the kind of probabilities a generative parser should get from a PoS tagger  and concludes that these should be P(w|t) “and nothing fancier”.3 In our setting  therefore  the Lattice is not used to induce a probability distribution on a linear context  but rather  it is used as a common-denominator of state-indexation of all segmentations possibilities of a surface form.</S><S sid =""54"" ssid = ""1"">A Hebrew surface token may have several readings  each of which corresponding to a sequence of segments and their corresponding PoS tags.</S>",['Implication_Citation']
17,P08-1043,E09-1038,0,"Goldberg and Tsarfaty, 2008",0,"Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parse val to use characters instead of space-delimited tokens as its basic units","Instead, we use the evaluation measure of (Tsarfaty, 2006), also used in (Goldberg and Tsarfaty, 2008), which is an adaptation of parseval to use characters instead of space-delimited tokens as its basic units","['164', '133', '22', '126', '173']","<S sid =""164"" ssid = ""2"">In addition we report for each model its performance on goldsegmented input (GS) to indicate the upper bound 11Overt definiteness errors may be seen as a wrong feature rather than as wrong constituent and it is by now an accepted standard to report accuracy with and without such errors. for the grammars’ performance on the parsing task.</S><S sid =""133"" ssid = ""11"">Morphological Analyzer Ideally  we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses.</S><S sid =""22"" ssid = ""1"">Segmental morphology Hebrew consists of seven particles m(“from”) f(“when”/“who”/“that”) h(“the”) w(“and”) k(“like”) l(“to”) and b(“in”). which may never appear in isolation and must always attach as prefixes to the following open-class category item we refer to as stem.</S><S sid =""126"" ssid = ""4"">When a comparison against previous results requires additional pre-processing  we state it explicitly to allow for the reader to replicate the reported results.</S><S sid =""173"" ssid = ""11"">The addition of vertical markovization enables non-pruned models to outperform all previously reported re12Cohen and Smith (2007) make use of a parameter (α) which is tuned separately for each of the tasks.</S>",['Method_Citation']
