Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
2,W06-2932,W06-2920,nan,"McDonald et al, 2006",0,"Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)","Introduce through post-processing ,e.g. through reattachment rules (Bick, 2006) or if the change increases overall parse tree probability (McDonald et al, 2006)","['64', '6', '7', '71', '2']","<S sid =""64"" ssid = ""2"">N/P: Allow non-projective/Force projective  S/A: Sequential labeling/Atomic labeling  M/B: Include morphology features/No morphology features. assignment of edge labels instead of individual assignment  and a rich feature set that incorporates morphological properties when available.</S><S sid =""6"" ssid = ""2"">With the availability of resources such as the Penn WSJ Treebank  much of the focus in the parsing community had been on producing syntactic representations based on phrase-structure.</S><S sid =""7"" ssid = ""3"">However  recently their has been a revived interest in parsing models that produce dependency graph representations of sentences  which model words and their arguments through directed edges (Hudson  1984; Mel'ˇcuk  1988).</S><S sid =""71"" ssid = ""9"">Including rich morphology features naturally helped with highly inflected languages  in particular Spanish  Arabic  Turkish  Slovene and to a lesser extent Dutch and Portuguese.</S><S sid =""2"" ssid = ""2"">The first stage based on the unlabeled dependency parsing models described by McDonald and Pereira (2006) augmented with morphological features for a subset of the languages.</S>",['Implication_Citation']
3,W06-2932,W06-2920,0,2006,0,Table 5 shows the official results for submitted parser outputs.31 The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),Table 5 shows the official results for submitted parser outputs. The two participant groups with the highest total score are McDonald et al (2006) and Nivre et al (2006),"['71', '20', '7', '78', '61']","<S sid =""71"" ssid = ""9"">Including rich morphology features naturally helped with highly inflected languages  in particular Spanish  Arabic  Turkish  Slovene and to a lesser extent Dutch and Portuguese.</S><S sid =""20"" ssid = ""2"">This system is primarily based on the parsing models described by McDonald and Pereira (2006).</S><S sid =""7"" ssid = ""3"">However  recently their has been a revived interest in parsing models that produce dependency graph representations of sentences  which model words and their arguments through directed edges (Hudson  1984; Mel'ˇcuk  1988).</S><S sid =""78"" ssid = ""16"">Even with this improvement  the labeling of verb dependents remains the highest source of error.</S><S sid =""61"" ssid = ""9"">In fact  for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).</S>",['Implication_Citation']
4,W06-2932,W06-2920,0,2006,0,"Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences","Even though McDonald et al (2006) and Nivre et al (2006) obtained very similar overall scores, a more detailed look at their performance shows clear differences","['20', '92', '28', '88', '10']","<S sid =""20"" ssid = ""2"">This system is primarily based on the parsing models described by McDonald and Pereira (2006).</S><S sid =""92"" ssid = ""14"">For example  in the test sentence Lo que decia Mae West de si misma podriamos decirlo tambi´en los hombres:...  decia’s head is given as decirlo  although the main verbs of relative clauses are normally dependent on what the relative modifies  in this case the article Lo.</S><S sid =""28"" ssid = ""10"">Consider a proposed dependency of a dependent xj on the head xi  each with morphological features Mj and Mi respectively.</S><S sid =""88"" ssid = ""10"">Nevertheless  this very preliminary experiment suggests that wider-range features may be useful in improving the recognition of overall sentence structure.</S><S sid =""10"" ssid = ""6"">Dependency graphs also encode much of the deep syntactic information needed for further processing.</S>",['Results_Citation']
5,W06-2932,W08-1007,0,2006,0,"The high est score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (anda different policy regarding the inclusion of punctuation) .The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)","The highest score on parsing German in the CoNLL-X shared task was obtained by the system of McDonald et al (2006) with a LAS of 87.34 based on the TIGER tree bank, but we want to stress that these results are not comparable due to different data sets (and a different policy regarding the inclusion of punctuation). The constituency versions were evaluated according to the labeled recall (LR), labeled precision (LP) and labeled F-score (LF)","['13', '36', '64', '30', '72']","<S sid =""13"" ssid = ""9"">We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al.  2006; Hajiˇc et al.  2004; Simov et al.  2005; Simov and Osenova  2003; Chen et al.  2003; B¨ohmov´a et al.  2003; Kromann  2003; van der Beek et al.  2002; Brants et al.  2002; Kawata and Bartels  2000; Afonso et al.  2002; Dˇzeroski et al.  2006; Civit Torruella and MartiAntonin  2002; Nilsson et al.  2005; Oflazer et al.  2003; Atalay et al.  2003).</S><S sid =""36"" ssid = ""5"">However  in a two stage system we can incorporate features over the entire output of the unlabeled parser since that structure is fixed as input.</S><S sid =""64"" ssid = ""2"">N/P: Allow non-projective/Force projective  S/A: Sequential labeling/Atomic labeling  M/B: Include morphology features/No morphology features. assignment of edge labels instead of individual assignment  and a rich feature set that incorporates morphological properties when available.</S><S sid =""30"" ssid = ""12"">These features play the obvious role of explicitly modeling consistencies and commonalities between a head and its dependents in terms of attributes like gender  case  or number.</S><S sid =""72"" ssid = ""10"">Derived morphological features improved accuracy in all these languages by 1-3% absolute.</S>",['Method_Citation']
6,W06-2932,W09-1210,0,2006,nan,McDonald et al (2006) use an additional algorithm,McDonald et al (2006) use an additional algorithm,"['109', '60', '107', '86', '101']","<S sid =""109"" ssid = ""6"">The current system simply includes all morphological bi-gram features.</S><S sid =""60"" ssid = ""8"">Furthermore  these results show that a twostage system can achieve a relatively high performance.</S><S sid =""107"" ssid = ""4"">It is our hypothesis that for languages with fine-grained label sets  joint parsing and labeling will improve performance.</S><S sid =""86"" ssid = ""8"">Unlabeled accuracy for all verbs increases from 71% to 73% and for all conjunctions from 71% to 74%.</S><S sid =""101"" ssid = ""23"">For example if we train on 200  400  800 and the full training set  labeled accuracies are 54%  60%  62% and 67%.</S>",['Method_Citation']
7,W06-2932,W12-3407,0,"McDonald et al, 2006",0,"Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)","Regarding the data-driven parsers, we have made use of MaltParser (Nivre et al, 2007b) and MST Parser (McDonald et al, 2006), two state of the art dependency parsers representing two dominant approaches in data-driven dependency parsing, and that have been successfully applied to typologically different languages and tree banks (McDonald and Nivre, 2007)","['86', '72', '101', '100', '64']","<S sid =""86"" ssid = ""8"">Unlabeled accuracy for all verbs increases from 71% to 73% and for all conjunctions from 71% to 74%.</S><S sid =""72"" ssid = ""10"">Derived morphological features improved accuracy in all these languages by 1-3% absolute.</S><S sid =""101"" ssid = ""23"">For example if we train on 200  400  800 and the full training set  labeled accuracies are 54%  60%  62% and 67%.</S><S sid =""100"" ssid = ""22"">The fact that Arabic has only 1500 training instances might also be problematic.</S><S sid =""64"" ssid = ""2"">N/P: Allow non-projective/Force projective  S/A: Sequential labeling/Atomic labeling  M/B: Include morphology features/No morphology features. assignment of edge labels instead of individual assignment  and a rich feature set that incorporates morphological properties when available.</S>",['Method_Citation']
8,W06-2932,I08-1012,0,"McDonald et al, 2006",0,"In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)? s parser, (McDonald et al., 2006)? s parser, and so on","In fact, our approach can also be applied to other parsers, such as (Yamada and Matsumoto, 2003)'s parser, (McDonald et al., 2006)'s parser, and so on","['66', '18', '30', '82', '41']","<S sid =""66"" ssid = ""4"">These results report the average labeled and unlabeled precision for the 10 languages with the smallest training sets.</S><S sid =""18"" ssid = ""14"">We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X)  pages 216–220  New York City  June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective  both of which are true in the data sets we use.</S><S sid =""30"" ssid = ""12"">These features play the obvious role of explicitly modeling consistencies and commonalities between a head and its dependents in terms of attributes like gender  case  or number.</S><S sid =""82"" ssid = ""4"">These weaknesses are not surprising  since these decisions encode the more global aspects of sentence structure: arrangement of clauses and adverbial dependents in multi-clause sentences  and prepositional phrase attachment.</S><S sid =""41"" ssid = ""10"">To model this we treat the labeling of the edges (i  j1)  ...   (i  jM) as a sequence labeling problem  We use a first-order Markov factorization of the score s(l(i jm)  l(i jm�1)  i  y  x) in which each factor is the score of labeling the adjacent edges (i  jm) and (i  jm−1) in the tree y.</S>",['Method_Citation']
11,W06-2932,N07-1050,0,"McDonald et al, 2006",0,"We have shown that, for languages with a7McDonald et al (2006) use post-processing for non projective dependencies and for labeling",McDonald et al (2006) use post-processing for non-projective dependencies and for labeling,"['107', '72', '51', '91', '60']","<S sid =""107"" ssid = ""4"">It is our hypothesis that for languages with fine-grained label sets  joint parsing and labeling will improve performance.</S><S sid =""72"" ssid = ""10"">Derived morphological features improved accuracy in all these languages by 1-3% absolute.</S><S sid =""51"" ssid = ""20"">Note that many of these features are beyond the scope of the edge based factorizations of the unlabeled parser.</S><S sid =""91"" ssid = ""13"">In doing this preliminary analysis  we noticed some inconsistencies in the reference dependency structures.</S><S sid =""60"" ssid = ""8"">Furthermore  these results show that a twostage system can achieve a relatively high performance.</S>",['Method_Citation']
12,W06-2932,D07-1122,0,"McDonald et al, 2006",0,"As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem","As described in (McDonald et al, 2006), we treat the labeling of dependencies as a sequence labeling problem","['86', '72', '90', '69', '71']","<S sid =""86"" ssid = ""8"">Unlabeled accuracy for all verbs increases from 71% to 73% and for all conjunctions from 71% to 74%.</S><S sid =""72"" ssid = ""10"">Derived morphological features improved accuracy in all these languages by 1-3% absolute.</S><S sid =""90"" ssid = ""12"">We need to look more carefully at verb features that may be useful here  in particular features that distinguish finite and non-finite forms.</S><S sid =""69"" ssid = ""7"">However  if we only allow projective parses  do not use morphological features and label edges with a simple atomic classifier  the overall drop in performance becomes significant (row 5 versus row 1).</S><S sid =""71"" ssid = ""9"">Including rich morphology features naturally helped with highly inflected languages  in particular Spanish  Arabic  Turkish  Slovene and to a lesser extent Dutch and Portuguese.</S>",['Method_Citation']
14,W06-2932,D07-1015,0,2006,0,5It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,It should be noted that McDonald et al (2006) use a richer feature set that is incomparable to our features,"['72', '18', '86', '93', '100']","<S sid =""72"" ssid = ""10"">Derived morphological features improved accuracy in all these languages by 1-3% absolute.</S><S sid =""18"" ssid = ""14"">We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X)  pages 216–220  New York City  June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective  both of which are true in the data sets we use.</S><S sid =""86"" ssid = ""8"">Unlabeled accuracy for all verbs increases from 71% to 73% and for all conjunctions from 71% to 74%.</S><S sid =""93"" ssid = ""15"">A quick look at unlabeled attachment accuracies indicate that errors in Arabic parsing are the most common across all languages: prepositions (62%)  conjunctions (69%) and to a lesser extent verbs (73%).</S><S sid =""100"" ssid = ""22"">The fact that Arabic has only 1500 training instances might also be problematic.</S>",['Implication_Citation']
18,W06-2932,D10-1004,0,2006,0,"Entries marked with? are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)","Entries marked with are the highest reported in the literature, to the best of our knowledge, beating (sometimes slightly) McDonald et al (2006), Martins et al (2008), Martins et al (2009), and, in the case of English Proj., also the third-order parser of Koo and Collins (2010), which achieves 93.04% on that dataset (their experiments in Czech are not comparable, since the datasets are different)","['109', '61', '0', '48', '93']","<S sid =""109"" ssid = ""6"">The current system simply includes all morphological bi-gram features.</S><S sid =""61"" ssid = ""9"">In fact  for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).</S><S sid =""0"" ssid = ""0"">Multilingual Dependency Analysis with a Two-Stage Discriminative Parser</S><S sid =""48"" ssid = ""17"">Is this the left/rightmost dependent for the head?</S><S sid =""93"" ssid = ""15"">A quick look at unlabeled attachment accuracies indicate that errors in Arabic parsing are the most common across all languages: prepositions (62%)  conjunctions (69%) and to a lesser extent verbs (73%).</S>",['Method_Citation']
19,W06-2932,P08-1108,0,"McDonald et al, 2006",0,"The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.2 2.3 Transition-Based Models","The specific graph-based model studied in this work is that presented by McDonald et al (2006), which factors scores over pairs of arcs (instead of just single arcs) and uses near exhaustive search for unlabeled parsing coupled with a separate classifier to label each arc. We call this system MSTParser, or simply MST for short, which is also the name of the freely available implementation.","['66', '82', '9', '61', '100']","<S sid =""66"" ssid = ""4"">These results report the average labeled and unlabeled precision for the 10 languages with the smallest training sets.</S><S sid =""82"" ssid = ""4"">These weaknesses are not surprising  since these decisions encode the more global aspects of sentence structure: arrangement of clauses and adverbial dependents in multi-clause sentences  and prepositional phrase attachment.</S><S sid =""9"" ssid = ""5"">Nivre (2005) gives an introduction to dependency representations of sentences and recent developments in dependency parsing strategies.</S><S sid =""61"" ssid = ""9"">In fact  for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).</S><S sid =""100"" ssid = ""22"">The fact that Arabic has only 1500 training instances might also be problematic.</S>",['Method_Citation']
20,W06-2932,P08-1108,0,"McDonald et al, 2006",0,"More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l)? Rk, where f is typically a bi nary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)","More precisely, dependency arcs (or pairs of arcs) are first represented by a high dimensional feature vector f (i, j, l) Rk, where f is typically a binary feature vector over properties of the arc as well as the surrounding input (McDonald et al, 2005a; McDonald et al, 2006)","['32', '2', '69', '18', '66']","<S sid =""32"" ssid = ""1"">The second stage takes the output parse y for sentence x and classifies each edge (i  j) E y with a particular label l(i j).</S><S sid =""2"" ssid = ""2"">The first stage based on the unlabeled dependency parsing models described by McDonald and Pereira (2006) augmented with morphological features for a subset of the languages.</S><S sid =""69"" ssid = ""7"">However  if we only allow projective parses  do not use morphological features and label edges with a simple atomic classifier  the overall drop in performance becomes significant (row 5 versus row 1).</S><S sid =""18"" ssid = ""14"">We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X)  pages 216–220  New York City  June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective  both of which are true in the data sets we use.</S><S sid =""66"" ssid = ""4"">These results report the average labeled and unlabeled precision for the 10 languages with the smallest training sets.</S>",['Method_Citation']
