Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P05-1013,W05-1505,0,"Nivre and Nilsson, 2005",0,"Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","['51', '53', '37', '83', '75']","<S sid =""51"" ssid = ""22"">In the second scheme  Head+Path  we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.</S><S sid =""53"" ssid = ""24"">In the third and final scheme  denoted Path  we keep the extra infor2Note that this is a baseline for the parsing experiment only (Experiment 2).</S><S sid =""37"" ssid = ""8"">Here we use a slightly different notion of lift  applying to individual arcs and moving their head upwards one step at a time: Intuitively  lifting an arc makes the word wk dependent on the head wi of its original head wj (which is unique in a well-formed dependency graph)  unless wj is a root in which case the operation is undefined (but then wj —* wk is necessarily projective if the dependency graph is well-formed).</S><S sid =""83"" ssid = ""10"">It is worth noting that  although nonprojective constructions are less frequent in DDT than in PDT  they seem to be more deeply nested  since only about 80% can be projectivized with a single lift  while almost 95% of the non-projective arcs in PDT only require a single lift.</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S>",['Implication_Citation']
2,P05-1013,P08-1006,0,"Nivre and Nilsson, 2005",0,"1http: //sourceforge.net/projects/mstparser Figure 1: CoNLL-X dependency tree Figure 2: Penn Treebank-style phrase structure tree KSDEP Sagae and Tsujii (2007)? s dependencyparser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","Sagae and Tsujii (2007)'s dependency parser, based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","['75', '38', '78', '34', '51']","<S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""38"" ssid = ""9"">Projectivizing a dependency graph by lifting nonprojective arcs is a nondeterministic operation in the general case.</S><S sid =""78"" ssid = ""5"">The entire treebank is used in the experiment  but only primary dependencies are considered.4 In all experiments  punctuation tokens are included in the data but omitted in evaluation scores.</S><S sid =""34"" ssid = ""5"">In the following  we use the notation wi wj to mean that (wi  r  wj) E A; r we also use wi wj to denote an arc with unspecified label and wi —*∗ wj for the reflexive and transitive closure of the (unlabeled) arc relation.</S><S sid =""51"" ssid = ""22"">In the second scheme  Head+Path  we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.</S>",['Implication_Citation']
3,P05-1013,W10-1401,0,"Nivre and Nilsson, 2005",0,"Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","['70', '23', '110', '25', '11']","<S sid =""70"" ssid = ""9"">Except for the left3The graphs satisfy all the well-formedness conditions given in section 2 except (possibly) connectedness.</S><S sid =""23"" ssid = ""19"">By applying an inverse transformation to the output of the parser  arcs with non-standard labels can be lowered to their proper place in the dependency graph  giving rise 1The dependency graph has been modified to make the final period a dependent of the main verb instead of being a dependent of a special root node for the sentence. to non-projective structures.</S><S sid =""110"" ssid = ""2"">The main result is that the combined system can recover non-projective dependencies with a precision sufficient to give a significant improvement in overall parsing accuracy  especially with respect to the exact match criterion  leading to the best reported performance for robust non-projective parsing of Czech.</S><S sid =""25"" ssid = ""21"">The rest of the paper is structured as follows.</S><S sid =""11"" ssid = ""7"">This is in contrast to dependency treebanks  e.g.</S>",['Results_Citation']
4,P05-1013,P12-3029,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees weuse the pseudo-projective parsing technique to trans form the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","['34', '24', '95', '77', '11']","<S sid =""34"" ssid = ""5"">In the following  we use the notation wi wj to mean that (wi  r  wj) E A; r we also use wi wj to denote an arc with unspecified label and wi —*∗ wj for the reflexive and transitive closure of the (unlabeled) arc relation.</S><S sid =""24"" ssid = ""20"">We call this pseudoprojective dependency parsing  since it is based on a notion of pseudo-projectivity (Kahane et al.  1998).</S><S sid =""95"" ssid = ""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S><S sid =""77"" ssid = ""4"">The Danish Dependency Treebank (DDT) comprises about 100K words of text selected from the Danish PAROLE corpus  with annotation of primary and secondary dependencies (Kromann  2003).</S><S sid =""11"" ssid = ""7"">This is in contrast to dependency treebanks  e.g.</S>",['Method_Citation']
5,P05-1013,W10-1403,0,"Nivre and Nilsson, 2005",0,"It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","['43', '65', '14', '18', '103']","<S sid =""43"" ssid = ""14"">Unlike Kahane et al. (1998)  we do not regard a projectivized representation as the final target of the parsing process.</S><S sid =""65"" ssid = ""4"">More details on the parsing algorithm can be found in Nivre (2003).</S><S sid =""14"" ssid = ""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%  the total proportion of non-projective arcs is normally only 1–2%.</S><S sid =""18"" ssid = ""14"">In addition  there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington  1990; Kahane et al.  1998; Duchier and Debusmann  2001; Holan et al.  2001; Hellwig  2003).</S><S sid =""103"" ssid = ""14"">On the other hand  given that all schemes have similar parsing accuracy overall  this means that the Path scheme is the least likely to introduce errors on projective arcs.</S>",['Method_Citation']
6,P05-1013,D08-1008,0,"Nivre and Nilsson, 2005",0,"To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson,2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson, 2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","['75', '42', '14', '55', '104']","<S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""42"" ssid = ""13"">Using the terminology of Kahane et al. (1998)  we say that jedna is the syntactic head of Z  while je is its linear head in the projectivized representation.</S><S sid =""14"" ssid = ""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%  the total proportion of non-projective arcs is normally only 1–2%.</S><S sid =""55"" ssid = ""26"">As can be seen from the last column in Table 1  both Head and Head+Path may theoretically lead to a quadratic increase in the number of distinct arc labels (Head+Path being worse than Head only by a constant factor)  while the increase is only linear in the case of Path.</S><S sid =""104"" ssid = ""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S>",['Method_Citation']
7,P05-1013,D07-1013,0,2005,0,",wn in O (n) time, producing a projective dependency graph satisfying conditions 1? 4 in section 2.1, possibly after adding arcs (0, i ,lr) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers) .Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to pre process training data and post-process parser output, so-called pseudo-projective parsing. To learn transition scores, these systems use discriminative learning methods ,e.g., memory-based learning or support vector machines","Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing","['11', '107', '14', '95', '66']","<S sid =""11"" ssid = ""7"">This is in contrast to dependency treebanks  e.g.</S><S sid =""107"" ssid = ""18"">Compared to related work on the recovery of long-distance dependencies in constituency-based parsing  our approach is similar to that of Dienes and Dubey (2003) in that the processing of non-local dependencies is partly integrated in the parsing process  via an extension of the set of syntactic categories  whereas most other approaches rely on postprocessing only.</S><S sid =""14"" ssid = ""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%  the total proportion of non-projective arcs is normally only 1–2%.</S><S sid =""95"" ssid = ""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S><S sid =""66"" ssid = ""5"">The choice between different actions is in general nondeterministic  and the parser relies on a memorybased classifier  trained on treebank data  to predict the next action based on features of the current parser configuration.</S>",['Method_Citation']
8,P05-1013,D07-1119,0,2005,0,"For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","['70', '81', '12', '78', '89']","<S sid =""70"" ssid = ""9"">Except for the left3The graphs satisfy all the well-formedness conditions given in section 2 except (possibly) connectedness.</S><S sid =""81"" ssid = ""8"">However  the overall percentage of non-projective arcs is less than 2% in PDT and less than 1% in DDT.</S><S sid =""12"" ssid = ""8"">Prague Dependency Treebank (Hajiˇc et al.  2001b)  Danish Dependency Treebank (Kromann  2003)  and the METU Treebank of Turkish (Oflazer et al.  2003)  which generally allow annotations with nonprojective dependency structures.</S><S sid =""78"" ssid = ""5"">The entire treebank is used in the experiment  but only primary dependencies are considered.4 In all experiments  punctuation tokens are included in the data but omitted in evaluation scores.</S><S sid =""89"" ssid = ""16"">The increase is generally higher for PDT than for DDT  which indicates a greater diversity in non-projective constructions.</S>",['Method_Citation']
9,P05-1013,N07-1050,0,"Nivre and Nilsson, 2005",0,"Whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","['12', '65', '5', '71', '66']","<S sid =""12"" ssid = ""8"">Prague Dependency Treebank (Hajiˇc et al.  2001b)  Danish Dependency Treebank (Kromann  2003)  and the METU Treebank of Turkish (Oflazer et al.  2003)  which generally allow annotations with nonprojective dependency structures.</S><S sid =""65"" ssid = ""4"">More details on the parsing algorithm can be found in Nivre (2003).</S><S sid =""5"" ssid = ""1"">It is sometimes claimed that one of the advantages of dependency grammar over approaches based on constituency is that it allows a more adequate treatment of languages with variable word order  where discontinuous syntactic constructions are more common than in languages like English (Mel’ˇcuk  1988; Covington  1990).</S><S sid =""71"" ssid = ""10"">For robustness reasons  the parser may output a set of dependency trees instead of a single tree. most dependent of the next input token  dependency type features are limited to tokens on the stack.</S><S sid =""66"" ssid = ""5"">The choice between different actions is in general nondeterministic  and the parser relies on a memorybased classifier  trained on treebank data  to predict the next action based on features of the current parser configuration.</S>",['Method_Citation']
10,P05-1013,W09-1207,0,"Nivre and Nilsson, 2005",0,"troduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","['51', '82', '86', '84', '70']","<S sid =""51"" ssid = ""22"">In the second scheme  Head+Path  we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.</S><S sid =""82"" ssid = ""9"">The last four columns in Table 3 show the distribution of nonprojective arcs with respect to the number of lifts required.</S><S sid =""86"" ssid = ""13"">As expected  the most informative encoding  Head+Path  gives the highest accuracy with over 99% of all non-projective arcs being recovered correctly in both data sets.</S><S sid =""84"" ssid = ""11"">In the second part of the experiment  we applied the inverse transformation based on breadth-first search under the three different encoding schemes.</S><S sid =""70"" ssid = ""9"">Except for the left3The graphs satisfy all the well-formedness conditions given in section 2 except (possibly) connectedness.</S>",['Implication_Citation']
11,P05-1013,E09-1034,0,"Nivre and Nilsson, 2005",0,"non projective (Nivre and Nilsson, 2005), we char ac terise a sense in which the structures appearing in tree banks can be viewed as being only? slightly? ill-nested","However, just as it has been noted that most non-projective structures appearing in practice are only 'slightly' non projective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in tree banks can be viewed as being only 'slightly' ill-nested","['85', '33', '60', '43', '44']","<S sid =""85"" ssid = ""12"">The results are given in Table 4.</S><S sid =""33"" ssid = ""4"">If (wi  r  wj) E A  we say that wi is the head of wj and wj a dependent of wi.</S><S sid =""60"" ssid = ""31"">In section 4 we evaluate these transformations with respect to projectivized dependency treebanks  and in section 5 they are applied to parser output.</S><S sid =""43"" ssid = ""14"">Unlike Kahane et al. (1998)  we do not regard a projectivized representation as the final target of the parsing process.</S><S sid =""44"" ssid = ""15"">Instead  we want to apply an inverse transformation to recover the underlying (nonprojective) dependency graph.</S>",['Method_Citation']
12,P05-1013,W09-1218,0,"Nivre and Nilsson, 2005",0,"In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","['65', '14', '25', '60', '75']","<S sid =""65"" ssid = ""4"">More details on the parsing algorithm can be found in Nivre (2003).</S><S sid =""14"" ssid = ""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%  the total proportion of non-projective arcs is normally only 1–2%.</S><S sid =""25"" ssid = ""21"">The rest of the paper is structured as follows.</S><S sid =""60"" ssid = ""31"">In section 4 we evaluate these transformations with respect to projectivized dependency treebanks  and in section 5 they are applied to parser output.</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S>",['Method_Citation']
13,P05-1013,C08-1081,0,"Nivre and Nilsson, 2005",0,"Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","['11', '104', '21', '26', '61']","<S sid =""11"" ssid = ""7"">This is in contrast to dependency treebanks  e.g.</S><S sid =""104"" ssid = ""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S><S sid =""21"" ssid = ""17"">First  the training data for the parser is projectivized by applying a minimal number of lifting operations (Kahane et al.  1998) and encoding information about these lifts in arc labels.</S><S sid =""26"" ssid = ""22"">In section 2 we introduce the graph transformation techniques used to projectivize and deprojectivize dependency graphs  and in section 3 we describe the data-driven dependency parser that is the core of our system.</S><S sid =""61"" ssid = ""32"">Before we turn to the evaluation  however  we need to introduce the data-driven dependency parser used in the latter experiments.</S>",['Method_Citation']
14,P05-1013,C08-1081,0,2005,0,"Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","['34', '11', '43', '81', '63']","<S sid =""34"" ssid = ""5"">In the following  we use the notation wi wj to mean that (wi  r  wj) E A; r we also use wi wj to denote an arc with unspecified label and wi —*∗ wj for the reflexive and transitive closure of the (unlabeled) arc relation.</S><S sid =""11"" ssid = ""7"">This is in contrast to dependency treebanks  e.g.</S><S sid =""43"" ssid = ""14"">Unlike Kahane et al. (1998)  we do not regard a projectivized representation as the final target of the parsing process.</S><S sid =""81"" ssid = ""8"">However  the overall percentage of non-projective arcs is less than 2% in PDT and less than 1% in DDT.</S><S sid =""63"" ssid = ""2"">The parser builds dependency graphs by traversing the input from left to right  using a stack to store tokens that are not yet complete with respect to their dependents.</S>",['Results_Citation']
15,P05-1013,C08-1081,0,2005,0,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,"['86', '57', '73', '61', '34']","<S sid =""86"" ssid = ""13"">As expected  the most informative encoding  Head+Path  gives the highest accuracy with over 99% of all non-projective arcs being recovered correctly in both data sets.</S><S sid =""57"" ssid = ""28"">In approaching this problem  a variety of different methods are conceivable  including a more or less sophisticated use of machine learning.</S><S sid =""73"" ssid = ""12"">More details on the memory-based prediction can be found in Nivre et al. (2004) and Nivre and Scholz (2004).</S><S sid =""61"" ssid = ""32"">Before we turn to the evaluation  however  we need to introduce the data-driven dependency parser used in the latter experiments.</S><S sid =""34"" ssid = ""5"">In the following  we use the notation wi wj to mean that (wi  r  wj) E A; r we also use wi wj to denote an arc with unspecified label and wi —*∗ wj for the reflexive and transitive closure of the (unlabeled) arc relation.</S>",['Implication_Citation']
16,P05-1013,C08-1081,0,2005,0,"Weprojectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","['83', '106', '78', '101', '25']","<S sid =""83"" ssid = ""10"">It is worth noting that  although nonprojective constructions are less frequent in DDT than in PDT  they seem to be more deeply nested  since only about 80% can be projectivized with a single lift  while almost 95% of the non-projective arcs in PDT only require a single lift.</S><S sid =""106"" ssid = ""17"">However  the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech  with a best performance of 73% UAS (Holan  2004).</S><S sid =""78"" ssid = ""5"">The entire treebank is used in the experiment  but only primary dependencies are considered.4 In all experiments  punctuation tokens are included in the data but omitted in evaluation scores.</S><S sid =""101"" ssid = ""12"">However  if we consider precision  recall and Fmeasure on non-projective dependencies only  as shown in Table 6  some differences begin to emerge.</S><S sid =""25"" ssid = ""21"">The rest of the paper is structured as follows.</S>",['Method_Citation']
17,P05-1013,D11-1006,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","['34', '24', '95', '77', '11']","<S sid =""34"" ssid = ""5"">In the following  we use the notation wi wj to mean that (wi  r  wj) E A; r we also use wi wj to denote an arc with unspecified label and wi —*∗ wj for the reflexive and transitive closure of the (unlabeled) arc relation.</S><S sid =""24"" ssid = ""20"">We call this pseudoprojective dependency parsing  since it is based on a notion of pseudo-projectivity (Kahane et al.  1998).</S><S sid =""95"" ssid = ""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S><S sid =""77"" ssid = ""4"">The Danish Dependency Treebank (DDT) comprises about 100K words of text selected from the Danish PAROLE corpus  with annotation of primary and secondary dependencies (Kromann  2003).</S><S sid =""11"" ssid = ""7"">This is in contrast to dependency treebanks  e.g.</S>",['Results_Citation']
18,P05-1013,P11-2121,0,"Nivre and Nilsson, 2005",0,"Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","['95', '65', '92', '60', '71']","<S sid =""95"" ssid = ""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S><S sid =""65"" ssid = ""4"">More details on the parsing algorithm can be found in Nivre (2003).</S><S sid =""92"" ssid = ""3"">Evaluation metrics used are Attachment Score (AS)  i.e. the proportion of tokens that are attached to the correct head  and Exact Match (EM)  i.e. the proportion of sentences for which the dependency graph exactly matches the gold standard.</S><S sid =""60"" ssid = ""31"">In section 4 we evaluate these transformations with respect to projectivized dependency treebanks  and in section 5 they are applied to parser output.</S><S sid =""71"" ssid = ""10"">For robustness reasons  the parser may output a set of dependency trees instead of a single tree. most dependent of the next input token  dependency type features are limited to tokens on the stack.</S>",['Aim_Citation']
19,P05-1013,E06-1010,0,"Nivre and Nilsson, 2005",0,"Itshould be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in them selves (Nivre and Nilsson, 2005)","It should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves (Nivre and Nilsson, 2005)","['67', '70', '82', '14', '81']","<S sid =""67"" ssid = ""6"">Table 2 shows the features used in the current version of the parser.</S><S sid =""70"" ssid = ""9"">Except for the left3The graphs satisfy all the well-formedness conditions given in section 2 except (possibly) connectedness.</S><S sid =""82"" ssid = ""9"">The last four columns in Table 3 show the distribution of nonprojective arcs with respect to the number of lifts required.</S><S sid =""14"" ssid = ""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%  the total proportion of non-projective arcs is normally only 1–2%.</S><S sid =""81"" ssid = ""8"">However  the overall percentage of non-projective arcs is less than 2% in PDT and less than 1% in DDT.</S>",['Method_Citation']
20,P05-1013,D07-1111,0,"Nivre and Nilsson, 2005",0,"The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective trans formations as described in (Nivre and Nilsson, 2005)","The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective transformations as described in (Nivre and Nilsson, 2005)","['51', '11', '34', '75', '63']","<S sid =""51"" ssid = ""22"">In the second scheme  Head+Path  we in addition modify the label of every arc along the lifting path from the syntactic to the linear head so that if the original label is p the new label is p↓.</S><S sid =""11"" ssid = ""7"">This is in contrast to dependency treebanks  e.g.</S><S sid =""34"" ssid = ""5"">In the following  we use the notation wi wj to mean that (wi  r  wj) E A; r we also use wi wj to denote an arc with unspecified label and wi —*∗ wj for the reflexive and transitive closure of the (unlabeled) arc relation.</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S><S sid =""63"" ssid = ""2"">The parser builds dependency graphs by traversing the input from left to right  using a stack to store tokens that are not yet complete with respect to their dependents.</S>",['Aim_Citation']
