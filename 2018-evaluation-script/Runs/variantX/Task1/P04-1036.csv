Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)","['98', '124', '5', '27', '65']","<S sid =""98"" ssid = ""27"">This seems intuitive given our expected relative usage of these senses in modern British English.</S><S sid =""124"" ssid = ""1"">A major motivation for our work is to try to capture changes in ranking of senses for documents from different domains.</S><S sid =""5"" ssid = ""5"">The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.</S><S sid =""27"" ssid = ""20"">We use WordNet as our sense inventory for this work.</S><S sid =""65"" ssid = ""21"">The measures provide a similarity score between two WordNet senses ( and )  these being synsets within WordNet. lesk (Banerjee and Pedersen  2002) This score maximises the number of overlapping words in the gloss  or definition  of the senses.</S>",['Implication_Citation']
2,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available","['124', '109', '95', '55', '132']","<S sid =""124"" ssid = ""1"">A major motivation for our work is to try to capture changes in ranking of senses for documents from different domains.</S><S sid =""109"" ssid = ""7"">We generated a thesaurus entry for all polysemous nouns in WordNet as described in section 2.1 above.</S><S sid =""95"" ssid = ""24"">Since SemCor is derived from the Brown corpus  which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6  the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid =""55"" ssid = ""11"">For the experiments in sections 3 and 4 we used the 90 million words of written English from the BNC.</S><S sid =""132"" ssid = ""9"">The FINANCE corpus consists of 117734 documents (about 32.5 million words).</S>",['Implication_Citation']
3,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The method is described in (McCarthy et al, 2004), which we summarise here","The method is described in (McCarthy et al, 2004), which we summarise here","['44', '137', '5', '110', '32']","<S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S><S sid =""137"" ssid = ""14"">Additionally  we evaluated our method quantitatively using the Subject Field Codes (SFC) resource (Magnini and Cavagli`a  2000) which annotates WordNet synsets with domain labels.</S><S sid =""5"" ssid = ""5"">The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.</S><S sid =""110"" ssid = ""8"">We obtained the predominant sense for each of these words and used these to label the instances in the noun data within the SENSEVAL-2 English allwords task.</S><S sid =""32"" ssid = ""25"">We describe some related work in section 6 and conclude in section 7. are therefore investigating a method of automatically ranking WordNet senses from raw text.</S>",['Results_Citation']
5,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges",McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD,"['124', '95', '96', '33', '44']","<S sid =""124"" ssid = ""1"">A major motivation for our work is to try to capture changes in ranking of senses for documents from different domains.</S><S sid =""95"" ssid = ""24"">Since SemCor is derived from the Brown corpus  which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6  the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid =""96"" ssid = ""25"">Another example where the ranking is intuitive  is soil.</S><S sid =""33"" ssid = ""26"">Many researchers are developing thesauruses from automatically parsed data.</S><S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S>",['Method_Citation']
6,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","['107', '124', '153', '147', '67']","<S sid =""107"" ssid = ""5"">To disambiguate senses a system should take context into account.</S><S sid =""124"" ssid = ""1"">A major motivation for our work is to try to capture changes in ranking of senses for documents from different domains.</S><S sid =""153"" ssid = ""1"">Most research in WSD concentrates on using contextual features  typically neighbouring words  to help determine the correct sense of a target word.</S><S sid =""147"" ssid = ""24"">The word share is among the words whose predominant sense remained the same for all three corpora.</S><S sid =""67"" ssid = ""23"">Each 2We use this version of WordNet since it allows us to map information to WordNets of other languages more accurately.</S>",['Method_Citation']
7,P04-1036,I08-2105,0,2004,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","['94', '162', '60', '95', '99']","<S sid =""94"" ssid = ""23"">This seems quite reasonable given the nearest neighbours: tube  cable  wire  tank  hole  cylinder  fitting  tap  cistern  plate....</S><S sid =""162"" ssid = ""10"">It only requires raw text from the given domain and because of this it can easily be applied to a new domain  or sense inventory  given sufficient text.</S><S sid =""60"" ssid = ""16"">If is the set of co-occurrence types such that is positive then the similarity between two nouns  and   can be computed as: where: A thesaurus entry of size for a target noun is then defined as the most similar nouns to .</S><S sid =""95"" ssid = ""24"">Since SemCor is derived from the Brown corpus  which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6  the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid =""99"" ssid = ""28"">Even given the difference in text type between SemCor and the BNC the results are encouraging  especially given that our results are for polysemous nouns.</S>",['Method_Citation']
8,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","['165', '101', '169', '108', '44']","<S sid =""165"" ssid = ""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus  whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid =""101"" ssid = ""30"">Thus  if we used the sense ranking as a heuristic for an “all nouns” task we would expect to get precision in the region of 60%.</S><S sid =""169"" ssid = ""17"">This method obtains precision of 61% and recall 51%.</S><S sid =""108"" ssid = ""6"">However  it is important to know the performance of this heuristic for any systems that use it.</S><S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S>",['Method_Citation']
9,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense","['136', '60', '169', '91', '127']","<S sid =""136"" ssid = ""13"">The words included in this experiment are not a random sample  since we anticipated different predominant senses in the SPORTS and FINANCE domains for these words.</S><S sid =""60"" ssid = ""16"">If is the set of co-occurrence types such that is positive then the similarity between two nouns  and   can be computed as: where: A thesaurus entry of size for a target noun is then defined as the most similar nouns to .</S><S sid =""169"" ssid = ""17"">This method obtains precision of 61% and recall 51%.</S><S sid =""91"" ssid = ""20"">This is to be expected regardless of any inherent shortcomings of the ranking technique since the senses within SemCor will differ compared to those of the BNC.</S><S sid =""127"" ssid = ""4"">We chose the domains of SPORTS and FINANCE since there is sufficient material for these domains in this publically available corpus.</S>",['Method_Citation']
11,P04-1036,P10-1155,0,2004,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)","['193', '136', '151', '123', '167']","<S sid =""193"" ssid = ""2"">This work was funded by EU-2001-34460 project MEANING: Developing Multilingual Web-scale Language Technologies  UK EPSRC project Robust Accurate Statistical Parsing (RASP) and a UK EPSRC studentship.</S><S sid =""136"" ssid = ""13"">The words included in this experiment are not a random sample  since we anticipated different predominant senses in the SPORTS and FINANCE domains for these words.</S><S sid =""151"" ssid = ""28"">This figure shows the domain labels assigned to the predominant senses for the set of 38 words after ranking the words using the SPORTS and the FINANCE corpora.</S><S sid =""123"" ssid = ""21"">This demonstrates that our method of providing a first sense from raw text will help when sense-tagged data is not available.</S><S sid =""167"" ssid = ""15"">In this work the lists of neighbours are themselves clustered to bring out the various senses of the word.</S>",['Method_Citation']
12,P04-1036,W12-3401,0,2004,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","['173', '5', '108', '95', '63']","<S sid =""173"" ssid = ""21"">It would be useful however to combine our method of finding predominant senses with one which can automatically find new senses within text and relate these to WordNet synsets  as Ciaramita and Johnson (2003) do with unknown nouns.</S><S sid =""5"" ssid = ""5"">The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.</S><S sid =""108"" ssid = ""6"">However  it is important to know the performance of this heuristic for any systems that use it.</S><S sid =""95"" ssid = ""24"">Since SemCor is derived from the Brown corpus  which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6  the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid =""63"" ssid = ""19"">We experimented using six of these to provide the in equation 1 above and obtained results well over our baseline  but because of space limitations give results for the two which perform the best.</S>",['Implication_Citation']
13,P04-1036,W12-3401,0,2004,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)","['184', '110', '60', '76', '55']","<S sid =""184"" ssid = ""7"">We have demonstrated the possibility of finding predominant senses in domain specific corpora on a sample of nouns.</S><S sid =""110"" ssid = ""8"">We obtained the predominant sense for each of these words and used these to label the instances in the noun data within the SENSEVAL-2 English allwords task.</S><S sid =""60"" ssid = ""16"">If is the set of co-occurrence types such that is positive then the similarity between two nouns  and   can be computed as: where: A thesaurus entry of size for a target noun is then defined as the most similar nouns to .</S><S sid =""76"" ssid = ""5"">The jcn measure uses corpus data for the calculation of IC.</S><S sid =""55"" ssid = ""11"">For the experiments in sections 3 and 4 we used the 90 million words of written English from the BNC.</S>",['Method_Citation']
14,P04-1036,W12-3401,0,2004,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","['123', '169', '147', '97', '8']","<S sid =""123"" ssid = ""21"">This demonstrates that our method of providing a first sense from raw text will help when sense-tagged data is not available.</S><S sid =""169"" ssid = ""17"">This method obtains precision of 61% and recall 51%.</S><S sid =""147"" ssid = ""24"">The word share is among the words whose predominant sense remained the same for all three corpora.</S><S sid =""97"" ssid = ""26"">The first ranked sense according to SemCor is the filth  stain: state of being unclean sense whereas the automatic ranking lists dirt  ground  earth as the first sense  which is the second ranked sense according to SemCor.</S><S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S>",['Method_Citation']
16,P04-1036,S12-1097,0,"McCarthy et al, 2004",0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","['61', '28', '124', '60', '34']","<S sid =""61"" ssid = ""17"">We use the WordNet Similarity Package 0.05 and WordNet version 1.6.</S><S sid =""28"" ssid = ""21"">The paper is structured as follows.</S><S sid =""124"" ssid = ""1"">A major motivation for our work is to try to capture changes in ranking of senses for documents from different domains.</S><S sid =""60"" ssid = ""16"">If is the set of co-occurrence types such that is positive then the similarity between two nouns  and   can be computed as: where: A thesaurus entry of size for a target noun is then defined as the most similar nouns to .</S><S sid =""34"" ssid = ""27"">In these each target word is entered with an ordered list of “nearest neighbours”.</S>",['Method_Citation']
17,P04-1036,W10-2803,0,"McCarthy et al, 2004",0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","['163', '124', '9', '0', '142']","<S sid =""163"" ssid = ""11"">Lapata and Brew (2004) have recently also highlighted the importance of a good prior in WSD.</S><S sid =""124"" ssid = ""1"">A major motivation for our work is to try to capture changes in ranking of senses for documents from different domains.</S><S sid =""9"" ssid = ""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al.  1998) in figure 1 below  where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al.  2001).</S><S sid =""0"" ssid = ""0"">Finding Predominant Word Senses in Untagged Text</S><S sid =""142"" ssid = ""19"">The results for 10 of the words from the qualitative experiment are summarized in table 3 with the WordNet sense number for each word supplied alongside synonyms or hypernyms from WordNet for readability.</S>",['Results_Citation']
18,P04-1036,W08-2107,0,2004,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","['138', '34', '22', '184', '92']","<S sid =""138"" ssid = ""15"">The SFC contains an economy label and a sports label.</S><S sid =""34"" ssid = ""27"">In these each target word is entered with an ordered list of “nearest neighbours”.</S><S sid =""22"" ssid = ""15"">More importantly  when working within a specific domain one would wish to tune the first sense heuristic to the domain at hand.</S><S sid =""184"" ssid = ""7"">We have demonstrated the possibility of finding predominant senses in domain specific corpora on a sample of nouns.</S><S sid =""92"" ssid = ""21"">For example  in WordNet the first listed sense ofpipe is tobacco pipe  and this is ranked joint first according to the Brown files in SemCor with the second sense tube made of metal or plastic used to carry water  oil or gas etc....</S>",['Implication_Citation']
19,P04-1036,D07-1026,0,"McCarthy et al, 2004",0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","['108', '173', '95', '185', '65']","<S sid =""108"" ssid = ""6"">However  it is important to know the performance of this heuristic for any systems that use it.</S><S sid =""173"" ssid = ""21"">It would be useful however to combine our method of finding predominant senses with one which can automatically find new senses within text and relate these to WordNet synsets  as Ciaramita and Johnson (2003) do with unknown nouns.</S><S sid =""95"" ssid = ""24"">Since SemCor is derived from the Brown corpus  which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6  the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid =""185"" ssid = ""8"">In the future  we will perform a large scale evaluation on domain specific corpora.</S><S sid =""65"" ssid = ""21"">The measures provide a similarity score between two WordNet senses ( and )  these being synsets within WordNet. lesk (Banerjee and Pedersen  2002) This score maximises the number of overlapping words in the gloss  or definition  of the senses.</S>",['Method_Citation']
20,P04-1036,W12-2429,0,"McCarthy et al, 2004",0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","['173', '110', '151', '95', '5']","<S sid =""173"" ssid = ""21"">It would be useful however to combine our method of finding predominant senses with one which can automatically find new senses within text and relate these to WordNet synsets  as Ciaramita and Johnson (2003) do with unknown nouns.</S><S sid =""110"" ssid = ""8"">We obtained the predominant sense for each of these words and used these to label the instances in the noun data within the SENSEVAL-2 English allwords task.</S><S sid =""151"" ssid = ""28"">This figure shows the domain labels assigned to the predominant senses for the set of 38 words after ranking the words using the SPORTS and the FINANCE corpora.</S><S sid =""95"" ssid = ""24"">Since SemCor is derived from the Brown corpus  which predates the BNC by up to 30 years 5 and contains a higher proportion of fiction 6  the high ranking for the tobacco pipe sense according to SemCor seems plausible.</S><S sid =""5"" ssid = ""5"">The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.</S>",['Results_Citation']
