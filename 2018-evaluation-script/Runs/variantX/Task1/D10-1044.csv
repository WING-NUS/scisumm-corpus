Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,D10-1044,P11-2074,0,"Foster et al, 2010",0,"Another popular task in SMT is domain adaptation (Foster et al, 2010)","Another popular task in SMT is domain adaptation (Foster et al, 2010)","['32', '2', '114', '101', '104']","<S sid =""32"" ssid = ""29"">This is a straightforward technique that is arguably better suited to the adaptation task than the standard method of treating representative IN sentences as queries  then pooling the match results.</S><S sid =""2"" ssid = ""2"">This extends previous work on discriminative weighting by using a finer granularity  focusing on the properties of instances rather than corpus components  and using a simpler training procedure.</S><S sid =""114"" ssid = ""18"">It was filtered to retain the top 30 translations for each source phrase using the TM part of the current log-linear model.</S><S sid =""101"" ssid = ""5"">The second setting uses the news-related subcorpora for the NIST09 MT Chinese to English evaluation8 as IN  and the remaining NIST parallel Chinese/English corpora (UN  Hong Kong Laws  and Hong Kong Hansard) as OUT.</S><S sid =""104"" ssid = ""8"">(Thus the domain of the dev and test corpora matches IN.)</S>",['Implication_Citation']
2,D10-1044,P12-1048,0,"Foster et al, 2010",0,"In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)","In addition, discriminative weighting methods were proposed to assign appropriate weights to the sentences from training corpus (Matsoukas et al, 2009) or the phrase pairs of phrase table (Foster et al, 2010)","['67', '138', '144', '133', '99']","<S sid =""67"" ssid = ""4"">We extend the Matsoukas et al approach in several ways.</S><S sid =""138"" ssid = ""7"">However  for multinomial models like our LMs and TMs  there is a one to one correspondence between instances and features  eg the correspondence between a phrase pair (s  t) and its conditional multinomial probability p(s1t).</S><S sid =""144"" ssid = ""1"">In this paper we have proposed an approach for instance-weighting phrase pairs in an out-of-domain corpus in order to improve in-domain performance.</S><S sid =""133"" ssid = ""2"">It is difficult to directly compare the Matsoukas et al results with ours  since our out-of-domain corpus is homogeneous; given heterogeneous training data  however  it would be trivial to include Matsoukas-style identity features in our instance-weighting model.</S><S sid =""99"" ssid = ""3"">The dev and test sets were randomly chosen from the EMEA corpus.</S>",['Implication_Citation']
3,D10-1044,D12-1129,0,"Foster et al., 2010",0,"Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010) .Research in Word Sense Disambiguation (Navigli, 2009, WSD), the task aimed at the automatic labeling of text with word senses, has been oriented towards domain text understanding for several years now","Domain knowledge also has the potential to improve open-text applications such as summarization (Ceylan et al 2010) and machine translation (Foster et al., 2010)","['67', '142', '8', '2', '38']","<S sid =""67"" ssid = ""4"">We extend the Matsoukas et al approach in several ways.</S><S sid =""142"" ssid = ""11"">There has also been some work on adapting the word alignment model prior to phrase extraction (Civera and Juan  2007; Wu et al.  2005)  and on dynamically choosing a dev set (Xu et al.  2007).</S><S sid =""8"" ssid = ""5"">)  which precludes a single universal approach to adaptation.</S><S sid =""2"" ssid = ""2"">This extends previous work on discriminative weighting by using a finer granularity  focusing on the properties of instances rather than corpus components  and using a simpler training procedure.</S><S sid =""38"" ssid = ""2"">The toplevel weights are trained to maximize a metric such as BLEU on a small development set of approximately 1000 sentence pairs.</S>",['Results_Citation']
4,D10-1044,P14-2093,0,2010,0,"Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models","Yasuda et al (2008) and Foster et al (2010) ranked the sentence pairs in the general-domain corpus according to the perplexity scores of sentences, which are computed with respect to in-domain language models","['8', '32', '83', '78', '136']","<S sid =""8"" ssid = ""5"">)  which precludes a single universal approach to adaptation.</S><S sid =""32"" ssid = ""29"">This is a straightforward technique that is arguably better suited to the adaptation task than the standard method of treating representative IN sentences as queries  then pooling the match results.</S><S sid =""83"" ssid = ""20"">We have not yet tried this.</S><S sid =""78"" ssid = ""15"">This has solutions: where pI(s|t) is derived from the IN corpus using relative-frequency estimates  and po(s|t) is an instance-weighted model derived from the OUT corpus.</S><S sid =""136"" ssid = ""5"">It is also worth pointing out a connection with Daum´e’s (2007) work that splits each feature into domain-specific and general copies.</S>",['Method_Citation']
5,D10-1044,E12-1055,0,2010,0,"However, such confounding factors do not affect the optimization algorithm, which works with a fixed set of phrase pairs, and merely varies? .Our main technical contributions are as fol lows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation. Also, we independently perform perplexity minimization for all four features of the standard SMTtranslation model: the phrase translation probabilities p (t|s) and p (s|t), and the lexical weights lex (t|s) and lex (s|t)","Our main technical contributions are as follows: Additionally to perplexity optimization for linear interpolation, which was first applied by Foster et al (2010), we propose perplexity optimization for weighted counts (equation 3), and a modified implementation of linear interpolation","['133', '118', '5', '1', '10']","<S sid =""133"" ssid = ""2"">It is difficult to directly compare the Matsoukas et al results with ours  since our out-of-domain corpus is homogeneous; given heterogeneous training data  however  it would be trivial to include Matsoukas-style identity features in our instance-weighting model.</S><S sid =""118"" ssid = ""22"">Log-linear combination (loglin) improves on this in all cases  and also beats the pure IN system.</S><S sid =""5"" ssid = ""2"">Even when there is training data available in the domain of interest  there is often additional data from other domains that could in principle be used to improve performance.</S><S sid =""1"" ssid = ""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain  determined by both how similar to it they appear to be  and whether they belong to general language or not.</S><S sid =""10"" ssid = ""7"">This is a standard adaptation problem for SMT.</S>",['Method_Citation']
6,D10-1044,E12-1055,0,2010,0,"Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) ex tend this approach by weighting individual phrase pairs","Matsoukas et al (2009) propose an approach where each sentence is weighted according to a classifier, and Foster et al (2010) extend this approach by weighting individual phrase pairs","['10', '5', '136', '104', '14']","<S sid =""10"" ssid = ""7"">This is a standard adaptation problem for SMT.</S><S sid =""5"" ssid = ""2"">Even when there is training data available in the domain of interest  there is often additional data from other domains that could in principle be used to improve performance.</S><S sid =""136"" ssid = ""5"">It is also worth pointing out a connection with Daum´e’s (2007) work that splits each feature into domain-specific and general copies.</S><S sid =""104"" ssid = ""8"">(Thus the domain of the dev and test corpora matches IN.)</S><S sid =""14"" ssid = ""11"">There is a fairly large body of work on SMT adaptation.</S>",['Method_Citation']
7,D10-1044,E12-1055,0,2010,0,"These more fine-grained methods need not be seen as alternatives to coarse-grained ones. Foster et al (2010) combine the two, applying linear interpolation to combine the instance 542 weighted out-of-domain model with an in-domain model","Foster et al (2010) combine the two, applying linear interpolation to combine the instance weighted out-of-domain model with an in-domain model","['64', '95', '78', '125', '20']","<S sid =""64"" ssid = ""1"">The sentence-selection approach is crude in that it imposes a binary distinction between useful and non-useful parts of OUT.</S><S sid =""95"" ssid = ""32"">Phrase tables were extracted from the IN and OUT training corpora (not the dev as was used for instance weighting models)  and phrase pairs in the intersection of the IN and OUT phrase tables were used as positive examples  with two alternate definitions of negative examples: The classifier trained using the 2nd definition had higher accuracy on a development set.</S><S sid =""78"" ssid = ""15"">This has solutions: where pI(s|t) is derived from the IN corpus using relative-frequency estimates  and po(s|t) is an instance-weighted model derived from the OUT corpus.</S><S sid =""125"" ssid = ""29"">Somewhat surprisingly  there do not appear to be large systematic differences between linear and MAP combinations.</S><S sid =""20"" ssid = ""17"">Daum´e (2007) applies a related idea in a simpler way  by splitting features into general and domain-specific versions.</S>",['Method_Citation']
8,D10-1044,E12-1055,0,Foster et al 2010,0,Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN) Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011),Note that both data sets have a relatively high ratio of in-domain to out-of-domain parallel training data (1:20 for DE? EN and 1:5 for HT? EN); Previous research has been performed with ratios of 1:100 (Foster et al 2010) or 1:400 (Axelrod et al 2011),"['151', '36', '19', '79', '114']","<S sid =""151"" ssid = ""8"">In future work we plan to try this approach with more competitive SMT systems  and to extend instance weighting to other standard SMT components such as the LM  lexical phrase weights  and lexicalized distortion.</S><S sid =""36"" ssid = ""33"">Section 5 covers relevant previous work on SMT adaptation  and section 6 concludes.</S><S sid =""19"" ssid = ""16"">The idea of distinguishing between general and domain-specific examples is due to Daum´e and Marcu (2006)  who used a maximum-entropy model with latent variables to capture the degree of specificity.</S><S sid =""79"" ssid = ""16"">This combination generalizes (2) and (3): we use either at = a to obtain a fixed-weight linear combination  or at = cI(t)/(cI(t) + 0) to obtain a MAP combination.</S><S sid =""114"" ssid = ""18"">It was filtered to retain the top 30 translations for each source phrase using the TM part of the current log-linear model.</S>",['Method_Citation']
9,D10-1044,E12-1055,0,Foster et al 2010,0,"We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translationmodels.15 We demonstrate perplexity optimization for weighted counts, which are a natural extension of unadapted MLE training, but are of little prominence in domain adaptation research",We expand on work by (Foster et al 2010) in establishing translation model perplexity minimization as a robust baseline for a weighted combination of translation models,"['118', '50', '88', '104', '19']","<S sid =""118"" ssid = ""22"">Log-linear combination (loglin) improves on this in all cases  and also beats the pure IN system.</S><S sid =""50"" ssid = ""14"">Linear weights are difficult to incorporate into the standard MERT procedure because they are “hidden” within a top-level probability that represents the linear combination.1 Following previous work (Foster and Kuhn  2007)  we circumvent this problem by choosing weights to optimize corpus loglikelihood  which is roughly speaking the training criterion used by the LM and TM themselves.</S><S sid =""88"" ssid = ""25"">We have not explored this strategy.</S><S sid =""104"" ssid = ""8"">(Thus the domain of the dev and test corpora matches IN.)</S><S sid =""19"" ssid = ""16"">The idea of distinguishing between general and domain-specific examples is due to Daum´e and Marcu (2006)  who used a maximum-entropy model with latent variables to capture the degree of specificity.</S>",['Method_Citation']
10,D10-1044,P12-1099,0,"Foster et al, 2010",0,"In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) 940 as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT","In addition to the basic approach of concatenation of in-domain and out-of-domain data, we also trained a log-linear mixture model (Foster and Kuhn, 2007) as well as the linear mixture model of (Foster et al, 2010) for conditional phrase-pair probabilities over IN and OUT","['51', '114', '127', '67', '118']","<S sid =""51"" ssid = ""15"">For the LM  adaptive weights are set as follows: where α is a weight vector containing an element αi for each domain (just IN and OUT in our case)  pi are the corresponding domain-specific models  and ˜p(w  h) is an empirical distribution from a targetlanguage training corpus—we used the IN dev set for this.</S><S sid =""114"" ssid = ""18"">It was filtered to retain the top 30 translations for each source phrase using the TM part of the current log-linear model.</S><S sid =""127"" ssid = ""31"">The iw all map variant uses a non-0 y weight on a uniform prior in p  (s t)  and outperforms a version with y = 0 (iw all) and the “flattened” variant described in section 3.2.</S><S sid =""67"" ssid = ""4"">We extend the Matsoukas et al approach in several ways.</S><S sid =""118"" ssid = ""22"">Log-linear combination (loglin) improves on this in all cases  and also beats the pure IN system.</S>",['Implication_Citation']
11,D10-1044,P12-1099,0,2010,0,m ?mpm (e? |f?) Our technique for setting? m is similar to that outlined in Foster et al (2010),Our technique for setting ? m is similar to that outlined in Foster et al (2010),"['1', '96', '128', '106', '111']","<S sid =""1"" ssid = ""1"">We describe a new approach to SMT adaptation that weights out-of-domain phrase pairs according to their relevance to the target domain  determined by both how similar to it they appear to be  and whether they belong to general language or not.</S><S sid =""96"" ssid = ""33"">We used it to score all phrase pairs in the OUT table  in order to provide a feature for the instance-weighting model.</S><S sid =""128"" ssid = ""32"">Clearly  retaining the original frequencies is important for good performance  and globally smoothing the final weighted frequencies is crucial.</S><S sid =""106"" ssid = ""10"">The corpora for both settings are summarized in table 1.</S><S sid =""111"" ssid = ""15"">We used a standard one-pass phrase-based system (Koehn et al.  2003)  with the following features: relative-frequency TM probabilities in both directions; a 4-gram LM with Kneser-Ney smoothing; word-displacement distortion model; and word count.</S>",['Method_Citation']
12,D10-1044,P12-1099,0,"Foster et al., 2010",0,"m ?mpm (e? |f?) For efficiency and stability, we use the EMalgorithm to find??, rather than L-BFGS as in (Foster et al., 2010)","For efficiency and stability, we use the EM algorithm to find ?, rather than L-BFGS as in (Foster et al., 2010)","['43', '64', '41', '60', '0']","<S sid =""43"" ssid = ""7"">Its success depends on the two domains being relatively close  and on the OUT corpus not being so large as to overwhelm the contribution of IN.</S><S sid =""64"" ssid = ""1"">The sentence-selection approach is crude in that it imposes a binary distinction between useful and non-useful parts of OUT.</S><S sid =""41"" ssid = ""5"">We do not adapt the alignment procedure for generating the phrase table from which the TM distributions are derived.</S><S sid =""60"" ssid = ""24"">The matching sentence pairs are then added to the IN corpus  and the system is re-trained.</S><S sid =""0"" ssid = ""0"">Discriminative Instance Weighting for Domain Adaptation in Statistical Machine Translation</S>",['Method_Citation']
13,D10-1044,P12-1099,0,2010,0,"Foster et al (2010), however, uses a different approach to select related sentences from OUT","Foster et al (2010), however, uses a different approach to select related sentences from OUT","['8', '67', '15', '71', '104']","<S sid =""8"" ssid = ""5"">)  which precludes a single universal approach to adaptation.</S><S sid =""67"" ssid = ""4"">We extend the Matsoukas et al approach in several ways.</S><S sid =""15"" ssid = ""12"">We introduce several new ideas.</S><S sid =""71"" ssid = ""8"">Finally  we incorporate the instance-weighting model into a general linear combination  and learn weights and mixing parameters simultaneously. where cλ(s  t) is a modified count for pair (s  t) in OUT  u(s|t) is a prior distribution  and y is a prior weight.</S><S sid =""104"" ssid = ""8"">(Thus the domain of the dev and test corpora matches IN.)</S>",['Method_Citation']
14,D10-1044,P12-1099,0,2010,0,Foster et al (2010) propose asimilar method for machine translation that uses features to capture degrees of generality,Foster et al (2010) propose a similar method for machine translation that uses features to capture degrees of generality,"['104', '151', '43', '135', '146']","<S sid =""104"" ssid = ""8"">(Thus the domain of the dev and test corpora matches IN.)</S><S sid =""151"" ssid = ""8"">In future work we plan to try this approach with more competitive SMT systems  and to extend instance weighting to other standard SMT components such as the LM  lexical phrase weights  and lexicalized distortion.</S><S sid =""43"" ssid = ""7"">Its success depends on the two domains being relatively close  and on the OUT corpus not being so large as to overwhelm the contribution of IN.</S><S sid =""135"" ssid = ""4"">Finally  we note that Jiang’s instance-weighting framework is broader than we have presented above  encompassing among other possibilities the use of unlabelled IN data  which is applicable to SMT settings where source-only IN corpora are available.</S><S sid =""146"" ssid = ""3"">The features are weighted within a logistic model to give an overall weight that is applied to the phrase pair’s frequency prior to making MAP-smoothed relative-frequency estimates (different weights are learned for each conditioning direction).</S>",['Results_Citation']
15,D10-1044,P13-1126,0,"Foster et al, 2010",0,"As in (Foster et al, 2010), this approach works at the level of phrase pairs","As in (Foster et al, 2010), this approach works at the level of phrase pairs","['16', '114', '83', '28', '17']","<S sid =""16"" ssid = ""13"">First  we aim to explicitly characterize examples from OUT as belonging to general language or not.</S><S sid =""114"" ssid = ""18"">It was filtered to retain the top 30 translations for each source phrase using the TM part of the current log-linear model.</S><S sid =""83"" ssid = ""20"">We have not yet tried this.</S><S sid =""28"" ssid = ""25"">We train linear mixture models for conditional phrase pair probabilities over IN and OUT so as to maximize the likelihood of an empirical joint phrase-pair distribution extracted from a development set.</S><S sid =""17"" ssid = ""14"">Previous approaches have tried to find examples that are similar to the target domain.</S>",['Implication_Citation']
16,D10-1044,D11-1033,0,2010,0,"The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)","The ranking of the sentences in a general-domain corpus according to in-domain perplexity has also been applied to machine translation by both Yasuda et al (2008), and Foster et al (2010)","['89', '78', '110', '109', '67']","<S sid =""89"" ssid = ""26"">We used 22 features for the logistic weighting model  divided into two groups: one intended to reflect the degree to which a phrase pair belongs to general language  and one intended to capture similarity to the IN domain.</S><S sid =""78"" ssid = ""15"">This has solutions: where pI(s|t) is derived from the IN corpus using relative-frequency estimates  and po(s|t) is an instance-weighted model derived from the OUT corpus.</S><S sid =""110"" ssid = ""14"">Je voudrais pr´eciser  a` l’adresse du commissaire Liikanen  qu’il n’est pas ais´e de recourir aux tribunaux nationaux.</S><S sid =""109"" ssid = ""13"">— I would also like to point out to commissioner Liikanen that it is not easy to take a matter to a national court.</S><S sid =""67"" ssid = ""4"">We extend the Matsoukas et al approach in several ways.</S>",['Method_Citation']
17,D10-1044,D11-1033,0,2010,0,"Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and re port a decrease in performance","Foster et al (2010) do not mention what percentage of the corpus they select for their IR-baseline, but they concatenate the data to their in-domain corpus and report a decrease in performance","['67', '64', '36', '131', '47']","<S sid =""67"" ssid = ""4"">We extend the Matsoukas et al approach in several ways.</S><S sid =""64"" ssid = ""1"">The sentence-selection approach is crude in that it imposes a binary distinction between useful and non-useful parts of OUT.</S><S sid =""36"" ssid = ""33"">Section 5 covers relevant previous work on SMT adaptation  and section 6 concludes.</S><S sid =""131"" ssid = ""35"">The general-language features have a slight advantage over the similarity features  and both are better than the SVM feature.</S><S sid =""47"" ssid = ""11"">Apart from MERT difficulties  a conceptual problem with log-linear combination is that it multiplies feature probabilities  essentially forcing different features to agree on high-scoring candidates.</S>",['Results_Citation']
18,D10-1044,D11-1033,0,2010,0,"Foster et al (2010) further perform this on extracted phrase pairs, not just sentences","Foster et al (2010) further perform this on extracted phrase pairs, not just sentences","['114', '136', '8', '11', '111']","<S sid =""114"" ssid = ""18"">It was filtered to retain the top 30 translations for each source phrase using the TM part of the current log-linear model.</S><S sid =""136"" ssid = ""5"">It is also worth pointing out a connection with Daum´e’s (2007) work that splits each feature into domain-specific and general copies.</S><S sid =""8"" ssid = ""5"">)  which precludes a single universal approach to adaptation.</S><S sid =""11"" ssid = ""8"">It is difficult when IN and OUT are dissimilar  as they are in the cases we study.</S><S sid =""111"" ssid = ""15"">We used a standard one-pass phrase-based system (Koehn et al.  2003)  with the following features: relative-frequency TM probabilities in both directions; a 4-gram LM with Kneser-Ney smoothing; word-displacement distortion model; and word count.</S>",['Aim_Citation']
19,D10-1044,P14-1012,0,"Foster et al, 2010",0,"To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments","To address the first shortcoming, we adapt and extend some simple but effective phrase features as the input features for new DNN feature learning, and these features have been shown significant improvement for SMT, such as, phrase pair similarity (Zhao et al, 2004), phrase frequency, phrase length (Hopkins and May, 2011), and phrase generative probability (Foster et al, 2010), which also show further improvement for new phrase feature learning in our experiments","['67', '111', '128', '92', '95']","<S sid =""67"" ssid = ""4"">We extend the Matsoukas et al approach in several ways.</S><S sid =""111"" ssid = ""15"">We used a standard one-pass phrase-based system (Koehn et al.  2003)  with the following features: relative-frequency TM probabilities in both directions; a 4-gram LM with Kneser-Ney smoothing; word-displacement distortion model; and word count.</S><S sid =""128"" ssid = ""32"">Clearly  retaining the original frequencies is important for good performance  and globally smoothing the final weighted frequencies is crucial.</S><S sid =""92"" ssid = ""29"">6One of our experimental settings lacks document boundaries  and we used this approximation in both settings for consistency.</S><S sid =""95"" ssid = ""32"">Phrase tables were extracted from the IN and OUT training corpora (not the dev as was used for instance weighting models)  and phrase pairs in the intersection of the IN and OUT phrase tables were used as positive examples  with two alternate definitions of negative examples: The classifier trained using the 2nd definition had higher accuracy on a development set.</S>",['Method_Citation']
