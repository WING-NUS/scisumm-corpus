Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Reference Citation
1,W99-0623,A00-2005,0,1999,0,1 Introduct ion Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,"['34', '106', '66', '65', '2']","<S sid =""34"" ssid = ""20"">Mi(c) is a binary function returning t when parser i (from among the k parsers) suggests constituent c should be in the parse.</S><S sid =""106"" ssid = ""35"">In each figure the upper graph shows the isolated constituent precision and the bottom graph shows the corresponding number of hypothesized constituents.</S><S sid =""66"" ssid = ""52"">Each decision determines the inclusion or exclusion of a candidate constituent.</S><S sid =""65"" ssid = ""51"">We model each parse as the decisions made to create it  and model those decisions as independent events.</S><S sid =""2"" ssid = ""2"">Two general approaches are presented and two combination techniques are described for each approach.</S>",['Implication_Citation']
2,W99-0623,A00-2005,0,1999,0,the collection of hypotheses ti =fi (Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999),"Given a novel sentence Stest E Ctest, combine the collection of hypotheses ti = fi(Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999)","['18', '15', '130', '57', '50']","<S sid =""18"" ssid = ""4"">These two principles guide experimentation in this framework  and together with the evaluation measures help us decide which specific type of substructure to combine.</S><S sid =""15"" ssid = ""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S><S sid =""130"" ssid = ""59"">The PCFG was trained from the same sections of the Penn Treebank as the other three parsers.</S><S sid =""57"" ssid = ""43"">The combining technique must act as a multi-position switch indicating which parser should be trusted for the particular sentence.</S><S sid =""50"" ssid = ""36"">There is a guarantee of no crossing brackets but there is no guarantee that a constituent in the tree has the same children as it had in any of the three original parses.</S>",['Implication_Citation']
4,W99-0623,N10-1091,0,"Henderson and Brill, 1999",0,"5 (Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","(Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","['122', '11', '24', '61', '107']","<S sid =""122"" ssid = ""51"">All of these systems were run on data that was not seen during their development.</S><S sid =""11"" ssid = ""7"">Similar advances have been made in machine translation (Frederking and Nirenburg  1994)  speech recognition (Fiscus  1997) and named entity recognition (Borthwick et al.  1998).</S><S sid =""24"" ssid = ""10"">We include a constituent in our hypothesized parse if it appears in the output of a majority of the parsers.</S><S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid =""107"" ssid = ""36"">Again we notice that the isolated constituent precision is larger than 0.5 only in those partitions that contain very few samples.</S>",['Results_Citation']
5,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","['92', '111', '104', '42', '117']","<S sid =""92"" ssid = ""21"">While we cannot prove there are no such useful features on which one should condition trust  we can give some insight into why the features we explored offered no gain.</S><S sid =""111"" ssid = ""40"">The first row represents the average accuracy of the three parsers we combine.</S><S sid =""104"" ssid = ""33"">In the cases where isolated constituent precision is larger than 0.5 the affected portion of the hypotheses is negligible.</S><S sid =""42"" ssid = ""28"">Call the crossing constituents A and B.</S><S sid =""117"" ssid = ""46"">Another way to interpret this is that less than 5% of the correct constituents are missing from the hypotheses generated by the union of the three parsers.</S>",['Method_Citation']
6,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"This approach roughly corresponds to (Henderson and Brill, 1999)? s Na ?ve Bayes parse hybridization","This approach roughly corresponds to (Henderson and Brill, 1999)'s Naive Bayes parse hybridization","['15', '139', '11', '39', '63']","<S sid =""15"" ssid = ""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S><S sid =""11"" ssid = ""7"">Similar advances have been made in machine translation (Frederking and Nirenburg  1994)  speech recognition (Fiscus  1997) and named entity recognition (Borthwick et al.  1998).</S><S sid =""39"" ssid = ""25"">There are simply not enough votes remaining to allow any of the crossing structures to enter the hypothesized constituent set.</S><S sid =""63"" ssid = ""49"">The probabilistic version of this procedure is straightforward: We once again assume independence among our various member parsers.</S>",['Method_Citation']
7,W99-0623,W05-1518,0,1999,0,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,"['39', '86', '27', '17', '61']","<S sid =""39"" ssid = ""25"">There are simply not enough votes remaining to allow any of the crossing structures to enter the hypothesized constituent set.</S><S sid =""86"" ssid = ""15"">Finally we show the combining techniques degrade very little when a poor parser is added to the set.</S><S sid =""27"" ssid = ""13"">Another technique for parse hybridization is to use a naïve Bayes classifier to determine which constituents to include in the parse.</S><S sid =""17"" ssid = ""3"">The substructures that are unanimously hypothesized by the parsers should be preserved after combination  and the combination technique should not foolishly create substructures for which there is no supporting evidence.</S><S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S>",['Method_Citation']
8,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) improved their best parser? s F-measure of 89.7 to 91.3, using their na ?ve Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","(Henderson and Brill, 1999) improved their best parser's F-measure of 89.7 to 91.3, using their naive Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","['112', '72', '21', '24', '139']","<S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""72"" ssid = ""1"">The three parsers were trained and tuned by their creators on various sections of the WSJ portion of the Penn Treebank  leaving only sections 22 and 23 completely untouched during the development of any of the parsers.</S><S sid =""21"" ssid = ""7"">One hybridization strategy is to let the parsers vote on constituents' membership in the hypothesized set.</S><S sid =""24"" ssid = ""10"">We include a constituent in our hypothesized parse if it appears in the output of a majority of the parsers.</S><S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S>",['Method_Citation']
10,W99-0623,P01-1005,0,"Henderson and Brill, 1999",0,"Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","['139', '96', '132', '38', '125']","<S sid =""139"" ssid = ""1"">We have presented two general approaches to studying parser combination: parser switching and parse hybridization.</S><S sid =""96"" ssid = ""25"">We call such a constituent an isolated constituent.</S><S sid =""132"" ssid = ""61"">The results of this experiment can be seen in Table 5.</S><S sid =""38"" ssid = ""24"">Under certain conditions the constituent voting and naïve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S><S sid =""125"" ssid = ""54"">The constituent voting and naïve Bayes techniques are equivalent because the parameters learned in the training set did not sufficiently discriminate between the three parsers.</S>",['Method_Citation']
11,W99-0623,D09-1161,0,1999,0,"Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","['43', '15', '52', '84', '93']","<S sid =""43"" ssid = ""29"">A receives a votes  and B receives b votes.</S><S sid =""15"" ssid = ""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S><S sid =""52"" ssid = ""38"">This drastic tree manipulation is not appropriate for situations in which we want to assign particular structures to sentences.</S><S sid =""84"" ssid = ""13"">The first shows how constituent features and context do not help in deciding which parser to trust.</S><S sid =""93"" ssid = ""22"">Because we are working with only three parsers  the only situation in which context will help us is when it can indicate we should choose to believe a single parser that disagrees with the majority hypothesis instead of the majority hypothesis itself.</S>",['Method_Citation']
12,W99-0623,D09-1161,0,1999,0,"Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","['101', '126', '27', '52', '43']","<S sid =""101"" ssid = ""30"">We show the results of three of the experiments we conducted to measure isolated constituent precision under various partitioning schemes.</S><S sid =""126"" ssid = ""55"">Table 4 shows how much the Bayes switching technique uses each of the parsers on the test set.</S><S sid =""27"" ssid = ""13"">Another technique for parse hybridization is to use a naïve Bayes classifier to determine which constituents to include in the parse.</S><S sid =""52"" ssid = ""38"">This drastic tree manipulation is not appropriate for situations in which we want to assign particular structures to sentences.</S><S sid =""43"" ssid = ""29"">A receives a votes  and B receives b votes.</S>",['Implication_Citation']
13,W99-0623,D09-1161,0,"Henderson and Brill, 1999",0,"Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","['126', '142', '111', '43', '52']","<S sid =""126"" ssid = ""55"">Table 4 shows how much the Bayes switching technique uses each of the parsers on the test set.</S><S sid =""142"" ssid = ""4"">Both of the switching techniques  as well as the parametric hybridization technique were also shown to be robust when a poor parser was introduced into the experiments.</S><S sid =""111"" ssid = ""40"">The first row represents the average accuracy of the three parsers we combine.</S><S sid =""43"" ssid = ""29"">A receives a votes  and B receives b votes.</S><S sid =""52"" ssid = ""38"">This drastic tree manipulation is not appropriate for situations in which we want to assign particular structures to sentences.</S>",['Method_Citation']
14,W99-0623,N06-2033,0,"Henderson and Brill, 1999",0,"Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","['101', '50', '15', '106', '22']","<S sid =""101"" ssid = ""30"">We show the results of three of the experiments we conducted to measure isolated constituent precision under various partitioning schemes.</S><S sid =""50"" ssid = ""36"">There is a guarantee of no crossing brackets but there is no guarantee that a constituent in the tree has the same children as it had in any of the three original parses.</S><S sid =""15"" ssid = ""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S><S sid =""106"" ssid = ""35"">In each figure the upper graph shows the isolated constituent precision and the bottom graph shows the corresponding number of hypothesized constituents.</S><S sid =""22"" ssid = ""8"">If enough parsers suggest that a particular constituent belongs in the parse  we include it.</S>",['Method_Citation']
15,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","['50', '111', '30', '28', '27']","<S sid =""50"" ssid = ""36"">There is a guarantee of no crossing brackets but there is no guarantee that a constituent in the tree has the same children as it had in any of the three original parses.</S><S sid =""111"" ssid = ""40"">The first row represents the average accuracy of the three parsers we combine.</S><S sid =""30"" ssid = ""16"">This is equivalent to the assumption used in probability estimation for naïve Bayes classifiers  namely that the attribute values are conditionally independent when the target value is given.</S><S sid =""28"" ssid = ""14"">The development of a naïve Bayes classifier involves learning how much each parser should be trusted for the decisions it makes.</S><S sid =""27"" ssid = ""13"">Another technique for parse hybridization is to use a naïve Bayes classifier to determine which constituents to include in the parse.</S>",['Method_Citation']
16,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","['61', '140', '131', '112', '34']","<S sid =""61"" ssid = ""47"">We pick the parse that is most similar to the other parses by choosing the one with the highest sum of pairwise similarities.</S><S sid =""140"" ssid = ""2"">For each experiment we gave an nonparametric and a parametric technique for combining parsers.</S><S sid =""131"" ssid = ""60"">It was then tested on section 22 of the Treebank in conjunction with the other parsers.</S><S sid =""112"" ssid = ""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid =""34"" ssid = ""20"">Mi(c) is a binary function returning t when parser i (from among the k parsers) suggests constituent c should be in the parse.</S>",['Results_Citation']
17,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"output (Figure 3) .Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework. Third, we extend these parser combination methods from 1-best outputs to n-best outputs","Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework","['87', '57', '37', '11', '100']","<S sid =""87"" ssid = ""16"">It is possible one could produce better models by introducing features describing constituents and their contexts because one parser could be much better than the majority of the others in particular situations.</S><S sid =""57"" ssid = ""43"">The combining technique must act as a multi-position switch indicating which parser should be trusted for the particular sentence.</S><S sid =""37"" ssid = ""23"">Here NO counts the number of hypothesized constituents in the development set that match the binary predicate specified as an argument.</S><S sid =""11"" ssid = ""7"">Similar advances have been made in machine translation (Frederking and Nirenburg  1994)  speech recognition (Fiscus  1997) and named entity recognition (Borthwick et al.  1998).</S><S sid =""100"" ssid = ""29"">When this metric is less than 0.5  we expect to incur more errors' than we will remove by adding those constituents to the parse.</S>",['Implication_Citation']
18,W99-0623,P09-1065,0,"Henderson and Brill, 1999",0,"System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","['83', '11', '108', '107', '118']","<S sid =""83"" ssid = ""12"">We performed three experiments to evaluate our techniques.</S><S sid =""11"" ssid = ""7"">Similar advances have been made in machine translation (Frederking and Nirenburg  1994)  speech recognition (Fiscus  1997) and named entity recognition (Borthwick et al.  1998).</S><S sid =""108"" ssid = ""37"">From this we see that a finer-grained model for parser combination  at least for the features we have examined  will not give us any additional power.</S><S sid =""107"" ssid = ""36"">Again we notice that the isolated constituent precision is larger than 0.5 only in those partitions that contain very few samples.</S><S sid =""118"" ssid = ""47"">The maximum precision oracle is an upper bound on the possible gain we can achieve by parse hybridization.</S>",['Method_Citation']
20,W99-0623,C10-1151,0,1999,0,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,"['18', '30', '52', '113', '50']","<S sid =""18"" ssid = ""4"">These two principles guide experimentation in this framework  and together with the evaluation measures help us decide which specific type of substructure to combine.</S><S sid =""30"" ssid = ""16"">This is equivalent to the assumption used in probability estimation for naïve Bayes classifiers  namely that the attribute values are conditionally independent when the target value is given.</S><S sid =""52"" ssid = ""38"">This drastic tree manipulation is not appropriate for situations in which we want to assign particular structures to sentences.</S><S sid =""113"" ssid = ""42"">The next two rows are results of oracle experiments.</S><S sid =""50"" ssid = ""36"">There is a guarantee of no crossing brackets but there is no guarantee that a constituent in the tree has the same children as it had in any of the three original parses.</S>",['Results_Citation']
