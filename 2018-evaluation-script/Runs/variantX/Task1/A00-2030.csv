Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,A00-2030,W01-0510,0,"Miller et al., 2000",0,"Section 5 compares our approach tooth ers in the literature, in particular that of (Miller et al., 2000)","Section 5 compares our approach too thiers in the literature, in particular that of (Miller et al., 2000)","['68', '79', '82', '102', '56']","<S sid =""68"" ssid = ""9"">The next steps are to generate in order: In this case  there are none.</S><S sid =""79"" ssid = ""1"">Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus.</S><S sid =""82"" ssid = ""1"">Given a sentence to be analyzed  the search program must find the most likely semantic and syntactic interpretation.</S><S sid =""102"" ssid = ""7"">The results are summarized in Table 2.</S><S sid =""56"" ssid = ""2"">For example  in the phrase &quot;Lt. Cmdr.</S>",['Implication_Citation']
2,A00-2030,W01-0510,0,"Miller et al, 2000",0,"The basic approach we described is very similar to the one presented in (Miller et al, 2000) however there are a few major di erences:  in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. The approach in (Miller","The basic approach we described is very similar to the one presented in (Miller et al, 2000) however there are a few major differences:  in our approach the augmentation of the syn tactic tags with semantic tags is straightforward due to the fact that the semantic constituents are matched exactly 5. The approach in (Miller","['65', '96', '23', '88', '9']","<S sid =""65"" ssid = ""6"">We illustrate the generation process by walking through a few of the steps of the parse shown in Figure 3.</S><S sid =""96"" ssid = ""1"">Our system for MUC-7 consisted of the sentential model described in this paper  coupled with a simple probability model for cross-sentence merging.</S><S sid =""23"" ssid = ""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S><S sid =""88"" ssid = ""7"">For purposes of pruning  and only for purposes of pruning  the prior probability of each constituent category is multiplied by the generative probability of that constituent (Goodman  1997).</S><S sid =""9"" ssid = ""7"">Manually creating sourcespecific training data for syntax was not required.</S>",['Implication_Citation']
3,A00-2030,W01-0510,0,"Miller et al, 2000",0,"The semantic annotation required by our task is much simpler than that employed by (Miller et al, 2000)","The semantic annotation required by our task is much simpler than that employed by (Miller et al, 2000)","['88', '68', '36', '6', '96']","<S sid =""88"" ssid = ""7"">For purposes of pruning  and only for purposes of pruning  the prior probability of each constituent category is multiplied by the generative probability of that constituent (Goodman  1997).</S><S sid =""68"" ssid = ""9"">The next steps are to generate in order: In this case  there are none.</S><S sid =""36"" ssid = ""4"">The five key facts in this example are: Here  each &quot;reportable&quot; name or description is identified by a &quot;-r&quot; suffix attached to its semantic label.</S><S sid =""6"" ssid = ""4"">In this paper  we report adapting a lexicalized  probabilistic context-free parser with head rules (LPCFG-HR) to information extraction.</S><S sid =""96"" ssid = ""1"">Our system for MUC-7 consisted of the sentential model described in this paper  coupled with a simple probability model for cross-sentence merging.</S>",['Results_Citation']
4,A00-2030,W01-0510,0,"Miller et al, 2000",0,"One possibly bene cial extension of our work suggested by (Miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level","One possibly beneficial extension of our work suggested by (Miller et al, 2000) would be to add semantic tags describing relations between entities (slots), in which case the semantic constraints would not be structured strictly on the two levels used in the current approach, respectively frame and slot level","['60', '62', '13', '36', '105']","<S sid =""60"" ssid = ""1"">In our statistical model  trees are generated according to a process similar to that described in (Collins 1996  1997).</S><S sid =""62"" ssid = ""3"">For each constituent  the head is generated first  followed by the modifiers  which are generated from the head outward.</S><S sid =""13"" ssid = ""3"">For each organization in an article  one must identify all of its names as used in the article  its type (corporation  government  or other)  and any significant description of it.</S><S sid =""36"" ssid = ""4"">The five key facts in this example are: Here  each &quot;reportable&quot; name or description is identified by a &quot;-r&quot; suffix attached to its semantic label.</S><S sid =""105"" ssid = ""2"">A single model proved capable of performing all necessary sentential processing  both syntactic and semantic.</S>",['Method_Citation']
5,A00-2030,W01-0510,0,"Miller et al, 2000",0,"Similar to the approach in (Miller et al, 2000 )weinitialized the SLM statistics from the UPenn Tree bank parse trees (about 1Mwds of training data) at the rst training stage, see Section 3","Similar to the approach in (Miller et al, 2000) we initialized the SLM statistics from the UPenn Tree bank parse trees","['38', '47', '73', '97', '80']","<S sid =""38"" ssid = ""6"">Other labels indicate relations among entities.</S><S sid =""47"" ssid = ""7"">It soon became painfully obvious that this task could not be performed in the available time.</S><S sid =""73"" ssid = ""14"">We now briefly summarize the probability structure of the model.</S><S sid =""97"" ssid = ""2"">The evaluation results are summarized in Table 1.</S><S sid =""80"" ssid = ""2"">However  because these estimates are too sparse to be relied upon  we use interpolated estimates consisting of mixtures of successively lowerorder estimates (as in Placeway et al. 1993).</S>",['Method_Citation']
6,A00-2030,P14-1078,0,"Miller et al, 2000",0,"Rule-based methods (Miller et al, 2000) employ a number of linguistic rules to capture relation patterns","Rule-based methods (Miller et al, 2000) employ a number of linguistic rules to capture relation patterns","['79', '15', '45', '88', '56']","<S sid =""79"" ssid = ""1"">Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus.</S><S sid =""15"" ssid = ""5"">For each location  one must also give its type (city  province  county  body of water  etc.).</S><S sid =""45"" ssid = ""5"">The retrieved articles would then be annotated with augmented tree structures to serve as a training corpus.</S><S sid =""88"" ssid = ""7"">For purposes of pruning  and only for purposes of pruning  the prior probability of each constituent category is multiplied by the generative probability of that constituent (Goodman  1997).</S><S sid =""56"" ssid = ""2"">For example  in the phrase &quot;Lt. Cmdr.</S>",['Method_Citation']
7,A00-2030,P05-1061,0,2000,0,"One interesting system that does not belong to the above class is that of Miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations","One interesting system that does not belong to the above class is that of Miller et al (2000), who take the view that relation extraction is just a form of probabilistic parsing where parse trees are augmented to identify all relations","['49', '70', '69', '95', '111']","<S sid =""49"" ssid = ""9"">By necessity  we adopted the strategy of hand marking only the semantics.</S><S sid =""70"" ssid = ""11"">Post-modifier constituents for the PER/NP.</S><S sid =""69"" ssid = ""10"">8.</S><S sid =""95"" ssid = ""14"">The semantics â€” that is  the entities and relations â€” can then be directly extracted from these sentential trees.</S><S sid =""111"" ssid = ""3"">The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies  either expressed or implied  of the Defense Advanced Research Projects Agency or the United States Government.</S>",['Method_Citation']
8,A00-2030,P05-1053,0,2000,0,"Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees","Miller et al (2000) augmented syntactic full parse trees with semantic information corresponding to entities and relations, and built generative models for the augmented trees","['23', '79', '4', '82', '67']","<S sid =""23"" ssid = ""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S><S sid =""79"" ssid = ""1"">Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus.</S><S sid =""4"" ssid = ""2"">Yet  relatively few have embedded one of these algorithms in a task.</S><S sid =""82"" ssid = ""1"">Given a sentence to be analyzed  the search program must find the most likely semantic and syntactic interpretation.</S><S sid =""67"" ssid = ""8"">We pick up the derivation just after the topmost S and its head word  said  have been produced.</S>",['Method_Citation']
9,A00-2030,P05-1053,0,2000,0,"Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model","Complicated relation extraction tasks may also impose a big challenge to the modeling approach used by Miller et al (2000) which integrates various tasks such as part-of-speech tagging, named entity recognition, template element extraction and relation extraction, in a single model","['20', '31', '0', '38', '84']","<S sid =""20"" ssid = ""3"">However  pipelined architectures suffer from a serious disadvantage: errors accumulate as they propagate through the pipeline.</S><S sid =""31"" ssid = ""14"">If the single generalized model could then be extended to semantic analysis  all necessary sentence level processing would be contained in that model.</S><S sid =""0"" ssid = ""0"">A Novel Use of Statistical Parsing to Extract Information from Text</S><S sid =""38"" ssid = ""6"">Other labels indicate relations among entities.</S><S sid =""84"" ssid = ""3"">Although mathematically the model predicts tree elements in a top-down fashion  we search the space bottom-up using a chartbased search.</S>",['Method_Citation']
10,A00-2030,H05-1094,0,2000,0,"(Miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. Part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable","(Miller et al, 2000) have combined entity recognition, parsing, and relation extraction into a jointly-trained single statistical parsing model that achieves improved performance on all the subtasks. Part of the contribution of the current work is to suggest that joint decoding can be effective even when joint training is not possible because jointly-labeled data is unavailable","['88', '38', '107', '104', '23']","<S sid =""88"" ssid = ""7"">For purposes of pruning  and only for purposes of pruning  the prior probability of each constituent category is multiplied by the generative probability of that constituent (Goodman  1997).</S><S sid =""38"" ssid = ""6"">Other labels indicate relations among entities.</S><S sid =""107"" ssid = ""4"">The semantic training corpus was produced by students according to a simple set of guidelines.</S><S sid =""104"" ssid = ""1"">We have demonstrated  at least for one problem  that a lexicalized  probabilistic context-free parser with head rules (LPCFGHR) can be used effectively for information extraction.</S><S sid =""23"" ssid = ""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S>",['Implication_Citation']
11,A00-2030,P04-1054,0,2000,0,Miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,Miller et al (2000) propose an integrated statistical parsing technique that augments parse trees with semantic labels denoting entity and relation types,"['82', '45', '74', '69', '111']","<S sid =""82"" ssid = ""1"">Given a sentence to be analyzed  the search program must find the most likely semantic and syntactic interpretation.</S><S sid =""45"" ssid = ""5"">The retrieved articles would then be annotated with augmented tree structures to serve as a training corpus.</S><S sid =""74"" ssid = ""15"">The categories for head constituents  clâ€ž are predicted based solely on the category of the parent node  cp: Modifier constituent categories  cm  are predicted based on their parent node  cp  the head constituent of their parent node  chp  the previously generated modifier  câ€ž _1  and the head word of their parent  wp.</S><S sid =""69"" ssid = ""10"">8.</S><S sid =""111"" ssid = ""3"">The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies  either expressed or implied  of the Defense Advanced Research Projects Agency or the United States Government.</S>",['Method_Citation']
12,A00-2030,P04-1054,0,2000,0,"WhereasMiller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance","Whereas Miller et al (2000) use a generative model to produce parse information as well as relation information, we hypothesize that a technique discriminatively trained to classify relations will achieve better performance","['45', '102', '82', '62', '68']","<S sid =""45"" ssid = ""5"">The retrieved articles would then be annotated with augmented tree structures to serve as a training corpus.</S><S sid =""102"" ssid = ""7"">The results are summarized in Table 2.</S><S sid =""82"" ssid = ""1"">Given a sentence to be analyzed  the search program must find the most likely semantic and syntactic interpretation.</S><S sid =""62"" ssid = ""3"">For each constituent  the head is generated first  followed by the modifiers  which are generated from the head outward.</S><S sid =""68"" ssid = ""9"">The next steps are to generate in order: In this case  there are none.</S>",['Method_Citation']
13,A00-2030,W05-0602,0,"Miller et al, 2000",0,"The syntactic model in (Miller et al, 2000) is similar to Collins?, but doesnot use features like sub cat frames and distance measures","The syntactic model in (Miller et al, 2000) is similar to Collins', but does not use features like subcat frames and distance measures","['45', '97', '75', '95', '59']","<S sid =""45"" ssid = ""5"">The retrieved articles would then be annotated with augmented tree structures to serve as a training corpus.</S><S sid =""97"" ssid = ""2"">The evaluation results are summarized in Table 1.</S><S sid =""75"" ssid = ""16"">Separate probabilities are maintained for left (pre) and right (post) modifiers: Part-of-speech tags  t    for modifiers are predicted based on the modifier  cm  the partof-speech tag of the head word  th  and the head word itself  wh: Head words  wâ€žâ€ž for modifiers are predicted based on the modifier  cm  the part-of-speech tag of the modifier word   tâ€žâ€ž the part-ofspeech tag of the head word   th  and the head word itself  wh: lAwmicm tm th wh)  e.g.</S><S sid =""95"" ssid = ""14"">The semantics â€” that is  the entities and relations â€” can then be directly extracted from these sentential trees.</S><S sid =""59"" ssid = ""5"">These labels serve to form a continuous chain between the relation and its argument.</S>",['Method_Citation']
14,A00-2030,N07-2041,0,"Miller et al, 2000",0,"Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2","Similar to the approach in (Miller et al, 2000) and (Kulick et al, 2004), our parser integrates both syntactic and semantic annotations into a single annotation as shown in Figure 2","['76', '36', '112', '101', '5']","<S sid =""76"" ssid = ""17"">Finally  word features  fm  for modifiers are predicted based on the modifier  cm  the partof-speech tag of the modifier word   tâ€žâ€ž the part-of-speech tag of the head word th  the head word itself  wh  and whether or not the modifier head word  wâ€žâ€ž is known or unknown.</S><S sid =""36"" ssid = ""4"">The five key facts in this example are: Here  each &quot;reportable&quot; name or description is identified by a &quot;-r&quot; suffix attached to its semantic label.</S><S sid =""112"" ssid = ""4"">We thank Michael Collins of the University of Pennsylvania for his valuable suggestions.</S><S sid =""101"" ssid = ""6"">We evaluated part-of-speech tagging and parsing accuracy on the Wall Street Journal using a now standard procedure (see Collins 97)  and evaluated name finding accuracy on the MUC7 named entity test.</S><S sid =""5"" ssid = ""3"">Chiba  (1999) was able to use such a parsing algorithm to reduce perplexity with the long term goal of improved speech recognition.</S>",['Results_Citation']
15,A00-2030,W10-2924,0,2000,0,Miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,Miller et al (2000) adapt a probabilistic context-free parser for information extraction by augmenting syntactic labels with entity and relation labels,"['56', '68', '13', '38', '23']","<S sid =""56"" ssid = ""2"">For example  in the phrase &quot;Lt. Cmdr.</S><S sid =""68"" ssid = ""9"">The next steps are to generate in order: In this case  there are none.</S><S sid =""13"" ssid = ""3"">For each organization in an article  one must identify all of its names as used in the article  its type (corporation  government  or other)  and any significant description of it.</S><S sid =""38"" ssid = ""6"">Other labels indicate relations among entities.</S><S sid =""23"" ssid = ""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S>",['Implication_Citation']
16,A00-2030,W06-0508,0,"Miller et al, 2000",0,"Most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as SVO, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (Miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (Gamallo et al, 2002)","Most of the approaches for relation extraction rely on the mapping of syntactic dependencies, such as SVO, onto semantic relations, using either pattern matching or other strategies, such as probabilistic parsing for trees augmented with annotations for entities and relations (Miller et al 2000), or clustering of semantically similar syntactic dependencies, according to their selectional restrictions (Gamallo et al, 2002)","['51', '62', '36', '79', '107']","<S sid =""51"" ssid = ""11"">To produce a corpus of augmented parse trees  we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus  now annotated with complete augmented trees like that in Figure 3.</S><S sid =""62"" ssid = ""3"">For each constituent  the head is generated first  followed by the modifiers  which are generated from the head outward.</S><S sid =""36"" ssid = ""4"">The five key facts in this example are: Here  each &quot;reportable&quot; name or description is identified by a &quot;-r&quot; suffix attached to its semantic label.</S><S sid =""79"" ssid = ""1"">Maximum likelihood estimates for the model probabilities can be obtained by observing frequencies in the training corpus.</S><S sid =""107"" ssid = ""4"">The semantic training corpus was produced by students according to a simple set of guidelines.</S>",['Method_Citation']
17,A00-2030,P07-1055,0,"Miller et al, 2000",0,"This includes parsing and relation extraction (Miller et al, 2000), entity labeling and relation extraction (Roth and Yih, 2004), and part-of-speech tagging and chunking (Sutton et al, 2004)","This includes parsing and relation extraction (Miller et al, 2000), entity labeling and relation extraction (Roth and Yih, 2004), and part-of-speech tagging and chunking (Sutton et al, 2004)","['6', '49', '38', '5', '39']","<S sid =""6"" ssid = ""4"">In this paper  we report adapting a lexicalized  probabilistic context-free parser with head rules (LPCFG-HR) to information extraction.</S><S sid =""49"" ssid = ""9"">By necessity  we adopted the strategy of hand marking only the semantics.</S><S sid =""38"" ssid = ""6"">Other labels indicate relations among entities.</S><S sid =""5"" ssid = ""3"">Chiba  (1999) was able to use such a parsing algorithm to reduce perplexity with the long term goal of improved speech recognition.</S><S sid =""39"" ssid = ""7"">For example  the coreference relation between &quot;Nance&quot; and &quot;a paid consultant to ABC News&quot; is indicated by &quot;per-desc-of.&quot; In this case  because the argument does not connect directly to the relation  the intervening nodes are labeled with semantics &quot;-ptr&quot; to indicate the connection.</S>",['Results_Citation']
18,A00-2030,W05-0636,0,2000,0,"For example, Miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks","For example, Miller et al (2000) showed that performing parsing and information extraction in a joint model improves performance on both tasks","['23', '57', '88', '31', '83']","<S sid =""23"" ssid = ""6"">An integrated model can limit the propagation of errors by making all decisions jointly.</S><S sid =""57"" ssid = ""3"">David Edwin Lewis &quot; a node is inserted to indicate that &quot;Lt. Cmdr.&quot; is a descriptor for &quot;David Edwin Lewis.&quot; 5.</S><S sid =""88"" ssid = ""7"">For purposes of pruning  and only for purposes of pruning  the prior probability of each constituent category is multiplied by the generative probability of that constituent (Goodman  1997).</S><S sid =""31"" ssid = ""14"">If the single generalized model could then be extended to semantic analysis  all necessary sentence level processing would be contained in that model.</S><S sid =""83"" ssid = ""2"">More precisely  it must find the most likely augmented parse tree.</S>",['Aim_Citation']
19,A00-2030,N06-1037,0,2000,0,Miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,Miller et al (2000) address the task of relation extraction from the statistical parsing viewpoint,"['95', '45', '34', '4', '6']","<S sid =""95"" ssid = ""14"">The semantics â€” that is  the entities and relations â€” can then be directly extracted from these sentential trees.</S><S sid =""45"" ssid = ""5"">The retrieved articles would then be annotated with augmented tree structures to serve as a training corpus.</S><S sid =""34"" ssid = ""2"">In these trees  the standard TREEBANK structures are augmented to convey semantic information  that is  entities and relations.</S><S sid =""4"" ssid = ""2"">Yet  relatively few have embedded one of these algorithms in a task.</S><S sid =""6"" ssid = ""4"">In this paper  we report adapting a lexicalized  probabilistic context-free parser with head rules (LPCFG-HR) to information extraction.</S>",['Method_Citation']
