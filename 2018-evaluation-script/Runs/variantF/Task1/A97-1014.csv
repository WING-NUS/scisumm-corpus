Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,A97-1014,E99-1016,0,"Skut et al, 1997",0,"This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)","This type of model is used to facilitate the syntactic annotation of the NEGRA corpus of German newspaper texts (Skut et al, 1997)","['169', '99', '156', '165', '168']","<S sid =""169"" ssid = ""11"">Since the combinatorics of syntactic constructions creates a. demand for very large corpora.  efficiency of annotation is an important. criterion for the success of the developed methodology and tools.</S><S sid =""99"" ssid = ""12"">Because of the intended theory-independence of the scheme  we annotate only the common minimum.</S><S sid =""156"" ssid = ""37"">Accuracy of the unreliable 10% of assignments is 75%  i.e.  the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.</S><S sid =""165"" ssid = ""7"">In addition the approach provides empirical material for psycholinguistic investigation  since preferences for the choice of certain syntactic constructions  linea.rizations  and attachments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alternatives in larger amounts of texts.</S><S sid =""168"" ssid = ""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S>",['Method_Citation']
2,A97-1014,E99-1016,0,"Skut et al, 1997",0,"For our experiments, we use the NEGRA corpus (Skut et al, 1997)","For our experiments, we use the NEGRA corpus (Skut et al, 1997)","['140', '99', '103', '168', '97']","<S sid =""140"" ssid = ""21"">For the implementation  we used Tcl/Tk Version 4.1.</S><S sid =""99"" ssid = ""12"">Because of the intended theory-independence of the scheme  we annotate only the common minimum.</S><S sid =""103"" ssid = ""16"">For instance  the first  determiner among the NK's can be treated as the specifier of the phrase.</S><S sid =""168"" ssid = ""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid =""97"" ssid = ""10"">Moreover  the so-called DP analysis views the article der as the head of the phrase.</S>",['Method_Citation']
3,A97-1014,E12-1047,0,"Skut et al, 1997",0,"As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training ,devel 1 10 100 1000 10000 100000 3 4 5 6 7 8 9 Frequenc y Parsing complexity head-driven optimal head-driven Figure 6: The distribution of parsing complexity among productions in Markovized, head-driven grammars read off from NEGRA-25","As data we use version 2 of the Negra (Skut et al1997) tree bank, with the common training","['99', '145', '156', '97', '151']","<S sid =""99"" ssid = ""12"">Because of the intended theory-independence of the scheme  we annotate only the common minimum.</S><S sid =""145"" ssid = ""26"">This amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above).</S><S sid =""156"" ssid = ""37"">Accuracy of the unreliable 10% of assignments is 75%  i.e.  the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.</S><S sid =""97"" ssid = ""10"">Moreover  the so-called DP analysis views the article der as the head of the phrase.</S><S sid =""151"" ssid = ""32"">For evaluation  the already annotated sentences were divided into two disjoint sets  one for training (90% of the corpus)  the other one for testing (10%).</S>",['Method_Citation']
5,A97-1014,I05-6010,0,1997,0,According to Skut et al (1997) tree banks have to meet the following requirements: 1,According to Skut et al (1997) tree banks have to meet the following requirements: 1,"['69', '111', '127', '158', '85']","<S sid =""69"" ssid = ""14"">Due to the rudimentary character of the argument structure representations  a great deal of information has to be expressed by grammatical functions.</S><S sid =""111"" ssid = ""24"">If the scope of such a word does not directly correspond to a tree node  the word is attached to the lowest node dominating all subconstituents appearing in its scope.</S><S sid =""127"" ssid = ""8"">As the need for certain functionalities becomes obvious with growing annotation experience  we have decided to implement the tool in two stages.</S><S sid =""158"" ssid = ""39"">Owing to the partial automation  the average annotation efficiency improves by 25% (from around 4 minutes to 3 minutes per sentence).</S><S sid =""85"" ssid = ""30"">In such cases  an additional edge is drawn from the embedded VP node to the controller  thus changing the syntactic tree into a graph.</S>",['Implication_Citation']
7,A97-1014,C10-1061,0,"Skut et al, 1997",0,"In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997) .Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node","In contrast, some other tree banks, such as the German NeGra and TIGER tree banks allow annotation with crossing branches (Skut et al, 1997). Non-local dependencies can then be expressed directly by grouping all dependent elements under a single node","['167', '111', '2', '165', '74']","<S sid =""167"" ssid = ""9"">In the second phase of the project Verbmobil a. treebank for :30 000 German spoken sentences as well as for the same amount of English and Japanese sentences will be created.</S><S sid =""111"" ssid = ""24"">If the scope of such a word does not directly correspond to a tree node  the word is attached to the lowest node dominating all subconstituents appearing in its scope.</S><S sid =""2"" ssid = ""2"">Since the requirements for such a formalism differ from those posited for configurational languages  several features have been added  influencing the architecture of the scheme.</S><S sid =""165"" ssid = ""7"">In addition the approach provides empirical material for psycholinguistic investigation  since preferences for the choice of certain syntactic constructions  linea.rizations  and attachments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alternatives in larger amounts of texts.</S><S sid =""74"" ssid = ""19"">During the first phase  the focus is on annotating correct structures and a coarse-grained classification of grammatical functions  which represent the following areas of information: Dependency type: complements are further classified according to features such as category and case: clausal complements (OC)  accusative objects (OA)  datives (DA)  etc.</S>",['Method_Citation']
8,A97-1014,C10-1061,0,"Skut et al, 1997",0,"Our data source is the German NeGra tree bank (Skut et al, 1997)","Our data source is the German NeGra tree bank (Skut et al, 1997)","['130', '150', '102', '128', '25']","<S sid =""130"" ssid = ""11"">The implementation of the first phase as described in the following paragraphs is completed.</S><S sid =""150"" ssid = ""31"">To keep the human annotator from missing errors made by the tagger  we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient)  the assignment is regarded as unreliable  and the annotator is asked to confirm the assignment.</S><S sid =""102"" ssid = ""15"">The difference between the particular NK's lies in the positional and part-of-speech information  which is also sufficient to recover theory-specific structures from our `underspecified' representations.</S><S sid =""128"" ssid = ""9"">In the first phase  the main functionality for building and displaying unordered trees is supplied.</S><S sid =""25"" ssid = ""15"">The underlying argument SirlteilITC is not represented directly  but can be recovered from the tree and trace-filler annotations.</S>",['Method_Citation']
9,A97-1014,P05-1039,0,"Skut et al, 1997",0,"The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences","The parsing models we present are trained and tested on the NEGRA corpus (Skut et al, 1997), a hand parsed corpus of German newspaper text containing approximately 20,000 sentences","['168', '71', '113', '90', '167']","<S sid =""168"" ssid = ""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid =""71"" ssid = ""16"">However  there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.</S><S sid =""113"" ssid = ""26"">Since a precise structural description of non-constituent coordination would require a. rich inventory of incomplete phrase types  we have agreed on a sort of unde.rspe.cified representations: the coordinated units are assigned structures in which missing lexical material is not represented at the level of primary links.</S><S sid =""90"" ssid = ""3"">In the following paragraphs  we give annotations for a number of such phenomena..</S><S sid =""167"" ssid = ""9"">In the second phase of the project Verbmobil a. treebank for :30 000 German spoken sentences as well as for the same amount of English and Japanese sentences will be created.</S>",['Method_Citation']
10,A97-1014,P03-1013,0,"Skut et al, 1997",0,"The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German","The present paper addresses this question by proposing a probabilistic parsing model trained on Negra (Skut et al, 1997), a syntactically annotated corpus for German","['4', '150', '111', '145', '90']","<S sid =""4"" ssid = ""1"">The work reported in this paper aims at providing syntactically annotated corpora (treebanks') for stochastic grammar induction.</S><S sid =""150"" ssid = ""31"">To keep the human annotator from missing errors made by the tagger  we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient)  the assignment is regarded as unreliable  and the annotator is asked to confirm the assignment.</S><S sid =""111"" ssid = ""24"">If the scope of such a word does not directly correspond to a tree node  the word is attached to the lowest node dominating all subconstituents appearing in its scope.</S><S sid =""145"" ssid = ""26"">This amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above).</S><S sid =""90"" ssid = ""3"">In the following paragraphs  we give annotations for a number of such phenomena..</S>",['Method_Citation']
11,A97-1014,P03-1013,0,"Skut et al, 1997",0,"The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences","The annotation scheme (Skut et al, 1997) is modeled to a certain extent on that of the Penn Treebank (Marcuset al, 1993), with crucial differences","['156', '165', '150', '69', '99']","<S sid =""156"" ssid = ""37"">Accuracy of the unreliable 10% of assignments is 75%  i.e.  the annotator has to alter the choice in 1 of 4 cases when asked for confirmation.</S><S sid =""165"" ssid = ""7"">In addition the approach provides empirical material for psycholinguistic investigation  since preferences for the choice of certain syntactic constructions  linea.rizations  and attachments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alternatives in larger amounts of texts.</S><S sid =""150"" ssid = ""31"">To keep the human annotator from missing errors made by the tagger  we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient)  the assignment is regarded as unreliable  and the annotator is asked to confirm the assignment.</S><S sid =""69"" ssid = ""14"">Due to the rudimentary character of the argument structure representations  a great deal of information has to be expressed by grammatical functions.</S><S sid =""99"" ssid = ""12"">Because of the intended theory-independence of the scheme  we annotate only the common minimum.</S>",['Method_Citation']
13,A97-1014,W04-1505,0,"Skut et al, 1997",0,"German is con sider ably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA an notation has been conceived to be quite at (Skut et al, 1997)","German is considerably more in ectional which means that discarding functional information is more harmful, and which explains why the NEGRA annotation has been conceived to be quite at (Skut et al, 1997)","['64', '109', '150', '102', '73']","<S sid =""64"" ssid = ""9"">The subject is itself a sentence in which the copula (zA) does occur and is assigned the tag HD'.</S><S sid =""109"" ssid = ""22"">In addition  we have adopted a simple convention for those cases in which context information is insufficient  for total disambiguation: the highest possible attachment  site is chosen.</S><S sid =""150"" ssid = ""31"">To keep the human annotator from missing errors made by the tagger  we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient)  the assignment is regarded as unreliable  and the annotator is asked to confirm the assignment.</S><S sid =""102"" ssid = ""15"">The difference between the particular NK's lies in the positional and part-of-speech information  which is also sufficient to recover theory-specific structures from our `underspecified' representations.</S><S sid =""73"" ssid = ""18"">While in the first phase each annotator has to annotate structures as well as categories and functions  the refinement call be done separately for each representation level.</S>",['Implication_Citation']
14,A97-1014,C04-1074,0,"Skut et al, 1997",0,"The factors used in the algorithms and the algorithms themselves are evaluated on a Germancorpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)","The factors used in the algorithms and the algorithms themselves are evaluated on a German corpus annotated with syntactic and co reference in formation (Negra) (Skut et al, 1997)","['168', '165', '71', '150', '137']","<S sid =""168"" ssid = ""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid =""165"" ssid = ""7"">In addition the approach provides empirical material for psycholinguistic investigation  since preferences for the choice of certain syntactic constructions  linea.rizations  and attachments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alternatives in larger amounts of texts.</S><S sid =""71"" ssid = ""16"">However  there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.</S><S sid =""150"" ssid = ""31"">To keep the human annotator from missing errors made by the tagger  we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient)  the assignment is regarded as unreliable  and the annotator is asked to confirm the assignment.</S><S sid =""137"" ssid = ""18"">The following commands are available: The three tagsets used by the annotation tool (for words  phrases  and edges) are variable and are stored together with the corpus.</S>",['Method_Citation']
16,A97-1014,P11-2067,0,"Skut et al, 1997",0,"CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)","CKK uses the Dubey and Keller (2003) parser, which is trained on the Negra corpus (Skut et al, 1997)","['150', '168', '71', '165', '102']","<S sid =""150"" ssid = ""31"">To keep the human annotator from missing errors made by the tagger  we additionally calculate the strongest competitor for each label G. If its probability is close to the winner (closeness is defined by a threshold on the quotient)  the assignment is regarded as unreliable  and the annotator is asked to confirm the assignment.</S><S sid =""168"" ssid = ""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid =""71"" ssid = ""16"">However  there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.</S><S sid =""165"" ssid = ""7"">In addition the approach provides empirical material for psycholinguistic investigation  since preferences for the choice of certain syntactic constructions  linea.rizations  and attachments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alternatives in larger amounts of texts.</S><S sid =""102"" ssid = ""15"">The difference between the particular NK's lies in the positional and part-of-speech information  which is also sufficient to recover theory-specific structures from our `underspecified' representations.</S>",['Implication_Citation']
17,A97-1014,W08-1007,0,"Skut et al, 1997",0,"Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negratreebank (Skut et al, 1997) reports that lexicaliza tion of PCFGs decrease the parsing accuracy when parsing Negra? s flat constituent structures","Earlier studies by Dubey and Keller (2003) and Dubey (2005) using the Negra treebank (Skut et al, 1997) reports that lexicalization of PCFGs decrease the parsing accuracy when parsing Negra's flat constituent structures","['165', '71', '167', '145', '112']","<S sid =""165"" ssid = ""7"">In addition the approach provides empirical material for psycholinguistic investigation  since preferences for the choice of certain syntactic constructions  linea.rizations  and attachments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alternatives in larger amounts of texts.</S><S sid =""71"" ssid = ""16"">However  there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.</S><S sid =""167"" ssid = ""9"">In the second phase of the project Verbmobil a. treebank for :30 000 German spoken sentences as well as for the same amount of English and Japanese sentences will be created.</S><S sid =""145"" ssid = ""26"">This amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above).</S><S sid =""112"" ssid = ""25"">A problem for the rudimentary argument. structure representations is the use of incomplete structures in natural language  i.e. phenomena such as coordination and ellipsis.</S>",['Method_Citation']
19,A97-1014,D07-1066,0,"Skut et al, 1997",0,"A comparison of unlexicalised PCFG parsing (Ku ?bler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)","A comparison of unlexicalised PCFG parsing (Kubler, 2005) trained and evaluated on the German NEGRA (Skut et al, 1997) and the Tu? Ba D/Z (Telljohann et al, 2004) tree banks using LoPar (Schmid, 2000) shows a difference in parsing results of about 16%, using the PARSEVAL metric (Black et al, 1991)","['165', '71', '168', '169', '145']","<S sid =""165"" ssid = ""7"">In addition the approach provides empirical material for psycholinguistic investigation  since preferences for the choice of certain syntactic constructions  linea.rizations  and attachments that have been observed in online experiments of language production and comprehension can now be put in relation with the frequency of these alternatives in larger amounts of texts.</S><S sid =""71"" ssid = ""16"">However  there is a trade-off between the granularity of information encoded in the labels and the speed and accuracy of annotation.</S><S sid =""168"" ssid = ""10"">We will closely coordinate the further development of our corpus with the annotation work in Verbmobil and with other German efforts in corpus annotation.</S><S sid =""169"" ssid = ""11"">Since the combinatorics of syntactic constructions creates a. demand for very large corpora.  efficiency of annotation is an important. criterion for the success of the developed methodology and tools.</S><S sid =""145"" ssid = ""26"">This amount of data suffices as training material to reliably assign the grammatical functions if the user determines the elements of a phrase and its type (step 1 of the list above).</S>",['Method_Citation']
