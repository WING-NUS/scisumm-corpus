The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson  1998; Hoste et al.  2001) and for systems that use it in lexical acquisition (McCarthy  1997; Merlo and Leybold  2001; Korhonen  2002) because of the limited size of hand-tagged resources.The problem with using the predominant  or first sense heuristic  aside from the fact that it does not take surrounding context into account  is that it assumes some quantity of handtagged data.Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al.  2001).To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful  there is a strong case for obtaining a first  or predominant  sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.A noun    is thus described by a set of co-occurrence triples and associated frequencies  where is a grammatical relation and is a possible cooccurrence with in that relation.There are words where the first sense in WordNet is counter-intuitive  because of the size of the corpus  and because where the frequency data does not indicate a first sense  the ordering is arbitrary.It only requires raw text from the given domain and because of this it can easily be applied to a new domain  or sense inventory  given sufficient text.This is just 5% lower than results using the first sense in the manually labelled SemCor  and we obtain 67% precision on polysemous nouns that are not in SemCor.We do not assume that the predominant sense is a method of WSD in itself.We describe some related work in section 6 and conclude in section 7. are therefore investigating a method of automatically ranking WordNet senses from raw text.This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al.  1998) in figure 1 below  where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al.  2001).Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus  whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.A major motivation for our work is to try to capture changes in ranking of senses for documents from different domains.In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).We use an allwords task because the predominant senses will reflect the sense distributions of all nouns within the documents  rather than a lexical sample task  where the target words are manually determined and the results will depend on the skew of the words in the sample.The results in table 1 show the accuracy of the ranking with respect to SemCor over the entire set of 2595 polysemous nouns in SemCor with the jcn and lesk WordNet similarity measures.This figure shows the domain labels assigned to the predominant senses for the set of 38 words after ranking the words using the SPORTS and the FINANCE corpora.The results for 10 of the words from the qualitative experiment are summarized in table 3 with the WordNet sense number for each word supplied alongside synonyms or hypernyms from WordNet for readability.We generated a thesaurus entry for all polysemous nouns which occurred in SemCor with a frequency 2  and in the BNC with a frequency 10 in the grammatical relations listed in section 2.1 above.Whilst there are a few hand-tagged corpora available for some languages  one would expect the frequency distribution of the senses of words  particularly topical words  to depend on the genre and domain of the text under consideration.4 We calculate the accuracy of finding the predominant sense  when there is indeed one sense with a higher frequency than the others for this word in SemCor ( ).We expect that the quantity and similarity of the neighbours pertaining to different senses will reflect the dominance of the sense to which they pertain.We experimented using six of these to provide the in equation 1 above and obtained results well over our baseline  but because of space limitations give results for the two which perform the best.Even given the difference in text type between SemCor and the BNC the results are encouraging  especially given that our results are for polysemous nouns.We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.Since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense  and is much more efficient than lesk  given the precompilation of the IC files.In section 5 we present results of the method on two domain specific sections of the Reuters corpus for a sample of words.We then use the WordNet similarity package (Patwardhan and Pedersen  2003) to give us a semantic similarity measure (hereafter referred to as the WordNet similarity measure) to weight the contribution that each neighbour makes to the various senses of the target word.We are of course able to apply the method to other versions of WordNet. synset  is incremented with the frequency counts from the corpus of all words belonging to that synset  directly or via the hyponymy relation.Let be the ordered set of the top scoring neighbours of from the thesaurus with associated distributional similarity scores The thesaurus was acquired using the method described by Lin (1998).Nevertheless  since many systems performed well on the English all-words task for SENSEVAL-2 by using the frequency information in SemCor this is a reasonable approach for evaluation.Indeed  the merit of our technique is the very possibility of obtaining predominant senses from the data at hand.word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.Our automatically acquired predominant sense performs nearly as well as the first sense provided by SemCor  which is very encouraging given that our method only uses raw text  with no manual labelling.It is not always intuitively clear which of the senses to expect as predominant sense for either a particular domain or for the BNC  but the first senses of words like division and goal shift towards the more specific senses (league and score respectively).In order to see how well the automatically acquired predominant sense performs on a WSD task from which the WordNet sense ordering has not been taken  we use the SENSEVAL-2 all-words data (Palmer et al.  2001).This is to be expected regardless of any inherent shortcomings of the ranking technique since the senses within SemCor will differ compared to those of the BNC.The random baseline for choosing the predominant sense over all these words ( ) is 32%.This is because there will be more relational data for the more prevalent senses compared to the less frequent senses.