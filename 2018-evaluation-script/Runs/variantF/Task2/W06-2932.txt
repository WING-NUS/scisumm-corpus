Performance is measured through unlabeled accuracy  which is the percentage of words that modify the correct head in the dependency graph  and labeled accuracy  which is the percentage of words that modify the correct head and label the dependency edge correctly in the graph.The second stage takes the output from the first and labels all the edges in the dependency graph with appropriate syntactic categories using a globally trained sequence classifier over components of the graph.These results show that the discriminative spanning tree parsing framework (McDonald et al.  2005b; McDonald and Pereira  2006) is easily adapted across all these languages.Note the difference in error between the unlabeled parser and the edge labeler: the former makes mistakes on edges into prepositions  conjunctions and verbs  and the latter makes mistakes on edges into nouns (subject/objects).That work extends the maximum spanning tree dependency parsing framework (McDonald et al.  2005a; McDonald et al.  2005b) to incorporate features over multiple edges in the dependency graph.We have presented results showing that the spanning tree dependency parsing framework of McDonald et al. (McDonald et al.  2005b; McDonald and Pereira  2006) generalizes well to languages other than English.The first stage based on the unlabeled dependency parsing models described by McDonald and Pereira (2006) augmented with morphological features for a subset of the languages.In fact  for every language our models perform significantly higher than the average performance for all the systems reported in Buchholz et al. (2006).These results report the average labeled and unlabeled precision for the 10 languages with the smallest training sets.We evaluate this parser on a diverse set of 13 languages using data provided by the CoNLL-X shared-task organizers (Buchholz et al.  2006; Hajiˇc et al.  2004; Simov et al.  2005; Simov and Osenova  2003; Chen et al.  2003; B¨ohmov´a et al.  2003; Kromann  2003; van der Beek et al.  2002; Brants et al.  2002; Kawata and Bartels  2000; Afonso et al.  2002; Dˇzeroski et al.  2006; Civit Torruella and MartiAntonin  2002; Nilsson et al.  2005; Oflazer et al.  2003; Atalay et al.  2003).We trained models for all 13 languages provided by the CoNLL organizers (Buchholz et al.  2006).The results are promising and show the language independence of our system under the assumption of a labeled dependency corpus in the target language.With the availability of resources such as the Penn WSJ Treebank  much of the focus in the parsing community had been on producing syntactic representations based on phrase-structure.The simplest labeler would be to take as input an edge (i  j) E y for sentence x and find the label with highest score  Doing this for each edge in the tree would produce the final output.Note that many of these features are beyond the scope of the edge based factorizations of the unlabeled parser.That system uses MIRA  an online large-margin learning algorithm  to compute model parameters.We use the MIRA online learner to set the weights (Crammer and Singer  2003; McDonald et al.  2005a) since we found it trained quickly and provide good performance.We then add to the representation of the edge: Mi as head features  Mj as dependent features  and also each conjunction of a feature from both sets.We Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-X)  pages 216–220  New York City  June 2006. c�2006 Association for Computational Linguistics assume that all dependency graphs are trees but may be non-projective  both of which are true in the data sets we use.Furthermore  it made the system homogeneous in terms of learning algorithms since that is what is used to train our unlabeled parser (McDonald and Pereira  2006).Ideally one would like to make all parsing and labeling decisions jointly so that the shared knowledge of both decisions will help resolve any ambiguities.This interest has generally come about due to the computationally efficient and flexible nature of dependency graphs and their ability to easily model non-projectivity in freer-word order languages.Similarly  for labeled accuracy  the hardest edges to label are for dependents of verbs  i.e.  subjects  objects and adverbials.For instance  sequential labeling improves the labeling of 2This difference was much larger for experiments in which gold standard unlabeled dependencies are used. objects from 81.7%/75.6% to 84.2%/81.3% (labeled precision/recall) and the labeling of subjects from 86.8%/88.2% to 90.5%/90.4% for Swedish.Although overall unlabeled accuracy is 86%  most verbs and some conjunctions attach to their head words with much lower accuracy: 69% for main verbs  75% for the verb ser  and 65% for coordinating conjunctions.To model this we treat the labeling of the edges (i  j1)  ...   (i  jM) as a sequence labeling problem  We use a first-order Markov factorization of the score s(l(i jm)  l(i jm�1)  i  y  x) in which each factor is the score of labeling the adjacent edges (i  jm) and (i  jm−1) in the tree y.Even with this improvement  the labeling of verb dependents remains the highest source of error.In a preliminary test of this hypothesis  we looked at all of the sentences from a development set in which a main verb is incorrectly attached.However  in a two stage system we can incorporate features over the entire output of the unlabeled parser since that structure is fixed as input.This is not surprising since these edge labels typically are the most correlated (i.e.  if you already know which noun dependent is the subject  then it should be easy to find the object).It is our hope that a better morphological feature set will help with both unlabeled parsing and labeling for highly inflected languages.We need to look more carefully at verb features that may be useful here  in particular features that distinguish finite and non-finite forms.Its power lies in the ability to define a rich set of features over parsing decisions  as well as surface level features relative to these decisions.Is this the first dependent to the left/right of the head?A dependency graph is represented by a set of ordered pairs (i  j) E y in which xj is a dependent and xi is the corresponding head.For instance  the system of McDonald et al. (2005a) incorporates features over the part of speech of words occurring between and around a possible head-dependent relation.