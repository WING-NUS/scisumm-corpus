These rules are often too stringent  cused on aligning text to a world (Liang et al.  2009)  and for complex utterances  especially in free word- using text in reinforcement learning (Branavan et al.  order languages  either disharmonic combinators are 2009; Branavan et al.  2010)  and many others.Feedback from the context; for example  the lexical entry for borders world has been used to guide both syntactic parsing is S\NP/NP : Ay.Ax.border(x  y)  which means (Schuler  2003) and semantic parsing (Popescu et borders looks right for the first argument and left al.  2003; Clarke et al.  2010).As in Clarke et al. (2010)  we obviate the need for annotated logical forms by considering the endto-end problem of mapping questions to answers.At the same time  representations such as FunQL (Kate et al.  2005)  which was used in Clarke et al. (2010)  are simpler but lack the full expressive power of lambda calculus.Eisenciations due to data sparsity  and having an insuffi- stein et al. (2009) induces conjunctive formulae and ciently large K. uses them as features in another learning problem.Results We first compare our system with Clarke et al. (2010) (henceforth  SEMRESP)  which also learns a semantic parser from question-answer pairs.To contrast  consider et al. (2010)  which we discussed earlier.The full definition of join is as follows: Aggregate The aggregate operation takes a denotation and forms a set out of the tuples in the first column for each setting of the rest of the columns: Now we turn to the mark (M) and execute (Xi) operations  which handles the divergence between syntactic and semantic scope.This yields a more system is based on a new semantic representation  factorized and flexible representation that is easier DCS  which offers a simple and expressive alterto search through and parametrize using features. native to lambda calculus.It is this transparency between syntax and semantics provided by DCS which leads to a simple and streamlined compositional semantics suitable for program induction.In DCS  the mark-execute and Tom Kwiatkowski for providing us with data construct provides a flexible framework for dealing and answering questions.The main technical contribution of this work is a new semantic representation  dependency-based compositional semantics (DCS)  which is both simple and expressive (Section 2).Table 3 shows that even DCS  which does not use prototypes  is comparable to the best previous system (Kwiatkowski et al.  2010)  and by adding a few prototypes  DCS+ offers a decisive edge (91.1% over 88.9% on GEO).It is impossible to represent the semantics of this phrase with just a CSP  so we introduce a new aggregate relation  notated E. Consider a tree hE:ci  whose root is connected to a child c via E. If the denotation of c is a set of values s  the parent’s denotation is then a singleton set containing s. Formally: Figure 3(a) shows the DCS tree for our running example.Supervised semantic parsers (Zelle and Mooney  1996; Tang and Mooney  2001; Ge and Mooney  2005; Zettlemoyer and Collins  2005; Kate and Mooney  2007; Zettlemoyer and Collins  2007; Wong and Mooney  2007; Kwiatkowski et al.  2010) rely on manual annotation of logical forms  which is expensive.The logical forms in this framework are trees  which is desirable for two reasons: (i) they parallel syntactic dependency trees  which facilitates parsing and learning; and (ii) evaluating them to obtain the answer is computationally efficient.We find that only for a small fraction of training examples do the K-best sets contain any trees yielding the correct answer (29% for DCS on GEO).For example  In a DCS tree  the quantifier appears as the child of a Q relation  and the restrictor is the parent (see Figure 4(b) for an example).Although a DCS tree is a logical form  note that it looks like a syntactic dependency tree with predicates in place of words.In tackling this challenging learning problem  we introduce a new semantic representation which highlights a parallel between dependency syntax and efficient evaluation of logical forms.This evaluation is done with respect to a world w. Recall that a world w maps each predicate p ∈ P to a set of tuples w(p).We say a value v is consistent for a node x if there exists a solution that assigns v to x.Next  we compared our systems (DCS and DCS+) with the state-of-the-art semantic parsers on the full dataset for both GEO and JOBS (see Table 3).We first present a basic version (Section 2.1) of dependency-based compositional semantics (DCS)  which captures the core idea of using trees to represent formal semantics.The key idea that allows us to give semanticallyscoped denotations to syntactically-scoped trees is as follows: We mark a node low in the tree with a mark relation (one of E  Q  or C).Then higher up in the tree  we invoke it with an execute relation Xi to create the desired semantic scope.2 This mark-execute construct acts non-locally  so to maintain compositionality  we must augment the denotation d = JzKw to include any information about the marked nodes in z that can be accessed by an execute relation later on.The restriction to present (for example  [in  loc] has high weight). trees is similar to economical DRT (Bos  2009).We now turn to the task of mapping natural language For the example in Figure 4(b)  the de- utterances to DCS trees.The logical forms in DCS are called DCS trees  where nodes are labeled with predicates  and edges are labeled with relations.Our model is arc-factored  so we can sum over all DCS trees in ZL(x) using dynamic programming.In DCS  we start with lexical triggers  which are 6 Conclusion more basic than CCG lexical entries.There are three cases: Extraction (d.ri = E) In the basic version  the denotation of a tree was always the set of consistent values of the root node.Formally: Definition 1 (DCS trees) Let Z be the set of DCS trees  where each z ∈ Z consists of (i) a predicate for each child i  the ji-th component of v must equal the j'i-th component of some t in the child’s denotation (t ∈ JciKw).CCG (Steedman  2000)  in which semantic pars- The integration of natural language with denotaing is driven from the lexicon.This algorithm is linear in the number of nodes times the size of the denotations.1 Now the dual importance of trees in DCS is clear: We have seen that trees parallel syntactic dependency structure  which will facilitate parsing.Free from the burden It also allows us to easily add new lexical triggers of annotating logical forms  we hope to use our without becoming mired in the semantic formalism. techniques in developing even more accurate and Quantifiers and superlatives significantly compli- broader-coverage language understanding systems. cate scoping in lambda calculus  and often type rais- Acknowledgments We thank Luke Zettlemoyer ing needs to be employed.