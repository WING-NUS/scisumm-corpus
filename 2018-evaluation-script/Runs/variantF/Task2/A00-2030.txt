We evaluated the new approach to information extraction on two of the tasks of the Seventh Message Understanding Conference (MUC-7) and reported in (Marsh  1998).The probability of a complete tree is the product of the probabilities of generating each element in the tree.We can think of this prior probability as an estimate of the probability of generating a subtree with the constituent category  starting at the topmost node.We illustrate the generation process by walking through a few of the steps of the parse shown in Figure 3.syntactic modifier of the other  the inserted node serves to indicate the relation as well as the argument.Given multiple constituents that cover identical spans in the chart  only those constituents with probabilities within a While our focus throughout the project was on TE and TR  we became curious about how well the model did at part-of-speech tagging  syntactic parsing  and at name finding.Given a new sentence  the outcome of this search process is a tree structure that encodes both the syntactic and semantic structure of the sentence.For example  the coreference relation between &quot;Nance&quot; and &quot;a paid consultant to ABC News&quot; is indicated by &quot;per-desc-of.&quot; In this case  because the argument does not connect directly to the relation  the intervening nodes are labeled with semantics &quot;-ptr&quot; to indicate the connection.Whenever a relation involves an entity that is not a direct descendant of that relation in the parse tree  semantic pointer labels are attached to all of the intermediate nodes.This simple semantic annotation was the only source of task knowledge used to configure the model.Figure 4 shows an example of the semantic annotation  which was the only type of manual annotation we performed.Nearly all of the work was done by the sentential model; disabling the cross-sentence model entirely reduced our overall F-Score by only 2 points.The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies  either expressed or implied  of the Defense Advanced Research Projects Agency or the United States Government.To produce a corpus of augmented parse trees  we used the following multi-step training procedure which exploited the Penn TREEBANK Applying this procedure yielded a new version of the semantically annotated corpus  now annotated with complete augmented trees like that in Figure 3.At each step in the process  a choice is made from a statistical distribution  with the probability of each possible selection dependent on particular features of previously generated elements.Instead  we applied an information retrieval system to select a large number of articles from the desired sources  yielding a corpus rich in the desired types of events.These labels serve to form a continuous chain between the relation and its argument.Almost all approaches to information extraction — even at the sentence level — are based on the divide-and-conquer strategy of reducing a complex problem to a set of simpler ones.Chiba  (1999) was able to use such a parsing algorithm to reduce perplexity with the long term goal of improved speech recognition.Since it was known that the MUC-7 evaluation data would be drawn from a variety of newswire sources  and that the articles would focus on rocket launches  it was important that our training corpus be drawn from similar sources and that it cover similar events.The semantics — that is  the entities and relations — can then be directly extracted from these sentential trees.In this section  we describe the algorithm that was used to automatically produce augmented trees  starting with a) human-generated semantic annotations and b) machinegenerated syntactic parse trees.In these trees  the standard TREEBANK structures are augmented to convey semantic information  that is  entities and relations.Initially  we tried to annotate the training corpus by hand marking  for each sentence  the entire augmented tree.Our integrated model represents syntax and semantics jointly using augmented parse trees.If the single generalized model could then be extended to semantic analysis  all necessary sentence level processing would be contained in that model.Although each model differed in its detailed probability structure  we believed that the essential elements of all three models could be generalized in a single probability model.In this paper we report adapting a lexic al ized  probabilistic context-free parser to information extraction and evaluate this new technique on MUC-7 template elements and template relations.Thus  each component of what would be the first three stages of our pipeline was based on the same general class of statistical model.Because generative statistical models had already proven successful for each of the first three stages  we were optimistic that some of their properties — especially their ability to learn from large amounts of data  and their robustness when presented with unexpected inputs — would also benefit semantic analysis.For this reason  we focused on designing an integrated model in which tagging  namefinding  parsing  and semantic interpretation decisions all have the opportunity to mutually influence each other.The retrieved articles would then be annotated with augmented tree structures to serve as a training corpus.We were already using a generative statistical model for part-of-speech tagging (Weischedel et al. 1993)  and more recently  had begun using a generative statistical model for name finding (Bikel et al.Thus  we did not consider simply adding semantic labels to the existing Penn TREEBANK  which is drawn from a single source — the Wall Street Journal — and is impoverished in articles about rocket launches.Word features are introduced primarily to help with unknown words  as in (Weischedel et al. 1993).In this paper  we report adapting a lexicalized  probabilistic context-free parser with head rules (LPCFG-HR) to information extraction.We have demonstrated  at least for one problem  that a lexicalized  probabilistic context-free parser with head rules (LPCFGHR) can be used effectively for information extraction.Currently  the prevailing architecture for dividing sentential processing is a four-stage pipeline consisting of: Since we were interested in exploiting recent advances in parsing  replacing the syntactic analysis stage of the standard pipeline with a modern statistical parser was an obvious possibility.For purposes of pruning  and only for purposes of pruning  the prior probability of each constituent category is multiplied by the generative probability of that constituent (Goodman  1997).The Template Element (TE) task identifies organizations  persons  locations  and some artifacts (rocket and airplane-related artifacts).Technical agents for part of this work were Fort Huachucha and AFRL under contract numbers DABT63-94-C-0062  F30602-97-C-0096  and 4132-BBN-001.The detailed probability structure differs  however  in that it was designed to jointly perform part-of-speech tagging  name finding  syntactic parsing  and relation finding in a single process.We evaluated part-of-speech tagging and parsing accuracy on the Wall Street Journal using a now standard procedure (see Collins 97)  and evaluated name finding accuracy on the MUC7 named entity test.In both Template Entity (TE) and Template Relation (TR)  our system finished in second place among all entrants.A single model proved capable of performing all necessary sentential processing  both syntactic and semantic.For the following example  the The Template Relations (TR) task involves identifying instances of three relations in the text: TR builds on TE in that TR reports binary relations between elements of TE.