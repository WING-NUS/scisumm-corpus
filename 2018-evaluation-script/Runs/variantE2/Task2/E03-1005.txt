 While the models of Collins (1996) and Eisner (1996) restricted the fragments to the locality of head-words later models showed the importance of including context from higher nodes in the tree (Charniak 1997; Johnson 1998a) Next the rank of each (shortest) derivation is computed as the sum of the ranks of the subtrees involved The underlying idea of combining LikelihoodDOP and Simplicity-DOP is that the parser selects the simplest tree from among the n most probable trees where n is a free parameter While the PCFG reduction of Bod (2001) obtains state-of-the-art results on the WSJ comparable to Charniak (2000) Bonnema et al While SL-DOP and LS-DOP have been compared before in Bod (2002) especially in the context of musical parsing this paper presents the The DOP approach is based on two distinctive features: (1) the use of corpus fragments rather than grammar rules and (2) the use of arbitrarily large fragments rather than restricted ones The DOP model on the other hand was the first model (to the best of our knowledge) that proposed not to train a predefined grammar on a corpus but to directly use corpus fragments as a grammar Two apparently opposing DOP models exist in the literature: one which computes the parse tree involving the most frequent subtrees from a treebank and one which computes the parse tree involving the fewest subtrees from a treebank The distinctive feature of the DOP approach when it was proposed in 1992 was to model sentence structures on the basis of previously observed frequencies of sentence structure fragments without imposing any constraints on the size of these fragments