Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Reference Citation
1,W99-0623,A00-2005,0,1999,0,1 Introduct ion Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,Henderson and Brill (1999) showed that independent human research efforts produce parsers that can be combined for an overall boost in accuracy,"'1','111','85','15'","<S sid=""1"" ssid=""1"">Three state-of-the-art statistical parsers are combined to produce more accurate parses, as well as new bounds on achievable Treebank parsing accuracy.</S><S sid=""111"" ssid=""40"">The first row represents the average accuracy of the three parsers we combine.</S><S sid=""85"" ssid=""14"">We then show that the combining techniques presented above give better parsing accuracy than any of the individual parsers.</S><S sid=""15"" ssid=""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S>",
2,W99-0623,A00-2005,0,1999,0,the collection of hypotheses ti =fi (Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999),"Given a novel sentence Stest E Ctest, combine the collection of hypotheses ti = fi(Stest) using the unweighted constituent voting scheme of Henderson and Brill (1999)","'23','41','105','38'","<S sid=""23"" ssid=""9"">We call this technique constituent voting.</S><S sid=""41"" ssid=""27"">IL+-1Proof: Assume a pair of crossing constituents appears in the output of the constituent voting technique using k parsers.</S><S sid=""105"" ssid=""34"">Similarly Figures 1 and 2 show how the isolated constituent precision varies by sentence length and the size of the span of the hypothesized constituent.</S><S sid=""38"" ssid=""24"">Under certain conditions the constituent voting and na&#239;ve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S>",
4,W99-0623,N10-1091,0,"Henderson and Brill, 1999",0,"5 (Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","(Henderson and Brill, 1999) used a similar framework in the context of constituent parsing and only three base parsers","'14','84','19','25'","<S sid=""14"" ssid=""10"">We used these three parsers to explore parser combination techniques.</S><S sid=""84"" ssid=""13"">The first shows how constituent features and context do not help in deciding which parser to trust.</S><S sid=""19"" ssid=""5"">The precision and recall measures (described in more detail in Section 3) used in evaluating Treebank parsing treat each constituent as a separate entity, a minimal unit of correctness.</S><S sid=""25"" ssid=""11"">In our particular case the majority requires the agreement of only two parsers because we have only three.</S>",
5,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","A successful application of voting and of a stacked classifier to constituent parsing followed in (Henderson and Brill, 1999)","'23','120','38','27'","<S sid=""23"" ssid=""9"">We call this technique constituent voting.</S><S sid=""120"" ssid=""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid=""38"" ssid=""24"">Under certain conditions the constituent voting and na&#239;ve Bayes constituent combination techniques are guaranteed to produce sets of constituents with no crossing brackets.</S><S sid=""27"" ssid=""13"">Another technique for parse hybridization is to use a na&#239;ve Bayes classifier to determine which constituents to include in the parse.</S>",
6,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"This approach roughly corresponds to (Henderson and Brill, 1999)? s Na ?ve Bayes parse hybridization","This approach roughly corresponds to (Henderson and Brill, 1999)'s Naive Bayes parse hybridization","'16','27','2','32'","<S sid=""16"" ssid=""2"">We call this approach parse hybridization.</S><S sid=""27"" ssid=""13"">Another technique for parse hybridization is to use a na&#239;ve Bayes classifier to determine which constituents to include in the parse.</S><S sid=""2"" ssid=""2"">Two general approaches are presented and two combination techniques are described for each approach.</S><S sid=""32"" ssid=""18"">In Equations 1 through 3 we develop the model for constructing our parse using na&#239;ve Bayes classification.</S>",
7,W99-0623,W05-1518,0,1999,0,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,Henderson and Brill (1999) also reported that context did not help them to outperform simple voting,"'84','23','120','129'","<S sid=""84"" ssid=""13"">The first shows how constituent features and context do not help in deciding which parser to trust.</S><S sid=""23"" ssid=""9"">We call this technique constituent voting.</S><S sid=""120"" ssid=""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid=""129"" ssid=""58"">In the interest of testing the robustness of these combining techniques, we added a fourth, simple nonlexicalized PCFG parser.</S>",
8,W99-0623,W05-1518,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) improved their best parser? s F-measure of 89.7 to 91.3, using their na ?ve Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","(Henderson and Brill, 1999) improved their best parser's F-measure of 89.7 to 91.3, using their naive Bayes voting on the Penn TreeBank constituent structures (16% error reduction)","'120','41','32','143'","<S sid=""120"" ssid=""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S><S sid=""41"" ssid=""27"">IL+-1Proof: Assume a pair of crossing constituents appears in the output of the constituent voting technique using k parsers.</S><S sid=""32"" ssid=""18"">In Equations 1 through 3 we develop the model for constructing our parse using na&#239;ve Bayes classification.</S><S sid=""143"" ssid=""5"">Through parser combination we have reduced the precision error rate by 30% and the recall error rate by 6% compared to the best previously published result.</S>",
10,W99-0623,P01-1005,0,"Henderson and Brill, 1999",0,"Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","Voting has proven to be an effective technique for improving classifier accuracy for many applications, including part-of-speech tagging (van Halteren, et al 1998), parsing (Henderson and Brill, 1999), and word sense disambiguation (Pederson, 2000)","'9','27','11','13'","<S sid=""9"" ssid=""5"">Recently, combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al., 1998; Brill and Wu, 1998).</S><S sid=""27"" ssid=""13"">Another technique for parse hybridization is to use a na&#239;ve Bayes classifier to determine which constituents to include in the parse.</S><S sid=""11"" ssid=""7"">Similar advances have been made in machine translation (Frederking and Nirenburg, 1994), speech recognition (Fiscus, 1997) and named entity recognition (Borthwick et al., 1998).</S><S sid=""13"" ssid=""9"">These three parsers have given the best reported parsing results on the Penn Treebank Wall Street Journal corpus (Marcus et al., 1993).</S>",
11,W99-0623,D09-1161,0,1999,0,"Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","Regarding the system combination study, Henderson and Brill (1999) propose two parser combination schemes, one that selects an entire tree from one of the parsers, and one that builds a new tree by selecting constituents suggested by the initial trees","'97','55','21','70'","<S sid=""97"" ssid=""26"">If we were working with more than three parsers we could investigate minority constituents, those constituents that are suggested by at least one parser, but which the majority of the parsers do not suggest.</S><S sid=""55"" ssid=""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S><S sid=""21"" ssid=""7"">One hybridization strategy is to let the parsers vote on constituents' membership in the hypothesized set.</S><S sid=""70"" ssid=""56"">In this case we are interested in finding' the maximum probability parse, ri, and Mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.</S>",
12,W99-0623,D09-1161,0,1999,0,"Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","Henderson and Brill (1999) combine three parsers and obtained an F1 score of 90.6, which is better than the score of 88.6 obtained by the best individual parser as reported in their paper","'112','111','14','120'","<S sid=""112"" ssid=""41"">The second row is the accuracy of the best of the three parsers.'</S><S sid=""111"" ssid=""40"">The first row represents the average accuracy of the three parsers we combine.</S><S sid=""14"" ssid=""10"">We used these three parsers to explore parser combination techniques.</S><S sid=""120"" ssid=""49"">The precision and recall of similarity switching and constituent voting are both significantly better than the best individual parser, and constituent voting is significantly better than parser switching in precision.4 Constituent voting gives the highest accuracy for parsing the Penn Treebank reported to date.</S>",
13,W99-0623,D09-1161,0,"Henderson and Brill, 1999",0,"Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","Besides the two model scores, we also adopt constituent count as an additional feature in spired by (Henderson and Brill 1999) and (Sagae and Lavie 2006)","'102','108','89','91'","<S sid=""102"" ssid=""31"">In Table 1 we see with very few exceptions that the isolated constituent precision is less than 0.5 when we use the constituent label as a feature.</S><S sid=""108"" ssid=""37"">From this we see that a finer-grained model for parser combination, at least for the features we have examined, will not give us any additional power.</S><S sid=""89"" ssid=""18"">None of the models we have presented utilize features associated with a particular constituent (i.e. the label, span, parent label, etc.) to influence parser preference.</S><S sid=""91"" ssid=""20"">Features and context were initially introduced into the models, but they refused to offer any gains in performance.</S>",
14,W99-0623,N06-2033,0,"Henderson and Brill, 1999",0,"Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","Henderson and Brill (1999) proposed two parser combination schemes, one that picks an entire tree from one of the parsers, and one that, like ours, builds a new tree from constituents from the initial trees","'67','116','34','55'","<S sid=""67"" ssid=""53"">The set of candidate constituents comes from the union of all the constituents suggested by the member parsers.</S><S sid=""116"" ssid=""45"">The maximum precision row is the upper bound on accuracy if we could pick exactly the correct constituents from among the constituents suggested by the three parsers.</S><S sid=""34"" ssid=""20"">Mi(c) is a binary function returning t when parser i (from among the k parsers) suggests constituent c should be in the parse.</S><S sid=""55"" ssid=""41"">We have developed a general approach for combining parsers when preserving the entire structure of a parse tree is important.</S>",
15,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","(Henderson and Brill, 1999) perform parse selection by maximizing the expected precision of the selected parse with respect to the set of parses being combined","'35','78','70','15'","<S sid=""35"" ssid=""21"">The hypothesized parse is then the set of constituents that are likely (P &gt; 0.5) to be in the parse according to this model.</S><S sid=""78"" ssid=""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid=""70"" ssid=""56"">In this case we are interested in finding' the maximum probability parse, ri, and Mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.</S><S sid=""15"" ssid=""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S>",
16,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","(Henderson and Brill, 1999) and (Sagae and Lavie, 2006) propose methods for parse hybridization by recombining constituents","'16','35','27','145'","<S sid=""16"" ssid=""2"">We call this approach parse hybridization.</S><S sid=""35"" ssid=""21"">The hypothesized parse is then the set of constituents that are likely (P &gt; 0.5) to be in the parse according to this model.</S><S sid=""27"" ssid=""13"">Another technique for parse hybridization is to use a na&#239;ve Bayes classifier to determine which constituents to include in the parse.</S><S sid=""145"" ssid=""7"">We plan to explore more powerful techniques for exploiting the diversity of parsing methods.</S>",
17,W99-0623,N09-2064,0,"Henderson and Brill, 1999",0,"output (Figure 3) .Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework. Third, we extend these parser combination methods from 1-best outputs to n-best outputs","Second, the parse selection method of (Henderson and Brill, 1999) selects the parse with maximum expected precision; here, we present an efficient, linear-time algorithm for selecting the parse with maximum expected f-score within the Mini mum Bayes Risk (MBR) framework","'118','27','32','70'","<S sid=""118"" ssid=""47"">The maximum precision oracle is an upper bound on the possible gain we can achieve by parse hybridization.</S><S sid=""27"" ssid=""13"">Another technique for parse hybridization is to use a na&#239;ve Bayes classifier to determine which constituents to include in the parse.</S><S sid=""32"" ssid=""18"">In Equations 1 through 3 we develop the model for constructing our parse using na&#239;ve Bayes classification.</S><S sid=""70"" ssid=""56"">In this case we are interested in finding' the maximum probability parse, ri, and Mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.</S>",
18,W99-0623,P09-1065,0,"Henderson and Brill, 1999",0,"System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","System combination has benefited various NLP tasks in recent years, such as products-of-experts (e.g., (Smith and Eisner, 2005)) and ensemble based parsing (e.g., (Henderson and Brill, 1999))","'9','6','12','141'","<S sid=""9"" ssid=""5"">Recently, combination techniques have been investigated for part of speech tagging with positive results (van Halteren et al., 1998; Brill and Wu, 1998).</S><S sid=""6"" ssid=""2"">The machine learning community has been in a similar situation and has studied the combination of multiple classifiers (Wolpert, 1992; Heath et al., 1996).</S><S sid=""12"" ssid=""8"">The corpus-based statistical parsing community has many fast and accurate automated parsing systems, including systems produced by Collins (1997), Charniak (1997) and Ratnaparkhi (1997).</S><S sid=""141"" ssid=""3"">All four of the techniques studied result in parsing systems that perform better than any previously reported.</S>",
20,W99-0623,C10-1151,0,1999,0,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,Henderson and Brill (1999) performs parse selection by maximizing the expected precision of selected parse with respect to the set of parses to be combined,"'78','35','70','15'","<S sid=""78"" ssid=""7"">The set is then compared with the set generated from the Penn Treebank parse to determine the precision and recall.</S><S sid=""35"" ssid=""21"">The hypothesized parse is then the set of constituents that are likely (P &gt; 0.5) to be in the parse according to this model.</S><S sid=""70"" ssid=""56"">In this case we are interested in finding' the maximum probability parse, ri, and Mi is the set of relevant (binary) parsing decisions made by parser i. ri is a parse selected from among the outputs of the individual parsers.</S><S sid=""15"" ssid=""1"">We are interested in combining the substructures of the input parses to produce a better parse.</S>",
