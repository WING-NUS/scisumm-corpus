 Next we compared our systems (DCS and DCS+) with the state-of-the-art semantic parsers on the full dataset for both GEO and JOBS (see Table 3) This algorithm is linear in the number of nodes times the size of the denotations Which one should we use?Intuitions How is our system learning?Our first question is: given notation of the DCS tree before execution is an utterance x what trees z ∈ Z are permissible?The dominant paradigm in compositional semantics is Montague semantics which constructs lambda calculus forms in a bottom-up manner However the logical forms there can become quite complex and in the context of program induction this would lead to an unwieldy search space The key idea that allows us to give semanticallyscoped denotations to syntactically-scoped trees is as follows: We mark a node low in the tree with a mark relation (one of E Q or C) In fact DCS performs comparably to even the version of SEMRESP trained using logical forms Unlike standard semantic parsing our end goal is only to generate the correct y so we are free to choose the representation for z What is the total population of the ten largest capitals in the US?The denotation of the middle node is {s} where s is all major cities However we still model the logical form (now as a latent variable) to capture the complexities of language CCG (Steedman 2000) in which semantic pars- The integration of natural language with denotaing is driven from the lexicon For JOBS if we use the standard Jobs database close to half the y’s are empty which makes it uninteresting