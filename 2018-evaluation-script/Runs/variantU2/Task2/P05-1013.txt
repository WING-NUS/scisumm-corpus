 The fact that projective dependency parsers can never exactly reproduce the analyses found in non-projective treebanks is often neglected because of the relative scarcity of problematic constructions Compared to related work on the recovery of long-distance dependencies in constituency-based parsing our approach is similar to that of Dienes and Dubey (2003) in that the processing of non-local dependencies is partly integrated in the parsing process via an extension of the set of syntactic categories whereas most other approaches rely on postprocessing only We assume that the goal in dependency parsing is to construct a labeled dependency graph of the kind depicted in Figure 1 The first thing to note is that projectivizing helps in itself even if no encoding is used as seen from the fact that the projective baseline outperforms the non-projective training condition by more than half a percentage point on attachment score although the gain is much smaller with respect to exact match The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text annotated on three levels the morphological analytical and tectogrammatical levels (HajiË‡c 1998) The main result is that the combined system can recover non-projective dependencies with a precision sufficient to give a significant improvement in overall parsing accuracy especially with respect to the exact match criterion leading to the best reported performance for robust non-projective parsing of Czech From the point of view of computational implementation this can be problematic since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness