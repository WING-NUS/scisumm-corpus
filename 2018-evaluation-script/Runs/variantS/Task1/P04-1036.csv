Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)","['1', '153', '154', '48', '105']","<S sid =""1"" ssid = ""1"">word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.</S><S sid =""153"" ssid = ""1"">Most research in WSD concentrates on using contextual features  typically neighbouring words  to help determine the correct sense of a target word.</S><S sid =""154"" ssid = ""2"">In contrast  our work is aimed at discovering the predominant senses from raw text because the first sense heuristic is such a useful one  and because handtagged data is not always available.</S><S sid =""48"" ssid = ""4"">To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid =""105"" ssid = ""3"">We use an allwords task because the predominant senses will reflect the sense distributions of all nouns within the documents  rather than a lexical sample task  where the target words are manually determined and the results will depend on the skew of the words in the sample.</S>",['Aim_Citation']
2,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available","['2', '17', '91', '154', '123']","<S sid =""2"" ssid = ""2"">The problem with using the predominant  or first sense heuristic  aside from the fact that it does not take surrounding context into account  is that it assumes some quantity of handtagged data.</S><S sid =""17"" ssid = ""10"">There are words where the first sense in WordNet is counter-intuitive  because of the size of the corpus  and because where the frequency data does not indicate a first sense  the ordering is arbitrary.</S><S sid =""91"" ssid = ""20"">This is to be expected regardless of any inherent shortcomings of the ranking technique since the senses within SemCor will differ compared to those of the BNC.</S><S sid =""154"" ssid = ""2"">In contrast  our work is aimed at discovering the predominant senses from raw text because the first sense heuristic is such a useful one  and because handtagged data is not always available.</S><S sid =""123"" ssid = ""21"">This demonstrates that our method of providing a first sense from raw text will help when sense-tagged data is not available.</S>",['Method_Citation']
3,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The method is described in (McCarthy et al, 2004), which we summarise here","The method is described in (McCarthy et al, 2004), which we summarise here","['3', '15', '37', '1', '170']","<S sid =""3"" ssid = ""3"">Whilst there are a few hand-tagged corpora available for some languages  one would expect the frequency distribution of the senses of words  particularly topical words  to depend on the genre and domain of the text under consideration.</S><S sid =""15"" ssid = ""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful  there is a strong case for obtaining a first  or predominant  sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid =""37"" ssid = ""30"">From inspection  one can see that the ordered neighbours of such a thesaurus relate to the different senses of the target word.</S><S sid =""1"" ssid = ""1"">word sense disambiguation the heuristic of choosing the most common sense is extremely powerful because the distribution of the senses of a word is often skewed.</S><S sid =""170"" ssid = ""18"">If WordNet sense distinctions are not ultimately required then discovering the senses directly from the neighbours list is useful because sense distinctions discovered are relevant to the corpus data and new senses can be found.</S>",['Method_Citation']
5,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges",McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD,"['4', '179', '178', '45', '171']","<S sid =""4"" ssid = ""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S><S sid =""179"" ssid = ""2"">We use an automatically acquired thesaurus and a WordNet Similarity measure.</S><S sid =""178"" ssid = ""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S><S sid =""45"" ssid = ""1"">In order to find the predominant sense of a target word we use a thesaurus acquired from automatically parsed text based on the method of Lin (1998).</S><S sid =""171"" ssid = ""19"">In contrast  we use the neighbours lists and WordNet similarity measures to impose a prevalence ranking on the WordNet senses.</S>",['Aim_Citation']
6,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","['5', '100', '116', '84', '88']","<S sid =""5"" ssid = ""5"">The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.</S><S sid =""100"" ssid = ""29"">In the English all-words SENSEVAL-2  25% of the noun data was monosemous.</S><S sid =""116"" ssid = ""14"">The performance of the predominant sense provided in the SENSEVAL-2 test data provides an upper bound for this task.</S><S sid =""84"" ssid = ""13"">The random baseline for choosing the predominant sense over all these words ( ) is 32%.</S><S sid =""88"" ssid = ""17"">The first sense in SemCor provides an upperbound for this task of 67%.</S>",['Method_Citation']
7,P04-1036,I08-2105,0,2004,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","['6', '126', '178', '13', '121']","<S sid =""6"" ssid = ""6"">This is a very promising result given that our method does not require any hand-tagged text  such as SemCor.</S><S sid =""126"" ssid = ""3"">We demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.</S><S sid =""178"" ssid = ""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S><S sid =""13"" ssid = ""6"">The high performance of the first sense baseline is due to the skewed frequency distribution of word senses.</S><S sid =""121"" ssid = ""19"">For these one would need to obtain more sense-tagged text in order to use this heuristic.</S>",['Method_Citation']
8,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","['7', '184', '178', '126', '158']","<S sid =""7"" ssid = ""7"">Furthermore  we demonstrate that our method discovers appropriate predominant senses for words from two domainspecific corpora.</S><S sid =""184"" ssid = ""7"">We have demonstrated the possibility of finding predominant senses in domain specific corpora on a sample of nouns.</S><S sid =""178"" ssid = ""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S><S sid =""126"" ssid = ""3"">We demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.</S><S sid =""158"" ssid = ""6"">We have evaluated our method using publically available resources  both for balanced and domain specific text.</S>",['Method_Citation']
9,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense","['8', '154', '14', '172', '115']","<S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid =""154"" ssid = ""2"">In contrast  our work is aimed at discovering the predominant senses from raw text because the first sense heuristic is such a useful one  and because handtagged data is not always available.</S><S sid =""14"" ssid = ""7"">Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al.  2001).</S><S sid =""172"" ssid = ""20"">We believe automatic ranking techniques such as ours will be useful for systems that rely on WordNet  for example those that use it for lexical acquisition or WSD.</S><S sid =""115"" ssid = ""13"">Our automatically acquired predominant sense performs nearly as well as the first sense provided by SemCor  which is very encouraging given that our method only uses raw text  with no manual labelling.</S>",['Results_Citation']
11,P04-1036,P10-1155,0,2004,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)","['9', '102', '116', '100', '5']","<S sid =""9"" ssid = ""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al.  1998) in figure 1 below  where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al.  2001).</S><S sid =""102"" ssid = ""31"">We test this below on the SENSEVAL-2 English all-words data.</S><S sid =""116"" ssid = ""14"">The performance of the predominant sense provided in the SENSEVAL-2 test data provides an upper bound for this task.</S><S sid =""100"" ssid = ""29"">In the English all-words SENSEVAL-2  25% of the noun data was monosemous.</S><S sid =""5"" ssid = ""5"">The acquired predominant senses give a of 64% on the nouns of the 2 English all-words task.</S>",['Method_Citation']
12,P04-1036,W12-3401,0,2004,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","['10', '180', '142', '109', '112']","<S sid =""10"" ssid = ""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al.  1993).</S><S sid =""180"" ssid = ""3"">The automatically acquired predominant senses were evaluated against the hand-tagged resources SemCor and the SENSEVAL-2 English all-words task giving us a WSD precision of 64% on an all-nouns task.</S><S sid =""142"" ssid = ""19"">The results for 10 of the words from the qualitative experiment are summarized in table 3 with the WordNet sense number for each word supplied alongside synonyms or hypernyms from WordNet for readability.</S><S sid =""109"" ssid = ""7"">We generated a thesaurus entry for all polysemous nouns in WordNet as described in section 2.1 above.</S><S sid =""112"" ssid = ""10"">We compare results using the first sense listed in SemCor  and the first sense according to the SENSEVAL-2 English all-words test data itself.</S>",['Method_Citation']
13,P04-1036,W12-3401,0,2004,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)","['11', '120', '42', '189', '117']","<S sid =""11"" ssid = ""4"">Senses that have not occurred in SemCor are ordered arbitrarily and after those senses of the word that have occurred.</S><S sid =""120"" ssid = ""18"">There were a similar number of words that were not covered by a predominant sense in SemCor.</S><S sid =""42"" ssid = ""35"">The neighbours for a word in a thesaurus are words themselves  rather than senses.</S><S sid =""189"" ssid = ""12"">Additionally  we need to determine whether senses which do not occur in a wide variety of grammatical contexts fare badly using distributional measures of similarity  and what can be done to combat this problem using relation specific thesauruses.</S><S sid =""117"" ssid = ""15"">The items that were not covered by our method were those with insufficient grammatical relations for the tuples employed.</S>",['Method_Citation']
14,P04-1036,W12-3401,0,2004,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","['12', '123', '153', '165', '178']","<S sid =""12"" ssid = ""5"">The figure distinguishes systems which make use of hand-tagged data (using HTD) such as SemCor  from those that do not (without HTD).</S><S sid =""123"" ssid = ""21"">This demonstrates that our method of providing a first sense from raw text will help when sense-tagged data is not available.</S><S sid =""153"" ssid = ""1"">Most research in WSD concentrates on using contextual features  typically neighbouring words  to help determine the correct sense of a target word.</S><S sid =""165"" ssid = ""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus  whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid =""178"" ssid = ""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S>",['Aim_Citation']
16,P04-1036,S12-1097,0,"McCarthy et al, 2004",0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","['13', '116', '147', '84', '126']","<S sid =""13"" ssid = ""6"">The high performance of the first sense baseline is due to the skewed frequency distribution of word senses.</S><S sid =""116"" ssid = ""14"">The performance of the predominant sense provided in the SENSEVAL-2 test data provides an upper bound for this task.</S><S sid =""147"" ssid = ""24"">The word share is among the words whose predominant sense remained the same for all three corpora.</S><S sid =""84"" ssid = ""13"">The random baseline for choosing the predominant sense over all these words ( ) is 32%.</S><S sid =""126"" ssid = ""3"">We demonstrate that choosing texts from a particular domain has a significant influence on the sense ranking.</S>",['Method_Citation']
17,P04-1036,W10-2803,0,"McCarthy et al, 2004",0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","['14', '8', '154', '182', '21']","<S sid =""14"" ssid = ""7"">Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al.  2001).</S><S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid =""154"" ssid = ""2"">In contrast  our work is aimed at discovering the predominant senses from raw text because the first sense heuristic is such a useful one  and because handtagged data is not always available.</S><S sid =""182"" ssid = ""5"">In many cases the sense ranking provided in SemCor differs to that obtained automatically because we used the BNC to produce our thesaurus.</S><S sid =""21"" ssid = ""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson  1998; Hoste et al.  2001) and for systems that use it in lexical acquisition (McCarthy  1997; Merlo and Leybold  2001; Korhonen  2002) because of the limited size of hand-tagged resources.</S>",['Method_Citation']
18,P04-1036,W08-2107,0,2004,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","['15', '154', '3', '8', '170']","<S sid =""15"" ssid = ""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful  there is a strong case for obtaining a first  or predominant  sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid =""154"" ssid = ""2"">In contrast  our work is aimed at discovering the predominant senses from raw text because the first sense heuristic is such a useful one  and because handtagged data is not always available.</S><S sid =""3"" ssid = ""3"">Whilst there are a few hand-tagged corpora available for some languages  one would expect the frequency distribution of the senses of words  particularly topical words  to depend on the genre and domain of the text under consideration.</S><S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid =""170"" ssid = ""18"">If WordNet sense distinctions are not ultimately required then discovering the senses directly from the neighbours list is useful because sense distinctions discovered are relevant to the corpus data and new senses can be found.</S>",['Method_Citation']
19,P04-1036,D07-1026,0,"McCarthy et al, 2004",0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","['16', '131', '140', '132', '76']","<S sid =""16"" ssid = ""9"">SemCor comprises a relatively small sample of 250 000 words.</S><S sid =""131"" ssid = ""8"">The SPORTS corpus consists of 35317 documents (about 9.1 million words).</S><S sid =""140"" ssid = ""17"">The resulting set consisted of 38 words.</S><S sid =""132"" ssid = ""9"">The FINANCE corpus consists of 117734 documents (about 32.5 million words).</S><S sid =""76"" ssid = ""5"">The jcn measure uses corpus data for the calculation of IC.</S>",['Method_Citation']
20,P04-1036,W12-2429,0,"McCarthy et al, 2004",0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","['17', '182', '13', '99', '170']","<S sid =""17"" ssid = ""10"">There are words where the first sense in WordNet is counter-intuitive  because of the size of the corpus  and because where the frequency data does not indicate a first sense  the ordering is arbitrary.</S><S sid =""182"" ssid = ""5"">In many cases the sense ranking provided in SemCor differs to that obtained automatically because we used the BNC to produce our thesaurus.</S><S sid =""13"" ssid = ""6"">The high performance of the first sense baseline is due to the skewed frequency distribution of word senses.</S><S sid =""99"" ssid = ""28"">Even given the difference in text type between SemCor and the BNC the results are encouraging  especially given that our results are for polysemous nouns.</S><S sid =""170"" ssid = ""18"">If WordNet sense distinctions are not ultimately required then discovering the senses directly from the neighbours list is useful because sense distinctions discovered are relevant to the corpus data and new senses can be found.</S>",['Method_Citation']
