Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P05-1013,W05-1505,0,"Nivre and Nilsson, 2005",0,"Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","Recent work by Nivre and Nilsson introduces a technique where the projectivization transformation is encoded in the non-terminals of constituents during parsing (Nivre and Nilsson, 2005)","['1', '13', '7', '16', '80']","<S sid =""1"" ssid = ""1"">In order to realize the full potential of dependency-based syntactic parsing  it is desirable to allow non-projective dependency structures.</S><S sid =""13"" ssid = ""9"">The fact that projective dependency parsers can never exactly reproduce the analyses found in non-projective treebanks is often neglected because of the relative scarcity of problematic constructions.</S><S sid =""7"" ssid = ""3"">From the point of view of computational implementation this can be problematic  since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.</S><S sid =""16"" ssid = ""12"">Still  from a theoretical point of view  projective parsing of non-projective structures has the drawback that it rules out perfect accuracy even as an asymptotic goal.</S><S sid =""80"" ssid = ""7"">As shown in Table 3  the proportion of sentences containing some non-projective dependency ranges from about 15% in DDT to almost 25% in PDT.</S>",['Aim_Citation']
2,P05-1013,P08-1006,0,"Nivre and Nilsson, 2005",0,"1http: //sourceforge.net/projects/mstparser Figure 1: CoNLL-X dependency tree Figure 2: Penn Treebank-style phrase structure tree KSDEP Sagae and Tsujii (2007)? s dependencyparser,2 based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","Sagae and Tsujii (2007)'s dependency parser, based on a probabilistic shift-reduce algorithm extended by the pseudo-projective parsing technique (Nivre and Nilsson, 2005)","['2', '44', '36', '30', '8']","<S sid =""2"" ssid = ""2"">We show how a datadriven deterministic dependency parser  in itself restricted to projective structures  can be combined with graph transformation techniques to produce non-projective structures.</S><S sid =""44"" ssid = ""15"">Instead  we want to apply an inverse transformation to recover the underlying (nonprojective) dependency graph.</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid =""30"" ssid = ""1"">We assume that the goal in dependency parsing is to construct a labeled dependency graph of the kind depicted in Figure 1.</S><S sid =""8"" ssid = ""4"">Thus  most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>",['Method_Citation']
3,P05-1013,W10-1401,0,"Nivre and Nilsson, 2005",0,"Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","Bengoetxea and Gojenola (2010) discuss non-projective dependencies in Basque and show that the pseudo-projective transformation of (Nivre and Nilsson, 2005) improves accuracy for dependency parsing of Basque","['3', '28', '29', '62', '75']","<S sid =""3"" ssid = ""3"">Experiments using data from the Prague Dependency Treebank show that the combined system can handle nonprojective constructions with a precision sufficient to yield a significant improvement in overall parsing accuracy.</S><S sid =""28"" ssid = ""24"">First  in section 4  we evaluate the graph transformation techniques in themselves  with data from the Prague Dependency Treebank and the Danish Dependency Treebank.</S><S sid =""29"" ssid = ""25"">In section 5  we then evaluate the entire parsing system by training and evaluating on data from the Prague Dependency Treebank.</S><S sid =""62"" ssid = ""1"">In the experiments below  we employ a data-driven deterministic dependency parser producing labeled projective dependency graphs 3 previously tested on Swedish (Nivre et al.  2004) and English (Nivre and Scholz  2004).</S><S sid =""75"" ssid = ""2"">The Prague Dependency Treebank (PDT) consists of more than 1M words of newspaper text  annotated on three levels  the morphological  analytical and tectogrammatical levels (Hajiˇc  1998).</S>",['Method_Citation']
4,P05-1013,P12-3029,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees weuse the pseudo-projective parsing technique to trans form the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","['4', '104', '106', '78', '8']","<S sid =""4"" ssid = ""4"">This leads to the best reported performance for robust non-projective parsing of Czech.</S><S sid =""104"" ssid = ""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S><S sid =""106"" ssid = ""17"">However  the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech  with a best performance of 73% UAS (Holan  2004).</S><S sid =""78"" ssid = ""5"">The entire treebank is used in the experiment  but only primary dependencies are considered.4 In all experiments  punctuation tokens are included in the data but omitted in evaluation scores.</S><S sid =""8"" ssid = ""4"">Thus  most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>",['Aim_Citation']
5,P05-1013,W10-1403,0,"Nivre and Nilsson, 2005",0,"It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","It uses graph transformation to handle non-projective trees (Nivre and Nilsson, 2005)","['5', '94', '99', '9', '47']","<S sid =""5"" ssid = ""1"">It is sometimes claimed that one of the advantages of dependency grammar over approaches based on constituency is that it allows a more adequate treatment of languages with variable word order  where discontinuous syntactic constructions are more common than in languages like English (Mel’ˇcuk  1988; Covington  1990).</S><S sid =""94"" ssid = ""5"">The first thing to note is that projectivizing helps in itself  even if no encoding is used  as seen from the fact that the projective baseline outperforms the non-projective training condition by more than half a percentage point on attachment score  although the gain is much smaller with respect to exact match.</S><S sid =""99"" ssid = ""10"">This may seem surprising  given the experiments reported in section 4  but the explanation is probably that the non-projective dependencies that can be recovered at all are of the simple kind that only requires a single lift  where the encoding of path information is often redundant.</S><S sid =""9"" ssid = ""5"">This is true of the widely used link grammar parser for English (Sleator and Temperley  1993)  which uses a dependency grammar of sorts  the probabilistic dependency parser of Eisner (1996)  and more recently proposed deterministic dependency parsers (Yamada and Matsumoto  2003; Nivre et al.  2004).</S><S sid =""47"" ssid = ""18"">In practice  we can therefore expect a trade-off such that increasing the amount of information encoded in arc labels will cause an increase in the accuracy of the inverse transformation but a decrease in the accuracy with which the parser can construct the labeled representations.</S>",['Method_Citation']
6,P05-1013,D08-1008,0,"Nivre and Nilsson, 2005",0,"To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson,2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","To simplify implementation, we instead opted for the pseudo-projective approach (Nivre and Nilsson, 2005), in which non projective links are lifted upwards in the tree to achieve projectivity, and special trace labels are used to enable recovery of the non projective links at parse time","['6', '2', '36', '44', '89']","<S sid =""6"" ssid = ""2"">However  this argument is only plausible if the formal framework allows non-projective dependency structures  i.e. structures where a head and its dependents may correspond to a discontinuous constituent.</S><S sid =""2"" ssid = ""2"">We show how a datadriven deterministic dependency parser  in itself restricted to projective structures  can be combined with graph transformation techniques to produce non-projective structures.</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid =""44"" ssid = ""15"">Instead  we want to apply an inverse transformation to recover the underlying (nonprojective) dependency graph.</S><S sid =""89"" ssid = ""16"">The increase is generally higher for PDT than for DDT  which indicates a greater diversity in non-projective constructions.</S>",['Method_Citation']
7,P05-1013,D07-1013,0,2005,0,",wn in O (n) time, producing a projective dependency graph satisfying conditions 1? 4 in section 2.1, possibly after adding arcs (0, i ,lr) for every node i 6= 0 that is a root in the output graph (where lr is a special label for root modifiers) .Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to pre process training data and post-process parser output, so-called pseudo-projective parsing. To learn transition scores, these systems use discriminative learning methods ,e.g., memory-based learning or support vector machines","Nivre and Nilsson (2005) showed how the restriction to projective dependency graphs could be lifted by using graph transformation techniques to preprocess training data and post-process parser output, so-called pseudo-projective parsing","['7', '16', '19', '1', '47']","<S sid =""7"" ssid = ""3"">From the point of view of computational implementation this can be problematic  since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.</S><S sid =""16"" ssid = ""12"">Still  from a theoretical point of view  projective parsing of non-projective structures has the drawback that it rules out perfect accuracy even as an asymptotic goal.</S><S sid =""19"" ssid = ""15"">Finally  since non-projective constructions often involve long-distance dependencies  the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson  2002; Dienes and Dubey  2003; Jijkoun and de Rijke  2004; Cahill et al.  2004; Levy and Manning  2004; Campbell  2004).</S><S sid =""1"" ssid = ""1"">In order to realize the full potential of dependency-based syntactic parsing  it is desirable to allow non-projective dependency structures.</S><S sid =""47"" ssid = ""18"">In practice  we can therefore expect a trade-off such that increasing the amount of information encoded in arc labels will cause an increase in the accuracy of the inverse transformation but a decrease in the accuracy with which the parser can construct the labeled representations.</S>",['Method_Citation']
8,P05-1013,D07-1119,0,2005,0,"For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","For handling non-projective relations, Nivre and Nilsson (2005) suggested applying a preprocessing step to a dependency parser, which consists in lifting non-projective arcs to their head repeatedly, until the tree becomes pseudo-projective","['8', '2', '104', '4', '30']","<S sid =""8"" ssid = ""4"">Thus  most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S><S sid =""2"" ssid = ""2"">We show how a datadriven deterministic dependency parser  in itself restricted to projective structures  can be combined with graph transformation techniques to produce non-projective structures.</S><S sid =""104"" ssid = ""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S><S sid =""4"" ssid = ""4"">This leads to the best reported performance for robust non-projective parsing of Czech.</S><S sid =""30"" ssid = ""1"">We assume that the goal in dependency parsing is to construct a labeled dependency graph of the kind depicted in Figure 1.</S>",['Results_Citation']
9,P05-1013,N07-1050,0,"Nivre and Nilsson, 2005",0,"Whereas most of the early approaches were limited to strictly projective dependency structures, where the projection of a syntactic head must be continuous, attention has recently shifted to the analysis of non-projective structures, which are required for linguistically adequate representations, especially in languages with free or flexible word order. The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","The most popular strategy for capturing non projective structures in data-driven dependency parsing is to apply some kind of post-processing to the output of a strictly projective dependency parser, as in pseudo-projective parsing (Nivre and Nilsson, 2005), corrective modeling (Hall and Nova? k, 2005), or approximate non-projective parsing (McDonald and Pereira, 2006)","['9', '10', '17', '105', '24']","<S sid =""9"" ssid = ""5"">This is true of the widely used link grammar parser for English (Sleator and Temperley  1993)  which uses a dependency grammar of sorts  the probabilistic dependency parser of Eisner (1996)  and more recently proposed deterministic dependency parsers (Yamada and Matsumoto  2003; Nivre et al.  2004).</S><S sid =""10"" ssid = ""6"">It is also true of the adaptation of the Collins parser for Czech (Collins et al.  1999) and the finite-state dependency parser for Turkish by Oflazer (2003).</S><S sid =""17"" ssid = ""13"">There exist a few robust broad-coverage parsers that produce non-projective dependency structures  notably Tapanainen and J¨arvinen (1997) and Wang and Harper (2004) for English  Foth et al. (2004) for German  and Holan (2004) for Czech.</S><S sid =""105"" ssid = ""16"">Although the best published results for the Collins parser is 80% UAS (Collins  1999)  this parser reaches 82% when trained on the entire training data set  and an adapted version of Charniak’s parser (Charniak  2000) performs at 84% (Jan Hajiˇc  pers. comm.).</S><S sid =""24"" ssid = ""20"">We call this pseudoprojective dependency parsing  since it is based on a notion of pseudo-projectivity (Kahane et al.  1998).</S>",['Method_Citation']
10,P05-1013,W09-1207,0,"Nivre and Nilsson, 2005",0,"troduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","We adopt the pseudo-projective approach introduced in (Nivre and Nilsson, 2005) to handle the non-projective languages including Czech, German and English","['10', '42', '36', '4', '12']","<S sid =""10"" ssid = ""6"">It is also true of the adaptation of the Collins parser for Czech (Collins et al.  1999) and the finite-state dependency parser for Turkish by Oflazer (2003).</S><S sid =""42"" ssid = ""13"">Using the terminology of Kahane et al. (1998)  we say that jedna is the syntactic head of Z  while je is its linear head in the projectivized representation.</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid =""4"" ssid = ""4"">This leads to the best reported performance for robust non-projective parsing of Czech.</S><S sid =""12"" ssid = ""8"">Prague Dependency Treebank (Hajiˇc et al.  2001b)  Danish Dependency Treebank (Kromann  2003)  and the METU Treebank of Turkish (Oflazer et al.  2003)  which generally allow annotations with nonprojective dependency structures.</S>",['Method_Citation']
11,P05-1013,E09-1034,0,"Nivre and Nilsson, 2005",0,"non projective (Nivre and Nilsson, 2005), we char ac terise a sense in which the structures appearing in tree banks can be viewed as being only? slightly? ill-nested","However, just as it has been noted that most non-projective structures appearing in practice are only 'slightly' non projective (Nivre and Nilsson, 2005), we characterise a sense in which the structures appearing in tree banks can be viewed as being only 'slightly' ill-nested","['11', '6', '78', '10', '36']","<S sid =""11"" ssid = ""7"">This is in contrast to dependency treebanks  e.g.</S><S sid =""6"" ssid = ""2"">However  this argument is only plausible if the formal framework allows non-projective dependency structures  i.e. structures where a head and its dependents may correspond to a discontinuous constituent.</S><S sid =""78"" ssid = ""5"">The entire treebank is used in the experiment  but only primary dependencies are considered.4 In all experiments  punctuation tokens are included in the data but omitted in evaluation scores.</S><S sid =""10"" ssid = ""6"">It is also true of the adaptation of the Collins parser for Czech (Collins et al.  1999) and the finite-state dependency parser for Turkish by Oflazer (2003).</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S>",['Method_Citation']
12,P05-1013,W09-1218,0,"Nivre and Nilsson, 2005",0,"In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","In order to avoid losing the benefits of higher-order parsing, we considered applying pseudo-projective transformation (Nivre and Nilsson, 2005)","['12', '10', '36', '42', '78']","<S sid =""12"" ssid = ""8"">Prague Dependency Treebank (Hajiˇc et al.  2001b)  Danish Dependency Treebank (Kromann  2003)  and the METU Treebank of Turkish (Oflazer et al.  2003)  which generally allow annotations with nonprojective dependency structures.</S><S sid =""10"" ssid = ""6"">It is also true of the adaptation of the Collins parser for Czech (Collins et al.  1999) and the finite-state dependency parser for Turkish by Oflazer (2003).</S><S sid =""36"" ssid = ""7"">As observed by Kahane et al. (1998)  any (nonprojective) dependency graph can be transformed into a projective one by a lifting operation  which replaces each non-projective arc wj wk by a projective arc wi —* wk such that wi —*∗ wj holds in the original graph.</S><S sid =""42"" ssid = ""13"">Using the terminology of Kahane et al. (1998)  we say that jedna is the syntactic head of Z  while je is its linear head in the projectivized representation.</S><S sid =""78"" ssid = ""5"">The entire treebank is used in the experiment  but only primary dependencies are considered.4 In all experiments  punctuation tokens are included in the data but omitted in evaluation scores.</S>",['Aim_Citation']
13,P05-1013,C08-1081,0,"Nivre and Nilsson, 2005",0,"Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","Pseudo-projective parsing for recovering non projective structures (Nivre and Nilsson, 2005)","['13', '2', '95', '1', '104']","<S sid =""13"" ssid = ""9"">The fact that projective dependency parsers can never exactly reproduce the analyses found in non-projective treebanks is often neglected because of the relative scarcity of problematic constructions.</S><S sid =""2"" ssid = ""2"">We show how a datadriven deterministic dependency parser  in itself restricted to projective structures  can be combined with graph transformation techniques to produce non-projective structures.</S><S sid =""95"" ssid = ""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S><S sid =""1"" ssid = ""1"">In order to realize the full potential of dependency-based syntactic parsing  it is desirable to allow non-projective dependency structures.</S><S sid =""104"" ssid = ""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S>",['Method_Citation']
14,P05-1013,C08-1081,0,2005,0,"Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","Although the parser only derives projective graphs, the fact that these graphs are labeled allows non-projective dependencies to be captured using the pseudo-projective approach of Nivre and Nilsson (2005) (section 3.4)","['14', '80', '106', '81', '100']","<S sid =""14"" ssid = ""10"">While the proportion of sentences containing non-projective dependencies is often 15–25%  the total proportion of non-projective arcs is normally only 1–2%.</S><S sid =""80"" ssid = ""7"">As shown in Table 3  the proportion of sentences containing some non-projective dependency ranges from about 15% in DDT to almost 25% in PDT.</S><S sid =""106"" ssid = ""17"">However  the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech  with a best performance of 73% UAS (Holan  2004).</S><S sid =""81"" ssid = ""8"">However  the overall percentage of non-projective arcs is less than 2% in PDT and less than 1% in DDT.</S><S sid =""100"" ssid = ""11"">It is likely that the more complex cases  where path information could make a difference  are beyond the reach of the parser in most cases.</S>",['Method_Citation']
15,P05-1013,C08-1081,0,2005,0,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,Pseudo-projective parsing was proposed by Nivreand Nilsson (2005) as a way of dealing with non projective structures in a projective data-driven parser,"['15', '106', '101', '110', '105']","<S sid =""15"" ssid = ""11"">As long as the main evaluation metric is dependency accuracy per word  with state-of-the-art accuracy mostly below 90%  the penalty for not handling non-projective constructions is almost negligible.</S><S sid =""106"" ssid = ""17"">However  the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech  with a best performance of 73% UAS (Holan  2004).</S><S sid =""101"" ssid = ""12"">However  if we consider precision  recall and Fmeasure on non-projective dependencies only  as shown in Table 6  some differences begin to emerge.</S><S sid =""110"" ssid = ""2"">The main result is that the combined system can recover non-projective dependencies with a precision sufficient to give a significant improvement in overall parsing accuracy  especially with respect to the exact match criterion  leading to the best reported performance for robust non-projective parsing of Czech.</S><S sid =""105"" ssid = ""16"">Although the best published results for the Collins parser is 80% UAS (Collins  1999)  this parser reaches 82% when trained on the entire training data set  and an adapted version of Charniak’s parser (Charniak  2000) performs at 84% (Jan Hajiˇc  pers. comm.).</S>",['Method_Citation']
16,P05-1013,C08-1081,0,2005,0,"Weprojectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","We projectivize training data by a minimal transformation, lifting non-projective arcs one step at a time, and extending the arc label of lifted arcs using the encoding scheme called HEAD by Nivre and Nilsson (2005), which means that a lifted arc is assigned the label r? h, where r is the original label and h is the label of the original head in the non-projective dependency graph","['16', '7', '1', '110', '19']","<S sid =""16"" ssid = ""12"">Still  from a theoretical point of view  projective parsing of non-projective structures has the drawback that it rules out perfect accuracy even as an asymptotic goal.</S><S sid =""7"" ssid = ""3"">From the point of view of computational implementation this can be problematic  since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.</S><S sid =""1"" ssid = ""1"">In order to realize the full potential of dependency-based syntactic parsing  it is desirable to allow non-projective dependency structures.</S><S sid =""110"" ssid = ""2"">The main result is that the combined system can recover non-projective dependencies with a precision sufficient to give a significant improvement in overall parsing accuracy  especially with respect to the exact match criterion  leading to the best reported performance for robust non-projective parsing of Czech.</S><S sid =""19"" ssid = ""15"">Finally  since non-projective constructions often involve long-distance dependencies  the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson  2002; Dienes and Dubey  2003; Jijkoun and de Rijke  2004; Cahill et al.  2004; Levy and Manning  2004; Campbell  2004).</S>",['Method_Citation']
17,P05-1013,D11-1006,0,"Nivre and Nilsson, 2005",0,"For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","For tree banks with non-projective trees we use the pseudo-projective parsing technique to transform the tree bank into projective structures (Nivre and Nilsson, 2005)","['4', '104', '106', '78', '8']","<S sid =""4"" ssid = ""4"">This leads to the best reported performance for robust non-projective parsing of Czech.</S><S sid =""104"" ssid = ""15"">The overall parsing accuracy obtained with the pseudo-projective approach is still lower than for the best projective parsers.</S><S sid =""106"" ssid = ""17"">However  the accuracy is considerably higher than previously reported results for robust non-projective parsing of Czech  with a best performance of 73% UAS (Holan  2004).</S><S sid =""78"" ssid = ""5"">The entire treebank is used in the experiment  but only primary dependencies are considered.4 In all experiments  punctuation tokens are included in the data but omitted in evaluation scores.</S><S sid =""8"" ssid = ""4"">Thus  most broad-coverage parsers based on dependency grammar have been restricted to projective structures.</S>",['Method_Citation']
18,P05-1013,P11-2121,0,"Nivre and Nilsson, 2005",0,"Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","Since the number of non-projective dependencies is much smaller than the number of projective dependencies (Nivre and Nilsson, 2005), it is not efficient to perform non-projective parsing for all cases","['18', '17', '20', '100', '109']","<S sid =""18"" ssid = ""14"">In addition  there are several approaches to non-projective dependency parsing that are still to be evaluated in the large (Covington  1990; Kahane et al.  1998; Duchier and Debusmann  2001; Holan et al.  2001; Hellwig  2003).</S><S sid =""17"" ssid = ""13"">There exist a few robust broad-coverage parsers that produce non-projective dependency structures  notably Tapanainen and J¨arvinen (1997) and Wang and Harper (2004) for English  Foth et al. (2004) for German  and Holan (2004) for Czech.</S><S sid =""20"" ssid = ""16"">In this paper  we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.</S><S sid =""100"" ssid = ""11"">It is likely that the more complex cases  where path information could make a difference  are beyond the reach of the parser in most cases.</S><S sid =""109"" ssid = ""1"">We have presented a new method for non-projective dependency parsing  based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S>",['Method_Citation']
19,P05-1013,E06-1010,0,"Nivre and Nilsson, 2005",0,"Itshould be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in them selves (Nivre and Nilsson, 2005)","It should be noted that the proportion of lost dependencies is about twice as high as the proportion of dependencies that are non-projective in themselves (Nivre and Nilsson, 2005)","['19', '7', '95', '13', '107']","<S sid =""19"" ssid = ""15"">Finally  since non-projective constructions often involve long-distance dependencies  the problem is closely related to the recovery of empty categories and non-local dependencies in constituency-based parsing (Johnson  2002; Dienes and Dubey  2003; Jijkoun and de Rijke  2004; Cahill et al.  2004; Levy and Manning  2004; Campbell  2004).</S><S sid =""7"" ssid = ""3"">From the point of view of computational implementation this can be problematic  since the inclusion of non-projective structures makes the parsing problem more complex and therefore compromises efficiency and in practice also accuracy and robustness.</S><S sid =""95"" ssid = ""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S><S sid =""13"" ssid = ""9"">The fact that projective dependency parsers can never exactly reproduce the analyses found in non-projective treebanks is often neglected because of the relative scarcity of problematic constructions.</S><S sid =""107"" ssid = ""18"">Compared to related work on the recovery of long-distance dependencies in constituency-based parsing  our approach is similar to that of Dienes and Dubey (2003) in that the processing of non-local dependencies is partly integrated in the parsing process  via an extension of the set of syntactic categories  whereas most other approaches rely on postprocessing only.</S>",['Method_Citation']
20,P05-1013,D07-1111,0,"Nivre and Nilsson, 2005",0,"The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective trans formations as described in (Nivre and Nilsson, 2005)","The resulting algorithm is projective, and nonprojectivity is handled by pseudo-projective transformations as described in (Nivre and Nilsson, 2005)","['20', '109', '24', '60', '95']","<S sid =""20"" ssid = ""16"">In this paper  we show how non-projective dependency parsing can be achieved by combining a datadriven projective parser with special graph transformation techniques.</S><S sid =""109"" ssid = ""1"">We have presented a new method for non-projective dependency parsing  based on a combination of data-driven projective dependency parsing and graph transformation techniques.</S><S sid =""24"" ssid = ""20"">We call this pseudoprojective dependency parsing  since it is based on a notion of pseudo-projectivity (Kahane et al.  1998).</S><S sid =""60"" ssid = ""31"">In section 4 we evaluate these transformations with respect to projectivized dependency treebanks  and in section 5 they are applied to parser output.</S><S sid =""95"" ssid = ""6"">The second main result is that the pseudo-projective approach to parsing (using special arc labels to guide an inverse transformation) gives a further improvement of about one percentage point on attachment score.</S>",['Aim_Citation']
