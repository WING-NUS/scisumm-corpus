Citance Number,Reference Article,Citing Article,Citation Marker Offset,Citation Marker,Citation Offset,Citation Text,Citation Text Clean,Reference Offset,Reference Text,Discourse Facet
1,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding con text into account (McCarthy et al, 2004)","The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account (McCarthy et al, 2004)","['8', '175', '14', '21', '25']","<S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""14"" ssid = ""7"">Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al.  2001).</S><S sid =""21"" ssid = ""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson  1998; Hoste et al.  2001) and for systems that use it in lexical acquisition (McCarthy  1997; Merlo and Leybold  2001; Korhonen  2002) because of the limited size of hand-tagged resources.</S><S sid =""25"" ssid = ""18"">However  the most accurate WSD systems are those which require manually sense tagged data in the first place  and their accuracy depends on the quantity of training examples (Yarowsky and Florian  2002) available.</S>",['Results_Citation']
2,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"Association for Computational Linguistics for the Semantic Analysis of Text, Barcelona, Spain, July 2004 SENSEVAL-3: Third International Workshop on the Evaluation of Systems PoS precision recall baseline Noun 95 73 45 Verb 79 43 22 Adjective 88 59 44 Adverb 91 72 59 All PoS 90 63 41Table 2: The SENSEVAL-2 first sense on the SEN SEVAL-2 English all-words data system can be tuned to a given genre or domain (McCarthy et al, 2004) and also because there will be words that occur with insufficient frequency inthe hand-tagged resources available","Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful, there is a case for obtaining a first, or predominant, sense from untagged corpus data so that a WSD system can be tuned to a given genre or domain (McCarthy et al., 2004) and also because there will be words that occur with insufficient frequency in the hand-tagged resources available","['15', '17', '178', '173', '175']","<S sid =""15"" ssid = ""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful  there is a strong case for obtaining a first  or predominant  sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid =""17"" ssid = ""10"">There are words where the first sense in WordNet is counter-intuitive  because of the size of the corpus  and because where the frequency data does not indicate a first sense  the ordering is arbitrary.</S><S sid =""178"" ssid = ""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S><S sid =""173"" ssid = ""21"">It would be useful however to combine our method of finding predominant senses with one which can automatically find new senses within text and relate these to WordNet synsets  as Ciaramita and Johnson (2003) do with unknown nouns.</S><S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S>",['Method_Citation']
3,P04-1036,W04-0837,0,"McCarthy et al, 2004",0,"The method is described in (McCarthy et al, 2004), which we summarise here","The method is described in (McCarthy et al, 2004), which we summarise here","['64', '175', '44', '9', '188']","<S sid =""64"" ssid = ""20"">We briefly summarise the two measures here; for a more detailed summary see (Patwardhan et al.  2003).</S><S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""44"" ssid = ""37"">We experiment with several WordNet Similarity measures (Patwardhan and Pedersen  2003) which aim to capture semantic relatedness within</S><S sid =""9"" ssid = ""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al.  1998) in figure 1 below  where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al.  2001).</S><S sid =""188"" ssid = ""11"">We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al.  2004).</S>",['Method_Citation']
5,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD.We build upon this previous research, and pro pose an unsupervised WSD method in which senses for two grammatically related words in the sentence will be connected through directed edges",McCarthy et al (2004) use a corpus and word similarities to induce a ranking of word senses from an untagged corpus to be used in WSD,"['165', '4', '15', '178', '66']","<S sid =""165"" ssid = ""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus  whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid =""4"" ssid = ""4"">We present work on the use of a thesaurus acquired from raw textual corpora and the WordNet similarity package to find predominant noun senses automatically.</S><S sid =""15"" ssid = ""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful  there is a strong case for obtaining a first  or predominant  sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid =""178"" ssid = ""1"">We have devised a method that uses raw corpus data to automatically find a predominant sense for nouns in WordNet.</S><S sid =""66"" ssid = ""22"">It uses the glosses of semantically related (according to WordNet) senses too. jcn (Jiang and Conrath  1997) This score uses corpus data to populate classes (synsets) in the WordNet hierarchy with frequency counts.</S>",['Method_Citation']
6,P04-1036,I08-2105,0,"McCarthy et al, 2004",0,"Previous re search in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","Previous research in inducing sense rankings from an untagged corpus (McCarthy et al, 2004), and inducing selectional preferences at the word level (for other applications) (Erk, 2007) will provide the starting point for research in this direction","['175', '156', '103', '15', '173']","<S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""156"" ssid = ""4"">Buitelaar and Sacaleanu (2001) have previously explored ranking and selection of synsets in GermaNet for specific domains using the words in a given synset  and those related by hyponymy  and a term relevance measure taken from information retrieval.</S><S sid =""103"" ssid = ""1"">In order to see how well the automatically acquired predominant sense performs on a WSD task from which the WordNet sense ordering has not been taken  we use the SENSEVAL-2 all-words data (Palmer et al.  2001).</S><S sid =""15"" ssid = ""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful  there is a strong case for obtaining a first  or predominant  sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid =""173"" ssid = ""21"">It would be useful however to combine our method of finding predominant senses with one which can automatically find new senses within text and relate these to WordNet synsets  as Ciaramita and Johnson (2003) do with unknown nouns.</S>",['Method_Citation']
7,P04-1036,I08-2105,0,2004,0,"McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","McCarthy et al (2004) report a disambiguation precision of 53.0% and recall of 49.0% on the Senseval-2 test data, using an approach that derives sense ranking based on word similarity and distributional analysis in a corpus","['175', '165', '66', '83', '47']","<S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""165"" ssid = ""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus  whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid =""66"" ssid = ""22"">It uses the glosses of semantically related (according to WordNet) senses too. jcn (Jiang and Conrath  1997) This score uses corpus data to populate classes (synsets) in the WordNet hierarchy with frequency counts.</S><S sid =""83"" ssid = ""12"">The results in table 1 show the accuracy of the ranking with respect to SemCor over the entire set of 2595 polysemous nouns in SemCor with the jcn and lesk WordNet similarity measures.</S><S sid =""47"" ssid = ""3"">We then use the WordNet similarity package (Patwardhan and Pedersen  2003) to give us a semantic similarity measure (hereafter referred to as the WordNet similarity measure) to weight the contribution that each neighbour makes to the various senses of the target word.</S>",['Method_Citation']
8,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","Research by (McCarthy et al, 2004) highlighted that the sense priors of a word in a corpus depend on the domain from which the corpus is drawn","['15', '175', '66', '17', '152']","<S sid =""15"" ssid = ""8"">Whilst a first sense heuristic based on a sense-tagged corpus such as SemCor is clearly useful  there is a strong case for obtaining a first  or predominant  sense from untagged corpus data so that a WSD system can be tuned to the genre or domain at hand.</S><S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""66"" ssid = ""22"">It uses the glosses of semantically related (according to WordNet) senses too. jcn (Jiang and Conrath  1997) This score uses corpus data to populate classes (synsets) in the WordNet hierarchy with frequency counts.</S><S sid =""17"" ssid = ""10"">There are words where the first sense in WordNet is counter-intuitive  because of the size of the corpus  and because where the frequency data does not indicate a first sense  the ordering is arbitrary.</S><S sid =""152"" ssid = ""29"">We see that both domains have a similarly high percentage of factotum (domain independent) labels  but as we would expect  the other peaks correspond to the economy label for the FINANCE corpus  and the sports label for the SPORTS corpus. inant senses for 38 polysemous words ranked using the SPORTS and FINANCE corpus.</S>",['Method_Citation']
9,P04-1036,P06-1012,0,"McCarthy et al, 2004",0,"In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which cal cu lates a prevalence score for each sense of a word to predict the predominant sense","In addition, we implemented the unsupervised method of (McCarthy et al, 2004), which calculates a prevalence score for each sense of a word to predict the predominant sense","['175', '171', '48', '165', '10']","<S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""171"" ssid = ""19"">In contrast  we use the neighbours lists and WordNet similarity measures to impose a prevalence ranking on the WordNet senses.</S><S sid =""48"" ssid = ""4"">To find the first sense of a word ( ) we take each sense in turn and obtain a score reflecting the prevalence which is used for ranking.</S><S sid =""165"" ssid = ""13"">Lapata and Brew obtain their priors for verb classes directly from subcategorisation evidence in a parsed corpus  whereas we use parsed data to find distributionally similar words (nearest neighbours) to the target word which reflect the different senses of the word and have associated distributional similarity scores which can be used for ranking the senses according to prevalence.</S><S sid =""10"" ssid = ""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al.  1993).</S>",['Method_Citation']
11,P04-1036,P10-1155,0,2004,0,"McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarityjcn measure (Jiang and Conrath, 1997)","McCarthy et al (2004) reported that the best results were obtained using k= 50 neighbors and the Wordnet Similarity jcn measure (Jiang and Conrath, 1997)","['188', '47', '65', '49', '85']","<S sid =""188"" ssid = ""11"">We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al.  2004).</S><S sid =""47"" ssid = ""3"">We then use the WordNet similarity package (Patwardhan and Pedersen  2003) to give us a semantic similarity measure (hereafter referred to as the WordNet similarity measure) to weight the contribution that each neighbour makes to the various senses of the target word.</S><S sid =""65"" ssid = ""21"">The measures provide a similarity score between two WordNet senses ( and )  these being synsets within WordNet. lesk (Banerjee and Pedersen  2002) This score maximises the number of overlapping words in the gloss  or definition  of the senses.</S><S sid =""49"" ssid = ""5"">Let be the ordered set of the top scoring neighbours of from the thesaurus with associated distributional similarity scores The thesaurus was acquired using the method described by Lin (1998).</S><S sid =""85"" ssid = ""14"">Both WordNet similarity measures beat this baseline.</S>",['Method_Citation']
12,P04-1036,W12-3401,0,2004,0,"In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","In doing so, we provide first results on the application to French parsing of WordNet automatic sense ranking (ASR), using the method of McCarthy et al (2004)","['175', '41', '54', '103', '10']","<S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""41"" ssid = ""34"">In this paper we describe and evaluate a method for ranking senses of nouns to obtain the predominant sense of a word using the neighbours from automatically acquired thesauruses.</S><S sid =""54"" ssid = ""10"">Thus we rank each sense using: parser (Briscoe and Carroll  2002).</S><S sid =""103"" ssid = ""1"">In order to see how well the automatically acquired predominant sense performs on a WSD task from which the WordNet sense ordering has not been taken  we use the SENSEVAL-2 all-words data (Palmer et al.  2001).</S><S sid =""10"" ssid = ""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al.  1993).</S>",['Method_Citation']
13,P04-1036,W12-3401,0,2004,0,"To define an appropriate categorical distribution over synsets for each 2 lemma x in our source vocabulary, we first use the WordNet resource to identify the set Sx of different senses of x. We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each sense s? Sx, following the approach of McCarthy et al (2004)","We then use a distributional thesaurus to perform ASR, which determines the prevalence with respect to x of each senses' Sx, following the approach of McCarthy et al (2004)","['171', '10', '175', '145', '188']","<S sid =""171"" ssid = ""19"">In contrast  we use the neighbours lists and WordNet similarity measures to impose a prevalence ranking on the WordNet senses.</S><S sid =""10"" ssid = ""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al.  1993).</S><S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""145"" ssid = ""22"">It is not always intuitively clear which of the senses to expect as predominant sense for either a particular domain or for the BNC  but the first senses of words like division and goal shift towards the more specific senses (league and score respectively).</S><S sid =""188"" ssid = ""11"">We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al.  2004).</S>",['Method_Citation']
14,P04-1036,W12-3401,0,2004,0,"As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","As explained in Section 2.2, ASR is performed using the method of McCarthy et al (2004)","['133', '175', '9', '54', '163']","<S sid =""133"" ssid = ""10"">We acquired thesauruses for these corpora using the procedure described in section 2.1.</S><S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""9"" ssid = ""2"">This is shown by the results of the English all-words task in SENSEVAL-2 (Cotton et al.  1998) in figure 1 below  where the first sense is that listed in WordNet for the PoS given by the Penn TreeBank (Palmer et al.  2001).</S><S sid =""54"" ssid = ""10"">Thus we rank each sense using: parser (Briscoe and Carroll  2002).</S><S sid =""163"" ssid = ""11"">Lapata and Brew (2004) have recently also highlighted the importance of a good prior in WSD.</S>",['Method_Citation']
16,P04-1036,S12-1097,0,"McCarthy et al, 2004",0,"This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","This approach is commonly used as a baseline for word sense disambiguation (McCarthy et al, 2004)","['175', '10', '54', '188', '8']","<S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""10"" ssid = ""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al.  1993).</S><S sid =""54"" ssid = ""10"">Thus we rank each sense using: parser (Briscoe and Carroll  2002).</S><S sid =""188"" ssid = ""11"">We want to investigate the effect of frequency and choice of distributional similarity measure (Weeds et al.  2004).</S><S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S>",['Results_Citation']
17,P04-1036,W10-2803,0,"McCarthy et al, 2004",0,"More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","More radical solutions than sense grouping that have been proposed are to restrict the task to determining predominant sense in a given domain (McCarthy et al, 2004), or to work directly with para phrases (McCarthy and Navigli, 2009)","['175', '21', '22', '159', '145']","<S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""21"" ssid = ""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson  1998; Hoste et al.  2001) and for systems that use it in lexical acquisition (McCarthy  1997; Merlo and Leybold  2001; Korhonen  2002) because of the limited size of hand-tagged resources.</S><S sid =""22"" ssid = ""15"">More importantly  when working within a specific domain one would wish to tune the first sense heuristic to the domain at hand.</S><S sid =""159"" ssid = ""7"">Magnini and Cavagli`a (2000) have identified WordNet word senses with particular domains  and this has proven useful for high precision WSD (Magnini et al.  2001); indeed in section 5 we used these domain labels for evaluation.</S><S sid =""145"" ssid = ""22"">It is not always intuitively clear which of the senses to expect as predominant sense for either a particular domain or for the BNC  but the first senses of words like division and goal shift towards the more specific senses (league and score respectively).</S>",['Method_Citation']
18,P04-1036,W08-2107,0,2004,0,"In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Word net resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al (2004))","['175', '99', '89', '146', '7']","<S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""99"" ssid = ""28"">Even given the difference in text type between SemCor and the BNC the results are encouraging  especially given that our results are for polysemous nouns.</S><S sid =""89"" ssid = ""18"">Since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense  and is much more efficient than lesk  given the precompilation of the IC files.</S><S sid =""146"" ssid = ""23"">Moreover  the chosen senses of the word tie proved to be a textbook example of the behaviour we expected.</S><S sid =""7"" ssid = ""7"">Furthermore  we demonstrate that our method discovers appropriate predominant senses for words from two domainspecific corpora.</S>",['Method_Citation']
19,P04-1036,D07-1026,0,"McCarthy et al, 2004",0,"It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","It is worthwhile to remark here that, being the IBLE algorithm fully unsupervised, improving the most frequent baseline is an excellent result, rarely achieved in the literature on unsupervised methods for WSD (McCarthy et al, 2004)","['175', '14', '8', '89', '74']","<S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""14"" ssid = ""7"">Even systems which show superior performance to this heuristic often make use of the heuristic where evidence from the context is not sufficient (Hoste et al.  2001).</S><S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid =""89"" ssid = ""18"">Since both measures gave comparable results we restricted our remaining experiments to jcn because this gave good results for finding the predominant sense  and is much more efficient than lesk  given the precompilation of the IC files.</S><S sid =""74"" ssid = ""3"">Nevertheless  since many systems performed well on the English all-words task for SENSEVAL-2 by using the frequency information in SemCor this is a reasonable approach for evaluation.</S>",['Method_Citation']
20,P04-1036,W12-2429,0,"McCarthy et al, 2004",0,"The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","The first, most frequent sense (MFS) (McCarthy et al, 2004), is widely used baseline for supervised WSD systems","['8', '175', '10', '21', '74']","<S sid =""8"" ssid = ""1"">The first sense heuristic which is often used as a baseline for supervised WSD systems outperforms many of these systems which take surrounding context into account.</S><S sid =""175"" ssid = ""23"">We are currently investigating the performance of the first sense heuristic  and this method  for other PoS on SENSEVAL-3 data (McCarthy et al.  2004)  although not yet with rankings from domain specific corpora.</S><S sid =""10"" ssid = ""3"">The senses in WordNet are ordered according to the frequency data in the manually tagged resource SemCor (Miller et al.  1993).</S><S sid =""21"" ssid = ""14"">We believe that an automatic means of finding a predominant sense would be useful for systems that use it as a means of backing-off (Wilks and Stevenson  1998; Hoste et al.  2001) and for systems that use it in lexical acquisition (McCarthy  1997; Merlo and Leybold  2001; Korhonen  2002) because of the limited size of hand-tagged resources.</S><S sid =""74"" ssid = ""3"">Nevertheless  since many systems performed well on the English all-words task for SENSEVAL-2 by using the frequency information in SemCor this is a reasonable approach for evaluation.</S>",['Aim_Citation']
