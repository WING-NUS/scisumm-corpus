Such resources exist for Hebrew (Itai et al.  2006)  but unfortunately use a tagging scheme which is incompatible with the one of the Hebrew Treebank.s For this reason  we use a data-driven morphological analyzer derived from the training data similar to (Cohen and Smith  2007).Since the lattice L for a given sentence W is determined by the morphological analyzer M we have which is precisely the formula corresponding to the so-called lattice parsing familiar from speech recognition.The current work treats both segmental and super-segmental phenomena  yet we note that there may be more adequate ways to treat supersegmental phenomena assuming Word-Based morphology as we explore in (Tsarfaty and Goldberg  2008).Our use of an unweighted lattice reflects our belief that all the segmentations of the given input sentence are a-priori equally likely; the only reason to prefer one segmentation over the another is due to the overall syntactic context which is modeled via the PCFG derivations.(Levinger et al.  1995; Goldberg et al.  ; Adler et al.  2008)) will make the parser more robust and suitable for use in more realistic scenarios.A Single Generative Model for Joint Morphological Segmentation and Syntactic ParsingSima’an et al. (2001) presented parsing results for a DOP tree-gram model using a small data set (500 sentences) and semiautomatic morphological disambiguation.Here we push the single-framework conjecture across the board and present a single model that performs morphological segmentation and syntactic disambiguation in a fully generative framework.A possible probabilistic model for assigning probabilities to complex analyses of a surface form may be and indeed recent sequential disambiguation models for Hebrew (Adler and Elhadad  2006) and Arabic (Smith et al.  2005) present similar models.This analyzer setting is similar to that of (Cohen and Smith  2007)  and models using it are denoted nohsp  Parser and Grammar We used BitPar (Schmid  2004)  an efficient general purpose parser 10 together with various treebank grammars to parse the input sentences and propose compatible morphological segmentation and syntactic analysis.Tsarfaty (2006) used a morphological analyzer (Segal  2000)  a PoS tagger (Bar-Haim et al.  2005)  and a general purpose parser (Schmid  2000) in an integrated framework in which morphological and syntactic components interact to share information  leading to improved performance on the joint task.Morphological disambiguators that consider a token in context (an utterance) and propose the most likely morphological analysis of an utterance (including segmentation) were presented by Bar-Haim et al. (2005)  Adler and Elhadad (2006)  Shacham and Wintner (2007)  and achieved good results (the best segmentation result so far is around 98%).Morphological analyzers for Hebrew that analyze a surface form in isolation have been proposed by Segal (2000)  Yona and Wintner (2005)  and recently by the knowledge center for processing Hebrew (Itai et al.  2006).Here we propose a single joint model for performing both morphological segmentation and syntactic disambiguation which bypasses the associated circularity.Cohen and Smith (2007) followed up on these results and proposed a system for joint inference of morphological and syntactic structures using factored models each designed and trained on its own.In our second model GTvpi we also distinguished finite and non-finite verbs and VPs as 10Lattice parsing can be performed by special initialization of the chart in a CKY parser (Chappelier et al.  1999).Previous work on morphological and syntactic disambiguation in Hebrew used different sets of data  different splits  differing annotation schemes  and different evaluation measures.Tsarfaty and Sima’an (2007) have reported state-of-the-art results on Hebrew unlexicalized parsing (74.41%) albeit assuming oracle morphological segmentation.Data We use the Hebrew Treebank  (Sima’an et al.  2001)  provided by the knowledge center for processing Hebrew  in which sentences from the daily newspaper “Ha’aretz” are morphologically segmented and syntactically annotated.A morphological analyzer M : W—* L is a function mapping sentences in Hebrew (W E W) to their corresponding lattices (M(W) = L E L).Morphological processes in Semitic languages deliver space-delimited words which introduce multiple  distinct  syntactic units into the structure of the input sentence.We refer to a segment and its assigned PoS tag as a lexeme  and so analyses are in fact sequences of lexemes.The input for the segmentation task is however highly ambiguous for Semitic languages  and surface forms (tokens) may admit multiple possible analyses as in (BarHaim et al.  2007; Adler and Elhadad  2006).The latter arcs correspond to OOV words in English.The possible analyses of a surface token pose constraints on the analyses of specific segments.Each connected path (l1 ... lk) E L corresponds to one morphological segmentation possibility of W. The Parser Given a sequence of input tokens W = w1 ... wn and a morphological analyzer  we look for the most probable parse tree π s.t.The Hebrew token ‘bcl’1  for example  stands for the complete prepositional phrase 'We adopt here the transliteration of (Sima’an et al.  2001).A similar structure is used in speech recognition.In our third model GTppp we also add the distinction between general PPs and possessive PPs following Goldberg and Elhadad (2007).Both (Tsarfaty  2006; Cohen and Smith  2007) have shown that a single integrated framework outperforms a completely streamlined implementation  yet neither has shown a single generative model which handles both tasks.To control for the effect of the HSPELL-based pruning  we also experimented with a morphological analyzer that does not perform this pruning.We use the HSPELL9 (Har’el and Kenigsberg  2004) wordlist as a lexeme-based lexicon for pruning segmentations involving invalid segments.Morphological Analyzer Ideally  we would use an of-the-shelf morphological analyzer for mapping each input token to its possible analyses.In sequential tagging models such as (Adler and Elhadad  2006; Bar-Haim et al.  2007; Smith et al.  2005) weights are assigned according to a language model The input for the joint task is a sequence W = w1  ...   wn of space-delimited tokens.This token may further embed into a larger utterance  e.g.  ‘bcl hneim’ (literally “in-the-shadow the-pleasant”  meaning roughly “in the pleasant shadow”) in which the dominated Noun is modified by a proceeding space-delimited adjective.