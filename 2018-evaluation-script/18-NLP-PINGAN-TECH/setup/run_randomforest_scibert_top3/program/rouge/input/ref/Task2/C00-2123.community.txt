In this paper, we describe a search procedure for statistical machine translation (MT) based on dynamic programming (DP). We are given a source string fJ 1 = f1:::fj :::fJ of length J, which is to be translated into a target string eI 1 = e1:::ei:::eI of length I. Among all possible target strings, we will choose the string with the highest probability (1), Pr(eI 1) is the language model, which is a trigram language model in this case. For the translation model Pr(fJ 1 jeI 1), we go on the assumption that each source word is aligned to exactly one target word. What is important and is not expressed by the notation is the so-called coverage constraint: each source position j should be &apos;hit&apos; exactly once by the path of the inverted alignment bI 1 = b1:::bi:::bI . Using the inverted alignments in the maximum approximation In order to handle the necessary word reordering as an optimization problem within our dynamic programming approach, we describe a solution to the traveling salesman problem (TSP) which is based on dynamic programming (Held, Karp, 1962). The algorithm works due to the fact that not all permutations of cities have to be considered explicitly. The type of alignment we have considered so far requires the same length for source and target sentence, i.e. I = J. Evidently, this is an unrealistic assumption, therefore we extend the concept of inverted alignments as follows: When adding a new position to the coverage set C, we might generate either Æ = 0 or Æ = 1 new target words. When translating the sentence monotonically from left to right, the translation of the German finite verb &apos;kann&apos;, which is the left verbal brace in this case, is postponed until the German noun phrase &apos;mein Kollege&apos; is translated, which is the subject of the sentence. This approach leads to a search procedure with complexity O(E3 J4). A dynamic programming recursion similar to the one in Eq. 2 is evaluated. This approach leads to a search procedure with complexity O(E3 J4). This measure has the advantage of being completely automatic. We apply a beam search concept as in speech recognition. For each source word f, the list of its possible translations e is sorted according to p(fje) puni(e), where puni(e) is the unigram probability of the English word e. It is suÆcient to consider only the best 50 words. For our demonstration system, we typically use the pruning threshold t0 = 5:0 to speed up the search by a factor 5 while allowing for a small degradation in translation accuracy. 