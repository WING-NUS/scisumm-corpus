<S sid="9" ssid="3">This paper discusses the use of unlabeled examples for the problem of named entity classification.</S>
<S sid="36" ssid="30">Roughly speaking, the new algorithm presented in this paper performs a similar search, but instead minimizes a bound on the number of (unlabeled) examples on which two classifiers disagree.</S>
<S sid="137" ssid="4">The new algorithm, which we call CoBoost, uses labeled and unlabeled data and builds two classifiers in parallel.</S>
d="79" ssid="12">2 We now introduce a new algorithm for learning from unlabeled examples, which we will call DLCoTrain (DL stands for decision list, the term Cotrain is taken from (Blum and Mitchell 98)).</S>
<S sid="10" ssid="4">The task is to learn a function from an input string (proper name) to its type, which we will assume to be one of the categories Person, Organization, or Location.</S>
<S sid="18" ssid="12">But we will show that the use of unlabeled data can drastically reduce the need for supervision.</S>
"<S sid=""236"" ssid=""3"">We chose one of four labels for each example: location, person, organization, or noise where the noise category was used for items that were outside the three categories.</S>
    <S sid=""237"" ssid=""4"">The numbers falling into the location, person, organization categories were 186, 289 and 402 respectively.</S>"
"<S sid=""26"" ssid=""20"">We present two algorithms.</S>
    <S sid=""27"" ssid=""21"">The first method builds on results from (Yarowsky 95) and (Blum and Mitchell 98).</S>"
<S sid="18" ssid="12">But we will show that the use of unlabeled data can drastically reduce the need for supervision.</S>
<S sid="85" ssid="18">(If fewer than n rules have Precision greater than pin, we 3Note that taking tlie top n most frequent rules already makes the method robut to low count events, hence we do not use smoothing, allowing low-count high-precision features to be chosen on later iterations. keep only those rules which exceed the precision threshold.) pm,n was fixed at 0.95 in all experiments in this paper.</S>
"<S sid=""8"" ssid=""2"">Recent results (e.g., (Yarowsky 95; Brill 95; Blum and Mitchell 98)) have suggested that unlabeled data can be used quite profitably in reducing the need for supervision.</S>