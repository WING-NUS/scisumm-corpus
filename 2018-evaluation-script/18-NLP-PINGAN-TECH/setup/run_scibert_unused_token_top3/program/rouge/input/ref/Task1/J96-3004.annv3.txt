Citance Number: 1 | Reference Article:  J96-3004.xml | Citing Article:  A00-2032.xml | Citation Marker Offset:  ['142'] | Citation Marker:  1996 | Citation Offset:  ['141','142'] | Citation Text:  <S sid ="141" ssid = "10">Chinese According to Sproat et al.</S><S sid ="142" ssid = "11">(1996), most prior work in Chinese segmentation has exploited lexical knowledge bases; indeed, the authors assert that they were aware of only one previously pubÂ­ lished instance (the mutual-information method of Sproat and Shih (1990)) of a purely statistical apÂ­ proach.</S> | Reference Offset:  ['89','90','91'] | Reference Text:  <S sid ="89" ssid = "27">Roughly speaking, previous work can be divided into three categories, namely purely statistical approaches, purely lexiÂ­ cal rule-based approaches, and approaches that combine lexical information with staÂ­ tistical information.</S><S sid ="90" ssid = "28">The present proposal falls into the last group.</S><S sid ="91" ssid = "29">Purely statistical approaches have not been very popular, and so far as we are aware earlier work by Sproat and Shih (1990) is the only published instance of such an approach.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 2 | Reference Article:  J96-3004.xml | Citing Article:  A00-2032.xml | Citation Marker Offset:  ['5'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['5'] | Citation Text:  <S sid ="5" ssid = "5">Proposed applications of segmentation technology include extracting new technical terms, indexing documents for information retrieval, and correcting optical character recognition (OCR) erÂ­ rors (Wu and Tseng, 1993; Nagao and Mori, 1994; Nagata, 1996a; Nagata, 1996b; Sproat et al., 1996; Fung, 1998).</S> | Reference Offset:  ['137','138'] | Reference Text:  <S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S><S sid ="138" ssid = "2">More formally, we start by representing the dictionary D as a Weighted Finite State TransÂ­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 3 | Reference Article:  J96-3004.xml | Citing Article:  C00-2095.xml | Citation Marker Offset:  ['80'] | Citation Marker:  Sproat ct a.l., 1996 | Citation Offset:  ['80'] | Citation Text:  <S sid ="80" ssid = "25">As (Sproat ct a.l., 1996) testify, several native Chinese speakers do not always agree on one unique tokeniza.tion for a. given sentence.</S> | Reference Offset:  ['297','298'] | Reference Text:  <S sid ="297" ssid = "6">The problem with these styles of evaluation is that, as we shall demonstrate, even human judges do not agree perfectly on how to segment a given text.</S><S sid ="298" ssid = "7">Thus, rather than give a single evaluative score, we prefer to compare the performance of our method with the judgments of several human subjects.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel |


Citance Number: 4 | Reference Article:  J96-3004.xml | Citing Article:  C02-1049.xml | Citation Marker Offset:  ['58'] | Citation Marker:  Sproat et al, 1996 | Citation Offset:  ['58'] | Citation Text:  <S sid ="58" ssid = "39">Conventionally a word segmentation process identifies the words in input text by matching lexical entries and resolving the ambiguous matching (Chen &amp; Liu, 1992, Sproat et al, 1996).</S> | Reference Offset:  ['108','109','112'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with segÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S sid ="109" ssid = "47">This method, one instance of which we term the &quot;greedy algorithm&quot; in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin­ ning) of the sentence is reached.</S><S sid ="112" ssid = "50">The simplest version of the maximum matching algorithm effectively deals with ambiguity by ignoring it, since the method is guaranteed to produce only one segmentation.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 5 | Reference Article:  J96-3004.xml | Citing Article:  C02-1049.xml | Citation Marker Offset:  ['127'] | Citation Marker:  Sproat et al, 1996 | Citation Offset:  ['125','126','127'] | Citation Text:  <S sid ="124" ssid = "105">Mutu al infor matio n-like statist ics are very often adopt ed in meas uring assoc iation stren gth msi (?)</S><S sid ="127" ssid = "108">dsi +1 () combine (i, i + 1) 1993, Sproat et al, 1996)</S> | Reference Offset:  ['92','93'] | Reference Text:  <S sid ="92" ssid = "30">In that work, mutual information was used to decide whether to group adjacent hanzi into two-hanzi words.</S><S sid ="93" ssid = "31">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 6 | Reference Article:  J96-3004.xml | Citing Article:  C02-1080.xml | Citation Marker Offset:  ['20'] | Citation Marker:  Sproat et al. 96 | Citation Offset:  ['20'] | Citation Text:  <S sid ="20" ssid = "20">Chinese NE recognition is much more difficult than that in English due to two major problems.</S><S sid ="21" ssid = "21">The first is the word segmentation problem (Sproat et al. 96, Palmer 97).</S> | Reference Offset:  ['51'] | Reference Text:  <S sid ="51" ssid = "12">Making the reasonable assumption that similar information is relevant for solving these problems in Chinese, it follows that a prerequisite for intonation-boundary assignment and prominence assignment is word segmentation.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 7 | Reference Article:  J96-3004.xml | Citing Article:  C02-1143.xml | Citation Marker Offset:  ['107'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['107'] | Citation Text:  <S sid ="107" ssid = "48">We used a maximum- matching algorithm and a dictionary compiled from the CTB (Sproat et al., 1996; Xue, 2001) to do segmentation | Reference Offset:  ['108'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with segÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 8 | Reference Article:  J96-3004.xml | Citing Article:  E09-1063.xml | Citation Marker Offset:  ['107'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['107'] | Citation Text:  <S sid ="107" ssid = "4">First of all, it is really difficult to build a reliable and objective gold-standard given the fact that there is only 70% agreement between native speakers on this task (Sproat et al., 1996).</S> | Reference Offset:  ['297','325'] | Reference Text:  <S sid ="297" ssid = "6">The problem with these styles of evaluation is that, as we shall demonstrate, even human judges do not agree perfectly on how to segment a given text.</S><S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15 On</S> | Discourse Facet:  ['Implication_Citation','Results_Citation'] | Annotator:  Ankita Patel |


Citance Number: 9 | Reference Article:  J96-3004.xml | Citing Article:  I05-3031.xml | Citation Marker Offset:  ['7'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['6','7'] | Citation Text:  <S sid ="6" ssid = "6">The Chinese word segmentation is a nontrivial task because no explicit delimiters (like spaces in English) are used for word separation.</S><S sid ="7" ssid = "7">As the task is an important precursor to many natural language processing systems, it receives a lot of attentions in the literature for the past decade (Wu and Tseng, 1993; Sproat et al., 1996).</S> | Reference Offset:  ['2','33'] | Reference Text:  <S sid ="2" ssid = "2">An initial step of any textÂ­ analysis task is the tokenization of the input into words.</S><S sid ="33" ssid = "33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 10 | Reference Article:  J96-3004.xml | Citing Article:  J00-3004.xml | Citation Marker Offset:  ['42'] | Citation Marker:  1996 | Citation Offset:  ['42'] | Citation Text:  <S sid ="42" ssid = "42">According to Sproat et al. {1996) and Wu and Fung {1994), experiments show that only about 75% agreement between native speakers is to be expected on the &quot;correct&quot; segmentation, and the figure reduces as more people become involved.</S> | Reference Offset:  ['297','325'] | Reference Text:  <S sid ="297" ssid = "6">The problem with these styles of evaluation is that, as we shall demonstrate, even human judges do not agree perfectly on how to segment a given text.</S><S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement.15</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 11 | Reference Article:  J96-3004.xml | Citing Article:  J00-3004.xml | Citation Marker Offset:  ['96'] | Citation Marker:  1996 | Citation Offset:  ['96'] | Citation Text:  <S sid ="96" ssid = "41">Sproat et al.</S><S sid ="97" ssid = "42">(1996) implement special recognizers not only for Chinese names and transliterated foreign names, but for components of morphologically obtained words as well.</S> | Reference Offset:  ['399'] | Reference Text:  <S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 12 | Reference Article:  J96-3004.xml | Citing Article:  J04-1004.xml | Citation Marker Offset:  ['53'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['53'] | Citation Text:  <S sid ="53" ssid = "53">In Chinese text segmentation there are three basic approaches (Sproat et al. 1996): pure heuristic, pure statistical, and a hybrid of the two.</S> | Reference Offset:  ['89'] | Reference Text:   <S sid ="89" ssid = "27">Roughly speaking, previous work can be divided into three categories, namely purely statistical approaches, purely lexiÂ­ cal rule-based approaches, and approaches that combine lexical information with staÂ­ tistical information.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 13 | Reference Article:  J96-3004.xml | Citing Article:  J04-1004.xml | Citation Marker Offset:  ['113'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['113'] | Citation Text:  <S sid ="113" ssid = "9">There are several commonly used segmentation methods such as forward maximum matching and backward maximum matching(Teahan et al. 2000; Dai, Loh, and Khoo 1999; Sproat et al. 1996).</S> | Reference Offset:  ['108'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 14 | Reference Article:  J96-3004.xml | Citing Article:  J04-1004.xml | Citation Marker Offset:  ['211'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['211'] | Citation Text:  <S sid ="211" ssid = "32">In addition, there is no commonly accepted standard for evaluating the performance of word extraction methods, and it is very hard to decide whether a word is meaningful or not (Sproat et al. 1996).</S> | Reference Offset:  ['133'] | Reference Text:  <S sid ="133" ssid = "71">Besides the lack of a clear definition of what constitutes a correct segmentation for a given Chinese sentence, there is the more general issue that the test corpora used in these evaluations differ from system to system, so meaningful comparison between systems is rendered even more difficult.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel |


Citance Number: 15 | Reference Article:  J96-3004.xml | Citing Article:  J04-1004.xml | Citation Marker Offset:  ['321'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['321'] | Citation Text:  <S sid ="321" ssid = "7">As even human judges differ when facing the task of segmenting a text into words and test corpora differ from system to system (Sproat et al. 1996), it is very difficult to compare two methods.</S> | Reference Offset:  ['297'] | Reference Text:  <S sid ="297" ssid = "6">The problem with these styles of evaluation is that, as we shall demonstrate, even human judges do not agree perfectly on how to segment a given text.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel |


Citance Number: 16 | Reference Article:  J96-3004.xml | Citing Article:  J05-4005.xml | Citation Marker Offset:  ['88'] | Citation Marker:  1996 | Citation Offset:  ['88'] | Citation Text:  <S sid ="88" ssid = "24">A previous work along this line is Sproat et al.</S><S sid ="89" ssid = "25">(1996), which is based on weighted finite-state transducers (FSTs).</S> | Reference Offset:  ['398'] | Reference Text:  <S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled efÂ­ fectively using weighted finite-state transducers.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 17 | Reference Article:  J96-3004.xml | Citing Article:  J05-4005.xml | Citation Marker Offset:  ['126'] | Citation Marker:  1996 | Citation Offset:  ['125','126'] | Citation Text:  <S sid ="125" ssid = "61">As shown in Sproat et al.</S><S sid ="126" ssid = "62">(1996), the rate of agreement between two human judges is less than 80%.</S> | Reference Offset:  ['325'] | Reference Text:  <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 18 | Reference Article:  J96-3004.xml | Citing Article:  J05-4005.xml | Citation Marker Offset:  ['132'] | Citation Marker:  1996 | Citation Offset:  ['131','132'] | Citation Text:  <S sid ="131" ssid = "67">Similarly, Sproat et al.</S><S sid ="132" ssid = "68">(1996) also uses multiple human judges.</S> | Reference Offset:  ['325'] | Reference Text:  <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 19 | Reference Article:  J96-3004.xml | Citing Article:  J05-4005.xml | Citation Marker Offset:  ['490'] | Citation Marker:  1996 | Citation Offset:  ['489','490'] | Citation Text:  <S sid ="489" ssid = "153">The Chinese person-name model is a modified version of that described in Sproat et al.</S><S sid ="490" ssid = "154">(1996).</S> | Reference Offset:  ['399'] | Reference Text:  <S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 20 | Reference Article:  J96-3004.xml | Citing Article:  J11-1005.xml | Citation Marker Offset:  ['123'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['123'] | Citation Text:  <S sid ="123" ssid = "14">Experiments have shown that there is only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al. 1996).</S> | Reference Offset:  ['325'] | Reference Text:  <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 21 | Reference Article:  J96-3004.xml | Citing Article:  J11-3001.xml | Citation Marker Offset:  ['326'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['326'] | Citation Text:  <S sid ="326" ssid = "279">Gold standards, however, 435 cannot be uniﬁed into a single standard (Fung and Wu 1994; Sproat et al. 1996).</S> | Reference Offset: ['296','297'] | Reference Text:  <S sid ="296" ssid = "5">Previous reports on Chinese segmentation have invariably cited performance either in terms of a single percent-correct score, or else a single precision-recall pair.</S><S sid ="297" ssid = "6">The problem with these styles of evaluation is that, as we shall demonstrate, even human judges do not agree perfectly on how to segment a given text.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel | 


Citance Number: 22 | Reference Article:  J96-3004.xml | Citing Article:  J96-4004.xml | Citation Marker Offset:  ['24'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['24'] | Citation Text:  <S sid ="24" ssid = "24">Our ap . proach differs from existing work on Chinese word segmentation (Liang 1983; Wang, Wang, and Bai 1991; Fan and Tsai 1988; Chang, Chen, and Chen 1991; Chiang et al. 1992; Sproat and Shih 1990; Wu and Su 1993; Lua and Gan 1994; Lai et al. 1992; Sproat et al. 1994; Sproat et al. 1996) primarily in that our system performs sentence interÂ­ pretation, in addition to word boundary identification.</S> | Reference Offset:  ['137'] | Reference Text:  <S sid ="137" ssid = "1">Chinese word segmentation can be viewed as a stochastic transduction problem.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 23 | Reference Article:  J96-3004.xml | Citing Article:  J97-4004.xml | Citation Marker Offset:  ['9'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['9'] | Citation Text:  <S sid ="9" ssid = "9">Since in written Chinese there is no explicit word delimiter (equivalent to the blank space in written English), the problem of Chinese sentence tokenization has been the focus of considerable research efforts, and significant advancements have been made (e.g., Bai 1995; Zhang et al. 1994; Chen and Liu 1992; Chiang et al. 1992; Fan and Tsai 1988; Gan 1995; Gan, Palmer, and Lua 1996; Guo 1993; He, Xu, and Sun 1991; Huang 1989; Huang and Xia 1996; Jie 1989; Jie, Liu, and Liang 1991a, 1991b; Jin and Chen 1995; Lai et al. 1992; Li et al. 1995; Liang 1986, 1987, 1990; Liu 1986a, 1986b; Liu, Tan, and Shen 1994; Lua 1990, 1994, and 1995; Ma 1996; Nie, Jin, and Hannan 1994; Sproat and Shih 1990; Sproat et al. 1996;</S> | Reference Offset:  ['21','33'] | Reference Text:  <S sid ="21" ssid = "21">In Chinese text, individual characters of the script, to which we shall refer by their traditional name of hanzi,Z are written one after another with no intervening spaces;</S><S sid ="33" ssid = "33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 24 | Reference Article:  J96-3004.xml | Citing Article:  J97-4004.xml | Citation Marker Offset:  ['515'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['515'] | Citation Text:  <S sid ="515" ssid = "92">The three tokenization definitions in this section are essentially descriptive restatements of the corresponding constructive tokenization procedures, which in turn are realizaÂ­ tions of the widely followed principle of maximum tokenization (e.g., Liu 1986; Liang 1986a, 1986b; Wang 1989; Jie 1989; Wang, Su, and Mo 1990; Jie, Liu, and Liang 1991a, b; Yeh and Lee 1991; Webster and Kit 1992; Chen and Liu 1992; Guo 1993; Wu and Su 1993; Nie, Jin, and Hannan 1994; Sproat et al. 1996;</S> | Reference Offset:  ['108'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 25 | Reference Article:  J96-3004.xml | Citing Article:  J97-4004.xml | Citation Marker Offset:  ['613'] | Citation Marker:  1996 | Citation Offset:  ['612','613'] | Citation Text:  <S sid ="612" ssid = "54">The weighted finite-state transducer model developed by Sproat et al.</S><S sid ="613" ssid = "55">(1996) is another excellent representative example.</S> | Reference Offset:  ['138'] | Reference Text:  <S sid ="138" ssid = "2">More formally, we start by representing the dictionary D as a Weighted Finite State TransÂ­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 26 | Reference Article:  J96-3004.xml | Citing Article:  J97-4004.xml | Citation Marker Offset:  ['621'] | Citation Marker:  1996 | Citation Offset:  ['621'] | Citation Text:  <S sid ="621" ssid = "63">While it may not be totally impossible to fully incorporate such knowledge and heuristics into the general framework of path evaluation and searching, they are apÂ­ parently employed neither in Sproat et al.</S><S sid ="622" ssid = "64">(1996) nor in Ma (1996).</S> | Reference Offset:  ['108'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 27 | Reference Article:  J96-3004.xml | Citing Article:  N10-1068.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['6'] | Citation Text:  <S sid ="6" ssid = "6">Many natural language models can be captured by weighted finite-state transducers (Pereira et al., 1994; Sproat et al., 1996; Knight and AlOnaizan, 1998; Clark, 2002; Kolak et al., 2003; Mathias and Byrne, 2006), which offer several benefits:â€¢ WFSTs provide a uniform knowledge represen tation.</S> | Reference Offset:  ['138'] | Reference Text:  <S sid ="138" ssid = "2">More formally, we start by representing the dictionary D as a Weighted Finite State TransÂ­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 28 | Reference Article:  J96-3004.xml | Citing Article:  P03-1035.xml | Citation Marker Offset:  ['41'] | Citation Marker:  1996 | Citation Offset:  ['41'] | Citation Text:  <S sid ="41" ssid = "18">One example of such approaches is Sproat et al.</S><S sid ="42" ssid = "19">(1996), which is based on weighted finite-state transducers (FSTs).</S> | Reference Offset:  ['138'] | Reference Text:  <S sid ="138" ssid = "2">More formally, we start by representing the dictionary D as a Weighted Finite State TransÂ­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 29 | Reference Article:  J96-3004.xml | Citing Article:  P03-1035.xml | Citation Marker Offset:  ['122'] | Citation Marker:  1996 | Citation Offset:  ['122'] | Citation Text:  <S sid ="122" ssid = "27">Because any character strings can be in principle named entities of one or more types, to limit the number of candidates for a more effective search, we generate named entity candidates, given an input string, in two steps: First, for each type, we use a set of constraints (which are compiled by 3 Sproat et al.</S> | Reference Offset:  ['419','420'] | Reference Text:  <S sid ="419" ssid = "22">The method reported in this paper makes use solely of unigram probabilities, and is therefore a zeroeth-order model: the cost of a particular segmentation is estimated as the sum of the costs of the individual words in the segmentation.</S><S sid ="420" ssid = "23">However, as we have noted, nothing inherent in the approach precludes incorporating higher-order constraints, provided they can be effectively modeled within a finite-state framework.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 30 | Reference Article:  J96-3004.xml | Citing Article:  P03-1035.xml | Citation Marker Offset:  ['155'] | Citation Marker:  1996 | Citation Offset:  ['155'] | Citation Text:  <S sid ="154" ssid = "59">5.2.4 Transliterations of foreign names As described in Sproat et al.</S><S sid ="155" ssid = "60">(1996): FNs are usually transliterated using Chinese character strings whose sequential pronunciation mimics the source language pronunciation of the name.</S> | Reference Offset:  ['281'] | Reference Text:  <S sid ="281" ssid = "145">Foreign names are usually transliterated using hanzi whose sequential pronunciation mimics the source language pronunciation of the name.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 31 | Reference Article:  J96-3004.xml | Citing Article:  P06-1010.xml | Citation Marker Offset:  ['43'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['42','43'] | Citation Text:  <S sid ="42" ssid = "10">Candidate Chinese transliterations are generated by consulting a list of characters that are frequently used for transliterating foreign names.</S><S sid ="43" ssid = "11">As discussed elsewhere (Sproat et al., 1996), a subset of a few hundred characters (out of several thousand) tends to be used overwhelmingly for transliterating foreign names into Chinese.</S> | Reference Offset:  ['283','284'] | Reference Text:  <S sid ="283" ssid = "147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 &apos;Shamir,&apos; which is a legal Chi­ nese personal name, retains a foreign flavor because of liM.</S><S sid ="284" ssid = "148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil­ ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 32 | Reference Article:  J96-3004.xml | Citing Article:  P06-1126.xml | Citation Marker Offset:  ['7'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['7'] | Citation Text:  <S sid ="7" ssid = "7">Chinese word segmentation is the initial stage of many Chinese language processing tasks, and has received a lot of attention in the literature (Sproat et al., 1996; Sun and Tsou, 2001; Zhang et al., 2003; Peng et al., 2004).</S> | Reference Offset:  ['88'] | Reference Text:  <S sid ="88" ssid = "26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S> | Discourse Facet:  Aim_Citation | Annotator:  Ankita Patel |


Citance Number: 33 | Reference Article:  J96-3004.xml | Citing Article:  P07-1015.xml | Citation Marker Offset:  ['113'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['113'] | Citation Text:  <S sid ="113" ssid = "21">Using the 495 characters that are frequently used for transliterating foreign names (Sproat et al., 1996), a sequence of three of more characters from the list was taken as a possible candidate for Chinese.</S> | Reference Offset:  ['283','284'] | Reference Text:  <S sid ="283" ssid = "147">Fortunately, there are only a few hundred hanzi that are particularly common in transliterations; indeed, the commonest ones, such as E. bal, m er3, and iij al are often clear indicators that a sequence of hanzi containing them is foreign: even a name like !:i*m xia4mi3-er3 &apos;Shamir,&apos; which is a legal Chi­ nese personal name, retains a foreign flavor because of liM.</S>	<S sid ="284" ssid = "148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabil­ ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 34 | Reference Article:  J96-3004.xml | Citing Article:  P07-1016.xml | Citation Marker Offset:  ['70'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['70'] | Citation Text:  <S sid ="70" ssid = "42">As discussed elsewhere (Sproat et al., 1996), out of several thousand common Chinese characters, a subset of a few hundred characters tends to be used overwhelmingly for transliterating English names to Chinese, e.g. only 731 Chinese characters are adopted in the E-C corpus.</S> | Reference Offset:  ['284'] | Reference Text:  <S sid ="284" ssid = "148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabilÂ­ ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 35 | Reference Article:  J96-3004.xml | Citing Article:  P12-1110.xml | Citation Marker Offset:  ['105'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['105'] | Citation Text:  <S sid ="105" ssid = "53">3.3.1 Dictionary features Because segmentation using a dictionary alone can serve as a strong baseline in Chinese word segmentation (Sproat et al., 1996), the use of dictionaries is expected to make our joint model more robust and enables us to investigate the contribution of the syntactic dependency in a more realistic setting.</S> | Reference Offset:  ['54'] | Reference Text:  <S sid ="54" ssid = "15">A minimal requirement for building a Chinese word segmenter is obviously a dictionary; furthermore, as has been argued persuasively by Fung and Wu (1994), one will perform much better at segmenting text by using a dictionary constructed with text of the same genre as the text to be segmented.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 36 | Reference Article:  J96-3004.xml | Citing Article:  P12-1111.xml | Citation Marker Offset:  ['91'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['91'] | Citation Text:  <S sid ="91" ssid = "31">In early work, rule-based models find words one by one based on heuristics such as forward maximum match (Sproat et al., 1996).</S> | Reference Offset:  ['108','109'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S sid ="109" ssid = "47">This method, one instance of which we term the &quot;greedy algorithm&quot; in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin­ ning) of the sentence is reached.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |



Citance Number: 37 | Reference Article:  J96-3004.xml | Citing Article:  P97-1041.xml | Citation Marker Offset:  ['12'] | Citation Marker:  1996 | Citation Offset:  ['12'] | Citation Text:  <S sid ="12" ssid = "12">For a discussion of recent Chinese segmentation work, see Sproat et al. {1996).</S> | Reference Offset:  ['87','88'] | Reference Text:  <S sid ="87" ssid = "25">Previous Work.</S><S sid ="88" ssid = "26">There is a sizable literature on Chinese word segmentation: recent reviews include Wang, Su, and Mo (1990) and Wu and Tseng (1993).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 38 | Reference Article:  J96-3004.xml | Citing Article:  P97-1041.xml | Citation Marker Offset:  ['39'] | Citation Marker:  1996 | Citation Offset:  ['39'] | Citation Text:  <S sid ="39" ssid = "5">It is rule-based, but relies on 2 See, for example, Sproat et al.</S><S sid ="40" ssid = "6">(1996)</S> | Reference Offset:  ['0'] | Reference Text:  <S sid ="0">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 39 | Reference Article:  J96-3004.xml | Citing Article:  P98-1076.xml | Citation Marker Offset:  ['145'] | Citation Marker:  1996 | Citation Offset:  ['144','145'] | Citation Text:  <S sid ="144" ssid = "11">The actual implementation of the weighted finiteÂ­ state transducer by Sproat et al.</S><S sid ="145" ssid = "12">(1996) can be taken as an evidence that the hypothesis of one tokenization per source has already in practical use.</S> | Reference Offset:  ['419','420'] | Reference Text:  <S sid ="419" ssid = "22">The method reported in this paper makes use solely of unigram probabilities, and is therefore a zeroeth-order model: the cost of a particular segmentation is estimated as the sum of the costs of the individual words in the segmentation.</S><S sid ="420" ssid = "23">However, as we have noted, nothing inherent in the approach precludes incorporating higher-order constraints, provided they can be effectively modeled within a finite-state framework.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel |


Citance Number: 40 | Reference Article:  J96-3004.xml | Citing Article:  P98-1076.xml | Citation Marker Offset:  ['150'] | Citation Marker:  1996 | Citation Offset:  ['149','150'] | Citation Text:  <S sid ="149" ssid = "2">utilizing local and sentential constraints, what Sproat et al.</S><S sid ="150" ssid = "3">( 1996) implemented was simply a token unigram scoring function.</S> | Reference Offset:  ['419'] | Reference Text:  <S sid ="419" ssid = "22">The method reported in this paper makes use solely of unigram probabilities, and is therefore a zeroeth-order model: the cost of a particular segmentation is estimated as the sum of the costs of the individual words in the segmentation.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 41 | Reference Article:  J96-3004.xml | Citing Article:  P99-1036.xml | Citation Marker Offset:  ['6'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['5','6'] | Citation Text:  <S sid ="5" ssid = "5">In Japanese, around 95% word segmentation acÂ­ curacy is reported by using a word-based lanÂ­ guage model and the Viterbi-like dynamic programÂ­ ming procedures (Nagata, 1994; Yamamoto, 1996; Takeuchi and Matsumoto, 1997; Haruno and MatÂ­ sumoto, 1997).</S><S sid ="6" ssid = "6">About the same accuracy is reported in Chinese by statistical methods (Sproat et al., 1996).</S> | Reference Offset:  ['356'] | Reference Text:  <S sid ="356" ssid = "65">The performance was 80.99% recall and 61.83% precision.</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 42 | Reference Article:  J96-3004.xml | Citing Article:  P99-1036.xml | Citation Marker Offset:  ['8'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['8'] | Citation Text:  <S sid ="8" ssid = "8">There are two approaches to solve this problem: to increase the coverage of the dictionary (Fung and Wu, 1994; Chang et al., 1995; Mori and Nagao, 1996) and to design a better model for unknown words (Nagata, 1996; Sproat et al., 1996).</S> | Reference Offset:  ['415','416','417'] | Reference Text:  <S sid ="415" ssid = "18">The major problem for our segÂ­ menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S><S sid ="416" ssid = "19">We have provided methods for handling certain classes of unknown words, and models for other classes could be provided, as we have noted.</S><S sid ="417" ssid = "20">However, there will remain a large number of words that are not readily adduced to any producÂ­ tive pattern and that would simply have to be added to the dictionary.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel |


Citance Number: 43 | Reference Article:  J96-3004.xml | Citing Article:  P99-1036.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">To improve word segmentaÂ­ tion accuracy, (Nagata, 1996) used a single general purpose unknown word model, while (Sproat et al., 1996) used a set of specific word models such as for plurals, personal names, and transliterated foreign words.</S> | Reference Offset:  ['398','399'] | Reference Text:  <S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled efÂ­ fectively using weighted finite-state transducers.</S><S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 44 | Reference Article:  J96-3004.xml | Citing Article:  P99-1036.xml | Citation Marker Offset:  ['178'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['178'] | Citation Text:  <S sid ="178" ssid = "108">Word segmentation accuracy is expressed in terms of recall and precision as is done in the previous research (Sproat et al., 1996).</S> | Reference Offset:  ['128'] | Reference Text:  <S sid ="128" ssid = "66">Following Sproat and Shih (1990), performance for Chinese segmentation systems is generally reported in terms of the dual measures of precision and recal</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 45 | Reference Article:  J96-3004.xml | Citing Article:  W00-0803.xml | Citation Marker Offset:  ['29'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['29'] | Citation Text:  <S sid ="29" ssid = "29">Segmentation rutd morphological analysis related issues of both Chinese and Japanese are intensively addressed elsewhere (Sproat et al., 1996; MatsUIIt(ltO et al., 1997 and many others).</S> | Reference Offset:  ['116'] | Reference Text:  <S sid ="116" ssid = "54">Methods for expanding the dictionary include, of course, morphological rules, rules for segmenting personal names, as well as numeral sequences, expressions for dates, and so forth (Chen and Liu 1992; Wang, Li, and Chang 1992; Chang and Chen 1993; Nie, Jin, and Hannan 1994).</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 46 | Reference Article:  J96-3004.xml | Citing Article:  W00-1207.xml | Citation Marker Offset:  ['10'] | Citation Marker:  Sproat et al 1996 | Citation Offset:  ['10'] | Citation Text:  <S sid ="10" ssid = "10">Purely statistical methods of word segmentation (e.g. de Marcken 1996, Sproat et al 1996, Tung and Lee 1994, Lin et al (1993), Chiang et al (1992), Lua, Huang et al, etc.) often fail to identify those words because of the sparse data problem, as the likelihood for those words to appear in the training texts is extremely low.</S> | Reference Offset:  ['415','417'] | Reference Text:  <S sid ="415" ssid = "18">The major problem for our segÂ­ menter, as for all segmenters, remains the problem of unknown words (see Fung and Wu [1994]).</S><S sid ="417" ssid = "20">However, there will remain a large number of words that are not readily adduced to any producÂ­ tive pattern and that would simply have to be added to the dictionary.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel |


Citance Number: 47 | Reference Article:  J96-3004.xml | Citing Article:  W01-0513.xml | Citation Marker Offset:  ['41'] | Citation Marker:  Sproat, et al, 1996 | Citation Offset:  ['40','41'] | Citation Text:  <S sid ="40" ssid = "11">The principal work on segmentation has focused either on identifying words in phonetic streams (Saffran, et.</S><S sid ="41" ssid = "12">al, 1996; Brent, 1996; de Marcken, 1996) or on tokenizing Asian and Indian languages that do not normally include word delimiters in their orthography (Sproat, et al, 1996; Ponte and Croft 1996; Shimohata, 1997; Teahan, et al., 2000; and many others).</S> | Reference Offset:  ['20','33'] | Reference Text:  <S sid ="20" ssid = "20">Most languages that use Roman, Greek, Cyrillic, Armenian, or Semitic scripts, and many that use Indian-derived scripts, mark orthographic word boundaries; however, languages written in a Chinese-derived writÂ­ ing system, including Chinese and Japanese, as well as Indian-derived writing systems of languages like Thai, do not delimit orthographic words.1 Put another way, written Chinese simply lacks orthographic words.</S><S sid ="33" ssid = "33">Thus, if one wants to segment words-for any purpose-from Chinese sentences, one faces a more difficult task than one does in English since one cannot use spacing as a guide.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel |


Citance Number: 48 | Reference Article:  J96-3004.xml | Citing Article:  W02-1117.xml | Citation Marker Offset:  ['13'] | Citation Marker:  Sproat et al. 1996 | Citation Offset:  ['13'] | Citation Text:  <S sid ="13" ssid = "13">For examples: these words should be obtained: The ambiguous string is .There are some methods to resolve this problem: the one is the method forward maximum matching, backward maximum matching and minimum matching are used to find out the possible word strings from the character string [Guo 1997; Sproat et al. 1996; Gu and Mao 1994; Li et al. 1991; Wang et al. 1991b; Wang et al. 1990].</S> | Reference Offset:  ['108','109'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with segÂ­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S sid ="109" ssid = "47">This method, one instance of which we term the &quot;greedy algorithm&quot; in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin­ ning) of the sentence is reached.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 49 | Reference Article:  J96-3004.xml | Citing Article:  W02-1808.xml | Citation Marker Offset:  ['5'] | Citation Marker:  1996 | Citation Offset:  ['5'] | Citation Text:  <S sid ="5" ssid = "5">Statistical approaches involve language mod els mostly finite-state ones trained on some large-scale corpora as showed in Fan and Tsai (1988) Chang et al (1991) Chiang et al (1992) Sproat et al (1996)</S> | Reference Offset:  ['65','168','169','170'] | Reference Text:  <S sid ="65" ssid = "3">In this paper we present a stochastic finite-state model for segmenting Chinese text into words</S><S sid ="168" ssid = "32">Word frequencies are estimated by a re-estimation procedure that involves apply­ ing the segmentation algorithm presented here to a corpus of 20 million words,8 using 8 Our training corpus was drawn from a larger corpus of mixed-genre text consisting mostly of.</S><S sid ="169" ssid = "33">newspaper material, but also including kungfu fiction, Buddhist tracts, and scientific material.</S><S sid ="170" ssid = "34">This larger corpus was kindly provided to us by United Informatics Inc.,</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 50 | Reference Article:  J96-3004.xml | Citing Article:  W03-1025.xml | Citation Marker Offset:  ['17'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['17'] | Citation Text:  <S sid ="17" ssid = "17">There are multiple studies (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) showing that the agreement between two (untrained) native speakers is about upper to lower</S> | Reference Offset:  ['325'] | Reference Text:  <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 51 | Reference Article:  J96-3004.xml | Citing Article:  W03-1025.xml | Citation Marker Offset:  ['180'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['180'] | Citation Text:  <S sid ="180" ssid = "4">Chinese word segmentation is a well-known problem that has been studied extensively (Wu and Fung, 1994; Sproat et al., 1996; Luo and Roukos, 1996) and it is known that human agreement is relatively low.</S> | Reference Offset:  ['0','325'] | Reference Text:  <S sid ="0">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S><S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 52 | Reference Article:  J96-3004.xml | Citing Article:  W03-1025.xml | Citation Marker Offset:  ['187'] | Citation Marker:  1996 | Citation Offset:  ['186','187'] | Citation Text:  <S sid ="186" ssid = "10">Sproat et al.</S><S sid ="187" ssid = "11">(1996) employs stochastic finite state machines to find word boundaries.</S> | Reference Offset:  ['138','149','150'] | Reference Text:  <S sid ="138" ssid = "2">More formally, we start by representing the dictionary D as a Weighted Finite State Trans­ ducer (WFST) (Pereira, Riley, and Sproat 1994).</S><S sid ="149" ssid = "13">This FSA I can be segmented into words by composing Id(I) with D*, to form the WFST shown in Figure 2(c), then selecting the best path through this WFST to produce the WFST in Figure 2(d).</S><S sid ="150" ssid = "14">This WFST represents the segmentation of the text into the words AB and CD, word boundaries being marked by arcs mapping between f and part-of-speech labels.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 53 | Reference Article:  J96-3004.xml | Citing Article:  W03-1728.xml | Citation Marker Offset:  ['3'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['3'] | Citation Text:  <S sid ="3" ssid = "3">This may sound simple enough but in reality identifying words in Chinese is a nontrivial problem that has drawn a large body of research in the Chinese language processing community (Fan and Tsai, 1988; Gan et al., 1996; Sproat et al., 1996; Wu, 2003; Xue, 2003).</S> | Reference Offset:  ['65'] | Reference Text:  <S sid ="65" ssid = "3">In this paper we present a stochastic finite-state model for segmenting Chinese text into words</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 54 | Reference Article:  J96-3004.xml | Citing Article:  W04-3236.xml | Citation Marker Offset:  ['157'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['157'] | Citation Text:  <S sid ="157" ssid = "35">Much previous research on Chinese language processing focused on word segmentation (Sproat et al., 1996; Teahan et al., 2000; Sproat and Emerson, 2003).</S> | Reference Offset:  ['0'] | Reference Text:  <S sid ="0">A Stochastic Finite-State Word-Segmentation Algorithm for Chinese</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 55 | Reference Article:  J96-3004.xml | Citing Article:  W05-0709.xml | Citation Marker Offset:  ['83'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['83'] | Citation Text:  <S sid ="83" ssid = "9">In addition to the model based upon a dictionary of stems and words, we also experimented with models based upon character n-grams, similar to those used for Chinese segmentation (Sproat et al., 1996).</S> | Reference Offset:  ['419'] | Reference Text:  <S sid ="419" ssid = "22">The method reported in this paper makes use solely of unigram probabilities, and is therefore a zeroeth-order model: the cost of a particular segmentation is estimated as the sum of the costs of the individual words in the segmentation.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 56 | Reference Article:  J96-3004.xml | Citing Article:  W06-1630.xml | Citation Marker Offset:  ['118'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['118'] | Citation Text:  <S sid ="118" ssid = "13">The words were stemmed all possible ways using simple hand-developed affix lists: for example, given a Hindi word c1 c2 c3 , if both c3 and c2 c3 are in our suffix and ending list, then this single word generates three possible candidates: c1 , c1 c2 , and c1c2 c3 . In contrast, Chinese candidates were extracted using a list of 495 characters that are frequently used for foreign names (Sproat et al., 1996).</S> | Reference Offset:  ['284'] | Reference Text:  <S sid ="284" ssid = "148">As a first step towards modeling transliterated names, we have collected all hanzi occurring more than once in the roughly 750 foreign names in our dictionary, and we estimate the probabilÂ­ ity of occurrence of each hanzi in a transliteration (pTN(hanzi;)) using the maximum likelihood estimate.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 57 | Reference Article:  J96-3004.xml | Citing Article:  W10-3212.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "2">In such languages, words are segmented using more advanced techniques, which can be categorized into three methods: (i) Dictionary/lexicon based approaches (ii) Linguistic knowledge based approaches (iii) Machine learning based approaches/statistical approaches (Haruechaiyasak et al., 2008) Longest matching (Poowarawan, 1986; Richard Sproat, 1996) and maximum matching (Sproat et al., 1996; Haizhou &amp; Baosheng, 1998) are examples of lexicon based approaches.</S> | Reference Offset:  ['305'] | Reference Text:  <S sid ="305" ssid = "14">A greedy algorithm (or maximum-matching algorithm), GR: proceed through the sentence, taking the longest match with a dictionary entry at each point.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 58 | Reference Article:  J96-3004.xml | Citing Article:  W10-3708.xml | Citation Marker Offset:  ['16'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['16'] | Citation Text:  <S sid ="16" ssid = "16">Experiments have shown only about 75% agreement among native speakers regarding the correct word segmentation (Sproat et al., 1996).</S> | Reference Offset:  ['325'] | Reference Text:  <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 59 | Reference Article:  J96-3004.xml | Citing Article:  W11-0823.xml | Citation Marker Offset:  ['174'] | Citation Marker:  1996 | Citation Offset:  ['174'] | Citation Text:  <S sid ="174" ssid = "7">There are a number of popular dictionary-based solutions such as Cha Sen10 and Juman.11 Sproat et al (1996) proposed an alternative solution based on distributional statistics such as mutual information.</S> | Reference Offset:  ['92','93','103'] | Reference Text:  <S sid ="92" ssid = "30">In that work, mutual information was used to decide whether to group adjacent hanzi into two-hanzi words.</S><S sid ="93" ssid = "31">Mutual information was shown to be useful in the segmentation task given that one does not have a dictionary.</S><S sid ="103" ssid = "41">Church and Hanks [1989]), and we have used lists of character pairs ranked by mutual information to expand our own dictionary.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 60 | Reference Article:  J96-3004.xml | Citing Article:  W12-1011.xml | Citation Marker Offset:  ['41'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['41'] | Citation Text:  <S sid ="41" ssid = "5">Indeed, even native speakers can agree on word boundaries in modern Chinese only about 76% of the time (Sproat et al., 1996).</S> | Reference Offset:  ['325'] | Reference Text:  <S sid ="325" ssid = "34">The average agreement among the human judges is .76, and the average agreement between ST and the humans is .75, or about 99% of the interhuman agreement</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 61 | Reference Article:  J96-3004.xml | Citing Article:  W12-1011.xml | Citation Marker Offset:  ['204'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['204'] | Citation Text:  <S sid ="204" ssid = "9">No comparable figure has been reported for classical Chinese word segmentation, but this rate compares favorably with past attempts for modern Chinese, e.g., an average of 76% inter- human agreement rate in (Sproat et al., 1996).</S> | Reference Offset:  ['325'] | Reference Text:  <S sid ="325" ssid = "34">The average agreement among the human judges is .76</S> | Discourse Facet:  Results_Citation | Annotator:  Ankita Patel |


Citance Number: 62 | Reference Article:  J96-3004.xml | Citing Article:  W12-2303.xml | Citation Marker Offset:  ['12'] | Citation Marker:  1996 | Citation Offset:  ['11','12'] | Citation Text:  <S sid ="11" ssid = "11">An extension of this approach is the dynamic programming search of the most probable word combination on the word lattice, such as Ma (1996) and Sproat et al.</S><S sid ="12" ssid = "12">(1996), which utilize information such as word frequency statistics in a corpus to build the model and are less efficient but more accurate.</S> | Reference Offset:  ['158'] | Reference Text:  <S sid ="158" ssid = "22">The cost is computed as follows, where N is the corpus size and f is the frequency: (1) Besides actual words from the base dictionary, the lexicon contains all hanzi in the Big 5 Chinese code/ with their pronunciation(s), plus entries for other characters that can be found in Chinese text, such as Roman letters, numerals, and special symbols.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 63 | Reference Article:  J96-3004.xml | Citing Article:  W12-2303.xml | Citation Marker Offset:  ['157'] | Citation Marker:  1996 | Citation Offset:  ['156','157'] | Citation Text:  <S sid ="155" ssid = "30">There are many other OOV recognition methods proposed in literature before the rise of machine learning in the field.</S><S sid ="156" ssid = "31">For example, the Sproat et al.</S><S sid ="157" ssid = "32">(1996) system can successfully recognize OOVs of strong patterns, such as Chinese personal names, transliterations, using finite-state techniques.</S> | Reference Offset:  ['398','399'] | Reference Text:  <S sid ="398" ssid = "1">In this paper we have argued that Chinese word segmentation can be modeled efÂ­ fectively using weighted finite-state transducers.</S><S sid ="399" ssid = "2">This architecture provides a uniform framework in which it is easy to incorporate not only listed dictionary entries but also morphological derivatives, and models for personal names and foreign names in transliteration.</S> | Discourse Facet:  Implication_Citation | Annotator:  Ankita Patel |


Citance Number: 64 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['26'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['26'] | Citation Text:  <S sid ="26" ssid = "26">One of the major problems in unsupervised word segmentation is the treatment of unseen word [Sproat et al., 1996] wrote lexical rules for each productive morphological process, such as plur noun formation, Chinese personal names, and transliterations of foreign words.</S> | Reference Offset:  ['67','68','69'] | Reference Text:  <S sid ="67" ssid = "5">The model incorporates various recent techniques for incorporating and manipulating linguistic knowledge using finite-state transducers.</S><S sid ="68" ssid = "6">It also incorporates the Good-Turing method (Baayen 1989; Church and Gale 1991) in estimating the likelihoods of previously unseen con­ structions, including morphological derivatives and personal names.</S><S sid ="69" ssid = "7">We will evaluate various specific aspects of the segmentation, as well as the overall segmentation per­ formance.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 65 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['69'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['69'] | Citation Text:  <S sid ="69" ssid = "5">We used a simple greedy algorithm described in [Sproat et al., 1996].</S> | Reference Offset:  ['108','109'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S sid ="109" ssid = "47">This method, one instance of which we term the &quot;greedy algorithm&quot; in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin­ ning) of the sentence is reached.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 66 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['73'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['73'] | Citation Text:  <S sid ="73" ssid = "9">[Sproat et al., 1996] also proposed another method to estimate a set of initial word frequencies without segmenting the corpus.</S> | Reference Offset:  ['190','191'] | Reference Text:  <S sid ="190" ssid = "54">The morphological anal­ysis itself can be handled using well-known techniques from finite-state morphol 9 The initial estimates are derived from the frequencies in the corpus of the strings of hanzi making up.</S><S sid ="191" ssid = "55">each word in the lexicon whether or not each string is actually an instance of the word in question.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 67 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['86'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['86'] | Citation Text:  <S sid ="86" ssid = "22">The problem of the longest match string frequency method is that if a word W1 is a substring of other word w2 and if wl always appears as a substring of w2 in the training text, just like m 1Although (Sproat et al., 1996] calls it &quot;maximum matching&quot;, we call this method &quot;longest match&quot; according to a review on Chinese word segmentation [Wu and Tseng, 1993) and the literal translation of the Japanese name of the method Hi!:.</S> | Reference Offset:  ['108','109'] | Reference Text:  <S sid ="108" ssid = "46">The most popular approach to dealing with seg­ mentation ambiguities is the maximum matching method, possibly augmented with further heuristics.</S><S sid ="109" ssid = "47">This method, one instance of which we term the &quot;greedy algorithm&quot; in our evaluation of our own system in Section 5, involves starting at the beginning (or end) of the sentence, finding the longest word starting (ending) at that point, and then repeating the process starting at the next (previous) hanzi until the end (begin­ ning) of the sentence is reached.</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |


Citance Number: 68 | Reference Article:  J96-3004.xml | Citing Article:  W97-0120.xml | Citation Marker Offset:  ['121'] | Citation Marker:  Sproat et al., 1996 | Citation Offset: ['121'] | Citation Text:  <S sid ="121" ssid = "15">Word Segmentation accuracy is expressed in terms of recall and precision as is done for bracketing of partial parses [Nagata, 1994, Sproat et al., 1996).</S> | Reference Offset:  ['142','143','356'] | Reference Text:  <S sid ="142" ssid = "6">We can 5 Recall that precision is defined to be the number of correct hits divided by the total number of items.</S><S sid ="143" ssid = "7">selected; and that recall is defined to be the number of correct hits divided by the number of items that should have been selected.</S><S sid ="356" ssid = "65">The performance was 80.99% recall and 61.83% precision.</S> | Discourse Facet:  ['Method_Citation','Results_Citation'] | Annotator:  Ankita Patel |


Citance Number: 69 | Reference Article:  J96-3004.xml | Citing Article:  W97-0316.xml | Citation Marker Offset:  ['11'] | Citation Marker:  Sproat et al., 1996 | Citation Offset:  ['10','11'] | Citation Text:  <S sid ="10" ssid = "10">Automatic methods for correctly isolating words in a sentence -- a process called word segmentation -- is therefore an important and necessary first step to be taken before other analysis can begin.</S><S sid ="11" ssid = "11">Many researchers have proposed practical methods to resolve this problem such as (Nie et al., 1995, Wu and Tsang, 1995, Jin &amp; Chen, 1996, Ponte &amp; Croft, 1996, Sproat et al., 1996, Sun et al., 1997).</S> | Reference Offset:  ['65'] | Reference Text:  <S sid ="65" ssid = "3">In this paper we present a stochastic finite-state model for segmenting Chinese text into words</S> | Discourse Facet:  Method_Citation | Annotator:  Ankita Patel |