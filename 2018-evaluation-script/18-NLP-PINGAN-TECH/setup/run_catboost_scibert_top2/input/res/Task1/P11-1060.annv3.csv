Citance Number,Citation Marker,Citation Marker Offset,Citation Offset,Citation Text,Citation Text Clean,Citing Article,Discourse Facet,Reference Article,Reference Offset,Reference Text
1.0,2011,0,0,"Clarkeet al (2010) and Liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while Goldwasser et al (2011) presents work on unsupervised learning","Clarke et al (2010) and Liang et al (2011) describe approaches for learning semantic parsers from questions paired with database answers, while Goldwasser et al (2011) presents work on unsupervised learning",D11-1039,"Hypothesis_Citation,Implication_Citation",P11-1060,"'0','2'","<S sid=""0"" ssid=""0"">Learning Dependency-Based Compositional Semantics</S><S sid=""2"" ssid=""2"">In this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs.</S>"
2.0,2011,0,0,"In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance","In particular, Clarke et al (2010) and Liang et al (2011) proposed methods to learn from question answer pairs alone, which represents a significant advance",P13-1092,"Method_Citation,Aim_Citation,Results_Citation,Implication_Citation",P11-1060,"'2','3'","<S sid=""2"" ssid=""2"">In this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs.</S><S sid=""3"" ssid=""3"">In tackling this challenging learning problem, we introduce a new semantic representation which highlights a parallel between dependency syntax and efficient evaluation of logical forms.</S>"
3.0,2011,0,0,"To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation 1Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments","To handle syntax-semantics mismatch, GUSP introduces a novel dependency-based meaning representation. Clarke et al (2010) and Liang et al (2011) used the annotated logical forms to compute answers for their experiments",P13-1092,"Method_Citation,Hypothesis_Citation,Implication_Citation",P11-1060,"'117','6'","<S sid=""117"" ssid=""2"">In each dataset, each sentence x is annotated with a Prolog logical form, which we use only to evaluate and get an answer y.</S><S sid=""6"" ssid=""2"">Answering these types of complex questions compositionally involves first mapping the questions into logical forms (semantic parsing).</S>"
4.0,2011,0,0,"More recently, Liang et al (2011 )proposedDCS for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins","More recently, Liang et al (2011) proposed DCS for dependency-based compositional semantics, which represents a semantic parse as a tree with nodes representing database elements and operations, and edges representing relational joins",P13-1092,"Method_Citation,Hypothesis_Citation,Implication_Citation",P11-1060,"'45','0'","<S sid=""45"" ssid=""21"">The logical forms in DCS are called DCS trees, where nodes are labeled with predicates, and edges are labeled with relations.</S><S sid=""0"" ssid=""0"">Learning Dependency-Based Compositional Semantics</S>"
5.0,"Liang et al, 2011",0,0,"GUSP represents meaning by a semantic tree, which is similar to DCS (Liang et al, 2011)","GUSP represents meaning by a semantic tree, which is similar to DCS (Liang et al, 2011)",P13-1092,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P11-1060,"'21','35'","<S sid=""21"" ssid=""17"">The main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (DCS), which is both simple and expressive (Section 2).</S><S sid=""35"" ssid=""11"">Although a DCS tree is a logical form, note that it looks like a syntactic dependency tree with predicates in place of words.</S>"
6.0,2011,0,0,"Matuszek et al [2010], Liang et al [2011] and Chen and Mooney [2011] describe models that learn compositional semantics, but word meanings are symbolic structures rather than patterns of features in the external world","Matuszek et al [2010], Liang et al [2011] and Chen and Mooney [2011] describe models that learn compositional semantics, but word meanings are symbolic structures rather than patterns of features in the external world",W12-2802,"Hypothesis_Citation,Implication_Citation",P11-1060,"'0','2'","<S sid=""0"" ssid=""0"">Learning Dependency-Based Compositional Semantics</S><S sid=""2"" ssid=""2"">In this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs.</S>"
7.0,"Liang et al, 2011",0,0,"It is well-studied in NLP, and a wide variety of methods have been proposed to tackle it ,e.g. rule-based (Popescu et al, 2003), super vised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al, 2011)","It is well-studied in NLP, and a wide variety of methods have been proposed to tackle it ,e.g. rule-based (Popescu et al, 2003), super vised (Zelle, 1995), unsupervised (Goldwasser et al., 2011), and response-based (Liang et al, 2011)",P13-2009,"Method_Citation,Hypothesis_Citation,Aim_Citation,Implication_Citation",P11-1060,"'3','163'","<S sid=""3"" ssid=""3"">In tackling this challenging learning problem, we introduce a new semantic representation which highlights a parallel between dependency syntax and efficient evaluation of logical forms.</S><S sid=""163"" ssid=""48"">Feedback from the context; for example, the lexical entry for borders world has been used to guide both syntactic parsing is S\NP/NP : Ay.Ax.border(x, y), which means (Schuler, 2003) and semantic parsing (Popescu et borders looks right for the first argument and left al., 2003; Clarke et al., 2010).</S>"
8.0,Liangetal2011,0,0,"One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Liangetal2011) or even a binary correct/incorrect signal (Clarke et al2010)","One line of work eliminates the need for an annotated logical form, instead using only the correct answer for a database query (Lianget al 2011) or even a binary correct/incorrect signal (Clarke et al2010)",D12-1069,"Method_Citation,Hypothesis_Citation,Implication_Citation",P11-1060,"'6','117'","<S sid=""6"" ssid=""2"">Answering these types of complex questions compositionally involves first mapping the questions into logical forms (semantic parsing).</S><S sid=""117"" ssid=""2"">In each dataset, each sentence x is annotated with a Prolog logical form, which we use only to evaluate and get an answer y.</S>"
9.0,2011,0,0,"For example, Liang et al (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form","For example, Liang et al (2011) constructs a latent parse similar in structure to a dependency grammar, but representing a logical form",N12-1049,"Method_Citation,Hypothesis_Citation,Implication_Citation",P11-1060,"'6','22'","<S sid=""6"" ssid=""2"">Answering these types of complex questions compositionally involves first mapping the questions into logical forms (semantic parsing).</S><S sid=""22"" ssid=""18"">The logical forms in this framework are trees, which is desirable for two reasons: (i) they parallel syntactic dependency trees, which facilitates parsing and learning; and (ii) evaluating them to obtain the answer is computationally efficient.</S>"
10.0,2011,0,0,Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers,Clarke et al (2010) and Liang et al (2011) trained systems on question and answer pairs by automatically finding semantic interpretations of the questions that would generate the correct answers,P12-1045,"Method_Citation,Aim_Citation,Results_Citation,Implication_Citation",P11-1060,"'2','6'","<S sid=""2"" ssid=""2"">In this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs.</S><S sid=""6"" ssid=""2"">Answering these types of complex questions compositionally involves first mapping the questions into logical forms (semantic parsing).</S>"
11.0,"Liang et al,2011",0,0,"Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al, 2011)","Dependency-based Compositional Semantics (DCS) provides an intuitive way to model semantics of questions, by using simple dependency-like trees (Liang et al, 2011)",P14-1008,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P11-1060,"'21','0'","<S sid=""21"" ssid=""17"">The main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (DCS), which is both simple and expressive (Section 2).</S><S sid=""0"" ssid=""0"">Learning Dependency-Based Compositional Semantics</S>"
12.0,"Liang et al, 2011",0,0,"DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al, 2011) (Figure 1)","DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees (Liang et al, 2011) (Figure 1)",P14-1008,"Results_Citation,Hypothesis_Citation,Implication_Citation,Method_Citation,Aim_Citation",P11-1060,"'21','0'","<S sid=""21"" ssid=""17"">The main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (DCS), which is both simple and expressive (Section 2).</S><S sid=""0"" ssid=""0"">Learning Dependency-Based Compositional Semantics</S>"
13.0,"Liang et al, 2011",0,0,"are explained in? 2.5. 5http: //nlp.stanford.edu/software/corenlp.shtml 6 In (Liang et al, 2011) DCS trees are learned from QApairs and database entries","In (Liang et al, 2011) DCS trees are learned from QA pairs and database entries",P14-1008,"Method_Citation,Aim_Citation,Results_Citation,Implication_Citation",P11-1060,"'2','167'","<S sid=""2"" ssid=""2"">In this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs.</S><S sid=""167"" ssid=""52"">In DCS, we start with lexical triggers, which are 6 Conclusion more basic than CCG lexical entries.</S>"
14.0,"Liang et al, 2011",0,0,"as in the sentence? Tropi cal storm Debby is blamed for death?, which is a tropical storm, is Debby, etc. Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al, 2011) of that variable","Technically, each germ in a DCS tree indicates a variable when the DCS tree is translated to a FOL formula, and the abstract denotation of the germ corresponds to the set of consistent values (Liang et al, 2011) of that variable",P14-1008,"Method_Citation,Hypothesis_Citation,Implication_Citation",P11-1060,"'42','85'","<S sid=""42"" ssid=""18"">The denotation JzKw (z evaluated on w) is the set of consistent values of the root node (see Figure 2 for an example).</S><S sid=""85"" ssid=""61"">Extraction allows us to return the set of consistent values of a marked non-root node.</S>"
15.0,2011,0,0,Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available,Clarke et al (2010) and Liang et al (2011) replace semantic annotations in the training set with target answers which are more easily available,D11-1140,"Method_Citation,Aim_Citation,Results_Citation,Implication_Citation",P11-1060,"'2','3'","<S sid=""2"" ssid=""2"">In this paper, we learn to map questions to answers via latent logical forms, which are induced automatically from question-answer pairs.</S><S sid=""3"" ssid=""3"">In tackling this challenging learning problem, we introduce a new semantic representation which highlights a parallel between dependency syntax and efficient evaluation of logical forms.</S>"
16.0,"Liang et al, 2011",0,0,"and Collins, 2005, 2007),? -WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al, 2010) systems and DCS (Liang et al, 2011)","WASP (Wong and Mooney, 2007), UBL (Kwiatkowski et al, 2010) systems and DCS (Liang et al, 2011)",D11-1140,"Method_Citation,Hypothesis_Citation,Implication_Citation",P11-1060,"'149','21'","<S sid=""149"" ssid=""34"">Think of DCS as a higher-level Our system learns lexical associations between programming language tailored to natural language, words and predicates.</S><S sid=""21"" ssid=""17"">The main technical contribution of this work is a new semantic representation, dependency-based compositional semantics (DCS), which is both simple and expressive (Section 2).</S>"
17.0,2011,0,0,"In general, every plural NPpotentially introduces an implicit universal, ranging 1For example, Liang et al (2011) in their state-of-the-art statistical semantic parser within the domain of natural language queries to databases, explicitly devise quantifier scoping in the semantic model","For example, Liang et al (2011) in their state-of-the-art statistical semantic parser within the domain of natural language queries to databases, explicitly devise quantifier scoping in the semantic model",P13-1007,"Hypothesis_Citation,Implication_Citation",P11-1060,"'172','0'","<S sid=""172"" ssid=""57"">Free from the burden It also allows us to easily add new lexical triggers of annotating logical forms, we hope to use our without becoming mired in the semantic formalism. techniques in developing even more accurate and Quantifiers and superlatives significantly compli- broader-coverage language understanding systems. cate scoping in lambda calculus, and often type rais- Acknowledgments We thank Luke Zettlemoyer ing needs to be employed.</S><S sid=""0"" ssid=""0"">Learning Dependency-Based Compositional Semantics</S>"
18.0,2011,0,0,"DD-ADMM may be useful in other frameworks involving logical constraints, such as the models for compositional semantics presented by Liang et al (2011)","DD-ADMM may be useful in other frameworks involving logical constraints, such as the models for compositional semantics presented by Liang et al (2011)",D11-1022,"Method_Citation,Hypothesis_Citation,Implication_Citation",P11-1060,"'6','22'","<S sid=""6"" ssid=""2"">Answering these types of complex questions compositionally involves first mapping the questions into logical forms (semantic parsing).</S><S sid=""22"" ssid=""18"">The logical forms in this framework are trees, which is desirable for two reasons: (i) they parallel syntactic dependency trees, which facilitates parsing and learning; and (ii) evaluating them to obtain the answer is computationally efficient.</S>"
19.0,2011,0,0,"In fact, for any CFG G, it 1See Liang et al (2011) for work in representing lambda calculus expressions with trees","In fact, for any CFG G, it 1See Liang et al (2011) for work in representing lambda calculus expressions with trees",P12-1051,"Method_Citation,Hypothesis_Citation,Implication_Citation",P11-1060,"'48','22'","<S sid=""48"" ssid=""24"">In addition, trees enable efficient computation, thereby establishing a new connection between dependency syntax and efficient semantic evaluation.</S><S sid=""22"" ssid=""18"">The logical forms in this framework are trees, which is desirable for two reasons: (i) they parallel syntactic dependency trees, which facilitates parsing and learning; and (ii) evaluating them to obtain the answer is computationally efficient.</S>"
